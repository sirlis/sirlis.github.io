[
  
  {
    "title": "模式识别（无监督分类器）",
    "url": "/posts/Pattern-Recognition-Unsupervised-Classifier/",
    "categories": "Academic, Knowledge",
    "tags": "pattern recognition",
    "date": "2025-05-12 15:10:49 +0800",
    





    
    "snippet": "本文介绍了无监督分类器的设计原理和方法。不同于前面章节介绍的分类器，无监督分类器旨在没有类别标签的情况下完成样本的分类。由于样本的类别标签位置，无监督分类器具有一定的学习能力，因此相关分类方法又被称为无监督学习。聚类（Clustering）分析是最典型的无监督学习方法。  1. 聚类          1.1. 相似性测度                  1.1.1. 闵可夫斯基距离   ...",
    "content": "本文介绍了无监督分类器的设计原理和方法。不同于前面章节介绍的分类器，无监督分类器旨在没有类别标签的情况下完成样本的分类。由于样本的类别标签位置，无监督分类器具有一定的学习能力，因此相关分类方法又被称为无监督学习。聚类（Clustering）分析是最典型的无监督学习方法。  1. 聚类          1.1. 相似性测度                  1.1.1. 闵可夫斯基距离                          1.1.1.1. 曼哈顿距离              1.1.1.2. 欧几里得距离              1.1.1.3. 切比雪夫距离                                1.1.2. 马氏距离          1.1.3. 相关系数                          1.1.3.1. 角度相关系数              1.1.3.2. 皮尔逊相关系数                                          1.2. 聚类准则函数                  1.2.1. 误差平方和准则          1.2.2. 离散度准则          1.2.3. SD 有效性函数                    1.3. 聚类方法                  1.3.1. 基于层次的聚类                          1.3.1.1. 层次聚类方向              1.3.1.2. 测度计算方法              1.3.1.3. 小结                                1.3.2. 基于划分的聚类                          1.3.2.1. K-均值聚类（K-means）              1.3.2.2. K-Means++ 算法              1.3.2.3. 迭代自组织数据分析方法（ISODATA）              1.3.2.4. 模糊 C-均值 聚类              1.3.2.5. 小结                                1.3.3. 基于密度的聚类                          1.3.3.1. DBSCAN              1.3.3.2. 小结                                          1. 聚类聚类是一种无监督学习方法，其在没有预先指定可能的类别，事先不知道所考虑问题应该分为几类，更不知道观测到的个体的具体分类的情况下，寻找样本数据潜在的自然分组结构和内在规律。聚类的目标是将样本集中的样本划分为不同的类别或簇，使得同一类别内的样本具有较高的相似度，而不同类别样本之间具有较高的相异性。在执行聚类时，针对包含大量未知类别样本的样本集，采用距离或相似性度量来计算样本之间的相似性，利用聚类算法根据计算的相似性把样本集划分为若干子集或簇，并使某种表示聚类质量的准则函数达到最优。因此  相似性测度：衡量两个数据（样本）之间的相似程度；  聚类准则函数：用于指导聚类算法的优化过程，或衡量不同聚类结果的优劣；  聚类算法称为聚类的三要素。1.1. 相似性测度「相似性测度」又被称为「相似性度量」或直接简称为「相似度」，一种典型的相似性度量方式是根据不同样本在特征空间中的距离，利用「同类样本相互靠近、异类样本相互远离」的策略进行聚类。假设两个样本的特征向量为 $\\boldsymbol{x}^{(1)},\\boldsymbol{x}^{(2)}\\in\\mathbb{R}^d$，可分别定义如下相似度。1.1.1. 闵可夫斯基距离闵可夫斯基距离（Minkowski distance，明式距离）是指两个样本在特征空间中的一类距离的统称，定义如下\\[M(\\boldsymbol{x}^{(1)}, \\boldsymbol{x}^{(2)}) = \\left(\\sum_{i=1}^d |x^{(1)}_{i} - x^{(2)}_{i}|^p\\right)^\\frac{1}{p}\\quad p\\geq 1\\]1.1.1.1. 曼哈顿距离当明式距离中的参数 $p=1$ 时，又称为曼哈顿距离（Manhattan distance，曼哈顿距离）或 $L_1$ 范数：\\[M(\\boldsymbol{x}^{(1)}, \\boldsymbol{x}^{(2)}) = \\sum_{i=1}^d |x^{(1)}_{i} - x^{(2)}_{i}| = \\Vert\\boldsymbol{x}^{(1)} - \\boldsymbol{x}^{(2)}\\Vert_1\\]曼哈顿距离的命名原因是从规划为方型建筑区块的城市（如曼哈顿）间，最短的行车路径而来。对于一个具有正南正北、正东正西方向规则布局的城镇街道，从一点到达另一点的距离正是在南北方向上旅行的距离加上在东西方向上旅行的距离，因此，曼哈顿距离又称为出租车距离。在早期的计算机图形学中，屏幕是由像素构成，是整数，点的坐标也一般是整数。当计算两个像素点之间的距离时，如果直接使用AB的欧氏距离，则必须要进行浮点运算，但浮点运算很昂贵，很慢而且有误差。如果使用曼哈顿距离，则只要计算加减法即可，这就大大提高了运算速度，而且不管累计运算多少次，都不会有误差。思考：二维特征空间中，采用曼哈顿距离定义「圆」的图案是什么？1.1.1.2. 欧几里得距离当明式距离中的参数 $p=2$ 时，又称为欧几里得距离（Euclidean distance，欧氏距离）或 $L_2$ 范数：\\[D = \\sqrt{\\sum_{i=1}^d (x^{(1)}_{i} - x^{(2)}_{i})^2} = \\Vert\\boldsymbol{x}^{(1)} - \\boldsymbol{x}^{(2)}\\Vert_2\\]1.1.1.3. 切比雪夫距离当明式距离中的参数 $p=\\infty$ 时，又称为切比雪夫距离（Chebyshev distance）或 $L_\\infty$ 范数：\\[D = \\max_{i=1,\\ldots,d} |x^{(1)}_{i} - x^{(2)}_{i}| = \\Vert\\boldsymbol{x}^{(1)} - \\boldsymbol{x}^{(2)}\\Vert_\\infty\\]证明如下：假设两个样本的特征向量各维度的绝对差为 $d_i = \\vert x^{(1)}{i} - x^{(2)}{i} \\vert$，闵科夫斯基距离写成如下形式：\\[D = \\left(\\sum_{i=1}^d d_i^p\\right)^\\frac{1}{p}\\]假设绝对差的最大值为 $d_{\\max} = \\max_i d_i$，将其提到求和符号外面，有\\[D = \\left(\\sum_{i=1}^d d_i^p\\right)^\\frac{1}{p} = d_{\\max} \\left(\\sum_{i=1}^d \\left(\\frac{d_i}{d_{\\max}}\\right)^p\\right)^\\frac{1}{p}\\]注意到，对于所有 $i$ 有 $\\frac{d_i}{d_{\\max}} \\leq 1$，因此当 $p\\to \\infty$ 时，有\\[\\begin{aligned}  \\left(\\frac{d_i}{d_{\\max}}\\right)^p\\to 0,\\quad d_i &lt; d_{\\max}\\\\  \\left(\\frac{d_i}{d_{\\max}}\\right)^p\\to 1,\\quad d_i = d_{\\max}\\end{aligned}\\]因此，求和项中只有最大项会保留（注意最大项可能不止一个！），假设最大项有 $k$ 个，则\\[\\sum_{i=1}^d \\left(\\frac{d_i}{d_{\\max}}\\right)^p \\to k\\]则\\[D = d_{\\max}\\cdot k^{1/p}\\]对于有限常数 $k$，$p\\to \\infty$ 时，有 $k^{1/p}\\to 1$，得证。1.1.2. 马氏距离马氏距离（Mahalanobis Distance）是由马哈拉诺比斯（P. C. Mahalanobis）提出的，表示数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法。马氏距离也可以定义为两个服从同一分布并且其协方差矩阵为 $\\Sigma$ 的随机变量之间的差异程度。\\[M = \\left( (\\boldsymbol{x}^{(1)}-\\boldsymbol{x}^{(2)})^\\top\\Sigma^{-1}(\\boldsymbol{x}^{(1)}-\\boldsymbol{x}^{(2)}) \\right)^{1/2}=\\sqrt{\\sum_{i=1}^d \\frac{(x^{(1)}_{i} - x^{(2)}_{i})^2}{\\sigma_i^2}}\\]如果协方差矩阵为单位矩阵，那么马氏距离就简化为欧氏距离；如果协方差矩阵为对角阵，各特征完全相互独立。马氏距离可以克服欧氏距离的一些缺点。欧氏距离将样品的不同特征之间的差别独立且等同看待，这一点有时不能满足实际要求，如身高和体重是有相关性的。马氏距离通过除以方差矩阵，将各个分量之间的方差除掉了，消除了量纲影响，如下图所示。1.1.3. 相关系数「距离」衡量的是两个数据点在空间中的绝对位置差异，强调的是“远近”关系。而相关系数衡量的是两个变量之间的线性相关程度，强调的是“变化趋势”的一致性。相比于距离，相关系数从另一个角度来衡量两个变量之间的关系。1.1.3.1. 角度相关系数角度相关系数表征两个向量的夹角余弦，又被称为余弦相似度。两个向量越相似（正相关），该值越接近 $1$；无线性关系，值等于零；越不相似（越负相关），该值越接近 $-1$。\\[\\cos(\\boldsymbol{x}^{(1)},\\boldsymbol{x}^{(2)}) = \\frac{\\boldsymbol{x}^{(1)}{}^\\top \\boldsymbol{x}^{(2)}}{\\Vert\\boldsymbol{x}^{(1)}\\Vert_2\\Vert\\boldsymbol{x}^{(2)}\\Vert_2}\\]余弦相似度只比较向量的夹角，与模长无关。例：文本相似性中，文档长度不影响结果。1.1.3.2. 皮尔逊相关系数皮尔逊相关系数（Pearson’s $r$）用于衡量两个连续变量之间的线性相关性，取值范围为 $[−1,1]$ 。\\[\\begin{aligned}r &amp;= \\frac{\\text{Cov}(\\boldsymbol{x}^{(1)},\\boldsymbol{x}^{(2)})}{\\sigma_{\\boldsymbol{x}^{(1)}} \\sigma_{\\boldsymbol{x}^{(2)}}} = \\frac{    (\\boldsymbol{x}^{(1)} - \\bar{\\boldsymbol{x}}^{(1)})^{\\top}    (\\boldsymbol{x}^{(2)} - \\bar{\\boldsymbol{x}}^{(2)})}{    \\|\\boldsymbol{x}^{(1)} - \\bar{\\boldsymbol{x}}^{(1)}\\|     \\cdot     \\|\\boldsymbol{x}^{(2)} - \\bar{\\boldsymbol{x}}^{(2)}\\|}\\\\&amp;= \\frac{\\sum_{i=1}^n (x^{(1)}_i - \\bar{x}^{(1)})(x^{(2)}_i - \\bar{x}^{(2)})}{\\sqrt{\\sum_{i=1}^n (x^{(1)}_i - \\bar{x}^{(1)})^2} \\sqrt{\\sum_{i=1}^n (x^{(2)}_i - \\bar{x}^{(2)})^2}}\\\\\\end{aligned}\\]皮尔逊相关系数类似余弦相似度，但数据已中心化（均值归一化）。1.2. 聚类准则函数聚类的准则函数用来评价聚类效果，比如采用不同的聚类方法可以计算相应的准则函数，取准则函数较优的聚类方法为最优聚类方法。又比如相同的聚类方法可以采用不同的算法参数（如 K-均值 聚类的初始类别数），然后计算相应的准则函数，取准则函数较优的算法参数为最优算法参数。1.2.1. 误差平方和准则误差平方和（Sum of Squared Errors, SSE）是聚类分析中最常用的准则函数之一，用于衡量类内数据的紧致性。其核心思想是：最小化每个数据点与其所属簇中心（质心）的距离的平方和。一般而言，这里的距离使用的是「欧几里得距离」。假设将样本划分为 $k$ 个簇，每个簇的质心（均值）为 $\\boldsymbol{\\mu}_i$，则 SSE 定义为：\\[SSE = \\sum_{i=1}^k \\sum_{x\\in w_i} \\Vert x - \\boldsymbol{\\mu}_i\\Vert^2\\]一个好的聚类方法应该能使每一个簇中的所有向量与其均值向量的 “误差” 的平方和 最小。使得误差平方和最小的聚类也被称为最小方差聚类。该方法的优缺点如下：优点：  计算简单：仅需计算欧氏距离的平方和，易于实现和优化；  可解释性强：直接反映类内数据的聚集程度，值越小说明簇内数据越紧密；  适用于凸形簇：对球形或凸形分布的数据聚类效果良好；缺点：  适用性有限：对于非凸形状的分布，聚类效果不好；  对异常值敏感：平方项会放大离群点的影响，导致质心偏移（可改用绝对误差或中位数）；  依赖初始质心：聚类结果与初始质心位置有关，随机初始化可能导致局部最优解；  需要预先指定簇数：聚类结果与簇数有关，需要预先指定。1.2.2. 离散度准则离散度准则采用离散度矩阵来刻画。离散度矩阵不仅反映同类样本的聚合程度，而且也反映不同类之间的分离程度，因此可以对聚类的质量进行全面的描述和评价。假设聚类为 $k$ 类，类内离散度矩阵和类间离散度矩阵可参考 模式识别（LDA和PCA） - 多分类LDA 定义如下：类内离散度矩阵：\\[\\boldsymbol{S}_w = \\sum_{i=1}^k \\boldsymbol{S}_{wi}=\\sum_{i=1}^k \\sum_{\\boldsymbol{x}\\in w_i}(\\boldsymbol{x}-\\boldsymbol{\\mu}_i)(\\boldsymbol{x}-\\boldsymbol{\\mu}_i)^\\top\\]类间离散度矩阵，为度量每类均值点相对于样本中心的散列情况，并用每类样本个数进行加权，即\\[\\boldsymbol{S}_b= \\sum_{i=1}^k N_i(\\boldsymbol{\\mu}_i-\\boldsymbol{\\mu})(\\boldsymbol{\\mu}_i-\\boldsymbol{\\mu})^\\top\\]定义总离散度矩阵为\\[\\boldsymbol{S}_t = \\boldsymbol{S}_w + \\boldsymbol{S}_b = \\sum_{i=1}^C \\sum_{\\boldsymbol{x}\\in w_i}(\\boldsymbol{x}-\\boldsymbol{\\mu})(\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top\\]上述定义式可以通过展开后分析（交叉项为零）证明。总离散度矩阵反映数据整体的变异性，是类内和类间离散的总和。为了更准确地度量类内离散度和类间离散度，可以引入一个标量来衡量离散度矩阵的“大小”———矩阵的迹和矩阵的行列式。      离散度矩阵迹准则    如果单独使用类内离散度矩阵的迹，注意到这与「误差平方和准则」完全一致\\[\\min \\; \\text{tr}\\boldsymbol{S}_w = \\sum_{i=1}^C \\sum_{\\boldsymbol{x}_{ij}\\in w_i}\\Vert\\boldsymbol{x}_{ij}-\\boldsymbol{\\mu}_i\\Vert^2\\]    当然也可以单独使用类间离散度矩阵的迹，即\\[\\min \\; \\text{tr}\\boldsymbol{S}_b = \\sum_{i=1}^C N_i\\Vert\\boldsymbol{\\mu}_i-\\boldsymbol{\\mu}\\Vert^2\\]    还可以同时考虑类内和类间离散度矩阵，设计迹准则\\[\\max \\; \\text{tr}(\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b)\\]    该准则与 LDA 的优化目标函数\\[\\max \\; J(\\boldsymbol{w}) = \\frac{\\boldsymbol{w}^\\top\\boldsymbol{S}_b\\boldsymbol{w}}{\\boldsymbol{w}^\\top\\boldsymbol{S}_w\\boldsymbol{w}}\\]    等价，因为 LDA 的优化问题可转化为求矩阵 $\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b$ 的特征值 $\\lambda$ 和特征向量 $\\boldsymbol{w}^{\\star}$。对于二分类 LDA 问题，最佳投影方向是矩阵 $\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b$ 的最大特征值对应的特征向量。对于多分类 LDA 问题，最佳投影矩阵的列是 $\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b$ 的前 $d$ 个最大特征值对应的特征向量。    而根据迹的定义有\\[\\text{tr}(\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b) = \\sum_{i=1}^d \\lambda_i\\]    当 LDA 目标函数最优（最大）时，前 $d$ 个最大特征值的和自然也最大。        离散度矩阵行列式准则  与离散度矩阵迹准则类似，可以采用行列式设计准则函数，如\\[\\max \\; \\vert \\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b \\vert\\]1.2.3. SD 有效性函数SD有效性函数（SD Validity Function）是一种用于评估聚类结果质量的准则函数，它综合考虑了聚类的平均散布性和聚类间的总体分离性。这种方法确实是在2000年左右被提出并广泛应用于聚类分析中。      平均散布性（Average Scattering）    设样本总方差和各个聚类的方差分别为 $\\sigma(\\Omega)$ 和 $\\sigma(\\omega_i)$，则平均散布性定义为：\\[\\text{Scat}(C)=\\frac{1}{C}\\sum_{i=1}^C\\frac{\\Vert\\sigma(\\omega_i)\\Vert}{\\Vert\\sigma(\\Omega)\\Vert}\\]    一个好的聚类具备较大的样本总方差和较低的各个聚类方差，因此平均散布性越小，聚类效果越好。        总体分离性（Total Separation）    假设 $D_{\\max}$ 和 $D_{\\min}$ 分别表示聚类中心间的最大和最小距离，则总体分离性定义为：\\[\\text{Dis}(C) = \\frac{D_{\\text{max}}}{D_{\\text{min}}} \\sum_{i=1}^{C} \\left( \\sum_{i=1}^{C} \\|\\boldsymbol{\\mu}_i - \\boldsymbol{\\mu}_j\\| \\right)^{-1}\\]    一个好的聚类中各类别中心间的最大和最小距离应该较为接近，且不同类别的均值的差较大，此时总体分离性会较低。  综上，我们希望最小化如下定义的 SD 有效性函数：\\[\\min \\; \\text{SD}(C) = \\alpha\\cdot \\text{Dis}(C) + \\text{Var}(C)\\]该准则函数越小表明聚类效果越好。1.3. 聚类方法聚类方法设计的核心大多都是围绕初始类别（或聚类中心）的选取来展开，如：  基于层次的聚类方法：假设初始每个样本都是一个类别，或者所有类别都属于一个类别；  基于划分的聚类方法：随机或凭借经验选择若干个初始聚类中心，并设计初始类别；1.3.1. 基于层次的聚类层次聚类（Hierarchical Clustering）又被称为分级聚类，是最常见的聚类分析算法之一。给定 $d$ 维特征空间中由 $N$ 个数据点所构成的样本集 $D={x_1,x_2,\\cdots,x_N}$，若需要将样本集聚类为 $C$ 个类别，假设类别与类别之间没有重合的数据点，那么可以选择以下两种层次聚类方向之一开始聚类。1.3.1.1. 层次聚类方向      自下而上聚合          将所有样本点都视为一个类别，即 $C=N$，每个类别的样本点个数为 $N$；      将相似性最强的两个类别合并，得到 $C-1$ 个聚类，即 $C=N-1$。      重复第二步，直到聚类的类别数目达到预期。            自上而下分解          创建一个初始类别，即 $C=1$，该类别的样本点个数为 $N$；      将最不相似的两个类别分离，得到 $C+1$ 个聚类，即 $C=N+1$；      重复第二步，直到聚类的类别数目达到预期。      可以看出，不论是自下而上还是自上而下，在聚类过程中都需要直接计算某个相似性测度，评估两个类别的相似性，进而进行类别合并或分离。1.3.1.2. 测度计算方法前述迭代聚类过程中，首先需要计算两个类别的相似性测度来决定哪两个类别进行合并或分离。根据具体任务需求，这里可以选择前面介绍过的任意相似性测度。其次，对于包含多个样本的类别，即使选择了特定的相似性测度，其具体计算也存在多样性。比如，选择欧氏距离作为相似性测度，那么可以采用以下三种计算方法：  最小距离法：将两类别中最「近」的两个数据点之间的欧氏距离作为测度；  最大距离法：将两类别中最「远」两个数据点之间的欧氏距离作为测度；  均值距离法：将两个类别的均值的欧式距离作为测度；  组平均距离法：将两个类别之间所有点对距离的平均值作为类别相似性测度。相比于最小距离法和最大距离法，组平均距离法可以有效避免类内特殊点带来的不利影响；  沃德距离法：将两个类别合并/拆分时带来的平方和误差（SSE）的变化量作为测度。1.3.1.3. 小结基于层次的聚类方法是一种较为简单的聚类方法，只需要通过一轮迭代即可完成聚类，原理简单易于实现，且相似性测度采用欧氏距离，该测度是具有真实意义的，但选取不同的计算方法可能会导致聚类结果的差异。1.3.2. 基于划分的聚类基于划分的聚类方法是一种自顶向下的方法，对于给定的由 $N$ 个样本数据组成的数据集 $X$，将该数据集划分为 $C$ 个分区，其中每个分区代表一个簇。给定要构建的分区数 $C$，首先创建一个初始划分，然后采用迭代重定位技术，通过把对象从一个组移动到另一个组来改进划分。一个好的划分准则是：同一个簇中的相关对象尽可能相互“接近”或相关，而不同簇中的对象尽可能地“远离”或不同。1.3.2.1. K-均值聚类（K-means）最经典的基于划分的聚类方法是 「K-means 聚类」。其核心思想是指定聚类中心，再通过迭代的方式更新聚类中心。  第一步：样本集初始划分（1）选择代表点  方式1：凭经验从数据中找出从合适的代表点；  方式2：将全部数据随机地分成 $C$ 类，计算每类均值作为每类代表点；  方式3：用前 $C$ 个样本点作为代表点。以上选择代表点的方法都是带有启发性的，不同的方法得到不同的初始代表点，它将直接影响到聚类的结果。（2）选择相似性测度不同的相似性测度选择也直接影响聚类的结果，一般而言常用的选择包括前面介绍的 欧几里得距离、闵科夫斯基距离、马氏距离、相关性测度等。  第二步：相似性测度选择和迭代计算确定相似性测度后，遍历所有待分类的样本 $x_i$，计算该样本与每个聚类中心（代表点）的距离，按照最小距离原则将样本划分到 $C$ 类中的某一类。这里有两种不同的遍历方式：      方式1：将其余样本点按照与代表点距离最近原则，划分到相应类中（代表点保持不变）；        方式2：每个代表点自成一类，将样本依顺序归入与其最近的代表点那一类，并立即重新计算该类的均值以代替原来的代表点（代表点进行动态更新）。然后再计算下一个样本的归类，直至所有的样本都归到相应的类为止。  两种方式各有利弊，方式 1 的计算量少，但收敛速度比较慢；方式 2 的计算量大，但收敛速度快。如此反复迭代并更新聚类中心，直至所有类的聚类中心都不再发生变化，聚类结束。  类别数的确定如果初始确定的聚类类别数是凭借经验确定的，那么这一步可以不进行。但是，凭借经验确定的类别数不一定是最优的。除了凭借经验确定类别数外，还可以通过计算不同类别数下的聚类准则（SSE、离散度、SD有效性）来选择最合适的类别数。一般情况下，我们可以绘制出聚类准则函数值随类别数的变化曲线，然后选取曲线拐点的个数作为聚类类别数。1.3.2.2. K-Means++ 算法前述 K-Means 方法中，随机的初始中心选择对计算结果和迭代次数有较大的影响，一种改进方法被称为 K-Means++。K-means++ 按照如下的思想选取 $C$ 个初始聚类中心：  第 $n=1$ 个聚类中心通过随机的方法选取；  从第 $n=2$ 初始聚类中心开始，距离当前 $n$ 个聚类中心越远的点会有更高的概率被选为第 $n+1$ 个聚类中心。K-Means++ 保证了初始聚类中心之间的相互距离要尽可能的远，可有效解决随机初始中心选择的问题。但是，对于聚类数量的预先设定，在 K-Means++ 中也没有很好的解决。1.3.2.3. 迭代自组织数据分析方法（ISODATA）迭代自组织数据分析方法（Iterative Self-Organizing Data Analysis Techniques Algorithm，ISODATA）在 K-Means 算法基础上增加对聚类结果的「合并」和「分裂」：      聚类合并：当两个聚类中心之间距离值小于某个阈值时，将两个聚类中心合并成一个；        聚类分裂：当某个聚类的类别其样本方差大于一定的阈值且该聚类内样本数量超过一定阈值时，将该聚类分裂为两个聚类。  经过以上两个操作，可有效解决聚类数量需要设定的问题。ISODATA 需要指定以下几个参数：  预期的类别数目 $C$虽然在ISODATA运行过程中类别数目是可变的，但还是需要由用户指定一个参考标准。事实上，该算法的聚类中心数目变动范围也由 $C$ 决定。具体地，最终输出的聚类中心数目范围是 $[C/2, 2C]$。  每个类所包含的最少样本数目 $N_{\\min}$用于判断当某个类别所包含样本分散程度较大时是否可以进行分裂操作。如果分裂后会导致某个子类别所包含样本数目小于 $N_{\\min}$ ，就不会对该类别进行分裂操作。  最大方差阈值 $\\Sigma$用于衡量某个类别中样本的分散程度。当样本的分散程度超过这个值时，则有可能进行分裂操作（注意同时需要满足 $N_{\\min}$ 条件）;  类间最小距离阈值 $d_{\\min}$如果两个类别靠得非常近（一般使用聚类中心之间的欧几里得距离衡量），则需要对这两个类别进行合并操作。是否进行合并的阈值由 $d_{\\min}$ 决定。ISODATA 算法流程如下：  从数据集中随机选取 $C_0$ 个样本作为初始聚类中心 $m_1, m_2, \\cdots, m_{C_0}$；  针对每个样本 $x_i$，计算它到 $C_0$ 个聚类中心的距离，并将该样本分到与其距离最小的聚类中心所对应的类中；  判断上述每个类中的样本数量是否小于 $N_{min}$ 。如果是，则需要删除该类，令 $C_0=C_0−1$，并将该类中的样本重新分配到剩下与其距离最小的类中;  针对每个类别，重新计算它的聚类中心；  如果当前类别数 $C_0 \\geq 2C$，表明当前类别数 $C_0$ 太多，需进行合并操作；          计算当前所有类别聚类中心两两之间的距离，用矩阵 $D$ 表示；      对于 $D(i,j) &lt; d_{\\min}(i\\neq j)$ 的两个类别 $w_i$ 和 $w_j$，进行合并操作，形成一个新的类，该类的聚类中心为：    \\[\\boldsymbol{m}_{\\text{new}}=\\frac{1}{N_i+N_j}(N_i \\boldsymbol{m}_i+N_j \\boldsymbol{m}_j)\\]    如果当前类别数 $C_0 \\leq C/2$，表明当前类别数 $C_0$ 太少，需进行分裂操作；          计算每个类别下所有样本在每个维度下的方差；      从每个类别的所有维度方差中挑选出最大的方差 $\\sigma_{\\max}$；      如果某个类别的 $\\sigma_{\\max}&gt;\\Sigma$ 并且该类别中所包含的样本数量 $N_i\\geq 2N_{\\min}$，则进行分裂操作;选取距离最远的两个样本作为类中心，将剩余样本根据距离归入两个子类中，并令 $C_0 = C_0 +1$。        如果达到最大迭代次数则终止，否则回到第 2 步继续执行。1.3.2.4. 模糊 C-均值 聚类K-均值算法是一种硬聚类算法，算法的依据是类内误差平方和最小化准则，给集合中的每个样本赋予一个明确的类别。但在实际应用中，有时样本在形态和类属方面存在中介性，不存在严格的属性划分。为了更好的解决这类问题，将模糊理论引入K-均值算法（也称C-均值算法），将其从硬聚类推广到模糊聚类，即本节要介绍的模糊C均值算法（Fuzzy C-Means，FCM）。  模糊控制是自动化控制领域的一项经典方法。其原理则是模糊数学、模糊逻辑。1965年美国加州大学柏克莱分校的扎德教授发表模糊集合“Fuzzy Sets”的论文，首次引入隶属度函数的概念，打破了经典数学“非0即1”的局限性，用 $[0,1]$ 之间的实数来描述中间状态。  隶属度很多经典的集合（即：论域U内的某个元素是否属于集合A，可以用一个数值来表示。在经典集合中，要么0，要么1）不能描述很多事物的属性，需要用模糊性词语来判断。比如天气冷热程度、人的胖瘦程度等等。模糊数学和模糊逻辑把只取1或0二值（属于/不属于）的普通集合概念推广到0~1区间内的多个取值，即隶属度。用“隶属度”来描述元素和集合之间的关系。如图所示，对于冷热程度，采取三个模糊子集：冷、暖、热。对于某一个温度，可能同时属于两个子集。要进一步具体判断，就需要提供一个描述“程度”的函数，即隶属度。除了折线外，还可以采用以下几种隶属度函数隶属度函数记作 $\\mu_A(\\boldsymbol{x})$，表示一个对象 $\\boldsymbol{x}$ 隶属于集合 $A$ 的程度，取值范围是 $[0,1]$。  $\\mu_A(\\boldsymbol{x}) = 1$ 表示 $x$ 属于 $A$，相当于 $\\boldsymbol{x}\\in A$；  $\\mu_A(\\boldsymbol{x}) = 0$ 表示 $x$ 不属于 $A$，相当于 $\\boldsymbol{x}\\notin A$；基于隶属度函数的定义，对于 $N$ 个样本的 $C$ 分类问题，可以定义优化问题为\\[\\begin{aligned}\\min\\quad &amp;J = \\sum_{i=1}^{N}\\sum_{j=1}^{C}\\mu_j(\\boldsymbol{x}_i)^b \\Vert\\boldsymbol{x}_i-\\boldsymbol{m}_j\\Vert^2\\\\s.t.\\quad &amp; \\sum_{j=1}^{C}\\mu_j(\\boldsymbol{x}_i) = 1 \\quad \\forall i=1,2,\\ldots,N\\\\\\end{aligned}\\]其中，$b&gt;1$ 为加权指数，又称为平滑因子，用来控制样本在模糊类间的分享程度，一般取为 2。可以采用拉格朗日乘子法求解上述等式约束优化问题，引入 $N$ 个拉格朗日因子得到拉格朗日函数\\[\\min \\quad \\sum_{i=1}^{N}\\sum_{j=1}^{C}\\mu_j(\\boldsymbol{x}_i) ^b\\Vert\\boldsymbol{x}_i-\\boldsymbol{m}_j\\Vert^2 + \\sum_{i=1}^{N}\\lambda_i \\left( \\sum_{j=1}^{C}\\mu_j(\\boldsymbol{x}_i) -1\\right)\\]对特定一个 $\\mu_j(\\boldsymbol{x}_i)$ 求偏导并令其为零，得到\\[\\frac{\\partial J}{\\partial \\mu_j(\\boldsymbol{x}_i)} = b\\mu_j(\\boldsymbol{x}_i)^{b-1}\\Vert\\boldsymbol{x}_i-\\boldsymbol{m}_j\\Vert^2 -\\lambda_i = 0\\]解得\\[\\mu_j(\\boldsymbol{x}_i) = \\left(\\frac{\\lambda_i}{d\\Vert\\boldsymbol{x}_i-\\boldsymbol{m}_j\\Vert^2}\\right)^{\\frac{1}{b-1}}\\]将上述解代入约束等式可解得 $\\lambda_i$，再次代回隶属度方差方程可解得 $\\mu_j(\\boldsymbol{x}_i)$\\[\\mu_j(\\boldsymbol{x}_i) = \\frac{\\left(\\frac{1}{\\Vert \\boldsymbol{x}_i-\\boldsymbol{m}_j \\Vert^2}\\right)^{\\frac{1}{b-1}}}  {\\sum_{j=1}^C\\left(\\frac{1}{\\Vert \\boldsymbol{x}_i-\\boldsymbol{m}_j \\Vert^2}\\right)^{\\frac{1}{b-1}}}\\]对特定聚类中心 $\\boldsymbol{m}_j$ 求偏导并令其为零，得到\\[\\frac{\\partial J}{\\partial \\boldsymbol{m}_j} = -2\\sum_{i=1}^N \\mu_j(\\boldsymbol{x}_i)^b (\\boldsymbol{x}_i - \\boldsymbol{m}_j) = 0\\]解得\\[\\boldsymbol{m}_j = \\frac{\\sum_{i=1}^N \\mu_j(\\boldsymbol{x}_i)^b\\boldsymbol{x}_i}{\\sum_{i=1}^N \\mu_j(\\boldsymbol{x}_i)^b}\\]可以看出，虽然可以分别得到待优化参数 $\\mu_j(\\boldsymbol{x}_i)$ 和 $\\boldsymbol{m}_j$ 的解析表达式，但是它们是相互依赖的，因此无法直接给出最优值，需要通过「迭代法」逐步求解。迭代终止条件可通过前后两次迭代的聚类中心变化量最大值小于某个阈值 $\\epsilon$ 来判断：\\[\\max \\Vert \\boldsymbol{m}_i^{t+1} - \\boldsymbol{m}_i^{t} \\Vert &lt; \\epsilon\\]1.3.2.5. 小结基于划分的聚类方法主要包括：K-Means 聚类、K-Means++ 聚类、ISODATA 聚类。三个方法是逐步递进完善的关系：  K-Means：简单快速，适用于大数据集，但需要预先指定 $K$ 值，对初始条件敏感。  K-Means++：改进了 K-Means 的初始聚类中心选择，提高了结果的稳定性，但仍需指定 K 值。  ISODATA：动态调整聚类数目，使用更多的参数来控制迭代过程，但计算复杂度较高。选择哪种算法取决于具体的应用场景和数据特性。1.3.3. 基于密度的聚类1.3.3.1. DBSCANDBSCAN（Density-Based Spatial Clustering of Applications with Noise）是比较有代表性的基于密度的聚类算法。其将簇（类）定义为「密度相连的点的最大集合」，能够把具有足够高密度的区域划分为簇，并可在噪声的空间数据库中发现任意形状的聚类。该算法不需要确定聚类的数量，而是基于数据推测聚类的数目，能够针对任意形状产生聚类。DBSCAN 算法涉及到以下几个定义：      密度：以每个数据点为圆心，以 $\\epsilon$ 为半径画个圈（称为 $\\epsilon$-邻域），然后数有多少个点在这个圈内，这个数就是该点密度；        核心点：一个点 $x$ 的密度大于等于某个阈值 MinPts 则被称为核心点；        边界点：一个点 $x$ 的密度小于阈值 MinPts，但是位于某核心点的邻域内的点，则被称为边界点；        噪声点：既不是核心点也不是边界点的点。  如图示，假设 MinPts$=5,\\epsilon$ 如图，三个点分别为：  点 $A$ 是核心点，因为 $A$ 的 $\\epsilon$-邻域内包含 7 个点；  点 $B$ 是边界点，因为 $B$ 的 $\\epsilon$-邻域内包含 3 个点，但位于核心点 $A$ 的邻域内；  点 $C$ 是噪声点，因为 $C$ 的 $\\epsilon$-邻域内包含 3 个点，且没有任何核心点落在其邻域内。基于上述定义，我们可以进一步延伸出以下概念：  密度直达（Directly Density-Reachable）：如果点 $q$ 在核心点 $p$ 的 $\\epsilon$-邻域内，则称 $p$ 密度直达 $q$；注意起点必须是核心点；  密度可达（Density-Reachable）：对于点链 $p_1\\to p_2\\to \\cdots\\to p_n$，若 $p_{i}$ 密度直达点 $p_{i+1}$，则称点 $p_1$ 密度可达 $p_n$，或者称点 $p_n$ 由 $p_i$ 密度可达；  密度相连（Density-Connected）：如果对于样本点 $p$ 和 $q$，存在一个样本点 $k$，使得 $p$ 和 $q$ 都由 $k$ 密度可达，那么我们说 $p$ 和 $q$ 密度相连。换句话说，如果 $p$ 和 $q$ 可以通过一系列密度可达的核心点连接起来，那么它们是密度相连的；  密度聚类簇（Density-Cluster）：由一个核心点和所有与其密度可达的点（包括核心点和边界点）构成的集合称为一个密度聚类簇。这意味着一个密度聚类簇可以包含核心点、边界点以及通过密度可达关系连接的所有其他点。根据上述定义和概念，对下图的三个点进行分析：图(a)中，点 $A$ 为核心点，点 $B$ 为边界点。$A$ 密度直达 $B$，但 $B$ 不密度直达 $A$（因为 $B$ 不是一个核心点）。图(b)中，点 $C$ 和 $A$ 为核心点。$C$ 密度直达 $A$，$A$ 密度直达 $B$，所以 $C$ 密度可达 $B$。$A$ 密度直达 $C$，但是 $B$ 不密度直达 $A$，所以 $B$ 不密度可达 $C$（也即密度可达不具备对称性）。但是 $B$ 和 $C$ 密度相连（$A$ 密度直达 $B$，$A$ 密度直达 $C$）。DBSCAN 根据密度可达来进行聚类，具体流程如下：  找寻数据集中的核心点，形成集合 $\\Omega_1$；  如果 $\\Omega_1 \\neq \\text{null}$:          从 $\\Omega_1$ 中任意选取核心点，找出由该核心点密度可达的所有样本点，形成一个簇；      将在该簇中的核心点从 $\\Omega_1$ 中清除；      重复以上步骤，直至 $\\Omega_1$ 为空。      下图展示了使用 DBSCAN 算法的一个聚类过程示意：下面的网站链接可以通过交互设置动态展示 DBSCAN 聚类算法的过程和结果。https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/1.3.3.2. 小结以 DBSCAN 算法为代表的基于密度的聚类方法具备以下优点：  不用人为设定簇的个数；  可以在聚类的同时发现异常点，对数据集中的异常点不敏感；  能发现任意形状的空间聚类，如能识别 “非球形” 的簇，而 K-Means 算法这种基于距离的聚类方法只能找出球状的簇；  聚类结果不依赖于遍历的初值选取，而 K-Means 算法的初始值对聚类结果有很大影响。"
  },
  
  {
    "title": "模式识别（特征选择与特征提取）",
    "url": "/posts/Pattern-Recognition-Feature-Selection-and-Extraction/",
    "categories": "Academic, Knowledge",
    "tags": "pattern recognition",
    "date": "2025-04-15 17:15:49 +0800",
    





    
    "snippet": "本文介绍了模式识别中特征的概念，包括颜色特征、形状特征、纹理特征、空间关系特征。然后介绍了常用的特征选择与特征提取方法，包括类别可分性准则、最优搜索、次优搜索、启发式搜索、线性特征提取、非线性特征提取等。  1. 特征          1.1. 颜色特征                  1.1.1. 颜色直方图          1.1.2. 颜色矩                   ...",
    "content": "本文介绍了模式识别中特征的概念，包括颜色特征、形状特征、纹理特征、空间关系特征。然后介绍了常用的特征选择与特征提取方法，包括类别可分性准则、最优搜索、次优搜索、启发式搜索、线性特征提取、非线性特征提取等。  1. 特征          1.1. 颜色特征                  1.1.1. 颜色直方图          1.1.2. 颜色矩                    1.2. 形状特征                  1.2.1. 霍夫变换（Hough）          1.2.2. 方向梯度直方图（HOG）          1.2.3. 傅里叶描述子（Fourier Descriptors）                    1.3. 纹理特征                  1.3.1. 灰度共生矩阵（GLCM）          1.3.2. 局部二值模式（LBP）                    1.4. 空间关系特征        2. 特征选择          2.1. 类别可分性准则                  2.1.1. 基于类内类间距离的可分性判据          2.1.2. 基于信息熵的可分性判据                    2.2. 最优搜索      2.3. 次优搜索                  2.3.1. 单独最优特征组合          2.3.2. 顺序后向搜索          2.3.3. 顺序前向搜索          2.3.4. 浮动搜索                    2.4. 启发式搜索                  2.4.1. 遗传算法          2.4.2. 模拟退火算法                      3. 特征提取          3.1. 线性特征提取                  3.1.1. 线性判别分析（LDA）          3.1.2. 主成分分析（PCA）                    3.2. 非线性特征提取                  3.2.1. 核方法          3.2.2. 流形学习                      4. 参考文献1. 特征模式识别中把每个样本都量化为一组特征来描述，构建特征空间是解决模式识别问题的第一步。  「特征」：可以用来体现类别之间相互区别的某些数学测度，也称作属性，测度的值称为特征值。  「特征向量」：由被识别的对象（样本）确定一组基本特征，这组特征的取值按向量形式排布，称为该样本的特征向量。  「特征空间」：由样本的特征构成的空间，空间的维数就是特征的个数，每个维度就是一个特征，因此每一个样本就是特征空间中的一个点。通过直接测量得到的特征称为原始特征。原始特征主要包括：物理特征、结构特征、数学特征  「物理和结构特征」：一般是由仪器直接测量出来的数值，这类特征易于为人的直觉感知，但是有时难以定量描述，因此不利于机器判别。  「数学特征」：则是对仪器所测量数据的进一步计算，比如根据图像中细胞的总光密度、大小、形状、核内纹理等统计特征来区分正常细胞和异常细胞，这类特征易于用机器判别和分析原始特征是我们直接测量获得的，但往往不能直接用于模式识别中，因为：  原始特征不能反应对象的本质特征；  原始特征的维度可能很大，不利于分类器设计。  举例：一张大小 $160\\times 120$ 的原始卫星图像，如果采用全部灰度值作为特征的话，原始特征即为 19200 维。但如果改为计算卫星的面积、周长、形状、纹理等有效特征，原始特征可能不超过 100 维。  为了设计出更好的分类器，需要对原始特征的测量值集合进行分析，经过选择和变换处理，组成有效的识别特征。处理方式主要包括：  特征选择：从原始特征中跳出一组最具有代表性、分类性能好的特征；  特征提取：通过映射（或变换）的方法将高维特征映射到低维空间，在低维空间表示样本。特征选择和特征提取的相似之处在于，二者想要达到的效果一样，即试图去减少特征数据集中的属性的数目。二者的不同在于：  特征提取是通过属性组合生成新属性，改变特征空间；  特征选择是从原始特征集中选取子集，不更改原特征空间。1.1. 颜色特征颜色特征是一种 全局特征，通常对图像或图像区域的方向、大小等变化不敏感，也就是说，颜色特征通常不能很好的描述图像中对象的局部特征。1.1.1. 颜色直方图颜色直方图描述一幅图像中颜色的全局分布，无法描述图像中颜色的局部分布及每种色彩所处的空间位置，即无法描述图像中的某一具体的对象或物体，只是颜色全局分布的统计结果。因此，颜色直方图只能刻画该范围内像素值的点有多少个，但无法确定点的具体位置。  灰度直方图灰度直方图是由图像中所有像素的灰度级别组成的直方图，它可以用来表示图像中每个灰度级别的像素数量。通常，灰度直方图是一个一维的向量，其长度等于图像的灰度级别数。  RGB直方图当图像为彩色图像时，图像包含 R、G、B 三个通道，可分别统计三个通道颜色取值绘制直方图。1.1.2. 颜色矩颜色矩‌是一种用来描述图像颜色分布的统计特征，主要通过计算图像的颜色一阶矩、二阶矩和三阶矩来反映图像的颜色特征。这些矩分别对应于颜色的「平均值」、「方差」、「偏斜度」、「峰度」，能够有效地表示图像中的颜色分布。由于颜色信息主要分布在低阶矩中，所以用一阶矩、二阶矩、三阶矩和四阶矩足以表达图像的颜色分布。该方法的优点是：不需要颜色空间量化，特征向量维数低；但是该方法的检索效率比较低，实际应用中常用来过滤图像，以缩小检索范围。  一阶矩（均值）一阶矩为原点矩，反应图像的整体明暗程度，值越大越亮。设 $i$ 为图像通道数，$P_{ij}$ 为第 $j$ 个像素在第 $i$ 个通道上的颜色值，则第 $i$ 个通道的一阶矩为：\\[E_i = \\frac{1}{N}\\sum_{j=1}^{N}P_{ij}\\]  二阶矩（方差）二阶矩反应图像颜色分布范围，值越大分布越广。第 $i$ 个通道的二阶矩为：\\[\\sigma_i = \\sqrt[2]{\\frac{1}{N}\\sum_{j=1}^{N}(P_{ij} - E_i)^2}\\]  三阶矩（偏斜度）三阶矩反应图像颜色分布的形状（对称性），值为0️零表示图像的颜色分布是对称的，小于零则颜色分布左偏或负偏，大于零则颜色分布右偏或正偏。则第 $i$ 个通道的三阶矩定义为：\\[S_i = \\sqrt[3]{\\frac{1}{N}\\sum_{j=1}^{N}(P_{ij} - E_i)^3}\\]  四阶矩（峰度）用于描述图像纹理的非线性特性（如尖锐度、尾部权重等），通常与低阶矩结合使用，形成更全面的特征表示。第 $i$ 个通道的四阶矩定义为：\\[M_i = \\sqrt[4]{\\frac{1}{N}\\sum_{i=1}^{N}(P_{ij} - E_i)^4}\\]四阶矩常与标准差（二阶矩）结合计算「峰度」（Kurtosis），用于衡量分布尖锐程度：\\[\\kappa_i = \\frac{M_i - 3}{\\sigma_i}\\]其中，减 3 是为了使正态分布峰度为 0。峰度量化特性如下：  峰度值越小，分布更平坦（轻尾，像素值集中）  峰度值越大，分布比正态分布更尖锐（重尾，可能存在异常值）  高阶矩能捕捉纹理的微观变化。四阶矩值越高，表明局部像素值变化越剧烈（如高频边缘或复杂纹理）。  对抗攻击常导致像素值分布异常，四阶矩可辅助识别人为扰动（相比正常图像，对抗样本的峰度值显著偏离）。1.2. 形状特征形状特征描述图像的形状，通常对图像的形状变化敏感，因此，形状特征可以很好的描述图像中对象的 局部特征。  轮廓特征：图像形状的外边界；  区域特征：面积、周长、半径、长度、宽度、高度。需要注意的是，形状区域的几何参数提取依赖于图像处理和分割效果，分割质量差可能导致参数无法提取。1.2.1. 霍夫变换（Hough）霍夫变换（Hough Transform）是一种用于检测图像中特定几何形状（如直线、圆、椭圆等）的参数空间投票算法，其核心思想是将图像空间的几何形状映射到参数空间进行累积统计。以直线为例：  在直角坐标系中，直线可以表示为 $y = kx + b$，其中 $a$ 为斜率，$b$ 为截距。但垂直直线（$k\\to\\infty$）会导致参数空间无限大。因此改用极坐标参数化；  在极坐标系中，直线可以表示为 $\\rho = x \\cos \\theta + y \\sin \\theta$，其中 $\\theta\\in[0,\\pi)$ 为直线法线与 $x$ 轴的夹角，$\\rho$ 为直线到原点的距离。按照极坐标表示，过一个点的所有直线可以在参数空间中绘制出一条 正弦线。因此，使用 Hough 变换的步骤为：  将 $\\rho,\\theta$ 离散化为若干区间，形成二维累加器数组 $A(\\rho,\\theta)$ 作为投票矩阵，初始值为0。  将图像转为灰度图像，然后使用使用Canny、Sobel等边缘检测算法提取图像中的边缘像素点（得到二值边缘图，边缘点为1，非边缘点为0）  对每个边缘点像素使用 Hough 变换，遍历所有可能的 $\\theta$ 值，计算对应的 $\\rho$ 值；  将计算得到的 $(\\rho, \\theta)$ 四舍五入到最近的离散区间，并在累加器投票矩阵 $A(\\rho,\\theta)$ 中投票（$+1$）。  共线的边缘点会在相同的 $(\\rho, \\theta)$ 处反复投票，形成局部峰值（下图颜色偏白的交点）；  最后，通过阈值筛选和非极大值抑制，找出若干峰值点，每个峰值点对应图像空间的一条直线。]可参考视频 Hough 变换1.2.2. 方向梯度直方图（HOG）方向梯度直方图（Histogram of Oriented Gradients，HOG）是一种用于图像识别和目标检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来描述图像的边缘特征，特别适用于检测具有明显边缘的目标，如人体、车辆等。HOG 描述子的核心思想是：局部目标的外观和形状可以通过其边缘的方向密度分布来描述。具体步骤如下：  对图像进行预处理，将宽高比降低到 $1:2$，如 $64\\times 128$；  裁剪出若干格子，如 $8\\times 8$ 小格，对每个格子的 64 个像素；  对于格子中的每个像素，计算其水平梯度$g_x$（右侧像素值-左侧像素值）和垂直梯度 $g_y$（下方像素值-上方像素值）；          一般采用 Soble 算子卷积，得到 $g_x$ 和 $g_y$；      计算该像素的梯度大小 $g = \\sqrt{g_x^2 + g_y^2}$；      计算该像素的梯度方向 $\\theta = \\arctan(g_y/g_x)$；        按照下面的规则统计格子的梯度直方图：          将梯度方向划分为若干区间，如 $0^{\\circ},20^{\\circ},40^{\\circ},\\cdots,160^{\\circ}$ 共 9 个区间；      根据格子中每个像素的梯度方向，将梯度幅值计入对应区间，如梯度方向 $34.3^{\\circ}$，幅值 $13.6$：                  对于 $20^{\\circ}$ 区间，累加 $(34.3-20)/20\\times 13.6$；          对于 $40^{\\circ}$ 区间，累加 $(40-34.3)/20\\times 13.6$；                    最终每个小格子得到 9 维向量。        通过滑动窗口的形式，将 4 个 $8\\times 8$ 格子组成一个块，对块内的直方图进行归一化，以减少光照和阴影的影响。          滑动步长为 8 像素，即每次移动 1 个格子，相邻块存在 50% 重叠；      每一个块大小为 $16\\times 16$，将会得到一个 36 维归一化特征向量。        将所有块的归一化直方图特征向量拼接，形成最终的 HOG 特征向量。          对于尺寸为 $64\\times 128$ 的原始图片，被划分 $(8-1)\\times (16-1)=105$ 个块；      最终得到 $105 \\times 36 = 3780$ 维特征向量。      可参考链接 图像特征工程：HOG 特征描述符的介绍1.2.3. 傅里叶描述子（Fourier Descriptors）傅里叶描述子（Fourier Descriptors）是一种用于描述图像形状的特征提取方法，它基于傅立叶变换的原理。傅立叶描述子通过分析形状的轮廓在频域中的表示，能够有效地捕捉形状的特征，并且对形状的平移、旋转和缩放具有一定的不变性。这使得傅立叶描述子在图像识别、目标检测和模式识别等领域中得到了广泛应用。傅立叶描述子的核心思想是将形状的轮廓表示为一个复数序列，然后对该序列进行傅立叶变换。具体步骤如下：  从图像中提取目标的轮廓。轮廓可以表示为一系列的点 $(x_k,y_k)$，其中 $k$ 是点的索引;  将轮廓点 $(x_i,y_i)$ 转换为复数序列 $z_k = x_k + iy_k$，其中 $j$ 为虚数单位；  对复数序列进行傅立叶变换，得到其频谱 $Z_n=\\sum_{k=0}^{N-1}z_k\\exp(-i2\\pi nk/N)$，其中 $n$ 为频率索引；  保留前 $M=10$ 个傅里叶系数，并进行归一化，得到特征向量称为傅里叶描述子。1.3. 纹理特征纹理特征也是一种全局特征，指图像中像素的某种空间排列规律，它反映了图像中局部区域的重复性模式或结构。但是，纹理特征不能完全反映出物体的本质属性，仅仅利用纹理特征是无法获得高层次图像内容的。1.3.1. 灰度共生矩阵（GLCM）灰度共生矩阵（Gray-Level Co-occurrence Matrix, GLCM）是一种用于描述图像中像素对之间灰度值关系的统计方法。它通过计算图像中每对像素在特定方向和距离上的灰度值组合的频率，来提取图像的纹理特征。GLCM 的计算步骤如下：  定义方向和距离          选择一个方向 $\\theta$（如 $0^{\\circ},45^{\\circ},90^{\\circ},135^{\\circ}$）和一个距离 $d$（如 $1,2,3$ 等）；      方向表示像素对之间的相对位置，距离表示像素对之间的间隔。        初始化 GLCM 矩阵          创建一个 $N\\times N$ 的矩阵，其中 $N$ 是灰度值的数量，用于存储每对像素的灰度值组合的概率 $P(i,j\\vert \\theta,d)$；      将矩阵的每个元素初始化为 0；        计算像素对的频率          遍历图像中的每个像素，对于每个像素，找到其在指定方向和距离上的邻域像素；      增加 GLCM 中对应于当前像素和邻域像素灰度值的元素的值。        归一化 GLCM          将 GLCM 中的每个元素除以像素对的总数，得到归一化的 GLCM。      归一化后的 GLCM 表示了不同灰度值组合的概率分布。      注意，定义方向时一般包含双向信息，比如 $0^{\\circ}$ 与 $180^{\\circ}$ 是同一方向，而 $45^{\\circ}$ 与 $-135^{\\circ}$ 是同一方向，因此统计概率时要考虑两种方向的组合。且注意到，灰度共生矩阵在双向定义下一定是一个对称矩阵。思考：有必要针对原始灰度图像计算灰度共生矩阵么？  两不同的灰度像素组合 $51\\to 165$ 和 $48\\to173$ 几乎无区别！  8 位灰度图像的GLCM 尺寸为 $256\\times 256 = 65536$ 太大！  大量灰度像素组合不存在，概率为 0，GLCM 特别稀疏！因此，我们可以降低灰度的级别，将其拆成若干区间，如取 $N=8$ 以降低 GLCM 的大小，且有效降低矩阵的稀疏性。虽然我们从 GLCM 中已经能反映出原图的某些特征，我们一般会将其进一步计算某些统计学特性。  对比度对比度是衡量图像纹理清晰度和纹理粗细程度的指标，反映了图像中像素对之间的灰度差异程度。其计算公式为\\[\\text{Contrast} = \\sum_{i=1}^{N}\\sum_{j=1}^{N}P(i,j\\vert \\theta,d)|i-j|^2\\]对比度值越大，表示图像纹理越清晰，纹理变化越明显，图像中像素对之间的灰度差异越大；对比度值越小，表示图像纹理越模糊，纹理变化越不明显。  能量能量是衡量图像纹理能量和纹理分布均匀度的指标，反映图像纹理的均匀程度。其计算公式为\\[\\text{Energy} = \\sum_{i=1}^{N}\\sum_{j=1}^{N}P(i,j\\vert \\theta,d)^2\\]能量值越大，表示图像纹理分布越均匀，纹理变化越规则（如黑白棋盘）；能量值越小，表示图像纹理变化越丰富（如噪声图）。  熵熵是衡量图像纹理混乱程度的指标，反映图像纹理的随机性。其计算公式为\\[\\text{Entropy} = -\\sum_{i=1}^{N}\\sum_{j=1}^{N}P(i,j\\vert \\theta,d)\\log P(i,j\\vert \\theta,d)\\]熵值越大，表示图像纹理分布不均匀，纹理变化越随机；熵值越小，表示图像纹理分布均匀，纹理变化越规则。  越杂乱无序，能量越小，熵越大（熵增、热力学第二定律的体现）。  相关性相关性用于衡量图像中像素对之间的线性相关程度，反映了图像纹理的规则性。其计算公式为\\[\\text{Correlation} = \\frac{\\sum_{i=1}^{N}\\sum_{j=1}^{N}(i-\\mu_i)(j-\\mu_j)P(i,j\\vert \\theta,d)}{\\sigma_i\\sigma_j}\\]其中\\[\\begin{aligned}  \\mu_i &amp;= \\sum_{i=1}^{N}\\sum_{j=1}^{N}iP(i,j\\vert \\theta,d) \\\\  \\mu_j &amp;= \\sum_{i=1}^{N}\\sum_{j=1}^{N}jP(i,j\\vert \\theta,d)\\\\  \\sigma_i &amp;= \\sqrt{\\sum_{i=1}^{N}\\sum_{j=1}^{N}(i-\\mu_i)^2P(i,j\\vert \\theta,d)}\\\\  \\sigma_j &amp;= \\sqrt{\\sum_{i=1}^{N}\\sum_{j=1}^{N}(j-\\mu_j)^2P(i,j\\vert \\theta,d)}\\end{aligned}\\]相关性值通常在 $[−1,1]$ 之间。  $1$ 表示完全正相关;  $-1$ 表示完全负相关;  $0$ 表示无相关性。高相关性表示图像纹理在指定方向上变化缓慢，低相关性表示纹理变化剧烈。  一致性一致性是用于衡量图像纹理局部变化的大小，即灰度相似的像素对在图像中出现的频率。其计算公式为\\[\\text{Homogeneity} = \\sum_{i=1}^{N}\\sum_{j=1}^{N}\\frac{P(i,j\\vert \\theta,d)}{1+\\vert i-j\\vert^2}\\]一致性值越大，表示图像中灰度相似的像素对越多，图像纹理越均匀；一致性值越小，表示图像中灰度差异较大的像素对越多，图像纹理变化越复杂。1.3.2. 局部二值模式（LBP）局部二值模式（Local Binary Pattern，LBP）是一种用于描述图像中像素邻域的纹理特征。它通过将图像中每个像素的灰度值与相邻像素的灰度值进行比较，生成一个二进制编码，以表示像素的灰度分布特征。它利用相邻像素间的关系，将0-255灰度级的像素值映射到重新定义的灰度级，然后通过统计直方图来反映图像的全局纹理信息。如下图所示，在 $3\\times 3$ 窗口内，以窗口中心像素为阈值，将相邻 8 个像素的灰度值与其阈值进行比较，得到一个二进制编码。若周围像素值大于中心像素值，则该像素点的位置被标记为 1，否则为 0。$3\\times 3$ 邻域内的 8 个点经比较可产生 8 位二进制数（通常转换为十进制数即LBP码，共256种），即得到该窗口中心像素点的LBP值，并用这个值来反映该区域的纹理信息。经过 LBP 提取后的图像依然是一副图，图片中每个像素记录的就是改像素的 LBP 值（如下图右侧子图所示）。应用中，如纹理分类、人脸分析等，一般都不将 LBP 图谱作为特征向量用于分类识别，而是采用 LBP 特征谱的统计直方图作为特征向量用于分类识别。LBP 的优点是简单、快速、易于计算、具有灰度不变性，缺点是计算量较大，需要考虑邻域内的像素值，且需要考虑像素的灰度值范围、且不具有旋转不变性。1.4. 空间关系特征空间关系是指图像中分割出来的多个目标之间的相互空间位置，或者相对方向关系。包括  相对空间位置信息：目标之间的相对情况，如上下左右关系等；  绝对空间位置信息：目标之间的距离大小以及方位。基于空间关系可定义常见的特征如下：  连接/邻接关系。  交叠/重叠关系。  包含/包容关系。详细介绍略。2. 特征选择特征选择的定义为：已知给定的 $M$ 个原始特征。从中优选出 $m$ 个特征（$m&lt;M$）。即：从给定的 $M$ 个原始特征中搜索到最优的特征组合。其包含两个方面：  选择的标准：定义不同的类别可分离性准则（判据）$J_{ij}$，用来衡量在一组特征下第 $i$ 类和第 $j$ 类之间的可分程度。  搜索算法：在允许的时间内找出最优的那组特征。可分离性准则（判据）应该与错误率（或错误率的上界）有单调关系，这样才能较好地反映分类目标。当特征独立时，判据对特征应该具有「可加性」。设特征变量为 $x_k,\\;k=1,2,\\cdots,d$，有\\[J_{ij}(x_1, x_2,\\cdots, x_d) = \\sum_{k=1}^k J_{ij}(x_k)\\]判据应该对特征具有「单调性」，即加入新的特征不会使判据减小\\[J_{ij}(x_1,x_2,\\cdots, x_d) \\leq J_{ij}(x_1,x_2,\\cdots, x_{k-1}, x_{k+1},\\cdots, x_d,\\textcolor{blue}{x_{d+1}})\\]判据还应该具有「以下特性」：\\[J_{ij}\\geq 0,\\; i\\neq j;\\quad J_{ij} = 0,\\; i=j;\\quad J_{ij} = J_{ji}\\]2.1. 类别可分性准则2.1.1. 基于类内类间距离的可分性判据各类样本可以分开是因为它们位于特征空间中的不同区域，显然这些区域之间距离越大，类别可分性就越大。距离度量有多种，如欧氏距离、各种平均平方距离。假设 $w_i, w_j$ 两个类别中的某两个样本特征向量间的距离定义为：$\\delta(\\boldsymbol{x}^{(i)}_k,\\boldsymbol{x}^{(j)}_l)$，那么基于类内类间距离的可分性判据定义为\\[J_d(\\boldsymbol{x}) = \\frac{1}{2}\\sum_{i=1}^cP_i\\sum_{j=1}^cP_j\\frac{1}{n_in_j}\\sum_{k=1}^{n_i}\\sum_{l=1}^{n_j}\\delta(\\boldsymbol{x}^{(i)}_k,\\boldsymbol{x}^{(j)}_l)\\]其中，$c$ 为类别数；$n_i,n_j$ 为类 $i$ 和 $j$ 的样本数；$P_i，P_j$ 为类 $i$ 和类 $j$ 的先验概率。如果我们采用欧氏距离作为距离度量，定义第 $i$ 类的均值为 $\\boldsymbol{m}^{(i)}$，则\\[\\boldsymbol{m}^{(i)} = \\frac{1}{n_i}\\sum_{k=1}^{n_i}\\boldsymbol{x}^{(i)}_k\\]则欧式距离可写为\\[\\begin{aligned}\\delta(\\boldsymbol{x}^{(i)}_k,\\boldsymbol{x}^{(j)}_l) =&amp; \\Vert\\boldsymbol{x}^{(i)}_k-\\boldsymbol{x}^{(j)}_l\\Vert^2\\\\=&amp;\\Vert \\textcolor{red}{\\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)}}+\\textcolor{blue}{\\boldsymbol{m}^{(i)}-\\boldsymbol{m}^{(j)}}+\\textcolor{green}{\\boldsymbol{m}^{(j)}-\\boldsymbol{x}^{(j)}_l}\\Vert^2\\\\=&amp;\\textcolor{red}{\\Vert\\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)}}\\Vert^2+ \\Vert\\textcolor{blue}{\\boldsymbol{m}^{(i)}-\\boldsymbol{m}^{(j)}}\\Vert^2 + \\Vert\\textcolor{green}{\\boldsymbol{x}^{(j)}_l-\\boldsymbol{m}^{(j)}}\\Vert^2\\\\+&amp; 2(\\textcolor{red}{\\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)}})^\\top(\\textcolor{blue}{\\boldsymbol{m}^{(i)}-\\boldsymbol{m}^{(j)}})\\\\+&amp; 2(\\textcolor{blue}{\\boldsymbol{m}^{(i)}-\\boldsymbol{m}^{(j)}})^\\top(\\textcolor{green}{\\boldsymbol{x}^{(j)}_l-\\boldsymbol{m}^{(j)}})\\\\+&amp; 2(\\textcolor{red}{\\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)}})^\\top(\\textcolor{green}{\\boldsymbol{x}^{(j)}_l-\\boldsymbol{m}^{(j)}})\\end{aligned}\\]将上述欧式距离表达式代回可分离性判据定义式，交叉性会相互抵消  对于第一个平方项 $\\Vert \\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)} \\Vert^2$，代入分离判据后，发现其与 $j,l$ 无关，因此\\[\\begin{aligned}&amp;\\frac{1}{2}\\sum_{i=1}^cP_i\\sum_{j=1}^cP_j\\frac{1}{n_in_j}\\sum_{k=1}^{n_i}\\sum_{l=1}^{n_j}\\Vert \\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)} \\Vert^2\\\\= &amp;\\frac{1}{2}\\sum_{i=1}^cP_i\\underbrace{\\left(\\sum_{j=1}^cP_j\\right)}_1\\frac{1}{n_in_j}\\sum_{k=1}^{n_i}\\underbrace{\\left(\\sum_{l=1}^{n_j}1\\right)}_{n_j}\\Vert \\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)} \\Vert^2\\\\= &amp;\\frac{1}{2}\\sum_{i=1}^cP_i\\frac{1}{n_i}\\sum_{k=1}^{n_i}\\Vert \\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)} \\Vert^2\\\\\\end{aligned}\\]  对于第三个平方和项 $\\Vert \\boldsymbol{x}^{(j)}_l-\\boldsymbol{m}^{(j)} \\Vert^2$，与 $i,k$ 无关，与前述类似\\[\\begin{aligned}&amp;\\frac{1}{2}\\sum_{i=1}^cP_i\\sum_{j=1}^cP_j\\frac{1}{n_in_j}\\sum_{k=1}^{n_i}\\sum_{l=1}^{n_j}\\Vert \\boldsymbol{x}^{(j)}_l-\\boldsymbol{m}^{(j)} \\Vert^2\\\\= &amp;\\frac{1}{2}\\sum_{j=1}^cP_j\\frac{1}{n_j}\\sum_{k=1}^{n_i}\\Vert \\boldsymbol{x}^{(j)}_l-\\boldsymbol{m}^{(j)} \\Vert^2\\\\\\end{aligned}\\]  注意到，上述两项实际上是相同的（只是上下标不同），因此可以合并。  对均值平方和项 $\\Vert \\boldsymbol{m}^{(i)}_k-\\boldsymbol{m}^{(j)} \\Vert^2$，其余 $k,l$ 无关，简化后得到\\[\\frac{1}{2}\\sum_{i=1}^cP_i\\sum_{j=1}^cP_j\\Vert \\boldsymbol{m}^{(i)}-\\boldsymbol{m}^{(j)} \\Vert^2\\]  对于交叉项，以\\[2(\\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)})^\\top(\\boldsymbol{m}^{(i)}-\\boldsymbol{m}^{(j)})\\]  为例，由于 $\\sum_{k=1}^{n_i}(\\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)})=0$（因为所有样本减去其均值的和为零），所以该项为零。同理其它两个交叉项也会因为上述对称性而取零。可分离性判据进行简化后得到\\[J_d(\\boldsymbol{x}) = \\sum_{i=1}^cP_i\\frac{1}{n_i}\\sum_{k=1}^{n_i}\\Vert \\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)} \\Vert^2 + \\frac{1}{2}\\sum_{i=1}^cP_i\\sum_{j=1}^cP_j\\Vert \\boldsymbol{m}^{(i)}-\\boldsymbol{m}^{(j)} \\Vert^2\\]定义总体均值向量为 $\\boldsymbol{m}$，即\\[\\boldsymbol{m} = \\frac{1}{n}\\sum_{i=1}^cP_i\\boldsymbol{m}_i\\]可以证明，对于第二项（类间散布）有如下两种等价表示\\[\\frac{1}{2}\\sum_{i=1}^cP_i\\sum_{j=1}^cP_j\\Vert \\boldsymbol{m}^{(i)}-\\boldsymbol{m}^{(j)} \\Vert^2 = \\sum_{i=1}^cP_i\\Vert \\boldsymbol{m}^{(i)}-\\boldsymbol{m} \\Vert^2\\]  可以将左右两边分别展开证明。这个等式在模式识别中非常重要，因为它将全局类间距离（所有类别两两比较）转换为中心距离（各类别与总体均值的距离），简化了计算。因此最终得到\\[J_d(\\boldsymbol{x}) = \\sum_{i=1}^cP_i\\left[\\frac{1}{n_i}\\sum_{k=1}^{n_i}\\Vert \\boldsymbol{x}^{(i)}_k-\\boldsymbol{m}^{(i)} \\Vert^2 + \\Vert \\boldsymbol{m}^{(i)}-\\boldsymbol{m} \\Vert^2\\right]\\]最终的可分离性判据衡量了类内紧致性和类间分离性的平衡。我们希望选择某些特征 $\\boldsymbol{x}^\\star$ 使得判据最大，即\\[J(\\boldsymbol{x}^\\star) = \\max_{\\boldsymbol{x}} J_d(\\boldsymbol{x})\\]2.1.2. 基于信息熵的可分性判据把类别 $w_i,i=1,\\cdots,c$ 看作一系列随机事件，它的发生依赖于随机向量𝒙，给定 $x$ 的后验概率 $P(w_i\\vert x)$。如果根据 $x$ 能完全确定 $w$，则 $w$ 就没有不确定性，对其本身的观察就不会再提供信息量，此时熵为 0，特征最有利于分类；如果 $x$ 完全不能确定 $w$ ，则𝜔不确定性最大，对本身的观察所提供信息量最大，此时熵为最大，特征最不利于分类。此时香浓熵定义为\\[H = -\\sum_{i=1}^cP(w_i\\vert x)\\log_2 P(w_i\\vert x)\\]平方熵（基尼系数）定义为\\[H = 2[1-\\sum_{i=1}^cP(w_i\\vert x)^2]\\]在熵的基础上，对特征的所有取值积分，就得到基于信息熵的可分性判据\\[J_E = \\int H(\\boldsymbol{x})p(\\boldsymbol{x})\\text{d}x\\]最后希望最小化该判据，判据越小可分性越好。2.2. 最优搜索理想的特征选择方法可以从给定的 $M$ 个原始特征中根据前述最优性判据，选出 $m\\leq M$ 个特征，使得判据最小。如果使用全局搜索，搜索次数为\\[C_M^m = \\frac{M!}{(M-m)!m!}\\]为了减小搜索次数，采用分支定界算法（Branch and Bound，B&amp;B），算法将所有可能的组合构成一个树状结构，按照特定的规则对树进行搜索和回溯，尽早达到最优解，而不必遍历树的所有分支。注意，分支定界法使用的前提是最优性判据必须满足单调性。  分支定界法常在运筹学的整数线性规划中被介绍。2.3. 次优搜索即使采用 B&amp;B 方法的计算量在有些情况下仍然难以接受。此时，一般会放弃最优搜索，转而使用计算量更小的次优搜索。2.3.1. 单独最优特征组合对所有 $M$ 个特征分别单独计算类别可分性判据，然后对单个特征的判据取值进行排序，选择其中前 $m$ 个单独最优的特征进行组合。这个方法有个前提，即假设单独使用时性能最优的特征，组合起来也是性能最优的。显然，在实际情况中这种假设不一定成立，即使特征是相互独立的，单独最优的特征组合也不一定是最优的。只有当判据是每个特征的判据的和或者积时，才能得到最优特征。2.3.2. 顺序后向搜索顺序后向搜索（Sequential Backward Selection, SBS）是一种贪心搜索算法，属于封装式（Wrapper）特征选择方法，通过逐步剔除最不重要的特征来优化模型性能。与顺序前向搜索（SFS）相反，SBS从完整特征集开始，每次删除一个对模型贡献最小的特征，直到达到目标特征数。显然，上述过程也是一个次优搜索过程，因为最终得到的最优特征组合，其上一步的来源并不一定是最优的特征组合。案例：基于SBS的乳腺癌分类（Wisconsin数据集）  数据：30个特征，目标预测肿瘤良恶性。  模型：SVM分类器，评估函数为5折交叉验证准确率。  SBS过程：          初始：30个特征，准确率 $95\\%$；      迭代剔除最不重要特征，每次保留使准确率下降最少的子集（此时判据直接选用分类准确率）；      终止：10个特征，准确率 $94.5\\%$（几乎无损失，但特征数减少2/3）。      2.3.3. 顺序前向搜索顺序前向搜索（Sequential Forward Selection, SFS）是一种贪心搜索算法，属于封装式（Wrapper）特征选择方法。它从空特征集开始，逐步添加对模型性能提升最大的单个特征，直到达到目标特征数或性能不再显著提高。与后向搜索（SBS）相反，SFS适用于特征数较多的场景，计算效率更高。案例：基于SFS的文本分类（TF-IDF特征）  数据：10,000 个 TF-IDF 特征（词汇表），目标为新闻分类。  模型：逻辑回归，评估函数为 5 折交叉验证 $F1$ 分数。  SFS过程：          初始：0 个特征，$F1=0$。      迭代添加使 $F1$ 提升最大的词。      终止：100 个特征，$F1=0.89$（接近全特征集的 $0.90$，但特征数减少 $99\\%$）。      2.3.4. 浮动搜索不论是顺序后向搜索还是顺序前向搜索，它们都存在一个弊端：  对于顺序后向搜索，某一个特征一旦被去掉就不会再被选中；  对于顺序前向搜索，某一个特征一旦被选中就不会再被去掉。他们都是根据局部最优准则来选取或去除特征的，很可能无法得到最优的特征组合。一种简单的改进思路就是将这两种方法结合起来，在去除或者选择过程中引入一个回溯步骤，允许被选择或者去除的特征正可以被重新选择或去除，这种技术被称为浮动搜索技术。  对于顺序后向搜索，若剔除某特征后性能下降过大，可在后续迭代中重新加入；  对于顺序前向搜索，若选择某特征后性能下降，可在后续迭代中重新去除。2.4. 启发式搜索2.4.1. 遗传算法遗传算法（Genetic Algorithm，GA）把候选对象编码为一条染色体（chromesome），在特征选择中，如果目标是从 $D$ 个特征中选择 $d$ 个，则把所有特征描述为一条由 $D$ 个二进制数（$0/1$）组成的字符串，$0$ 代表该特征没有被选中，$1$ 代表该特征被选中，这个字符串就叫做染色体，记作 $m$。显然，要求的是一条有且仅有 $d$ 个 $1$ 的染色体，这样的染色体共有 $C_8^4$ 种。 优化的目标被描述成适应度（fitness）函数，每一条染色体对应一个适应 度值 $f(m)$。可以用前面定义的两种类别可分性判据为适应度。使用遗传算法寻找最优特征组合的具体步骤如下：  初始化：          $t=0$      设定种群规模 $k$，随机初始化 $k$ 条染色体 $m_1, m_2, …, m_k$，形成初代种群 $M(t)$；      初始化交叉率、变异率、迭代次数；        遗传操作：          计算各个染色体的适应度 $f(m_i),\\;i = 1, 2, …, k$；      选择                  $t = t + 1$          根据适应度值，选择一部分染色体作为父染色体，组成初始的下一代种群 $M(t)$；          按照染色体的适应度值逐个累加形成一个区间，然后从 $[0,1]$ 区间随机选择一个数，该数落在那个区间就取哪条染色体；          这样保证适应度高的父染色体被选择的概率高；                    交叉                  遍历每两个随机染色体，根据交叉率判断是否进行交叉；          若是，从第一个父染色体中随机选取一个长度为 $l$ 的片段，记录其中值为 $1$ 的基因个数；          从第二个父染色体中寻找长度相同且与前述基因值为 $1$ 的个数相同的片段，若找到则进行交叉操作，反之则再选择一个父染色体直到遍历整个父代种群；                    变异                  遍历每一个染色体，按变异率确定是否进行变异操作；          若是，随机地选择一个基因进行反转，若该基因由 $1$ 变为了 $0$， 则再随机选一个 $0$ 变成 $1$。                      迭代：          得到最终的下一代种群 $M(t)$；      若满足迭代次数则停止迭代，输出种群中适应度最大的染色体作为特征选择结果；      否则返回遗传操作，继续迭代。      2.4.2. 模拟退火算法模拟退火算法（Simulated Annealing，SA）来源于固体退火原理，是一种基于概率的算法。算法思想为：先从一个较高的初始温度出发，逐渐降低温度，直到温度降低到满足热平衡条件为止。在每个温度下，进行 $n$ 轮搜索，每轮搜索时对旧解添加随机扰动生成新解，并按一定规则接受新解。使用模拟退火算法寻找最优特征组合的具体步骤如下：  初始化：          $t=0$      随机产生一个解 $m(t) = [0 1 1 0 0 1 0 \\cdots]$；      设定初始温度 $T = 1000$，设定退火系数 $\\alpha = 0.9$，设定退火迭代次数 $N = 1000$；        在当前温度迭代：          计算当前温度 $T = T \\times \\alpha$；      遍历 $N$ 次：                  计算解 $m(t)$ 的适应度 $f(m(t))$；          对解进行随机扰动，如选取相异的某两位翻转 $m(t^\\prime) = [0 \\textcolor{red}{0} 1 0 0 1 \\textcolor{red}{1} \\cdots]$；          计算扰动后解 $m(t^\\prime)$ 的适应度 $f(m(t^\\prime))$；          计算扰动前后评价函数的差值 $\\Delta = f(m(t^\\prime)) - f(m(t))$，假设要求评价函数越小越好；                          若 $\\Delta &lt; 0$，则接受扰动后的解 $m(t^\\prime)$ 作为新解；              若 $\\Delta \\geq 0$，则根据一定概率接受扰动后的解 $m(t^\\prime)$ 作为新解；              概率函数为：$P=\\exp(\\frac{-\\Delta}{T})$，此处参考多磁体系统或合金中多原子系统达到最低能量的退火方法；                                $t = t^\\prime$                    3. 特征提取3.1. 线性特征提取3.1.1. 线性判别分析（LDA）线性判别分析（Linear Discriminant Analysis，LDA）是一类有监督的线性特征提取算法，它的目的是选取一组最优投影方向，是的投影之后的同类样本尽可能靠近，不同类样本尽可能远离。LDA 已经在 前述章节 （模式识别 - LDA&amp;PCA - 线性判别分析）中进行了详细介绍，此处不再赘述。3.1.2. 主成分分析（PCA）主成分分析（Principal Component Analysis，PCA）是常用的特征提取数据分析方法。PCA是通过线性变换，将原始数据变换为一组各维度线性无关的数据表示方法，可用于提取数据的主要特征分量，常用于高维数据的降维。PCA 已经在 前述章节 （模式识别 - LDA&amp;PCA - 主成分分析）中进行了详细介绍，此处不再赘述。3.2. 非线性特征提取3.2.1. 核方法核方法（Kernel Method）是机器学习中一种非线性特征提取方法，它利用核函数将原始数据映射到高维空间，从而实现非线性特征提取。常用的核函数有线性核、多项式核、高斯核、拉普拉斯核以及 Sigmoid 核等。常见的用于非线性特征提取的核方法有核 Fisher 线性判别分析（KFDA）、核主成分分析（KPCA）等。关于核的详细介绍请参考 前述章节（模式识别 - 非线性分类器 - 核技巧）。3.2.2. 流形学习由于传统的线性特征提取算法（PCA、LDA）以及核方法都是试图发现数据的全局结构，对于原始空间中数据可能存在的局部信息或者低维流形结构没有给予关注，而流行学习（Manifold Learning）是基于局部性质的，旨在发现高维数据的分布规律，揭示其内在几何结构。  流形与流形学习流形是局部具有欧几里得空间性质的拓扑空间。换句话说，流形是一个可以在局部范围内近似为欧几里得空间的空间。换言之，它在局部空间有欧式空间的性质，能用欧式空间来进行距离计算。因此，很容易地在局部建立降维映射关系，然后再设法将局部关系推广到全局，进而进行可视化展示。  更加严谨地说，流形是在局部与欧氏空间同胚的空间。换言之，它在局部具有欧氏空间的性质，能用欧氏距离来进行距离计算。流形是欧几里得空间中的曲线、曲面等概念的推广。  例：地球表面就是一个二维流形的例子。尽管地球表面是一个三维空间的曲面，但是在局部范围内，地球表面看起来是平坦的（三维$\\to$二维）。意味着在小的区域内，我们可以使用二维坐标系（如纬度和经度）来描述地球表面上的点。流形学习认为，我们所能观察到的数据实际上是由一个低维流形映射到高维空间的。由于数据内部特征的限制，一些高维中的数据会产生维度上的冗余，实际上这些数据只要比较低的维度就能唯一的表示。若低维流形嵌入到高维空间中，则数据样本在高维空间的分布虽然看上去非常复杂，但在局部上仍具有欧氏空间的性质，因此，可以容易地在局部建立降维映射关系，然后再设法将局部映射关系推广到全局。当维数被降至二维或三维时，能对数据进行可视化展示，因此流形学习也可被用于可视化。流形学习在处理非线性数据结构时特别有效，它能够揭示数据背后的复杂关系，而不仅仅是通过线性变换来简化数据。流形学习的基本表述如下：设 $\\boldsymbol{Y} \\in \\mathbb{R}^d$ 是一个低维流形，映射 $f:\\boldsymbol{Y}\\to \\mathbb{R}^D$ 是一个光滑嵌入，其中 $D&gt;d$ 是高维空间。假设经过 $f$ 映射为观察空间的数据为 $\\boldsymbol{x}_i=f(\\boldsymbol{y_i})$，流形学习就是在给定 $\\boldsymbol{x}_i$ 的条件下，重构 $f$ 和 $\\boldsymbol{y}_i$。  多维多尺度变换（Multi-Dimensional Scaling，MDS）该方法的核心思想：找到一个低维空间使得样本间的距离在高维空间和低维空间基本一致，即约简后低维空间中任意两点间的距离应该与它们在原高维空间中的距离相同。所以 MDS 算法是利用样本间的相似性来保持降维后的使用效果与降维前一致。一般情况下，在低维空间可以使用欧氏距离度量样本间的相似关系，MDS 方法将其推广到高维空间，在高维空间中也采用欧氏距离度量样本间的距离。但是，直接在高维空间中计算欧式距离具有误导性，因为高维空间中的直线距离在低维嵌入流形上不可达。而低维嵌入流形上两点间的本真距离是 测地距离（geodesic distance）。两点之间的测地距离的计算，可以利用流形在局部上与欧式空间同胚这个性质，对于每个点基于欧式距离找出其最近邻点，然后就能建立一个近邻连接图，于是计算两点之间的测地距离的问题，就转变成为计算近邻连接图上两点之间的最短路径问题（Dijkstra算法）。  等度量映射（Isometric Mapping，Isomap）Isomap 方法对 MDS 方法进行了改进，通过保持数据点之间的测地距离来保留流形结构。它利用数据点之间的近邻关系建立一个连接图，并计算出数据点在流形上的近似测地距离，然后将数据映射到一个更低维空间，在此低维空间中的欧式距离和高维空间近似测地距离保持近乎一致。Isomap 的算法伪代码如下：以 Isomap 论文（A Global GEometric Framework for Nonlinear Dimensionality Reduction）中的原始例子为例，给出的数据集是 698 个 $64\\times 64$ 的同一个人的脸部图像，那么每一个图像就相当于 4096 空间中的一个坐标点，实际上这些人脸照片也是嵌入在一个流行体内，根据主观判断，我们可以得出影响人脸的因素有三个：光照方向、是否上下抬头、是否左右偏头。使用 Isomap 将数据降维到二维空间可得  横坐标：人左右偏头的程度；  纵坐标：人上下偏头的程度  滑动条：光照的方向。下图给出了 Isomap 和 PCA 降维后的残差对比。图中纵轴是残差方差，其值越小表示和原始数据越相近。横轴表示降维之后的特征维度。其中空心三角是PCA对人脸图片降维的残差方差，实心圆圈是 Isomap 对人脸图片进行降维的残差方差。可以看出 Isomap 效果要优于 PCA。观察代表isomap的曲线，当维度等于 3 的时候，方差残差下降非常快，同时在维度高于 3 之后，残差方差值变化很小。我们可以断定流行体是三维的数据点嵌入到了高维空间。另一个例子是 MNIST 手写数字识别的案例，数据集一共有 1000 个数据项，每个数据项是 $28\\times 28$ 大小的图片。将数据降维至 2 维，我们通过观察低维空间数据点代表的图像，发现有两个明显的特征：  横坐标表示数字 2 底部是否有一个环形；  纵坐标表示数字 2 顶部的歪曲角度的大小。与 PCA 方法的残差对比曲线如下图所示。  局部线性嵌入（Local Linear Embedding，LLE）lsomap 算法是全局的，它要找到所有样本的全局最优解，当数据量很大时或者样本维度很高时，计算量非常大。因此更常用的算法是局部线性嵌入，LLE 放弃所有样本全局最优的降维，只是通过保证局部最优来降维。LLE 算法的两个基本假设是：  一个流形的局部可以近似于一个欧式空间；  每个样本都可以利用其邻居进行线性重构。因此，LLE 算法通过构造样本点和它的邻域点之间的权向量，并在低维空间保持每个邻域中的权值不变来实现降维。如下图所示LLE 算法的过程如下：  设高维空间 $\\mathbb{R}^D$ 中给定样本集 $\\boldsymbol{X}=[\\boldsymbol{x}_1,\\boldsymbol{x}_2,\\dots,\\boldsymbol{x}_N],\\boldsymbol{x}_i\\in\\mathbb{R}^{D\\times 1}$，投影之后的低维流形 中的特征样本集为 $\\boldsymbol{Y} = [\\boldsymbol{y}_1,\\boldsymbol{y}_2,\\dots,\\boldsymbol{y}_N]$；      求取每个特征样本的 $k$ 个邻域点，构成邻域集 $\\boldsymbol{X}_i$\\[\\boldsymbol{X}_i = [\\boldsymbol{x}_{i}^{(1)},\\boldsymbol{x}_{i}^{(2)},\\dots,\\boldsymbol{x}_{i}^{(k)}]\\in\\mathbb{R}^{D\\times k}\\]        求取该特征样本与它的各个邻域点之间的权向量 $w_{ij}$，使得该特征样本用它的近邻点线性表示的「均方误差」最小。    为了保证解的唯一性，对权向量添加一个正则化约束，则基于均方误差来优化权向量的优化问题可表示为\\[\\min_{\\boldsymbol{w}_i} \\frac{1}{2}\\Vert \\boldsymbol{x}_i - \\sum_{j=1}^k w_{ij} \\boldsymbol{x}_{i}^{(j)} \\Vert^2\\quad s.t. \\sum_{j=1}^k w_{ij} = 1\\]    注意到，权重的优化求解是逐点独立进行的，而不是对所有样本的权重联合优化。这是LLE的核心思想之一：局部线性重构。    令\\[\\boldsymbol{w}_i = [w_{i1},w_{i2},\\dots,w_{ik}]^\\top\\in\\mathbb{R}^{k\\times 1}\\]    对目标函数变形如下\\[\\begin{aligned}  J(\\boldsymbol{w}_i) &amp;= \\frac{1}{2} \\Vert \\boldsymbol{x}_i - \\sum_{j=1}^k w_{ij} \\boldsymbol{x}_{i}^{(j)} \\Vert^2\\\\  &amp;=\\frac{1}{2} \\Vert \\boldsymbol{x}_i - \\boldsymbol{X}_{i}\\boldsymbol{w}_i \\Vert^2\\\\  &amp;= \\frac{1}{2} (\\boldsymbol{x}_i - \\boldsymbol{X}_{i}\\boldsymbol{w}_i)^\\top (\\boldsymbol{x}_i - \\boldsymbol{X}_{i}\\boldsymbol{w}_i)\\\\  &amp;= \\frac{1}{2} (\\boldsymbol{x}_i^\\top\\boldsymbol{x}_i-\\boldsymbol{x}_i^\\top\\boldsymbol{X}_{i}\\boldsymbol{w}_i -\\boldsymbol{w}_i^\\top\\boldsymbol{X}_i^\\top\\boldsymbol{x}_i + \\boldsymbol{w}_i^\\top\\boldsymbol{X}_{i}^\\top\\boldsymbol{X}_{i}\\boldsymbol{w}_i)\\\\\\end{aligned}\\]    考虑到目标函数中，第一项是常数项，不影响优化，可忽略；第二项和第三项都是标量，转置等于自身，可合并。最终有\\[J(\\boldsymbol{w}_i) = \\frac{1}{2} \\boldsymbol{w}_i^\\top\\boldsymbol{X}_{i}^\\top\\boldsymbol{X}_{i}\\boldsymbol{w}_i - \\boldsymbol{w}_i^\\top\\boldsymbol{X}_{i}^\\top\\boldsymbol{x}_i\\]    对约束条件同样进行矩阵化，有\\[\\sum_{j=1}^k w_{ij} = 1 \\Rightarrow \\boldsymbol{w}_i^\\top\\cdot \\boldsymbol{1}_{k\\times 1}=1\\]    上述问题可采用拉格朗日乘子法求解\\[L(\\boldsymbol{w}_i) =\\frac{1}{2} \\boldsymbol{w}_i^\\top\\boldsymbol{X}_{i}^\\top\\boldsymbol{X}_{i}\\boldsymbol{w}_i - \\boldsymbol{w}_i^\\top\\boldsymbol{X}_{i}^\\top\\boldsymbol{x}_i + \\lambda \\left(\\boldsymbol{w}_i^\\top\\cdot \\boldsymbol{1}_{k\\times 1}-1\\right)\\]    对 $\\boldsymbol{w}_i,\\lambda$ 求导并令导数等于零可得到\\[\\begin{cases}\\boldsymbol{X}_i^\\top \\boldsymbol{X}_i \\boldsymbol{w}_{i} - \\boldsymbol{X}_i^\\top\\boldsymbol{x}_i + \\lambda \\boldsymbol{1}_{k\\times 1} = 0\\\\\\boldsymbol{w}_i^\\top \\cdot \\boldsymbol{1}_{k\\times 1} - 1 = 0\\end{cases}\\]    解方程组，令 $\\boldsymbol{C}=\\boldsymbol{X}_i^\\top \\boldsymbol{X}_i$，有\\[\\boldsymbol{w}_i^\\star = \\frac{\\boldsymbol{C}^{-1}\\boldsymbol{1}_{k\\times 1}}{\\boldsymbol{1}_{k\\times 1}^\\top \\boldsymbol{C}^{-1}\\boldsymbol{1}_{k\\times 1}}\\]        映射到低维流形 $\\mathbb{R}^d$ 后，保持权向量不变，求 $\\boldsymbol{x}_i$ 在低维空间的映射 $\\boldsymbol{y}_i\\in\\mathbb{R}^{d\\times 1}$，使得低维重构误差最小。    同时，上述优化问题还需要满足，低维特征的每个维度均值为 0， 方差为 1。因此，针对低维映射的优化问题可表示为\\[\\begin{aligned}\\min_Y&amp; \\sum_{i=1}^N \\Vert \\boldsymbol{y}_i - \\sum_{j=1}^k w_{ij} \\boldsymbol{y}_i^{(j)} \\Vert_2^2\\\\s.t.&amp; \\sum_{i=1}^N \\boldsymbol{y}_i = 0, \\frac{1}{N}\\sum_{i=1}^N \\boldsymbol{y}_{i}\\boldsymbol{y}_{i}^\\top = \\boldsymbol{I}\\end{aligned}\\]    其中 $\\boldsymbol{y}_i^{(j)}$ 是 $\\boldsymbol{y}_i$ 的近邻点，对应高维空间中 $\\boldsymbol{x}_i^{(j)}$ 的低维映射。    将目标函数改写为矩阵形式，有\\[\\begin{aligned}J(Y) &amp;= \\Vert \\boldsymbol{Y}-\\boldsymbol{Y}\\boldsymbol{w}_i^\\star \\Vert^2_F\\\\&amp;= \\text{tr}[(\\boldsymbol{Y}-\\boldsymbol{Y}\\boldsymbol{w}_i^\\star)^\\top(\\boldsymbol{Y}-\\boldsymbol{Y}\\boldsymbol{w}_i^\\star)]\\\\&amp;=\\text{tr}[\\boldsymbol{Y}^\\top(\\boldsymbol{I}-\\boldsymbol{w}_i^\\star)^\\top(\\boldsymbol{I}-\\boldsymbol{w}_i^\\star)\\boldsymbol{Y}]\\end{aligned}\\]    定义矩阵 $\\boldsymbol{M} = (\\boldsymbol{I}-\\boldsymbol{w}_i^\\star)^\\top(\\boldsymbol{I}-\\boldsymbol{w}_i^\\star)$，则问题转化为\\[\\min_Y \\;\\text{tr}(\\boldsymbol{Y}^\\top\\boldsymbol{M}\\boldsymbol{Y})\\quad s.t. \\quad\\boldsymbol{Y}\\boldsymbol{Y}^\\top = N\\boldsymbol{I},\\quad \\sum_{i=1}^N \\boldsymbol{y}_i = 0\\]    优化问题等价于求解矩阵 $\\boldsymbol{M}$ 的最小的 $d$ 个特征值对应的特征向量（需要排除零特征值），这可以通过拉格朗日乘子法进行求解展开得到验证。需要对 $\\boldsymbol{M}$ 进行特征分解。    4. 参考文献    Cat food. 形象理解拉格朗日乘子法"
  },
  
  {
    "title": "日常tips手册（Zotero文献管理）",
    "url": "/posts/tips-zotero/",
    "categories": "Diary",
    "tags": "tips",
    "date": "2025-04-08 14:22:49 +0800",
    





    
    "snippet": "本文介绍了使用 Zotero 进行文献管理的一些方法和技巧。  1. 引言  2. 添加条目  3. 同步  4. 插件  5. 文献导出          5.1. 英文 CSL 样式      5.2. 中文 CSL 样式      5.3. 导出格式      1. 引言Zotero 是一款免费、易于使用的工具，可以帮助您收集、管理、阅读、批注、引用和共享文献。使用 Zotero 将使...",
    "content": "本文介绍了使用 Zotero 进行文献管理的一些方法和技巧。  1. 引言  2. 添加条目  3. 同步  4. 插件  5. 文献导出          5.1. 英文 CSL 样式      5.2. 中文 CSL 样式      5.3. 导出格式      1. 引言Zotero 是一款免费、易于使用的工具，可以帮助您收集、管理、阅读、批注、引用和共享文献。使用 Zotero 将使你的学术生产效率大增。其特点包括：  一键抓取文献，保存一切：当您浏览网页时，Zotero 会自动探测文献。  按你想要的方式管理文献：按照标签、作者、年份等，轻松管理文献。  用正确的样式引用文献：Zotero 可立即为任何文本编辑器创建引注和参考文献表，并内建对 Word、Latex/BibTeX 和 Google Docs 的支持。  保持同步：配合软件自带的同步或第三方软件（如坚果云）可跨设备同步您的数据，使您的文件、笔记和题录无缝保持最新。Zotero 的说明、文档、下载和生态均可在 Zotero 中文社区 查阅。2. 添加条目Zotero 按照 「条目」-「附件」的二级管理方式来管理文献。其中，条目是父项，附件是父项具体包含的 PDF、网页、Word 文档、EPub 文件等。当下载得到一篇 PDF 文献后，将其拖入 Zotero 即可完成文献导入，Zotero 会自动嗅探文献的元数据，并生成对应的条目。使用 Edge、Chrome、Firefox 等浏览器均可通过 Zotero Connector 插件直接抓取条目。以上都可以参考 Zotero 中文社区 - 抓取条目。3. 同步同步包含数据同步和文件同步。  数据的同步指 条目字段信息、批注、笔记 的同步，这些数据仅能通过 Zotero 官方提供的服务同步。无论如何，您都需要注册一个 Zotero 的官方账户，用于同步条目信息、批注以及笔记。如果您没有注册，可 快速创建一个 Zotero 账户。  文件的同步指 PDF 附件、网页附件、Word 文档、EPub 文件 等所有附件的同步。这些文件既可以通过 Zotero 官方服务同步，也可以通过 WebDAV 网盘来同步。仅推荐通过支持 WebDAV 的 坚果云网盘 进行同步，具体方法见 Zotero 中文社区 - 同步。  目前坚果云官方团队已经开发了 Zotero 的坚果云单点登录插件 Nutstore SSO，可以直接通过插件登录坚果云账户并自动配置好 WebDAV。4. 插件Zotero 的一大特色功能是支持丰富的官方和自定义插件，增强其在文献管理、文献导出等的功能。推荐安装以下插件：  Linter for Zotero  Jasminum - 茉莉花将下载得到的 .xpi 插件文件拖入 Zotero 的插件管理器中即可安装。5. 文献导出通过 Zotero 可以按照个人喜好以任意的形式导出参考文献，而无需手动一维护自己的文章或论文参考文献列表。具体操作包括但不限于：  对自己的每一篇文章/论文单独创建文件夹/分类，然后将使用到的参考文献添加到对应文件夹/分类中，最后对所有条目导出到 Word、LaTeX/BibTeX 等。  根据文章类别、作者等对文献进行分类，然后自行筛选导出到 Word、LaTeX/BibTeX 等。根据不同需求，导出文献的格式主要分为英文和中文两种样式，具体如下。5.1. 英文 CSL 样式Zotero 默认自带一系列参考文献样式，右键某一条或某写条目，选择「用所选条目创建参考文献列表...」即可选择默认的英文参考文献样式。如果没有需要的样式，可以点击下方的「管理样式」-「获取更多样式」来下载使用更多的样式。5.2. 中文 CSL 样式与英文样式类似，中文的国标样式也可以通过 「管理样式」-「获取更多样式」来获得，在样式搜索中输入「GB」既可添加中文参考文献国标规范格式样式：China National Standard GB/T 7714-2015 (author-date.中文)(2024-09-18 20:42:19)china Wational Standard GB/T 7714-2015 (note,中文)(2024-09-18 20:42:19)China National Standard GB/T 7214-2015 (numeric,中文)(2024-09-18 20:42:19)其中 author-date 为作者-年份格式（多用于社科），note 为引文格式，numeric 为数字格式（多用于理工科）。此外，Zotero 中文社区 - 样式 提供了额外的中文 CSL 样式供下载。这里提供下载的样式主要分为两类，第一类是基于 GB/T 7714-2015 标准的各类改进版，第二类是针对国内各单位/学校（包括北航）适用的 CSL 样式。下载样式使用前，请优先参阅 「安装样式文件」 以了解样式文件安装步骤和常见问题。注意，由于这些改进的 CSL 样式使用了 citeproc-js 提供了 CSL-M 扩展功能，因此安装时会出现「xxx.csl 不是一个有效的 CSL 1.0.2 样式文件，可能不能和 Zotero 一起正常工作」的警告，属于正常现象，选择「OK」即可。如果安装了 Zotero Connector 可以点击网页链接直接唤起安装，如果没有安装 Zotero Connector，则需要右键下载地址手动保存 .csl 文件，然后在 Zotero 运行的情况下双击样式文件安装。5.3. 导出格式Zotero 文献导出支持导出为 BibTeX、BibLaTeX、RIS、CSL JSON、CSL YAML、CSV 等多种格式，也支持直接输出到 RTF、HTML、剪切板等。"
  },
  
  {
    "title": "模式识别（非线性分类器）",
    "url": "/posts/Pattern-Recognition-Nonlinear-Classifier/",
    "categories": "Academic, Knowledge",
    "tags": "pattern recognition",
    "date": "2025-03-30 21:34:19 +0800",
    





    
    "snippet": "很多情况下，类别之间的分类边界并不是线性的，一种更好的选择是使用更复杂的非线性函数来描述分类。本文介绍了模式识别常用的非线性分类器，主要包括近邻法分类器（NN、KNN）、支持向量机（SVM）、决策树（DT），最后介绍分类器的集成。本章内容预计花费 4 个课时学习。  1. 引言  2. 近邻法分类器（NN / KNN）          2.1. 最近邻法      2.2. K 近邻法  ...",
    "content": "很多情况下，类别之间的分类边界并不是线性的，一种更好的选择是使用更复杂的非线性函数来描述分类。本文介绍了模式识别常用的非线性分类器，主要包括近邻法分类器（NN、KNN）、支持向量机（SVM）、决策树（DT），最后介绍分类器的集成。本章内容预计花费 4 个课时学习。  1. 引言  2. 近邻法分类器（NN / KNN）          2.1. 最近邻法      2.2. K 近邻法      2.3. KD 树      2.4. 构造 KD 树        3. 支持向量机（SVM）          3.1. 线性支持向量机                  3.1.1. 硬间隔 SVM 优化问题                          3.1.1.1. 优化问题描述              3.1.1.2. 拉格朗日乘子              3.1.1.3. 对偶问题求解                                3.1.2. 软间隔 SVM 优化问题                          3.1.2.1. 优化问题描述              3.1.2.2. 拉格朗日乘子              3.1.2.3. 对偶问题求解                                3.1.3. 统计机器学习的一般形式                    3.2. 非线性支持向量机                  3.2.1. 特征升维分类实例          3.2.2. 核技巧                          3.2.2.1. 多项式核函数              3.2.2.2. RBF 核函数                                            4. 决策树（DT）          4.1. ID3 算法                  4.1.1. 信息熵          4.1.2. 条件熵          4.1.3. 信息增益                    4.2. C4.5 算法                  4.2.1. 信息增益的局限          4.2.2. 信息增益比（增益率）                    4.3. CART 算法                  4.3.1. 基尼指数          4.3.2. CART 分类树          4.3.3. CART 回归树          4.3.4. 三种决策树构建算法区别                    4.4. 局限性与剪枝        5. 分类器集成          5.1. Bagging                  5.1.1. 随机森林                    5.2. Boosting                  5.2.1. AdaBoost          5.2.2. 加性模型与指数损失函数                    5.3. 集成表决策略      5.4. Stacking        6. 参考文献1. 引言在介绍线性分类器时，我们介绍过大多数线性分类器在样本线性可分的情况下可以取得很好的效果。但很多情况下，类别之间的分类边界并不是线性的，如果依然使用线性分类器也能勉强使用，但一种更好的选择是使用更复杂的非线性函数来描述分类。2. 近邻法分类器（NN / KNN）2.1. 最近邻法对于一个新样本，把它逐一与已知样本进行比较，找出距离新样本最近的已知样本，并以该样本的类别作为新样本的类别。其严格的数学描述如下：假定有 $c$ 个类别的模式识别问题，每类包含样本个数为 $N_i,i=1,2,\\cdots,c$。定义两个样本之间的距离度量 $\\delta(\\boldsymbol{x_i},\\boldsymbol{x_j})$（比如可以采用欧式距离 $\\delta(\\boldsymbol{x_i},\\boldsymbol{x_j})=\\Vert \\boldsymbol{x_i} - \\boldsymbol{x_j} \\Vert$），则对于任意未知新样本 $\\boldsymbol{x}$，可以规定类 $w_i$ 的判别函数为：\\[g_i(\\boldsymbol{x}) = \\min_k \\delta(\\boldsymbol{x}, \\boldsymbol{x_i}^{(k)}), \\; k =1,2,\\cdots,N_i\\]其中 $\\boldsymbol{x}_k$ 是类别 $w_i$ 中的第 $k$ 个样本。对于每个类别都求出其判别函数，那么决策规则为\\[\\boldsymbol{x}\\in w_i\\quad\\text{if}\\quad i=\\arg\\min_i g_i(\\boldsymbol{x}),\\; i=1,2,\\cdots,c\\]可以看出，最近邻法的思想很简单，新样本离谁最近，就把新样本判为最近的样本所属的类别。但在很多情况下，把决策建立在一个最近的样本上有一定风险，尤其是当数据分布复杂或数据中噪声严重时。如下图所示：图中，黄色圆点为新样本（已知其为蓝色类别），但其最近邻为红色圆点样本。很明显，该红色样本是一个野值，其深入到了蓝色样本所属类别的区域。如果以最近邻的类别作为新样本的类别，那么显会导致分类错误。为了更严格地分析最近邻法的错误率，我们需要进行一定的数学推导。当近邻法中训练样本的数量无限多（$N\\rightarrow \\infty$）时，某待分类的未知样本 $\\boldsymbol{x}$ 的最近邻在极限意义上就是其自身，此时最近邻法分类正确的条件为：样本与它最近邻都属于同一类别。即分类正确率为\\[\\sum_{i=1}^c P(w_i\\vert \\boldsymbol{x})P(w_i\\vert \\boldsymbol{x}) = \\sum_{i=1}^c P(w_i\\vert \\boldsymbol{x})^2\\]对应的错误率为\\[\\lim_{N\\rightarrow\\infty} P_N(e\\vert \\boldsymbol{x}) = 1 - \\sum_{i=1}^c P(w_i\\vert \\boldsymbol{x})^2\\]则平均错误率为\\[\\begin{aligned}P &amp;= \\lim_{N\\rightarrow \\infty}P(e) =\\lim_{N\\rightarrow \\infty} \\int P_N(e\\vert \\boldsymbol{x})p(\\boldsymbol{x})\\text{d}x\\\\&amp;= \\int \\lim_{N\\rightarrow \\infty} P_N(e\\vert \\boldsymbol{x})p(\\boldsymbol{x})\\text{d}x\\\\&amp;= \\int \\left(1 - \\sum_{i=1}^c P(w_i\\vert \\boldsymbol{x})^2\\right)p(\\boldsymbol{x})\\text{d}x\\end{aligned}\\]$P$ 又被称为最近邻法的渐进平均错误率，是 $P_N(e)$ 在 $N\\rightarrow \\infty$ 的极限。为了更进一步了解最近邻法错误率的上界和下界，我们可以将其和理论上具备最优错误率的贝叶斯错误率进行比较。已知 $c$ 分类问题的贝叶斯错误率为\\[P^\\star = \\int[1- \\max_i P(w_i \\vert \\boldsymbol{x})]p(\\boldsymbol{x})\\text{d}x,\\; i=1,2,\\cdots,c\\]记 $m = \\arg\\max_i P(w_i\\vert \\boldsymbol{x})$，则\\[P^\\star = \\int[1- P(w_m\\vert \\boldsymbol{x})]p(\\boldsymbol{x})\\text{d}x\\]因此，比较最近邻错误率和贝叶斯错误率的关键在于衡量以下两者的大小关系：\\[P(w_m\\vert \\boldsymbol{x}) \\quad \\text{和} \\quad \\sum_{i=1}^c P(w_i\\vert \\boldsymbol{x})^2\\]二者作差\\[\\begin{aligned}P(w_m\\vert x) - \\sum_{i=1}^c P(w_i\\vert x)^2 &amp;= P(w_m\\vert x) -P(w_m\\vert x)^2 - \\sum_{i\\neq m} P(w_i\\vert x)^2\\\\&amp;= P(w_m\\vert x)(1-P(w_m\\vert x)) - \\sum_{i\\neq m} P(w_i\\vert x)^2\\\\&amp;= P(w_m\\vert x)\\sum_{i\\neq m} P(w_i\\vert x) - \\sum_{i\\neq m} P(w_i\\vert x)^2\\\\&amp;= \\sum_{i\\neq m} P(w_i\\vert x)[P(w_m\\vert x) - P(w_i\\vert x)]\\\\&amp;\\geq 0\\end{aligned}\\]至此我们确定了最近邻法的错误率下界为贝叶斯错误率，即\\[P^\\star \\leq P\\]为了求得最近邻法的错误率上界，需要借助柯西-施瓦茨不等式。  柯西-施瓦茨不等式：对于任意两个实值随机变量 $a$ 和 $b$，有\\[\\left( \\sum_{i=1}^n a_ib_i \\right)^2 \\leq \\sum_{i=1}^n a_i^2 \\sum_{i=1}^n b_i^2\\]  推论为\\[n\\sum_{i=1}^n a_i^2 \\geq \\left( \\sum_{i=1}^n a_i \\right)^2\\]对于最近邻错误率有\\[\\begin{aligned}\\sum_{i\\neq m} P(w_i\\vert x)^2 &amp;\\geq \\frac{1}{c-1}\\left(\\sum_{i\\neq m} P(w_i\\vert x)\\right)^2\\\\&amp;= \\frac{1}{c-1}\\left(1 - P(w_m\\vert x)\\right)^2\\end{aligned}\\]左右两边同时补上 $P(w_m\\vert x)^2$ 有\\[\\begin{aligned}\\sum_{\\textcolor{red}{i=1}}^c P(w_i\\vert x)^2 &amp;\\geq \\frac{1}{c-1}\\left(1 - P(w_m\\vert x)\\right)^2 + \\textcolor{red}{P(w_m\\vert x)^2}\\\\\\textcolor{green}{1 - }\\sum_{i=1}^c P(w_i\\vert x)^2 &amp;\\textcolor{green}{\\leq 1 - }\\frac{1}{c-1}\\left(1 - P(w_m\\vert x)\\right)^2 + \\textcolor{red}{[1-(1-P(w_m\\vert x))]^2}\\end{aligned}\\tag{1}\\]将上式右侧展开有\\[\\begin{aligned}&amp;1-\\frac{1}{c-1}\\left(1 - P(w_m\\vert x)\\right)^2 - [1-(1-P(w_m\\vert x))]^2\\\\=&amp; 1 - \\frac{1}{c-1}\\left(1 - P(w_m\\vert x)\\right)^2 -[1-2(1-P(w_m\\vert x)) + (1-P(w_m\\vert x))^2]\\\\=&amp; 1 - \\frac{1}{c-1}\\left(1 - P(w_m\\vert x)\\right)^2 - 1 + 2(1-P(w_m\\vert x)) - (1-P(w_m\\vert x))^2\\\\=&amp; (-\\frac{1}{c-1}-1)\\left(1 - P(w_m\\vert x)\\right)^2 + 2(1-P(w_m\\vert x))\\\\=&amp; (1-P(w_m\\vert x))[2-(1+\\frac{1}{c-1})(1-P(w_m\\vert x))]\\\\=&amp; (1-P(w_m\\vert x))\\left[2-\\frac{c}{c-1}(1-P(w_m\\vert x))\\right]\\\\\\end{aligned}\\tag{2}\\]将式（2）代回式（1），左右同时积分有\\[\\begin{aligned}1-\\sum_{i=1}^c P(w_i\\vert x)^2 &amp;\\leq (1-P(w_m\\vert x))\\left[2-\\frac{c}{c-1}(1-P(w_m\\vert x))\\right]\\\\\\int \\left(1-\\sum_{i=1}^c P(w_i\\vert x)^2\\right)p(x)\\text{d}x &amp;\\leq \\int [1-P(w_m\\vert x)]p(x)\\text{d}x\\left[2-\\frac{c}{c-1}\\int [1-P(w_m\\vert x)]\\text{d}x\\right]\\\\\\end{aligned}\\]因此我们得到最近邻法的错误率上界为\\[P \\leq P^\\star \\left[2-\\frac{c}{c-1}P^\\star\\right]\\]经过数学推导可知，最近邻的渐进错误率最坏不会超过两倍的贝叶斯错误率，而最好则有可能接近或达到贝叶斯错误率。最后分析等号成立的条件，即最近邻法的错误率等于贝叶斯错误率的条件。      对于下界，当且仅当 $P(w_m\\vert x) = P(w_i\\vert x)$ 时取到等号，此时 $P(w_m\\vert x) = P(w_i\\vert x) = 1/c$，即所有类别的后验概率相等，不管是最近邻分类器还是贝叶斯分类器都相当于瞎猜，二者因此错误率都一样。        对于上界，当且仅当 $P(w_m\\vert x) = 1$ 时取到等号，此时 $P(w_m\\vert x) = 1$，即后验概率最大的类别的后验概率为 1，表明样本全为某一类，此时贝叶斯分类器和最近邻分类器都能 100% 做出正确决策。  2.2. K 近邻法为了解决最近邻法容易受到噪声和野值影响的问题，简单且符合直觉的想法是可以考虑使用 $k$ 近邻法，即找出距离新样本最近的 $k$ 个样本，然后以这 $k$ 个样本中出现次数最多的类别作为新样本的类别。根据 $k$ 值选取的不同，可做出如下讨论：  $k$ 值越小，模型复杂度越高，容易发生过拟合。极端情况 $k=1$ 退化为最近邻法，如果恰好遇到噪声，就会完全错误；随着 $k$ 值增大，模型泛化能力也增大，但丢失的信息也增多。$k$ 值的增大就意味着整体的模型变得简单；  $k=N$，则任意新输入样例的分类就等于训练样例中样本数最多的分类，此时无论输入样本是什么，都只是简单的预测它属于在训练样本中最多的类。对于 $k$ 近邻法，其错误率的上界和下界与最近邻法类似，但是 $k$ 近邻法的错误率上界和下界都比最近邻法的要好。$k$ 近邻法的特点概括如下：  优点：可以解决几乎所有分类问题，概念简单未经优化，分类器设计容易，且错误率并不高；  缺点：计算量大，内存开销大，特别依赖快速搜索算法。2.3. KD 树K-近邻算法是机器学习中最简单的算法之一，如果训练样本过大，则传统的遍历全样本寻找 K-近邻的方式将导致性能的急剧下降。为了优化效率，不同的训练数据存储结构被纳入到实现方式之中。KD 树（K-Dimension Tree）是一种对 $k$ 维空间中的实例点进行存储以便对其进行快速检索的树形数据结构，主要用于高效地组织和搜索多维空间中的点。2.4. 构造 KD 树构造 KD 树相当于不断地用垂直于坐标轴的超平面将 $k$ 维空间切分，构成一系列的 $k$ 维超矩形区域。KD 树的每个节点对应于一个 $k$ 维超矩形区域。通常，依次选择坐标轴对空间划分，选择训练样本点在选定坐标轴上的中位数为切分点，这样得到的 KD 树是是平衡的。以样本 $a = {(2,3)^\\top,(5,4)^\\top,(9,6)^\\top,(4,7)^\\top,(8,1)^\\top,(7,2)^\\top }$ 为例，构造 KD 树的过程如下：  计算方差，选择方差最大的维度开始，本例中为 $x$ 轴，之后按照维度顺序进行切分。有时为了简便起见，直接按照维度顺序切分而不计算方差；  选择 $x$ 轴，对 $a$ 中的样本按照 $x$ 轴坐标进行排序，得到 $a_x = {(2,3)^\\top,(4,7)^\\top,(5,4)^\\top,(7,2)^\\top,(8,1)^\\top,(9,6)^\\top }$，选择中位数 $m = (5,4)^\\top$ 作为切分点，得到左右子树 $a_{x_l} = {(2,3)^\\top,(4,7)^\\top,(7,2)^\\top }$ 和 $a_{x_r} = {(8,1)^\\top,(9,6)^\\top }$；  选择 $y$ 轴，对 $a_{x_l}$ 中的样本按照 $y$ 轴坐标进行排序，得到 $a_{x_l,y} = {(2,3)^\\top,(7,2)^\\top,(4,7)^\\top }$，选择中位数 $m = (7,2)^\\top$ 作为切分点，得到左右子树 $a_{x_l,y_l} = {(2,3)^\\top }$ 和 $a_{x_l,y_r} = {(4,7)^\\top }$；  如此循环直至所有样本都被划分到叶子节点。得到的划分如下图所示。形成的 KD 树如下图所示。完成 KD 树的构建只是第一步，接下来需要对 KD 树进行搜索。查询时，从根节点开始，沿着与查询点在当前维度上最接近的方向遍历树。到达叶子节点或分裂超平面时，会检查另一个子空间是否有更近的点，这依赖于当前点到查询点的距离和超平面的距离。这一过程重复，直到找到最近的点或达到预定的搜索深度。进行最近邻搜索时，KD 树利用其结构减少搜索空间，具体步骤如下：  从根节点出发，根据构造 KD 树时的切分规则（切分维度顺序和左小右大），递归地向下访问 KD 树的节点，直到到达叶子节点；  跟踪最近点：记录遍历过程中遇到的最近点，并在每个节点处计算是否可能存在更近的点在另一侧的子树中；  回溯：递归地向上回退，检查每个节点的另一侧是否可能存在更近的点，直到整个树都被搜索完毕。对于上述实例，如果查询点为 $(2,4.5)^\\top$，则搜索过程如下：  找寻最近点：          从根节点开始，根据 $x$ 轴坐标，查询点 $(2,4.5)^\\top$ 在 $x$ 轴上小于 $(7,2)^\\top$，因此向左子树搜索；      在左子树中，根据 $y$ 轴坐标，查询点 $(2,4.5)^\\top$ 在 $y$ 轴上大于 $(5,4)^\\top$，因此向右子树搜索；      在右子树中，查询点 $(2,4.5)^\\top$ 的最近点为 $(4,7)^\\top$，计算二者距离为 $3.2$；        回溯：          回溯上层 $(5,4)^\\top$，计算距离为 $3.04$，比 $(4,7)^\\top$ 更近，更新最近点为 $(5,4)^\\top$；      以 $3.04$ 做圆；此圆与 $(5,4)^\\top$ 所切分的上下两个平面相交，需要检查$(5,4)^\\top$ 的另外侧；      $(5,4)^\\top$ 的另一侧子节点为 $(2,3)^\\top$ ，与之距离为 $1.5$，更新最近点为 $(2,3)^\\top$；      由于 $(2,3)^\\top$ 为叶子节点，回溯至 $(7,2)^\\top$，确认与 $(7,2)^\\top$ 切分的右子平面无关；      抵达根节点，回溯结束。最终确定最近点为 $(2,3)^\\top$。      进一步，给出使用 KD 树进行 K 近邻搜索的伪代码：  输入查询节点 $x$；  创建 $k$ 个元素的空列表 $L$，用于存储 $x$ 的最近邻点和相应距离；  （1） 根据 $x$ 的坐标和当前节点切分规则（左小右大）向下搜索；  （2） 到达底部节点，将其标记为访问过，如果 $L$ 中有空位且叶子节点与 $x$ 的距离小于 $L$ 中的最大值，则用叶子节点替换其中距离最大值对应节点；  （3） 如果当前节点不是根节点，执行 （4）；反之，输出 $L$ 算法结束；  （4） 向上回溯一个节点，抵达 $p$。如果 $p$ 未被访问过，将其标记为访问过，并执行后续子步骤；如果访问过，则再次执行 （4）；          （a） 如果 $L$ 有空位，则将 $p$ 加入 $L$；反之，如果 $L$ 已满 但 $p$ 与 $x$ 的距离小于 $L$ 中的最大值，则用 $p$ 替换 $L$ 中的最大值；      （b） 计算 $x$ 与 $p$ 的切分线的距离，记为 $d$；如果 $d$ 小于 $L$ 中的最大值，或者 $L$ 中有空位，则访问 $p$ 的另一侧子节点，回到 （1） 执行；反之，如果 $d$ 大于 $L$ 中的最大值且$L$ 已满，则切分线另一边不会有更近的点，返回 （3）。      KD 树的缺点：  维度诅咒：随着维度的增加，KD树的效率急剧下降。这是因为高维空间中，数据点间的距离变得非常相似，难以通过简单的分割有效区分，这种现象被称为“维度诅咒”。  平衡问题：KD树的性能对分割轴的选择很敏感，如果数据分布不均匀或者选择的分割策略不当，容易导致树的不平衡，进而影响搜索效率。尽管有一些平衡策略，但完全避免不平衡较难。  维护成本：在动态数据集中，频繁的插入和删除操作可能导致KD树结构失衡，需要花费额外的时间来重新平衡树，这可能抵消掉一部分查询效率的优势。  不适合高度倾斜或复杂数据分布：当数据分布呈现高度偏斜或具有复杂模式时，简单地按照中位数分割可能不是最优选择，这会导致搜索效率降低。在这种情况下，更复杂的树结构，如球树（Ball Tree）或覆盖树（Cover Tree），可能提供更好的性能。3. 支持向量机（SVM）支持向量机（Support Vector Machines，SVM）被提出于1964年，20世纪90年代后得到快速发展，并衍生出一系列改进和扩展算法。在解决小样本情况下的机器学习问题和高维、非线性问题中表现出较为优异的效果。SVM 是基于线性可分的最优分类面提出的，最优分类面的定义保证了在样本一定的情况下，两类样本间的距离最大。注意到，截至目前讨论的 SVM 似乎表现为一个线性分类器而不是非线性分类器，但后面会介绍到，SVM 的非线性分类能力是通过引入核函数来实现的。3.1. 线性支持向量机前面介绍线性分类器时，我们介绍了感知准则，并提到了线性可分性的概念。假设 $D_0$ 和 $D_1$ 是 $n$ 维欧式空间中的两个点集，$D_0$ 和 $D_1$ 线性可分的条件是存在一个超平面 $H$，使得 $D_0$ 和 $D_1$ 分别位于超平面的两侧。即存在一个向量 $\\boldsymbol{w}$ 和一个标量 $b$，使得对于任意的 $\\boldsymbol{x}_1\\in D_0$ 和 $\\boldsymbol{x}_2\\in D_1$，都有：\\[\\begin{aligned}\\boldsymbol{w}^\\top \\boldsymbol{x}_1 + b &amp;&gt; 0,\\; \\boldsymbol{x}_1\\in D_0\\\\\\boldsymbol{w}^\\top \\boldsymbol{x}_2 + b &amp;&lt; 0,\\; \\boldsymbol{x}_2\\in D_1\\end{aligned}\\]对于线性可分的样本，感知准则可以找到一个超平面将两类样本完全分开，但并不能保证该超平面是最优的。SVM 可以看作感知准则的一种改进，SVM 的目标是找到一个超平面将两类样本分开，并且使得两类样本到超平面的距离最（标量）大，从而引入了某种最优性。3.1.1. 硬间隔 SVM 优化问题3.1.1.1. 优化问题描述以二分类为例，假设样本集为 $S={(\\boldsymbol{x}_1,y_1),(\\boldsymbol{x}_2,y_2),\\cdots,(\\boldsymbol{x}_N,y_N)}$，其中 $\\boldsymbol{x_i}$ 是样本，$y_i$ 是样本的类别标签（取值为 $\\pm 1$）。假设样本集线性可分，存在一个超平面 $H$ 将两类样本完全分开。假设超平面 $H$ 的法向量为 $\\boldsymbol{w}$，超平面到原点的距离为 $b$，则超平面可以表示为：\\[\\boldsymbol{w}^\\top \\boldsymbol{x} + b = 0\\]那么判别函数可写为\\[\\begin{cases}  \\boldsymbol{w}^\\top \\boldsymbol{x_i} + b &gt; 0, y = 1\\\\  \\boldsymbol{w}^\\top \\boldsymbol{x_i} + b &lt; 0, y= -1\\end{cases}\\]合并为简单形式，则线性可分的条件为\\[y_i(\\boldsymbol{w}^\\top\\boldsymbol{x_i}+b) \\geq 0, \\forall i=1,2,\\cdots,N\\]根据前述 SVM 目标，我们希望求解如下优化问题：\\[\\begin{aligned}\\max_{\\boldsymbol{w},b} &amp;\\quad \\text{margin} (\\boldsymbol{w},b)\\\\  s.t. &amp;\\quad  y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) &gt; 0, \\forall i=1,2,\\cdots,N\\end{aligned}\\]上述优化问题中唯一不确定的地方就是间隔（margin）的定义。间隔被定义为样本中离决策面最近的那些样本到决策面的距离。设 $d_i$ 为样本 $\\boldsymbol{x_i}$ 到超平面的距离（标量），则有：\\[d_i = \\frac{\\vert \\boldsymbol{w}^\\top \\boldsymbol{x_i} + b\\vert}{\\Vert \\boldsymbol{w} \\Vert}\\]那么间隔定义为\\[\\text{margin}(\\boldsymbol{w},b) = \\min_{i} d_i\\]则 SVM 的优化问题变为\\[\\begin{aligned}\\max_{\\boldsymbol{w},b}  \\min_{i} &amp;\\quad\\frac{\\vert \\boldsymbol{w}^\\top \\boldsymbol{x_i} + b\\vert}{\\Vert \\boldsymbol{w} \\Vert}\\\\  s.t. &amp;\\quad  y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) &gt; 0, \\forall i=1,2,\\cdots,N\\end{aligned}\\]注意到，约束条件表明 $y_i$ 和 $\\boldsymbol{w}\\boldsymbol{x_i}+b$ 同号且二者相乘恒大于零，那么可安全地将优化目标函数的绝对值打开，得到\\[\\begin{aligned}\\max_{\\boldsymbol{w},b} \\min_{i} &amp;\\quad\\frac{\\textcolor{green}{y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i} + b)}}{\\Vert \\boldsymbol{w} \\Vert}\\\\s.t. &amp;\\quad  y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) &gt; 0, \\forall i=1,2,\\cdots,N\\end{aligned}\\]观察优化目标函数中，不同优化方向的作用对象，可移项如下\\[\\begin{aligned}\\max_{\\boldsymbol{w},b}&amp;\\; \\textcolor{green}{\\frac{1}{\\Vert \\boldsymbol{w} \\Vert}} \\; \\min_{i} \\; y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i} + b)\\\\s.t. &amp;\\quad  y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) &gt; 0, \\forall i=1,2,\\cdots,N\\\\\\end{aligned}\\]既然约束条件要求 $y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) &gt; 0$，那么一定有\\[\\exists \\gamma &gt; 0,\\; \\min_i y_i(\\boldsymbol{w}^\\top\\boldsymbol{x_i}+b) =\\gamma\\]此处 $\\gamma$ 被称为 函数间隔。引入函数间隔后，优化问题变为如下形式\\[\\begin{aligned}\\max_{\\boldsymbol{w},b}&amp;\\; \\frac{1}{\\Vert \\boldsymbol{w} \\Vert} \\; \\min_{i} \\; y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i} + b)\\\\s.t. &amp;\\quad  y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) \\textcolor{red}{\\geq \\gamma}, \\forall i=1,2,\\cdots,N\\\\\\text{or}\\quad s.t.\\quad \\textcolor{green}{\\min_i}&amp;\\quad  \\textcolor{green}{y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) = \\gamma}, \\forall i=1,2,\\cdots,N\\end{aligned}\\]注意到，绿色的等式约束条件和原始的不等式约束条件是等价的。将绿色的等价等式约束条件代入目标函数，消去 $\\min_i$ 项，有\\[\\begin{aligned}\\max_{\\boldsymbol{w},b}&amp;\\quad \\frac{\\textcolor{red}{\\gamma}}{\\Vert \\boldsymbol{w} \\Vert}\\\\s.t. &amp;\\quad  y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) \\textcolor{red}{\\geq \\gamma}, \\forall i=1,2,\\cdots,N\\end{aligned}\\]注意到当 $\\boldsymbol{w},b$ 发生变化（如分别扩大两倍）也会导致函数间隔发生变化（同样扩大两倍）。虽然这种操作不会改变最优解，但会产生一个等价的优化问题。为了避免这种情况，不妨令 $\\gamma = 1$，优化问题变为\\[\\begin{aligned}\\max_{\\boldsymbol{w},b}&amp;\\quad \\frac{1}{\\Vert \\boldsymbol{w} \\Vert}\\\\s.t. &amp;\\quad  y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) \\geq 1, \\forall i=1,2,\\cdots,N\\end{aligned}\\]  这一事实给了我们另一个启示，我们应该对法向量 $\\boldsymbol{w}$ 加一个约束，使得间隔固定不变，此时的间隔为 几何间隔。最后，利用如下等价性\\[\\max_{\\boldsymbol{w},b} \\frac{1}{\\Vert \\boldsymbol{w}\\Vert} = \\min_{\\boldsymbol{w},b} \\Vert \\boldsymbol{w}\\Vert^2 = \\frac{1}{2}\\min_{\\boldsymbol{w},b} \\boldsymbol{w}^\\top \\boldsymbol{w}\\]得到最终的 SVM 优化问题的描述\\[\\begin{aligned}\\textcolor{blue}{\\min_{\\boldsymbol{w},b}} &amp;\\quad \\textcolor{blue}{\\frac{1}{2} \\boldsymbol{w}^\\top \\boldsymbol{w}}\\\\\\textcolor{blue}{s.t.} &amp;\\textcolor{blue}{\\quad  y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) \\geq 1, \\forall i=1,2,\\cdots,N}\\end{aligned}\\]上述优化问题是一个包含 $N$ 个不等式约束的二次凸优化问题。对于线性可分的样本，所有样本一定能够满足上面的不等式约束，也即所有样本都可以位于间隔的两侧，不存在错分的情况，所以上述优化问题一定有解。我们称上述优化问题为 硬间隔 SVM 优化问题。对应的图示如下3.1.1.2. 拉格朗日乘子对于一个带约束的优化问题，采用拉格朗日乘子法转化为一个无约束优化问题，拉格朗日函数如下\\[\\textcolor{blue}{L(\\boldsymbol{w},b,\\lambda) = \\frac{1}{2}\\boldsymbol{w}^\\top\\boldsymbol{w} + \\sum_{i=1}^N\\lambda_i(1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b)),\\; \\lambda_i \\geq 0}\\]优化问题变为\\[\\begin{aligned}\\textcolor{blue}{\\min_{w,b}}\\quad &amp; \\textcolor{blue}{\\max_\\lambda L(\\boldsymbol{w},b,\\lambda)}\\\\\\textcolor{blue}{s.t.} &amp; \\quad \\textcolor{blue}{\\lambda_i \\geq 0, \\forall i=1,2,\\cdots,N}\\\\\\end{aligned}\\]拉格朗日乘子法变换后的优化问题与原始优化问题的等价性可分析如下：定义 $\\delta = 1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b)$，SVM 优化问题的约束条件变为\\[\\delta_i \\leq 0\\]整个 $(\\boldsymbol{w},b)$ 空间可划分为两个部分，不满足约束（$\\delta &gt; 0$）和满足约束（$\\delta \\leq 0$）。  对于 $\\delta &gt; 0$，约束被违反，可以取 $\\lambda \\to \\infty$ 使得优化目标\\[\\max_\\lambda L(\\boldsymbol{w},b,\\lambda) =  \\frac{1}{2}\\boldsymbol{w}^\\top\\boldsymbol{w} + \\infty = +\\infty\\]  对于 $\\delta \\leq 0$，约束被满足，可以取$\\lambda = 0$ 使得优化目标取到最大值\\[\\max_\\lambda L(\\boldsymbol{w},b,\\lambda) =  \\frac{1}{2}\\boldsymbol{w}^\\top\\boldsymbol{w} + 0 = \\frac{1}{2}\\boldsymbol{w}^\\top\\boldsymbol{w}\\]综上两种情况，拉格朗日乘子法的优化问题可以写为\\[\\min_{w,b}\\max_\\lambda L(\\boldsymbol{w},b,\\lambda) = \\min_{w,b} [+\\infty,\\;\\frac{1}{2}\\boldsymbol{w}^\\top\\boldsymbol{w}] = \\min_{w,b} \\frac{1}{2}\\boldsymbol{w}^\\top\\boldsymbol{w}\\]也即与原始优化问题等价，其中外层 $\\min_{w,b}$ 会自动忽略不满足约束（$\\delta &gt; 0$）的解。3.1.1.3. 对偶问题求解上述优化问题的 对偶问题 为（交换 $\\max$ 与 $\\min$）\\[\\begin{aligned}\\textcolor{blue}{\\max_\\lambda \\min_{w,b}} &amp;\\quad \\textcolor{blue}{L(\\boldsymbol{w},b,\\lambda)}\\\\\\textcolor{blue}{s.t.} &amp;\\quad \\textcolor{blue}{\\lambda_i \\geq 0, \\forall i=1,2,\\cdots,N}\\end{aligned}\\]  关于为何 SVM 要引入原问题的对偶问题，是因为：      支持向量的稀疏性：    在对偶问题中，拉格朗日乘子 $\\lambda_i$ 只有在支持向量上才会非零，而支持向量的数量通常远小于总样本数。这意味着在分类时，只需要计算支持向量与查询点的内积，大大减少了计算量。      高维空间的计算效率：    如果直接求解原问题，分类时需要计算 $w^\\top x$，其中 $w$ 是一个高维向量（维度为 $d$）。而在对偶问题中，分类只需要计算支持向量与查询点的内积 $\\sum \\lambda_i y_i \\langle \\boldsymbol{x_i}, x \\rangle$，这可以通过核函数高效完成，避免直接处理高维向量。      核函数的引入：    对偶问题的形式天然适合引入核函数，将数据映射到高维空间进行非线性分类，而无需显式计算高维空间中的坐标。这是 SVM 能够处理非线性问题的关键。注意原问题和对偶问题存在如下关系\\[\\min_{w,b}\\max_\\lambda L(\\boldsymbol{w},b,\\lambda) \\geq \\max_\\lambda \\min_{w,b} L(\\boldsymbol{w},b,\\lambda)\\]在优化理论中，原始问题（Primal Problem）和对偶问题（Dual Problem）之间存在一定的关系，而 KKT（Karush-Kuhn-Tucker）条件 是连接两者的桥梁。对于支持向量机（SVM）的优化问题，原始问题和对偶问题之间满足 弱对偶性（Weak Duality），而在一定条件下（如凸优化+Slater条件），它们还满足 强对偶性（Strong Duality），即原始问题的最优值等于对偶问题的最优值。此时，KKT条件成为取等号的充要条件。  KKT 条件，$\\forall i=1,2,\\cdots,N$，有\\[\\begin{aligned}\\frac{\\partial L}{\\partial w} = 0,\\frac{\\partial L}{\\partial b} = 0,\\frac{\\partial L}{\\partial \\lambda} = 0\\quad \\text{梯度可行性}\\\\\\lambda_i(1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b))=0\\quad \\text{互补松弛性}\\\\\\lambda_i \\geq 0\\quad \\text{对偶可行性}\\\\1-y_i(\\boldsymbol{w}^\\top x + b)\\leq 0\\quad \\text{原始可行性}\\\\\\end{aligned}\\]求解此对偶问题，根据梯度可行性条件，目标函数首先对 $b$ 求偏导令其为零，有\\[\\frac{\\partial L}{\\partial b} = 0\\Rightarrow \\sum_{i=1}^N\\lambda_i y_i = 0\\\\\\]将其代入目标函数进行化简，有\\[\\begin{aligned}L(\\boldsymbol{w},b,\\lambda) &amp;= \\frac{1}{2}\\boldsymbol{w}^\\top\\boldsymbol{w} + \\sum_{i=1}^N\\lambda_i(1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b))\\\\&amp;= \\frac{1}{2}\\boldsymbol{w}^\\top\\boldsymbol{w} + \\sum_{i=1}^N \\lambda_i - \\sum_{i=1}^N \\lambda_i y_i w^\\top \\boldsymbol{x_i}\\end{aligned}\\]简化后的目标函数对 $w$ 求偏导令其为零，得到最优参数 $\\boldsymbol{w}^\\star$ 的形式\\[\\frac{\\partial L}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} - \\sum_{i=1}^N \\lambda_i y_i \\boldsymbol{x_i} = 0\\Rightarrow \\boldsymbol{w}^\\star= \\sum_{i=1}^N \\lambda_i y_i \\boldsymbol{x_i}\\]将其代入目标函数进行进一步化简，有\\[\\begin{aligned}L(\\boldsymbol{w},b,\\lambda) =&amp; \\frac{1}{2}(\\sum_{i=1}^N\\lambda_i y_i \\boldsymbol{x_i})^\\top (\\sum_{i=j}^N\\lambda_j y_j \\boldsymbol{x_j})+ \\sum_{i=1}^N \\lambda_i\\\\&amp; - \\sum_{i=1}^N \\lambda_i y_i (\\sum_{i=j}^N \\lambda_j y_j \\boldsymbol{x_j})^\\top \\boldsymbol{x_i}\\\\=&amp;\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N \\lambda_i \\lambda_j y_i y_j \\boldsymbol{x_i}^\\top \\boldsymbol{x_j} + \\sum_{i=1}^N \\lambda_i\\\\&amp; - \\sum_{i=1}^N\\sum_{j=1}^N \\lambda_i \\lambda_j y_i y_j \\boldsymbol{x_j}^\\top \\boldsymbol{x_i}\\\\=&amp; -\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N \\lambda_i \\lambda_j y_i y_j \\boldsymbol{x_i}^\\top \\boldsymbol{x_j} + \\sum_{i=1}^N \\lambda_i\\end{aligned}\\]至此我们根据 KKT 条件中的梯度可行性条件，得到了 $w^\\star$ 的形式，并对目标函数进行了化简。下面继续根据 KKT 条件中的互补松弛条件、对偶可行条件、原始可行条件，确定最优参数 $b^\\star$ 的形式\\[\\begin{aligned}\\lambda_i(1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b))=0\\\\\\lambda_i \\geq 0\\\\1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x}_i + b)\\leq 0\\\\\\end{aligned}\\]对于第 $k$ 个样本 $(\\boldsymbol{x}_k, y_k)$ 的原始可行性条件分类讨论如下：      第一种情况，样本使得 $y_i(\\boldsymbol{w}^\\top \\boldsymbol{x} + b) = 1$    这个样本点就是距离分类面最近的那些样本点，被称为 支持向量（Support Vector）。此时对 $\\lambda_i$ 没有额外约束。因此我们通过 选择任意一个支持向量 可以求出 $b^\\star$\\[\\begin{aligned}y_k(\\boldsymbol{w}^\\top \\boldsymbol{x}_k + b) &amp;= 1\\\\\\Rightarrow y_k^2(\\boldsymbol{w}^\\top \\boldsymbol{x}_k + b) &amp;= y_k\\end{aligned}\\]    注意到类别标签取值为 $\\pm 1$，因此 $y_k^2 = 1$，则可以得到最优参数 $b^\\star$ 的形式\\[b^\\star = y_k-w^\\top \\boldsymbol{x}_k= y_k-\\sum_{i=1}^N \\lambda_i y_i \\boldsymbol{x}_i^\\top \\boldsymbol{x}_k\\]    考虑到样本带噪声的情况，我们也可以通过对所有支持向量求出 $b$ 后取均值得到 $b^\\star$。        第二种情况，样本使得 $y_i(\\boldsymbol{w}^\\top x + b) &gt; 1$    此时，该样本为距离分类面较远的样本，不是支持向量。根据互补松弛条件，必须要求$\\lambda_i = 0$。    也就是说，只有当样本是支撑向量时对应的 $\\lambda_i \\neq 0$，否则 $\\lambda_i = 0$。这极大简化 $\\boldsymbol{w}^\\star,b^\\star$ 的计算，因为不用计算其中$\\lambda_i = 0$ 项的向量内积。  至此，我们已经确定了内层优化 $\\min_{w,b}$ 的最优解，并且得到了最优参数的表达式\\[\\begin{aligned}  \\boldsymbol{w}^\\star &amp;= \\sum_{i=1}^N \\lambda_i y_i \\boldsymbol{x_i}\\\\  b^\\star &amp;= y_k-\\sum_{i=1}^N \\lambda_i y_i \\boldsymbol{x}_i^\\top \\boldsymbol{x}_k\\quad \\text{support vector}\\; (\\boldsymbol{x}_k,y_k)\\end{aligned}\\]注意到其中拉格朗日系数还是未知的，需要求解剩余的外层优化问题得到\\[\\begin{aligned}\\max_\\lambda &amp;\\quad -\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N \\lambda_i \\lambda_j y_i y_j \\boldsymbol{x_i}^\\top \\boldsymbol{x_j} + \\sum_{i=1}^N \\lambda_i\\\\s.t. &amp;\\quad \\lambda_i \\geq 0,\\;\\sum_{i=1}^N\\lambda_i y_i = 0,\\; \\forall i=1,2,\\cdots,N\\end{aligned}\\]这个问题是针对 $N$ 个拉格朗日乘子 $\\lambda_i$ 进行优化，我们需要求一个 $N$ 元函数的受不等式约束的极值问题。当 $N$ 很大的时候，这个问题很难求解。我们需要借助 序列最小化算法（Sequential Minimal Optimization，SMO），将问题简化为，每次只变动两个参数，记作 $\\alpha_i,\\alpha_j$，与此同时固定其余所有的参数，问题就能转变为一个一元二次函数求极值问题，最终可以求解得到所有的 $\\lambda_i$，具体求解略。  之所以选择变动两个参数，是因为我们有限制条件\\[\\sum_{i=1}^N\\lambda_i y_i = 0\\]  如果仅变动一个参数，那么这个参数实际上可以由其他参数唯一确定。  关于 SMO 算法的详细讨论，可以参考：https://zhuanlan.zhihu.com/p/367578887至此解出了所有参数 $\\boldsymbol{w}^\\star, b^\\star, \\lambda_i$，得到 SVM 的判别函数 如下\\[f(x) = \\text{sign}({\\boldsymbol{w}^\\star}^\\top x + b^\\star)\\]并且知道 $\\boldsymbol{w}^\\star,b^\\star$ 仅是 支持向量 的线性组合（因为 $\\lambda_i$ 只有在样本为支持向量时才不为零）。所以 SVM 训练完成后，大部分的训练样本都不需要保留，最终的分类模型仅与支持向量有关。3.1.2. 软间隔 SVM 优化问题3.1.2.1. 优化问题描述前面一直假定训练样本在样本空间或特征空间线性可分，即存在一个超平面将不同类的样本完全划分开。但现实中，很难确定使得训练样本在特征空间中线性可分。缓解该问题的办法是允许支持向量机出错，可以通过在目标函数中额外添加一项 $\\text{loss}$ 来实现这一点，新的优化问题如下\\[\\begin{aligned}\\min_{\\boldsymbol{w},b} &amp;\\quad \\frac{1}{2} \\boldsymbol{w}^\\top \\boldsymbol{w} + \\text{loss}\\\\s.t. &amp;\\quad  y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) \\geq 1, \\;\\forall i=1,2,\\cdots,N\\end{aligned}\\]$\\text{loss}$ 选取可以有以下几种形式，第一种是引入 $0/1$ 损失函数作为惩罚项，每当有一个样本不满足约束则计数加 $1$，最后寻找参数 $(\\boldsymbol{w},b)$ 使得包含计数的损失函数最小\\[\\begin{aligned}  \\text{loss} &amp;= C\\sum_{i=1}^N l_{0/1}\\{1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b)\\}, \\;\\forall i=1,2,\\cdots,N\\\\  l_{0/1} &amp;= \\begin{cases}    0,\\;\\text{if}\\;1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) \\leq 0 \\\\    1,\\;\\text{if}\\;1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) &gt; 0 \\;\\text{违背约束}  \\end{cases}\\end{aligned}\\]但 $0/1$ 损失函数非凸、非连续，不容易优化，需要采用其他替代损失。令 $z = y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b)$，几种可行的替代损失如下图所示  求解替代损失函数得到的解是否仍为原问题的解，在理论上称为替代损失的 “一致性” 问题。替代损失一般选取为原始损失损失函数的上界，这样替代损失函数得到优化时，原始损失函数也同样得到优化。此外，替代函数一般选为凸函数，便于优化。上图中列出的几种常见替代损失都已被证明是一致的，可以替代 $0/1$ 损失函数。SVM 求解选取 hinge loss 作为替代损失，同时引入 $C$ 作为惩罚参数\\[\\textcolor{blue}{\\text{loss} = C\\sum_{i=1}^N\\max\\{ 0, 1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) \\}}\\]对 hinge loss 展开分析如下：  $z=y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b)\\geq 1, \\quad\\text{loss}=0$  $z=y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b)&lt; 1, \\quad\\text{loss}=1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b)$可以看出，hinge loss 在约束满足时取值为 0，在约束不满足时取值即为约束的正值，两个区间的边界处（$z=1$）的函数值是连续的。引入这个惩罚项后，假设有样本不满足约束，我们通过优化带上述惩罚项的目标函数，即希望使得不满足约束的样本带来的影响（对约束的违背程度）尽可能小。虽然 hinge loss 函数取值已经连续了，但由于存在 $\\max$ 算符，在实际使用时仍然不太方便。这里把 hinge loss 单独定义为一个变量 $\\xi_i$，并且要求 $\\xi_i \\geq 0$，即\\[\\xi_i =  \\max\\{0,1-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b)\\}\\]可进行如下讨论  当 $\\xi_i = 0$ 时， 样本满足 $y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) \\geq 1\\textcolor{green}{=1-\\xi_i}$；  当 $\\xi_i &gt; 0$ 时， 样本满足 $y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) = 1 - \\xi_i$；因此惩罚项可以移除 $\\max$ 写成统一的形式，约束不等式也可以写为统一的形式。则优化问题可以写成如下的 软间隔 SVM 优化问题\\[\\begin{aligned}\\textcolor{blue}{\\min_{\\boldsymbol{w},b,\\xi_i}} &amp;\\quad \\textcolor{blue}{\\frac{1}{2} \\boldsymbol{w}^\\top \\boldsymbol{w} + C\\sum_{i=1}^N\\textcolor{red}{\\xi_i}}\\\\\\textcolor{blue}{s.t.} &amp;\\quad  \\textcolor{blue}{y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b) \\geq \\textcolor{red}{1-\\xi_i},\\; \\xi_i \\geq 0,\\; \\forall i=1,2,\\cdots,N}\\end{aligned}\\]其中 $\\xi_i$ 又称为松弛变量，引入松弛变量相当于我们放宽了对样本点的约束，原本要求其必须在硬间隔之外，现在只要都保证在软间隔之外即可。最小化目标函数包含两层含义：第一项使硬间隔尽量大，第二项使误分类点的个数尽量小，$C$ 是调和二者的系数。并且只要错分一个样本点，我们都将付出 $C\\xi_i$ 的代价。极端情况下，当 $C\\to \\infty$，表明此时我们无法容忍误分类样本点，只要有一丁点误分就会导致目标函数变得很大，相当于 $\\xi_i\\to 0$，软间隔 SVM 问题退化成为硬间隔 SVM 问题。软间隔 SVM 优化问题的图示如下所示3.1.2.2. 拉格朗日乘子同样采用拉格朗日乘子法，上述软间隔 SVM 优化问题可以写成如下形式\\[\\begin{aligned}&amp;\\min_{w,b,\\xi_i} \\max_{\\lambda, \\mu}L(\\boldsymbol{w},b,\\xi,\\lambda, \\mu) = \\\\&amp;\\frac{1}{2}\\boldsymbol{w}^\\top\\boldsymbol{w} + C\\sum_{i=1}^N \\xi_i \\textcolor{red}{+ \\sum_{i=1}^N \\lambda_i(1-\\xi_i-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b)) - \\sum_{i=1}^N \\mu_i\\xi_i}\\\\&amp;s.t. \\quad \\xi_i \\geq 0, \\lambda_i \\geq 0,\\mu_i \\geq 0, \\quad \\forall i=1,2,\\cdots,N\\end{aligned}\\]3.1.2.3. 对偶问题求解同样将原问题转化为对偶问题\\[\\begin{aligned}&amp;\\textcolor{green}{\\max_{\\lambda, \\mu} \\min_{w,b,\\xi_i}} L(\\boldsymbol{w},b,\\xi,\\lambda, \\mu) = \\\\&amp;\\frac{1}{2}\\boldsymbol{w}^\\top\\boldsymbol{w} + C\\sum_{i=1}^N \\xi_i + \\sum_{i=1}^N \\lambda_i(1-\\xi_i-y_i(\\boldsymbol{w}^\\top \\boldsymbol{x_i}+b)) - \\sum_{i=1}^N \\mu_i\\xi_i\\\\&amp;s.t. \\quad \\xi_i \\geq 0, \\lambda_i \\geq 0,\\mu_i \\geq 0, \\quad \\forall i=1,2,\\cdots,N\\end{aligned}\\]根据 KKT 条件中的梯度可行性条件，可以得到如下的等式：\\[\\begin{cases}  \\nabla_w L(\\boldsymbol{w},b,\\xi,\\lambda, \\mu) = \\boldsymbol{w} - \\sum_{i=1}^N \\lambda_i y_i \\boldsymbol{x_i} = 0\\\\  \\nabla_b L(\\boldsymbol{w},b,\\xi,\\lambda, \\mu) = - \\sum_{i=1}^N \\lambda_i y_i = 0, \\quad \\forall i=1,2,\\cdots,N\\\\  \\nabla_{\\xi_i} L(\\boldsymbol{w},b,\\xi,\\lambda, \\mu) = C - \\lambda_i - \\mu_i = 0\\\\\\end{cases}\\]可以得到\\[\\begin{cases}  \\boldsymbol{w} = \\sum_{i=1}^N \\lambda_i y_i \\boldsymbol{x_i}\\\\  \\sum_{i=1}^N \\lambda_i y_i=0, \\quad \\forall i=1,2,\\cdots,N\\\\  C-\\lambda_i-\\mu_i=0\\end{cases}\\]又根据 KKT 条件中的互补松弛性等条件，对于 $ \\forall i=1,2,\\cdots,N$\\[\\begin{aligned}\\lambda_i \\geq 0,\\mu_i \\geq 0 &amp;\\quad \\text{对偶可行性}\\\\1-\\xi_i-y_i(\\boldsymbol{w}^T\\boldsymbol{x_i}+b) \\leq 0,\\;\\xi_i\\geq 0 &amp;\\quad \\text{原始可行性}\\\\\\lambda_i(1-\\xi_i-y_i(\\boldsymbol{w}^T\\boldsymbol{x_i}+b))=0 &amp;\\quad \\text{互补松弛性}\\\\\\mu_i\\xi_i=0 &amp;\\quad \\text{互补松弛性}\\end{aligned}\\]对于第 $i$ 个样本分析如下  $ \\lambda_i = 0$：样本不是支持向量；  梯度可行条件条件：$\\lambda_i+\\mu_i=C$，因此 $ \\mu \\geq 0 \\Rightarrow \\lambda_i \\leq C$          $0&lt;\\lambda_i &lt; C \\Rightarrow \\mu_i &gt; 0 \\Rightarrow \\xi_i = 0$：样本是支持向量；      $\\lambda_i = C \\Rightarrow \\mu_i = 0$：$\\xi_i$ 取值任意，样本不是支持向量；                  $0\\leq \\xi_i &lt; 1$：样本落在最大间隔内部；          $\\xi_i = 1$：样本落在分类超平面上；          $\\xi_i &gt; 1$：样本被错误分类；                    代入原始目标函数可得化简的目标函数（隐去 $\\mu_i$）为\\[\\begin{aligned}\\max_\\lambda &amp;\\quad -\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N \\lambda_i \\lambda_j y_i y_j \\boldsymbol{x_i}^\\top \\boldsymbol{x_j} + \\sum_{i=1}^N \\lambda_i\\\\s.t. &amp;\\quad \\sum_{i=1}^N \\lambda_i y_i=0,\\; \\textcolor{green}{0\\leq \\lambda_i \\leq C},\\; i=1,2,\\cdots,N\\\\\\end{aligned}\\]上述标绿约束也是 软间隔 SVM 与 硬间隔 SVM 优化问题的唯一区别。利用 KKT 条件和 SMO 算法继续求解拉格朗日系数 $\\lambda_i$，此处不在赘述。最后我们也可以解得优化问题的最优解为\\[\\begin{aligned}w^\\star &amp;= \\sum_{i=1}^N \\lambda_i y_i \\boldsymbol{x_i}\\\\b^\\star &amp;= y_k-\\sum_{i=1}^N \\lambda_i y_i \\boldsymbol{x_i}^\\top \\boldsymbol{x}_k\\quad \\text{support vector}\\; (\\boldsymbol{x}_k,y_k)\\end{aligned}\\]得到 SVM 的判别函数 如下\\[f(x) = \\text{sign}({\\boldsymbol{w}^\\star}^\\top x + b^\\star)\\]其形式和 硬间隔 SVM 的最优解形式是一样的。3.1.3. 统计机器学习的一般形式我们用一个统一的目标函数同时刻画 硬间隔 SVM 和 软间隔 SVM 的目标函数，即：\\[\\min_f \\quad \\underbrace{\\Omega(f)}_{结构风险} + \\underbrace{C\\sum_{i=1}^N l(f(\\boldsymbol{x}_i),y_i)}_{经验风险}\\]其中  结构风险（Structural Risk）：描述模型本身的某些性质，通常称为正则化项，使用正则化项的方法称之为 “罚函数法”；  经验风险（Experience Risk）：描述模型在训练数据集上的拟合程度。相比于其他基于数据的机器学习，SVM 这类基于统计的机器学习通过对不希望的结果（模型选择）施加惩罚，使得优化过程趋向于希望目标。从贝叶斯估计的角度，则可认为结构风险这一正则化项是提供了模型的先验概率（对模型的喜好和态度），或者称为归纳偏好。3.2. 非线性支持向量机对于非线性可分问题，我们本着简化问题的思想，自然是希望将其转化为熟悉的线性可分问题进行处理。Cover 定理指出：将复杂的模式分类问题非线性地投射到高维空间将比投射到低维空间更可能是线性可分的。极端情况下，在维度超过数据数量时，数据一定线性可分（试想如果我们把每个数据点都映射到不同的坐标轴上，那么可不就是线性可分的了么）。因此，我们对非线性可分的数据，可以将数据映射至高维空间，然后再用我们熟悉的线性支持向量机分类，至此，剩下的问题就是怎么映射至高维。  通过坐标变换而不进行升维在一些特殊场景下也能实现分类，如    使用极坐标 $\\phi(x):[x_1,x_2]^\\top \\to [r,\\theta]^\\top,\\quad \\mathbb{R}^2\\to \\mathbb{R}^2$  但这种映射方式适用面较窄，并不常用。3.2.1. 特征升维分类实例考虑如下四个样本，需要将其进行分类，可以发现没有任何一个线性分类面能够完成此任务\\[\\begin{aligned}\\text{class 1}:\\;&amp;(0,3),(3,0)\\\\\\text{class 2}:\\;&amp;(2,1),(1,2)\\end{aligned}\\]我们尝试通过升维操作来解决分类问题。那么第三个维度可以选什么呢？我们尝试如下三种\\[(x,y,\\textcolor{red}{x+y}),(x,y,\\textcolor{green}{xy}),(x,y,\\textcolor{blue}{x^2})\\]分别求得三种情况下的第三维度计算结果                   $\\textcolor{red}{(0,3)}$      $\\textcolor{green}{(1,2)}$      $\\textcolor{green}{(2,1)}$      $\\textcolor{red}{(3,0)}$                  $x+y$      3      3      3      3              $xy$      0      2      2      0              $x^2$      0      1      4      9      很明显，使用第三个维度为 $xy$ 时能够区分两类不同的样本。结果如图所示上述过程实际上是一个朴素的特征映射过程，其仍然存在以下两个问题：  特征映射需要凭借经验设计（如设计第三个维度为 $xy$）；  特征映射引入了额外的计算成本（后面展开介绍）。3.2.2. 核技巧观察线性 SVM 的优化目标函数\\[\\max_\\lambda \\quad -\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N \\lambda_i \\lambda_j y_i y_j \\boldsymbol{x_i}^\\top \\boldsymbol{x_j} + \\sum_{i=1}^N \\lambda_i\\]可以看出其主要通过计算样本的内积来优化得到分类超平面。由于升维可以使得原本线性不可分的样本变得线性可分，其关键在于如何对样本进行升维后求内积。  观察线性 SVM 的判别函数可以得到同样的结论，因为其超平面方程的参数 $b^\\star$ 表达式中同样包含样本内积假设我们用一个映射函数 $\\phi(\\cdot)$ 将原始样本升维，那么优化函数变为\\[\\max_\\lambda \\quad -\\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N \\lambda_i \\lambda_j y_i y_j \\phi(\\boldsymbol{x_i})^\\top \\phi(\\boldsymbol{x_j}) + \\sum_{i=1}^N \\lambda_i\\]假设样本在映射函数 $\\phi(\\cdot)$ 的作用下从二维升至六维，如下\\[\\boldsymbol{x} = [a, b]^\\top\\mathop{\\longrightarrow}\\limits^{\\phi}\\phi(\\boldsymbol{x})=[1,\\sqrt{2}a,\\sqrt{2}b,a^2,b^2,\\sqrt{2}ab]^\\top\\]那么先映射后再求内积可以得到\\[\\phi(\\boldsymbol{x}_1)\\cdot \\phi(\\boldsymbol{x}_2) = 1+2a_1a_2+2b_1b_2+a_1^2a_2^2+b_1^2b_2^2+2a_1a_2b_1b_2\\]可以看出，  设计六维特征已经十分繁杂，更高维度特征设计我们无从下手；  随着维度的增加，求内积操作变得十分复杂。下面通过引入核函数的方式解决上述两个问题。3.2.2.1. 多项式核函数我们转换思想，尝试 先求内积再进行映射，定义如下关于内积的函数：\\[\\begin{aligned}\\mathcal{K}(\\boldsymbol{x}_1,\\boldsymbol{x}_2) &amp;= (1+\\boldsymbol{x}_1^\\top\\cdot\\boldsymbol{x}_2)^2\\\\&amp;=(1+a_1a_2+b_1b_2)^2\\\\&amp;=1+2a_1a_2+2b_1b_2+a_1^2a_2^2+b_1^2b_2^2+2a_1a_2b_1b_2\\end{aligned}\\]可以发现，其结果正好等于前述映射到六维后的样本内积结果。因此，在实际使用时只需要在样本低维空间先求内积，然后将内积的结果代入函数中，进行简单计算即可得到映射到高维空间后的内积结果。上述操作使用的函数被称为「核函数」，通过引入核函数来简化内积计算的这种操作被称为「核技巧」，具体而言，这里采用的是 多项式核函数\\[\\mathcal{K}_{poly}^{(c,d)}(\\boldsymbol{x}_1,\\boldsymbol{x}_2) = (c+\\boldsymbol{x}_1^\\top\\cdot\\boldsymbol{x}_2)^d\\]当 $c=1,d=2$ 时，就可以将原本的样本升至前述六维。如果换一组参数，可以将原样本升至不同的维度。因此，多项式核函数确定了一组参数后，也就确定了转换后的样本特征维度。多项式核函数中的常数 $c$ 十分重要，其决定了内积结果的表达始终包含了从低次项到高次项的数据组合，体现出维度的多样性。当 $c=0$ 时，点积展开式将只包含高次项。进一步，我们可以通过将多个不同次的多项式核函数相加组合，使结果同时具有高低次项，以此丰富维度的多样性\\[\\begin{aligned}&amp;\\textcolor{red}{c=1,d=2:}\\\\&amp;\\mathcal{K}(\\boldsymbol{x}_1,\\boldsymbol{x}_2) =\\textcolor{green}{1+2a_1a_2+2b_1b_2}+a_1^2a_2^2+b_1^2b_2^2+2a_1a_2b_1b_2\\\\&amp;\\textcolor{red}{c=0,d=2:}\\\\&amp;\\mathcal{K}(\\boldsymbol{x}_1,\\boldsymbol{x}_2) =a_1^2a_2^2+b_1^2b_2^2+2a_1a_2b_1b_2\\\\&amp;\\textcolor{red}{(c=0,d=2)+(c=0,d=2):}\\\\&amp;\\mathcal{K}(\\boldsymbol{x}_1,\\boldsymbol{x}_2) =\\textcolor{green}{2a_1a_2+2b_1b_2}+a_1^2a_2^2+b_1^2b_2^2+2a_1a_2b_1b_2\\\\\\end{aligned}\\]多项式核函数通过构建特征的高次组合，适用于存在较明显非线性但复杂度适中的数据。多项式阶数的选择直接影响模型的复杂度和拟合能力，过高可能导致过拟合，过低可能无法捕捉数据的非线性特性。虽然引入核函数可以在某种程度上简化高维特征的设计问题（通过调节参数 $c$ 和 $d$ 即可直接得到不同的高维特征），并且可以降低计算量。但是多项式核函数仍然存在以下局限性：  阶数 $d$ 的选择困难：          $d$ 太小可能导致模型欠拟合，无法捕捉复杂模式；      $d$ 太大容易过拟合，且计算复杂度高（特征空间维度爆炸增长）。            数值问题：当 $d$ 较大时，$\\boldsymbol{x}_i^\\top\\boldsymbol{x}_j$ 的值可能非常大或非常小，导致数值不稳定。        对特征尺度敏感：多项式核的性能受特征尺度影响较大，通常需要标准化数据，而高斯核对尺度敏感度较低（因已包含距离度量）。    灵活性不足：多项式核只能捕捉固定阶数的多项式关系，而高斯核可以近似任意复杂函数。下面介绍的 RBF （高斯）核函数能够解决上述绝大部分局限，使用更为广泛。3.2.2.2. RBF 核函数根据 Cover 定理，维度越高越有可能使得样本变得线性可分。极端情况下，如果希望样本特征升至无限维，那么原本的先映射再计算内积的方法就失效了，因为我们无法对映射后的无限维特征进行求内积操作。因此我们只能使用核技巧来计算。注意到，即使使用多项式核函数也无法通过 $d=+\\infty$ 实现无限升维。这里我们给出另一种核函数，被称为 RBF 核函数（Radial Basis Function）、径向基核函数 或 高斯核函数。其定义如下\\[\\begin{aligned}RBF(\\boldsymbol{x}_i, \\boldsymbol{x}_j) &amp; = \\exp\\left(-\\frac{\\Vert \\boldsymbol{x}_i-\\boldsymbol{x}_j\\Vert^2}{2\\sigma^2}\\right) \\\\\\end{aligned}\\]其反应了两个样本向量的相似度信息，其参数 $\\sigma$ 是核函数的参数，用来调控对样本向量之间的相似度和距离之间的敏感程度。简便起见，令 $\\sigma = 1$，对 RBF 核函数展开如下\\[\\begin{aligned}RBF(\\boldsymbol{x}_i, \\boldsymbol{x}_j) &amp;= \\exp\\left(-\\frac{\\Vert \\boldsymbol{x}_i-\\boldsymbol{x}_j\\Vert^2}{2}\\right) \\\\&amp;=\\exp\\left(-\\frac{1}{2}(\\boldsymbol{x}_i-\\boldsymbol{x}_j)^\\top(\\boldsymbol{x}_i-\\boldsymbol{x}_j)\\right) \\\\&amp;=\\exp\\left(-\\frac{1}{2}[\\boldsymbol{x}_i^\\top\\boldsymbol{x}_i+\\boldsymbol{x}_j^\\top\\boldsymbol{x}_j - 2\\boldsymbol{x}_i^\\top\\boldsymbol{x}_j]\\right)\\\\&amp;= \\exp\\left(-\\frac{1}{2}[\\boldsymbol{x}_i^\\top\\boldsymbol{x}_i+\\boldsymbol{x}_j^\\top\\boldsymbol{x}_j]\\right)\\exp\\left(\\boldsymbol{x}_i^\\top\\boldsymbol{x}_j\\right)\\\\&amp;=C\\cdot\\exp\\left(\\boldsymbol{x}_i^\\top\\boldsymbol{x}_j\\right)\\end{aligned}\\]可以看出，RBF 核函数是关于两向量内积的指数函数，对其进行泰勒展开可以得到\\[RBF(\\boldsymbol{x}_i,\\boldsymbol{x}_j) = C\\cdot\\sum_{n=0}^{\\infty}\\frac{1}{n!}\\left(\\boldsymbol{x}_i^\\top\\boldsymbol{x}_j\\right)^n = C\\cdot\\sum_{n=0}^{\\infty}\\frac{1}{n!}\\left(\\mathcal{K}_{poly}^{(0,n)}\\right)\\]\\[\\exp(x) = \\sum_{n=0}^{\\infty}\\frac{1}{n!}x^n\\]因此，RBF 核函数可以看作无数个不带常数的多项式核函数从低次到高次的加权和，可以表达高低次项的无限多样性。这样，我们就实现了在不实质踏入无限维度的情况下，得到无限维度下向量相似度的结果。RBF 核函数是最常用的非线性核函数之一，尤其适用于高维、复杂非线性数据。其参数 $\\gamma = \\frac{1}{2\\sigma^2}$ 决定了核函数的宽度，对模型的复杂度和分类效果有显著影响。RBF核因其局部性、平滑性和无限维映射等特性，常能在保持较低模型复杂度的同时获得良好的分类性能。4. 决策树（DT）‌决策树（Decision Tree）‌是一种用于分类和回归的监督学习方法。它通过构建树形结构来模拟决策过程，每个内部节点表示一个特征属性上的选择，每个分支代表一个选择结果，每个叶子节点代表一个类别或预测结果。决策树通过递归地划分数据集，将数据集分割成更小的子集，直到满足停止条件为止‌。二叉树是最简单的决策树模型，每个非终止节点上采用线性分类器进行决策，每个非终止节点有两个分支，故称为二叉树。二叉树将多峰问题或多类问题转换为多级的线性问题。4.1. ID3 算法构建决策树的一般步骤如下：  特征选择：从众多的特征中选择（属性）一个特征作为当前节点分裂的标准；  决策树生成：根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止决策树生长；  剪枝：缩小树结构规模、缓解过拟合。随之而来的第一个问题是，如何从众多特征中选择一个特征作为当前节点分裂的标准呢？这里介绍 ID3（Interactive Dichotomizer-3）算法，其采用信息熵和信息增益来衡量不同特征的优先级。对于信息增益大的特征，优先选择该特征作为当前节点分裂的标准。以下表为例，根据苹果颜色特征和形状特征来对苹果甜不甜进行分类，假设数据如下：            苹果编号      红不红H      圆不圆Y      甜不甜T                  1      1      1      1              2      1      1      1              3      1      0      0              4      0      1      0              5      0      1      0      4.1.1. 信息熵在信息论中，熵（entropy） 是随机变量不确定性的度量，熵越大，则随机变量的不确定性越大。信息熵是度量样本集合纯度最常用的一种指标。设 $X$ 是一个取有限个值的离散随机变量，其概率分布为\\[P(X=x_i) = p_i,\\;i=1,2,\\ldots,n\\]则随机变量 $X$ 的熵定义为\\[H(X) = -\\sum_{i=1}^n p_i\\log_2 p_i\\]且约定 $0\\log_2 0 = 0$。信息熵反映了信息的纯度，信息熵越大表明信息的纯度越低（越杂乱），包含的不同类别越多。纯度越高表明同一类别的样本占比越高。当熵中的概率由数据估计得到时，所对应的熵称为经验熵(empirical entropy)。对于苹果分类的例子，我们首先计算该数据的经验熵为：\\[\\begin{aligned}H(T) &amp;= -\\sum_{i=0}^1 p_i\\log_2 p_i\\\\ &amp;=- P(T=1)\\log_2 P(T=1)-P(T=0)\\log_2 P(T=0)\\\\&amp;= -\\frac{2}{5}\\log_2 \\frac{2}{5} -\\frac{3}{5}\\log_2 \\frac{3}{5}\\approx 0.971\\; \\text{bit}\\end{aligned}\\]4.1.2. 条件熵随机变量 $X$ 给定的条件下，随机变量 $Y$ 的条件熵（conditional entropy）定义为：$X$ 给定的条件下 $Y$ 的条件概率分布的信息熵对 $X$ 的数学期望：\\[H(Y\\vert X) = \\sum_{i=1}^n p_i H(Y\\vert X=x_i)\\]类似地，当条件熵中的概率由数据估计（特别是极大似然估计）得到时，称为经验条件熵。给定苹果 “红不红” 的条件，有  若为红苹果\\[\\begin{aligned}H(T\\vert H=1)&amp;= -\\sum_{i=0}^1 P(T=i\\vert H=1) \\log_2 P(T=i\\vert H=1)\\\\&amp;=-(\\frac{2}{3}\\log_2 \\frac{2}{3} + \\frac{1}{3}\\log_2 \\frac{1}{3})\\approx 0.918\\; \\text{bit}\\end{aligned}\\]  若为不红苹果\\[\\begin{aligned}  H(T\\vert H=0) &amp;= -\\sum_{i=0}^1 P(T=i\\vert H=0) \\log_2 P(T=i\\vert H=0)\\\\  &amp;=-(\\frac{0}{2}\\log_2 \\frac{0}{2} + \\frac{2}{2}\\log_2 \\frac{2}{2})=0\\; \\text{bit}\\end{aligned}\\]则条件熵为：\\[\\begin{aligned}H(T\\vert H) &amp;= P(H=1)H(T\\vert H=1) + P(H=0)H(T\\vert H=0)\\\\&amp;=\\frac{3}{5}\\cdot 0.918 + \\frac{2}{5}\\cdot 0 =0.551\\; \\text{bit}\\end{aligned}\\]类似给定苹果 “圆不圆” 的条件，有  圆苹果条件下的条件熵为：\\[\\begin{aligned}&amp;H(T\\vert Y=1) = -\\sum_{i=0}^{1}P(T=i\\vert Y=1)\\log_2 P(T=i\\vert Y=1)\\\\&amp;=-\\left(\\frac{2}{4}\\log_2 \\frac{2}{4} + \\frac{2}{4}\\log_2 \\frac{2}{4}\\right)=1\\; \\text{bit}\\end{aligned}\\]  不圆苹果条件下的条件熵为：\\[\\begin{aligned}H(T\\vert Y=0) &amp;= -\\sum_{i=0}^{1}P(T=i\\vert Y=0)\\log_2 P(T=i\\vert Y=0)\\\\&amp;=-\\left(\\frac{1}{1}\\log_2 \\frac{1}{1} + \\frac{0}{1}\\log_2 \\frac{1}{0}\\right)=0\\; \\text{bit}\\end{aligned}\\]则条件熵为：\\[\\begin{aligned}H(T\\vert Y) &amp;= P(Y=1)H(T\\vert Y=1) + P(Y=0)H(T\\vert Y=0)\\\\&amp;= \\frac{4}{5}\\cdot 1 + \\frac{1}{5}\\cdot 0 = 0.8\\; \\text{bit}\\end{aligned}\\]4.1.3. 信息增益计算出原始样本的经验熵，以及给定不同特征的经验条件熵，那么衡量特征的优先级，就可以使用信息增益来判断。信息增益（Information Gain，IG）为在已知某个特征的情况下，对总体的信息（不确定性）减少程度。计算公式为\\[\\text{IG}(Y,X) = H(Y) - H(Y|X)\\]给定上述苹果数据集后，我们分别计算不同特征的信息增益，可以得到如下结果：\\[\\begin{aligned}\\text{IG}(T,H) &amp;= H(T) - H(T|H) = 0.971 - 0.551 = 0.420 \\; \\text{bit}\\\\\\text{IG}(T,Y) &amp;= H(T) - H(T|Y) = 0.971 - 0.800 = 0.171\\; \\text{bit}\\\\\\end{aligned}\\]可以看出 “红不红”（H）这个特征的信息增益比较大，意味着按照该特征进行划分能够更好的降低信息的不确定性，提高信息的纯度，有利于分类。所以应该首先选 “红不红” 这个特征来进行划分，因此构建决策树如下：flowchart TD;    A[红不红] --不红--&gt; D[不甜];    A[红不红] --红--&gt; B[圆不圆];    B[圆不圆] --不圆--&gt; C[不甜];    B[圆不圆] --圆--&gt; E[甜];信息增益又被称为互信息（mutual information），等价于训练数据集中类别与特征的互信息。4.2. C4.5 算法4.2.1. 信息增益的局限ID3 算法使用信息增益时存在两个局限性。首先，当某个特征的取值非常多时，对该特征计算条件熵几乎为0，带来的信息增益几乎等于原始数据本身的信息熵，此时因为其信息增益最大，ID3 算法会使用该特征进行决策树划分，这种情况下会造成过拟合。比如，对上述苹果数据集进行扩充，引入价格特征如下：            苹果编号      价格P      红不红H      圆不圆Y      甜不甜T                  1      5.7      1      1      1              2      6.5      1      1      1              3      5.1      1      0      0              4      5.2      0      1      0              5      6.0      0      1      0      每一个价格唯一对应一个样本，因此每组仅含有1个样本，纯度为100%。对价格计算条件熵为\\[H(T \\vert P=5.7) = H(T \\vert P=6.5) = \\cdots = 0\\;\\text{bit}\\]\\[H(T\\vert P) = -\\sum_{i=1}^5 P_i\\log_2 H(T\\vert P_i) = -\\sum_{i=1}^5 \\frac{1}{5}\\cdot 0 = 0\\;\\text{bit}\\]信息增益为\\[\\text{IG}(T,P) = H(T) - H(T\\vert P) = 0.971 - 0 = 0.971\\;\\text{bit}\\]则价格特征的信息增益最大，应该按照该特征进行划分，很显然这是不对的。其次，信息增益的数值是相对于训练数据集而言的，观察其计算公式可以发现其计算过程和样本的个数有关，并没有绝对意义。因此我们需要对 ID3 算法进行改进。4.2.2. 信息增益比（增益率）采用信息增益比来代替信息增益进行特征选择，该方法称为 C4.5 算法。特征 $X$ 对训练数据集 $D$ 的信息增益比定义为：信息增益与特征 $X$ 对数据集划分的信息熵 之比，即\\[\\text{Gain Ratio} = \\frac{\\text{IG}(D,X)}{H_X(D)} = \\frac{\\text{IG}(D,X)}{\\text{SplitInfo}(X)}\\]特征 $X$ 对数据集划分的信息熵 又称为 分裂信息（Split Information），其衡量该特征的分布均匀程度。其定义为\\[\\text{SplitInfo}(X) = -\\sum_{i=1}^n \\frac{D_i}{D} \\log_2 \\frac{D_i}{D}\\]其中 $n$ 为特征 $X$ 的不同取值个数，$D_i$ 表示特征 $X$ 的第 $i$ 个取值对应的数据集的个数，$D$ 表示训练数据集 $D$ 的个数。对上述苹果数据集，三个特征的分裂信息为：\\[\\begin{aligned}  \\text{SplitInfo}(H) &amp;= - \\sum_{i=0}^1 P(H=i) \\log_2 P(H=i) \\approx 0.971\\; \\text{bit} \\\\  \\text{SplitInfo}(Y) &amp;= - \\sum_{i=0}^1 P(Y=i) \\log_2 PY=i) \\approx 0.722\\; \\text{bit}\\\\  \\text{SplitInfo}(P) &amp;= - \\sum_{i=\\textcolor{red}{1}}^{\\textcolor{red}{5}} P(P=i) \\log_2 P(P=i) \\approx 2.321\\; \\text{bit}\\end{aligned}\\]则三个特征的信息增益比为：\\[\\begin{aligned}  \\text{Gain Ratio}(T,H) &amp;= \\frac{0.420}{0.971} = 0.433 \\;\\text{bit}\\\\  \\text{Gain Ratio}(T,Y) &amp;= \\frac{0.171}{0.722} = 0.237 \\;\\text{bit}\\\\  \\text{Gain Ratio}(T,P) &amp;= \\frac{0.971}{2.321} = 0.418 \\;\\text{bit}\\end{aligned}\\]可以发现，“红不红” 特征的信息增益比最大。因此 4.5 算法可以有效客服高基数特征（取值多的特征）带来的影响。4.3. CART 算法ID3 和 C4.5算法，生成的决策树是多叉树（叉的个数与选取的特征的取值个数有关，每个特征只会参与一次节点建立），且只能处理分类不能处理回归。下面介绍的 CART 算法形成的决策树是二叉树，具备更好的数学性质，且既可用于分类也可用于回归。如果配合剪枝、集成等策略，基于CART 算法生成的决策树可构建出很多非常优秀的模型，比如随机森林、随机梯度上升树等。4.3.1. 基尼指数基尼指数是决策树（如CART算法）中用于衡量数据不纯度的指标，类似于信息熵（Entropy），但计算更高效（不用计算 $\\log_2$）。假设数据集 $D$ 中的目标变量 $Y$ 有 $c$ 个类别，则基尼指数定义为：\\[\\text{Gini}(D) = 1 - \\sum_{i=1}^{c} p_i^2 = 1- \\sum_{i=1}^{c} (\\frac{D_i}{D})^2\\]对于所有样本的特征 $X$，假设其有 $k$ 个取值，将这些取值从小到大排列为 $x_1, x_2, \\cdots, x_k$，分别取两个相邻特征值的均值作为分裂点，则一共有 $k-1$ 个分裂点，第 $i$ 个分裂点为 $t_i = ({x_i+x_{i+1}})/{2}$。则特征 $X$ 条件（分裂）下的基尼指数定义为：\\[\\begin{aligned}&amp;D_{\\text{left}} = \\{D\\vert X\\leq t_i\\},\\quad D_{\\text{right}} = \\{D\\vert X&gt;t_i\\}\\\\&amp;\\text{Gini}_{\\text{split}}(D) = \\frac{D_{\\text{left}}}{D} \\text{Gini}(D_{\\text{left}})+ \\frac{D_{\\text{right}}}{D} \\text{Gini}(D_{\\text{right}})\\end{aligned}\\]基尼指数反应数据集 $D$ 的不确定性，特征 $X$ 条件下（分裂后）的基尼指数反应了特征 $X$ 条件下（分裂后）数据集 $D$ 的不确定性。与信息增益类似，分裂前后的基尼指数的变化反映了特征的好坏。我们可以直接选择特征条件下基尼指数小的特征作为分裂特征，此时表示经由该特征分裂后，数据集的基尼指数下降的多。4.3.2. CART 分类树使用基尼系数作为决策树特征划分的指标的方法称为 「CART 算法」（Classification and Regression Trees）。下面结合算法伪代码，给出 CART 算法生成二叉树分类决策树的过程：  输入：训练数据集 $D$，阈值；  从根节点开始，递归地对每个节点进行以下操作，构建二叉树：          Step0：判断当前节点是否满足停止计算的条件，若满足则退出当前递归循环。停止计算的条件为：达到最大深度阈值、节点中的样本个数小于阈值，或样本集的基尼指数小于阈值，或者没有更多特征。      Step1：计算现有特征对该数据集D的基尼指数。即对每一个特征A，对其可能取的每个值  ，根据样本是否满足 $A=a$ 将 $D$ 划分为 $D_1$和 $D_2$ 两部分，计算 $A=a$ 条件下的基尼指数 $\\text{Gini}_{A=a}(D)$；      Step2：在所有可能的特征 $A$ 以及他们所有可能的划分点 $a$ 中，选择基尼指数最小的特征及其对应可能的划分点作为最优特征和最优划分点。根据最优特征和最优划分点，从现节点生成两个子节点 $A\\geq a, \\;A &lt; a $，将训练数据集依特征分配到两个子节点中去；      Step3：对两个子节点，返回 Step0 继续递归；        输出：CART 决策树 $T$。在使用决策树时，抵达叶子节点后，叶子节点负责做出最终决策。它可以输出以下几种结果：  「类别标签」：在分类任务中，叶子节点输出数据点所属的类别，由该节点中样本的多数决定；  「类别概率」：在概率分类任务中，叶子节点输出数据点属于不同类别的概率；  「标量取值」：在回归任务中，叶子节点输出一个连续的数值结果，为叶子节点所含所有样本点的均值。4.3.3. CART 回归树对于回归问题，CART 采用均方误差（MSE）来衡量误差\\[MSE(D) = \\frac{1}{D}\\sum_{i=1}^{D}(y_i - \\bar{y})^2\\]其中 $\\bar{y}$ 是数据集 $D$ 中所有样本的均值。对数据进行分裂，得到两部分$D_{\\text{left}},D_{\\text{right}}$，则分裂后的均方误差为：\\[MSE_{\\text{split}}(D) = \\frac{D_{\\text{left}}}{D} MSE(D_{\\text{left}})+ \\frac{D_{\\text{right}}}{D} MSE(D_{\\text{right}})\\]目标是找到使得 $MSE_{\\text{split}}$ 最小的分裂方式。与 CART 分类树类似，回归树的生成过程主要包括：  计算所有可能分裂点的 MSE，选择最优分裂点。  递归分裂，直到满足停止条件（如叶子节点的样本数小于某个阈值）。  叶子节点的输出是该节点样本的均值。4.3.4. 三种决策树构建算法区别  CART 算法：          【树结构】：二叉树（严格二叉树，每个节点只有左右两个分支）；      【分裂规则】：                  对分类问题：使用 基尼指数（Gini Index） 选择最优特征和分割点；          对回归问题：使用 均方误差（MSE）；                    【分裂方式】：                  对于连续特征：通过阈值二分（如”红程度 ≥ 0.5”）；          对于类别特征：通过”是/否”二分（如”颜色=红色?”）。                      C4.5 算法：          【树结构】：多叉树（一个节点可以有多个子节点，取决于特征取值数量）；      【分裂规则】：使用信息增益比（Gain Ratio）；      【分裂方式】：直接按特征的所有可能取值划分（如“颜色$\\in${红,黄,绿}”生成3个子节点）；        ID3 算法：          【树结构】：多叉树（类似C4.5，但无连续特征处理能力）；      【分裂规则】：使用信息增益（Information Gain）；      【局限性】：                  只能处理离散特征，不能直接处理连续特征或缺失值；          对多值特征敏感（可能生成过深的树）。                    为什么CART必须是二叉树？  计算效率：二分法简化了特征选择和分割点搜索（尤其对连续特征）。  泛化能力：避免多值特征导致过拟合（如“用户ID”若多叉划分会完全拟合数据）。  统一性：回归和分类问题均可使用相同的二分框架。思考：CART 如何处理缺失值特征？  赋给所有训练样本中该属性的最常见值；  赋给它对应类别的训练样本中该属性的最常见值；  为缺失值的每个可能值赋予一个概率，而不是简单地将最常见的值赋给它。4.4. 局限性与剪枝对于构建（特别是 CART 算法）得到的决策树，一个很大的局限性是树存在较大的过拟合问题。因此我们需要采取剪枝来缓解过拟合问题。剪枝是从已经生成的树上裁掉一些子树或叶节点，并将其根节点或父节点作为新的叶子节点，从而简化决策树模型的方法。剪枝分为先剪枝和后剪枝：  先剪枝就是控制决策树的生长，在决策树构建过程中决定某节点是叶节点、还是继续分枝。这在前述算法伪代码中有所体现；  后剪枝是在决策树得到充分生长之后，再对其进行修剪。从叶节点开始，合并具有相同父节点的叶节点后不会导致纯度明显降低，则执行合并。5. 分类器集成分类器集成是机器学习中集成学习领域的一个子集，是针对模式识别中分类问题的应用。集成学习原名为 Classifier combination / ensemble learning，它是根据训练数据构造一组基分类器（base classifier），通过聚合每个基分类器的输出来进行分类。  基分类器的性能取决于它选择的分类算法和训练集；  对于单个性能比较弱的基分类器，称之为弱分类器（错误率略优于0.5）；  对于单个性能比较强的基分类器，称之为强分类器（准确率很高，并且能在多项式时间内完成）。  多项式时间‌是计算机科学中用于衡量算法时间复杂度的核心概念，指算法的运行时间随输入规模 $n$ 的增长可按某个多项式函数（如 $O(n^k)$）增长。‌该概念是区分 “高效” 算法与 “低效” 算法的重要标准‌  常见的多项式复杂度算法包括：      $O(n^2)$：如冒泡排序的最差情况；    $O(n\\log n)$：如快速排序的最差情况；    $O(n)$：如遍历数组的最差情况；    多项式时间算法的效率显著高于超多项式时间（如指数时间 $O(2^n)$ 或阶乘时间 $O(n!)$）。当输入规模增大时，后者的运行时间会急剧上升，远超实际可行性。  根据多项式时间可以判定一些问题的求解难度：      P类问题‌：可在多项式时间内解决的判定问题，例如排序、最短路径等；    NP类问题‌：虽不确定是否存在多项式时间解法，但可在多项式时间内验证解的正确性，例如旅行商问题（TSP）的判定版本。NP完全性理论进一步探讨了这类问题的计算难度边界。  为什么需要集成学习?  弱分类器间存在一定的差异性 ，这会导致分类的边界不同，也就是说可能存在错误。那么将多个弱分类器合并后，就可以得到更加合理的边界，减少整体的错误率，实现更好的效果;  对于数据集过大或者过小，可以分别进行划分和有放回的操作产生不同的数据子集，然后使用数据子集训练不同的分类器，最终再合并成为一个大的分类器;  如果数据的划分边界过于复杂，使用线性模型很难描述情况，那么可以训练多个模型，然后再进行模型的融合;  对于多个异构的特征集的时候，很难进行融合，那么可以考虑每个数据集构建一个分模型，然后将多个模型融合。关于多个弱分类器集成能提高分类效果降低错误率的分析如下：考虑一种简单的情况，对于一个二分类问题 $y\\in{-1,+1}$，最简单直接的集成策略就是少数服从多数的投票，即对于 $T$（不妨设为奇数）个基分类器 $h_i(\\boldsymbol{x}),\\; i=1,\\ldots,T$ 的投票结果为\\[H(\\boldsymbol{x}) = \\text{sign}\\left[ \\sum_{i=1}^T h_i(\\boldsymbol{x}) \\right]\\]集成分类器若分类错误，相当于假设有 $k=[0,(T-1)/2]$ 个基分类器分类正确，此时分类正确的基分类器占少数，所以总分类器实际上是错分的。因此，计算集成分类器的错误率需要对 $k$ 进行遍历，然后计算不同 $k$ 取值下的概率和。假设基分类器的错误率相互独立，且错误率均为 $\\varepsilon$，则集成分类器的错误率为\\[E = \\sum _{k=0}^{(T-1)/2} C_T^k (1-\\varepsilon)^k\\varepsilon^{T-k}\\]上式根据一个很复杂的变换可以转化为下面的格式\\[E \\leq \\exp (-\\frac{1}{2} T(1-2\\varepsilon)^2)\\]即集成学习其分类错误的概率存在一个上限值，这个值在 $\\varepsilon = 0.5$ 时达到最大值 1。当 $\\varepsilon$ 保持不变的情况下，集成分类器的错误率随着分类器数目 $T$ 的增大呈现指数级的缩小。上述分析有一个关键假设，基分类器的误差相互独立。现实任务中，基分类器是为了解决同一个问题（甚至基于同一个数据集）而训练出来的，显然不可能相互独立。事实上，基分类器的 “准确性” 和 “多样性” 本身就存在冲突，如何产生 “好而不同” 的基分类器是集成学习研究的核心。根据集成学习的思想不同，分为 Bagging、Boosting、Stacking 等。5.1. BaggingBagging 方法又叫做自举汇聚法（Bootstrap Aggregating），是一种并行的算法。其基本思想是︰在原始数据集上通过有放回的抽样的方式，重新选择出 $T$ 个新数据集来分别训练 $T$ 个分类器的集成技术。也就是说这些模型的训练数据中允许存在重复数据。      Bagging 的“自举”（Bootsrap）：从训练集里面采集固定个数的样本，但是每采集一个样本后，都将样本放回。也就是说，之前采集到的样本在放回后有可能继续被采集到。        Bagging 的汇聚（Aggregating）：对于分类问题，通常使用简单投票法，得到最多票数的类别或者类别之一为最终的模型输出。对于回归问题，通常使用简单平均法，对 $T$ 个弱学习器得到的回归结果进行算术平均得到最终的模型输出。  由于 Bagging 算法每次都进行采样来训练模型，因此泛化能力很强，对于降低模型的方差很有作用。当然对于训练集的拟合程度就会差一些，也就是模型的偏差会大一些。Bagging 方法的弱学习器可以是前面介绍过的基本算法模型，比如 Linear、ID3、C4.5、CART、SVM、KNN 等。如果 Bagging 中每一个弱分类器都是一个决策树，那么称该方法为 「随机森林」。5.1.1. 随机森林在 Bagging 集成策略的基础上，通过构建决策树作为弱分类器，可以得到随机森林（Random Forest），具体步骤如下：  从样本集 $N$ 中用 Bootstrap 采样选出 $n$ 个样本；  从所有属性 $K$ 中随机选择 $k\\ll K$ 个属性，选择出最佳分割属性作为节点创建决策树；  重复以上两步 $m$ 次，即建立 $m$ 棵决策树；  这 $m$ 个决策树形成随机森林，通过投票表决结果决定数据属于那一类。随机森林中「随机」二字的内涵之一就是源于 Bagging 思想中对样本的随机抽样和放回操作。抽样数据在一定程度上体现了全体样本数据的特性，所以可以用样本数据训练模型来预测其他的全体数据。但是，抽样数据与全体样本数据之间仍然是存在差异性的，弱分类器（决策树）在拟合各自抽样得到的数据集时，有可能出现不拟合生产环境中数据的情况，这就是过拟合。在决策树中，进行特征属性划分选择的时候，如果选择最优，表示这个划分在当前数据集上一定是最优的，但是不一定在全体数据中最优；在随机森林中，如果每个决策树都是选择最优的进行划分，就会导致所有弱分类器模型（决策树）很大概率上会使用相同的特征属性进行数据的划分，容易导致过拟合，所以在随机森林中一般使用随机的方式选择特征属性划分，这也是随机森林中「随机」二字的内涵之一。影响随机森林的分类效果因素包括：  随机森林中任意两棵树的相关性，相关性越强错误率越大；  森林中每棵树的分类能力，越强则整棵树的错误率越小；  特征 $k$ 的个数，减少特征个数，树的相关性和分类能力都会下降；反之二者也会随之增大。特征个数 $k$ 和树的个数 $m$ 是随机森林的两个参数，其中 $k$ 的选择是随机森林的一个重要参数，因为其对随机森林的性能影响很大。5.2. Boosting在正式介绍Boosting思想之前，先介绍一个例子：将每次测验的错的题目记录在错题本上，不停的翻阅，直到我们完全掌握。这个例子都说明 Boosting 的道理，也就是不断重复学习达到最终的要求。  Boosting 的思想源于计算学习理论中的概率计算正确理论 PAC（Probably Approximately Correct）。某个模型如果称为 PAC 可学习的（learnable ），则存在一种算法能够以很大的概率，学到一个很高的精确度，并且在多项式时间内完成。实际上，由于需要对任意高的概率和精确度都可学习，只有很少的模型是属于 PAC 可学习范畴的 “强” 可学习模型。“弱” 可学习模型只能保证以任意高的概率学到比随机猜测好一点。  Valiant 和 Kearns 首次提出了 PAC 学习模型中弱学习算法和强学习算法的等价性问题，即任意给定仅比随机猜测略好的弱学习算法，是否可以将其提升为强学习算法。  Schapire 于 1990 年构造性地证明了：“弱”可学习模型与“强”可学习模型这两个概念是等价的。说明，任何弱学习算法都可以被组合成一个强学习算法。这个证明就是最初实际可用的 Boosting 算法（即 AdaBoost）。Boosting 方法是按照一定的顺序来训练不同的基模型，每个模型都针对前序模型的错误进行专门训练,从而增加不同基模型之间的差异性。 Boosting 方法是一种非常强大的集成方法，只要基模型的准确率比随机猜测高，就可以通过集成方法来显著地提高集成模型的准确率。算法的步骤如下：  首先从初始训练集训练出一个弱分类器 1，根据弱分类器 1 的表现对训练样本分布进行调整，使得之前弱分类器1识别错误的训练样本在后面得到更多的重视  然后基于调整后的训练集来训练弱分类器 2，如此重复进行，直到弱分类器数达到事先指定的数目 $T$  最终将这 $T$ 个弱分类器通过集成策略进行整合，得到最终的强分类器。Boosting 方法的示意图如下所示。在上述算法步骤中，有两个问题需要进一步解决：  如何调整训练集权重用于训练弱分类器？  如何将训练好的各弱分类器联合起来形成强分类器？下面介绍 AdaBoost 算法为上面两个问题提供了一种解决方案。5.2.1. AdaBoostAdaBoost（Adaptive Boosting）算法是 Boosting 方法的一种，采用了以下策略：  使用加权后选取的训练数据代替随机选取的训练样本，这样将训练的焦点集中在比较难分的训练数据样本上；  将弱分类器联合起来，使用「加权的投票机制」代替平均投票机制。让分类效果好的弱分类器具有较大的权重，而分类效果差的分类器具有较小的权重。对于一个二分类任务而言，首先对样本集中所有 $n$ 样本点的权重初始化为相同的大小，对于第 $t=1$ 次迭代时有\\[w_t(i) = \\frac{1}{n}, i = 1, 2, \\cdots, n\\]调用弱学习算法，产生一个基分类器 $h_t$，该分类器的「加权错误率」为 $\\varepsilon_t$，可得\\[\\varepsilon_t = \\sum_{i=1}^n w_t(i) \\cdot l_{0/1}\\{y_i \\neq h_t(x_i)\\},\\; y\\in\\{-1,+1\\}-\\]其中 $l_{0/1}$ 为 0/1 计数函数，当括号内条件满足时为 1，否则为 0。定义 $\\alpha_t$ 为基分类器 $h_t$ 的权重系数，其计算公式为\\[\\alpha_t = \\frac{1}{2} \\ln \\left( \\frac{1 - \\varepsilon_t}{\\varepsilon_t} \\right)\\]当 $\\varepsilon = 0.5$ 时（相当于基分类器随机猜测），对应权重系数为 0。但凡基分类器是一个弱分类器，其权重系数就会大于零。基分类器性能越好，错误率越小，权重系数越大。注意，此处的权重定义并非随意指定的，而是可以通过加性模型（Additive Model）的梯度下降优化或指数损失函数的最小化严格推导得出，详见后文。但凡弱分类器的错误率 $\\varepsilon &lt; 0.5$，即可对样本集中的所有样本更新权值分布，即\\[w_{t+1}(i) = \\begin{cases}  w_t(i)\\exp(-\\alpha_t),\\; h_i(\\boldsymbol{x}) = y_i\\\\  w_t(i)\\exp(\\alpha_t),\\; h_i(\\boldsymbol{x}) \\neq y_i\\end{cases}\\]也即对于误分的样本其权值会乘以一个 $\\exp(\\alpha_t) &gt; 1$ 的系数；反之则会乘以一个 $\\exp(-\\alpha_t) &lt; 1$ 的系数。可将其写为一行的简化形式，并进行归一化\\[\\begin{aligned}w_{t+1}(i) &amp;= w_t(i)\\exp(-\\alpha_t \\cdot y_i h_t(\\boldsymbol{x}_i))\\\\w_{t+1}(i) &amp;= \\frac{w_{t+1}(i)}{\\sum_{j=1}^n w_{t+1}(j)}\\end{aligned}\\]基于权重更新过后的样本集再次设计新的基分类器。如此重复经过全部 $T$ 轮迭代后，定义最终的强分类器为 $H$，其为迭代过程中所有基分类器 $h_t$ 按照一定的规则组合起来，一种加权投票的组合形式如下\\[H(\\boldsymbol{x}) = \\text{sign}\\left(\\sum_{t=1}^T \\alpha_th_t(\\boldsymbol{x})\\right)\\]所以，与前面介绍的 Bagging 算法不同，AdaBoost 是一种「串行」的算法，通过弱学习器开始加强，它每一步产生弱预测模型（如决策树），并加权累加到总模型中。5.2.2. 加性模型与指数损失函数AdaBoost可视为对加性模型\\[H(\\boldsymbol{x}) = \\sum_{t=1}^T \\alpha_th_t(\\boldsymbol{x})\\]的优化，其目标是最小化指数损失函数\\[L(H) = \\mathbb{E}_{(\\boldsymbol{x},y)\\sim D}[e^{-yH(\\boldsymbol{x})}]\\]当预测正确时，$yH(\\boldsymbol{x})&gt;0$，损失较小；反之损失较大。在第 $t$ 轮迭代中，假设已经得到前 $t-1$ 轮的模型 $H_{t+1}(x)$，当前目标是找到一个弱分类器 $h_t(\\boldsymbol{x})$ 和权重 $\\alpha_t$ 使得以下损失函数最小化\\[L(\\alpha_t, h_t) = \\mathbb{E}_D\\left[e^{-y(H_{t-1}(\\boldsymbol{x}) + \\alpha_t h_t(\\boldsymbol{x}))}\\right]\\]令\\[w_t(i) = e^{-y_i H_{t-1}(\\boldsymbol{x}_i)}\\]为前 $t-1$ 轮累计的权重因子，则损失函数变为\\[L(\\alpha_t, h_t) = \\sum_{i=1}^n w_t(i)e^{-y_i\\alpha_t h_t(\\boldsymbol{x}_i)}\\]损失函数可按分类结果拆分为两部分\\[L(\\alpha_t) = \\sum_{y_i=h_t(\\boldsymbol{x}_i)}^n w_t(i)e^{-\\alpha_t}+\\sum_{y_i\\neq h_t(\\boldsymbol{x}_i)}^n w_t(i)e^{\\alpha_t}\\]定义第 $t$ 轮迭代得到的基分类器 $h_t$ 的加权错误率为\\[\\varepsilon_t = \\frac{\\sum_{y_i\\neq h_t(\\boldsymbol{x}_i)} w_t(i)}{\\sum_{i=1}^n w_t(i)}\\]则损失函数可以表示为\\[L(\\alpha_t) = (1-\\varepsilon_t)e^{-\\alpha_t} + \\varepsilon_te^{\\alpha_t}\\]对损失函数关于 $\\alpha_t$ 求导并令导数为零，有\\[(1-\\varepsilon_t)e^{-\\alpha_t} = \\varepsilon_te^{\\alpha_t} \\; \\Rightarrow \\; \\frac{1-\\varepsilon_t}{\\varepsilon_t} = e^{2\\alpha_t} \\; \\Rightarrow \\; \\alpha_t = \\frac{1}{2}\\ln \\left( \\frac{1 - \\varepsilon_t}{\\varepsilon_t} \\right)\\]上述推导和前面基分类器系数定义是一致的。5.3. 集成表决策略将个体学习器结合为集成学习器的方法有很多种，下面简单进行介绍总结。  平均法          简单平均法：$H(x) = \\frac{1}{N}\\sum_{i=1}^N h_i(x)$      加权平均法:$H(x) = \\sum_{i=1}^N \\alpha_i h_i(x)$        投票法          绝对多数投票：如果某个标签的的票数超过半数，则预测为该标记；否则拒绝该标记      相对多数投票：预测为得票数最多的类别，如果有多个类别的票数相同且都最高，那么从这几个类别中随机选择一个      加权投票：与前述加权平均法类似，对每个基分类器施加权重，再输出得票最多的类别。        学习法          当训练数据过多时，使用简单的结合策略可能会导致很大的误差，这时可以采用一个更为强大的学习策略：学习法，即通过另一个学习器来进行结合。最为著名的学习法的代表就是「Stacking」方法，这里我们把个体学习器称为初级学习器，把用于结合的学习器称为次级学习器。      5.4. Stacking前述 Boosting 和 Bagging 通常都是使用同一种基分类器，因此我们一般称之为同质集成方法。Stacking 通常都是基于多个不同的基分类器做的集成，因此我们称之为异质集成方法。可参考：https://zhuanlan.zhihu.com/p/5014266716. 参考文献[1] 周志华. 机器学习. 北京：清华大学出版社, 2016.[2] T. M. Cover and P. E. Hart. Nearest neighbor pattern classification. IEEE Transactions on Information Theory, 13:21–27, January 1967.[3] blilbili. SVM白板推导(六)-支持向量机SVM（Support Vector Machine）.[4] 知乎. 机器学习-白板推导系列(六)-支持向量机SVM（Support Vector Machine）笔记."
  },
  
  {
    "title": "深度学习（基础数学知识）",
    "url": "/posts/deep-learning-basic-math/",
    "categories": "Academic, Knowledge",
    "tags": "deep learning",
    "date": "2025-03-05 18:30:19 +0800",
    





    
    "snippet": "本文介绍了机器（深度）学习的基础数学知识，作为后续深入学习的基础。  1. 矩阵          1.1. 迹（trace）      1.2. 范数                  1.2.1. 向量范数          1.2.2. 矩阵范数                    1.3. 正交矩阵      1.4. 矩阵的值域、零空间和秩                  1....",
    "content": "本文介绍了机器（深度）学习的基础数学知识，作为后续深入学习的基础。  1. 矩阵          1.1. 迹（trace）      1.2. 范数                  1.2.1. 向量范数          1.2.2. 矩阵范数                    1.3. 正交矩阵      1.4. 矩阵的值域、零空间和秩                  1.4.1. 向量的张成（span）          1.4.2. 向量的投影          1.4.3. 矩阵的值域（range）          1.4.4. 矩阵的零空间（nullspace）          1.4.5. 秩-零度定理          1.4.6. 矩阵的秩（rank）                    1.5. 二次型                  1.5.1. 定义          1.5.2. 与投影的关系                      2. 矩阵的梯度          2.1. 多元函数的梯度      2.2. 向量函数的梯度（雅可比矩阵）      2.3. 矩阵函数的梯度      2.4. 分子布局与分母布局                  2.4.1. 分子布局          2.4.2. 分母布局                    2.5. 向量函数/矩阵函数梯度的链式法则                  2.5.1. 基本形式          2.5.2. 分子布局下的链式法则          2.5.3. 分母布局下的链式法则          2.5.4. 举例                      3. 矩阵的全微分          3.1. 多元函数的全微分      3.2. 矩阵函数的全微分      1. 矩阵1.1. 迹（trace）方阵 $\\boldsymbol{A}\\in \\mathbb{R}^{n\\times n}$ 的迹定义为对角线元素之和\\[\\text{tr}(\\boldsymbol{A}) = \\sum_{i=1}^n a_{ii}\\]迹有如下性质：  对于 $\\boldsymbol{A}\\in\\mathbb{R}^{n\\times n}, \\text{tr}(\\boldsymbol{A}) = \\text{tr}(\\boldsymbol{A}^\\top)$          方阵的转置不改变对角元素        对于 $\\boldsymbol{A},\\boldsymbol{B}\\in\\mathbb{R}^{n\\times n}, \\text{tr}(\\boldsymbol{A}+\\boldsymbol{B}) = \\text{tr}(\\boldsymbol{A})+\\text{tr}(\\boldsymbol{B})$          矩阵的和为各元素加和        对于 $\\boldsymbol{A}\\in\\mathbb{R}^{n\\times n}, t\\in\\mathbb{R}, \\text{tr}(t\\boldsymbol{A}) = t\\text{tr}(\\boldsymbol{A})$          矩阵与数字相乘是将矩阵中每个元素与该数字相乘        对于 $\\boldsymbol{A}\\in\\mathbb{R}^{m\\times n},\\boldsymbol{B}\\in\\mathbb{R}^{n\\times m}, \\text{tr}(\\boldsymbol{AB}) = \\text{tr}(\\boldsymbol{BA})$    \\[\\begin{aligned}\\text{tr} \\boldsymbol{A} \\boldsymbol{B} &amp; =\\sum_{i=1}^{m}(\\boldsymbol{A} \\boldsymbol{B})_{i i}=\\sum_{i=1}^{m}\\left(\\sum_{j=1}^{n} A_{i j} B_{j i}\\right) \\\\&amp; =\\sum_{i=1}^{m} \\sum_{j=1}^{n} A_{i j} B_{j i}=\\sum_{j=1}^{n} \\sum_{i=1}^{m} B_{j i} A_{i j} \\\\&amp; =\\sum_{j=1}^{n}\\left(\\sum_{i=1}^{m} B_{j i} A_{i j}\\right)=\\sum_{j=1}^{n}(B A)_{j j}=\\text{tr} \\boldsymbol{B} \\boldsymbol{A} .\\end{aligned}\\]        对于 $\\boldsymbol{A},\\boldsymbol{B}\\in\\mathbb{R}^{m\\times n}, \\text{tr}(\\boldsymbol{AB^\\top}) = \\sum_{i=1}^m\\sum_{j=1}^n A_{ij}B_{ij}$          通过观察上一个性质的中间推导过程，将其中 $\\boldsymbol{B}$ 的转置带入即可        对于 $\\boldsymbol{A}\\in\\mathbb{R}^{m\\times n}, \\text{tr}(\\boldsymbol{AA^\\top}) = \\sum_{i=1}^m\\sum_{j=1}^n \\boldsymbol{A}_{ij}^2 = \\Vert\\boldsymbol{A}\\Vert_F^2$          将前述性质推导中的 $\\boldsymbol{B}$ 替换为 $\\boldsymbol{A}$ 即可，其中定义矩阵的 Frobenius 范数为\\(\\Vert\\boldsymbol{A}\\Vert_F = \\sqrt{\\sum_{i=1}^m\\sum_{j=1}^n \\boldsymbol{A}_{ij}^2} = \\sqrt{\\text{tr}(\\boldsymbol{A}^\\top \\boldsymbol{A})}\\)      1.2. 范数1.2.1. 向量范数向量范数的含义：测量响亮的“长度”或向量到原点的距离。数学描述为定义在 $\\mathbb{R}^n$ 上的实值函数 $\\Vert \\cdot \\Vert$ 称为向量范数，如果 $\\forall \\boldsymbol{x},\\boldsymbol{x} \\in \\mathbb{R}^n, k\\in \\mathbb{R}$ 满足  正定性：$\\Vert \\boldsymbol{x} \\Vert \\geq 0$  齐次性：$\\Vert k\\boldsymbol{x} \\Vert = k\\Vert \\boldsymbol{x} \\Vert$  满足三角不等式：$\\Vert \\boldsymbol{x} + \\boldsymbol{y} \\Vert \\leq \\Vert \\boldsymbol{x} \\Vert + \\Vert \\boldsymbol{y} \\Vert$常用范数有  $l_1$范数：\\(\\Vert \\boldsymbol{x} \\Vert_1 = \\sum_{i=1}^n |x_i|\\)  $l_2$范数：\\(\\Vert \\boldsymbol{x} \\Vert_2 = \\sqrt{\\sum_{i=1}^n x_i^2} = \\sqrt{\\boldsymbol{x}^\\top \\boldsymbol{x}}\\)  $l_p$范数：\\(\\Vert \\boldsymbol{x} \\Vert_p = \\left(\\sum_{i=1}^n |x_i|^p\\right)^{\\frac{1}{p}}\\)  L$\\infty$范数：\\(\\Vert \\boldsymbol{x} \\Vert_\\infty = \\max_{i=1}^n |x_i|\\)1.2.2. 矩阵范数将向量范数推广到矩阵范数有      矩阵 1-范数（列和范数），即各列元素绝对值之和的最大值：\\(\\Vert \\boldsymbol{A} \\Vert_1 = \\max_{1\\leq j\\leq n} \\sum_{i=1}^m |a_{ij}|\\)        矩阵 2-范数（谱范数）:\\(\\Vert\\boldsymbol{A} \\Vert_2 = \\sqrt{\\lambda_{\\max}(\\boldsymbol{A}^\\top \\boldsymbol{A})}\\)        Frobenius 范数：\\(\\Vert \\boldsymbol{A} \\Vert_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n a_{ij}^2}\\)        矩阵 $\\infty$-范数（行和范数），即各行元素绝对值之和的最大值：\\(\\Vert \\boldsymbol{A} \\Vert_\\infty = \\max_{1\\leq i\\leq m} \\sum_{j=1}^n |a_{ij}|\\)  1.3. 正交矩阵若两向量 $\\boldsymbol{x},\\boldsymbol{y}$ 满足$\\boldsymbol{x}^\\top \\boldsymbol{y}=0$，则称向量 $\\boldsymbol{x},\\boldsymbol{y}$ 正交（orthogonal）。若向量 $\\boldsymbol{x}\\in\\mathbb{R}^n$ 满足 $\\Vert\\boldsymbol{x}\\Vert_2=1$，则称向量 $\\boldsymbol{x}$ 是规范的（normalized）。推广到矩阵，若方阵 $\\boldsymbol{U}\\in\\mathbb{R}^{n\\times n}$ 满足所有列向量彼此正交，且所有列向量均规范，则称其为正交矩阵。      性质1（非方阵仅满足左半）:\\(\\boldsymbol{U}^\\top \\boldsymbol{U} = \\boldsymbol{I} = \\boldsymbol{U}\\boldsymbol{U}^\\top\\)        性质2（正交矩阵不改变向量的 $l_2$ 范数）:\\(\\Vert\\boldsymbol{U} \\boldsymbol{x}\\Vert_2 = \\Vert \\boldsymbol{x}\\Vert_2\\)  \\[\\Vert \\boldsymbol{U} \\boldsymbol{x}\\Vert_2 =\\sqrt{ (\\boldsymbol{U} \\boldsymbol{x})^\\top \\boldsymbol{U} \\boldsymbol{x}} = \\sqrt{\\boldsymbol{x}^\\top \\boldsymbol{U}^\\top\\boldsymbol{U} \\boldsymbol{x}} = \\sqrt{\\boldsymbol{x}^\\top \\boldsymbol{x}}=\\Vert \\boldsymbol{x}\\Vert_2\\]  性质3：$\\boldsymbol{U}^\\top = \\boldsymbol{U}^{-1}$  性质4：$\\det{\\boldsymbol{U}} = 1\\; or -1$一些重要的矩阵分解涉及到了正交矩阵，包括：  QR分解：$\\boldsymbol{A} = \\boldsymbol{QR}$，其中 $\\boldsymbol{Q}$ 是正交矩阵，$\\boldsymbol{R}$ 是上三角矩阵。  奇异值（SVD）分解：$\\boldsymbol{A} = \\boldsymbol{U}\\boldsymbol{D}\\boldsymbol{V}^\\top$，其中 $\\boldsymbol{U}$ 和 $\\boldsymbol{V}$ 是正交矩阵，$\\boldsymbol{D}$ 是对角矩阵。  谱分解：$\\boldsymbol{A} = \\boldsymbol{U}\\boldsymbol{Λ}\\boldsymbol{U}^\\top$，其中 $\\boldsymbol{U}$ 是正交矩阵，$\\boldsymbol{Λ}$ 是对角矩阵。1.4. 矩阵的值域、零空间和秩1.4.1. 向量的张成（span）向量的张成（span）是指一组向量通过线性组合所能生成的所有向量的集合。即：给定向量空间 $ V $ 中的一组向量 $ \\boldsymbol{v}_1, \\boldsymbol{v}_2, \\dots, \\boldsymbol{v}_k $，它们的张成（span）是这些向量的所有线性组合构成的集合，记作：\\[\\text{span}\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\dots, \\boldsymbol{v}_k\\} = \\{ c_1 \\boldsymbol{v}_1 + c_2 \\boldsymbol{v}_2 + \\dots + c_k \\boldsymbol{v}_k \\mid c_1, c_2, \\dots, c_k \\in \\mathbb{R} \\}\\]其中 $ c_1, c_2, \\dots, c_k $ 是标量。向量的张成是线性代数中描述向量组生成空间的核心概念。它通过线性组合的方式，刻画了向量组所能覆盖的空间范围。例1：二维空间中的向量\\[\\boldsymbol{v}_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}，\\boldsymbol{v}_2 =\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\]则\\[\\text{span}\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2\\} = \\mathbb{R}^2\\]即这两个向量张成了整个二维空间。例2：三维空间中的向量\\[\\boldsymbol{v}_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} , \\boldsymbol{v}_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}\\]则\\[\\text{span}\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2\\} = \\{ (x, y, 0) \\mid x, y \\in \\mathbb{R} \\}\\]张成一个二维（$xy$）平面。例3：线性相关的向量\\[\\boldsymbol{v}_1 = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}, \\boldsymbol{v}_2 = \\begin{bmatrix} 2 \\\\ 4 \\end{bmatrix}\\]则\\[\\text{span}\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2\\} = \\text{span}\\{\\boldsymbol{v}_1\\} = \\{ c \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\mid c \\in \\mathbb{R} \\}\\]张成的空间退化为一条直线。向量的张成有如下性质：  向量组的张成是向量空间 $V$ 的一个子空间（特殊情况下是向量空间本身，例1）；  如果向量组线性无关，则他们构成张成空间的一组基；  张成空间的维度等于向量组的秩（即最大线性无关向量组的个数）。1.4.2. 向量的投影向量 $\\boldsymbol{y}\\in \\mathbb{R}^n$ 在向量 $\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\dots, \\boldsymbol{v}_k \\in \\mathbb{R}^n $ 的张成上的投影定义为：在向量张成空间中与其距离最小的向量\\[\\boldsymbol{p} = \\text{Proj}(\\boldsymbol{y}; {\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\dots, \\boldsymbol{v}_k}) = \\mathop{\\arg\\min}\\limits_{\\boldsymbol{x}\\in \\text{span}\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\dots, \\boldsymbol{v}_k\\}} \\Vert \\boldsymbol{y} - \\boldsymbol{x} \\Vert_2\\]上述投影将 $\\boldsymbol{y}$ 分解为两个部分：一个位于该子空间内的向量（即投影向量 $\\boldsymbol{p}$），另一个与子空间正交的向量 $\\boldsymbol{y}-\\boldsymbol{p}$。此时，投影 $\\boldsymbol{p}$ 是 $\\boldsymbol{y}$ 在子空间 $\\mathcal{V}$ 中的最近点，即：\\[\\Vert\\boldsymbol{y}-\\boldsymbol{p}\\Vert_2 \\leq \\Vert\\boldsymbol{y}-\\boldsymbol{u}\\Vert_2 \\quad \\forall \\boldsymbol{u}\\in \\mathcal{V}\\]上述投影还有两个额外性质：性质1：投影 $\\boldsymbol{p}$ 是 $\\boldsymbol{y}$ 在空间 $V$ 上的正交投影，即 $\\boldsymbol{y}-\\boldsymbol{p}$ 与 $V$ 中的任意向量正交。性质2：如果 $\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\dots, \\boldsymbol{v}_k$ 是 $V$ 的一组基（即线性无关），构造矩阵 $\\boldsymbol{A}=[\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\dots, \\boldsymbol{v}_k] $ 显然是一个满秩矩阵，那么 $\\boldsymbol{p}$ 可以表示为\\[\\boldsymbol{p} = \\boldsymbol{A}(\\boldsymbol{A}^\\top \\boldsymbol{A})^{-1} \\boldsymbol{A}^\\top \\boldsymbol{y}\\]此时 $\\boldsymbol{A}^+ = (\\boldsymbol{A}^\\top \\boldsymbol{A})^{-1} \\boldsymbol{A}^\\top$ 为 $\\boldsymbol{A}$ 的 Moore-Penrose 伪逆，有\\[\\boldsymbol{p} = \\boldsymbol{A}\\boldsymbol{A}^+ \\boldsymbol{y}\\]当 $\\boldsymbol{A}$ 不满秩时，上述公式中的 $(\\boldsymbol{A}^\\top \\boldsymbol{A})^{-1}$ 不成立，此时伪逆 $\\boldsymbol{A}^+$ 需要通过其他方法计算（例如奇异值分解，SVD）。在这种情况下，投影矩阵仍然可以表示为 $\\boldsymbol{A}\\boldsymbol{A}^+$。1.4.3. 矩阵的值域（range）矩阵的值域（range），也成为列空间（Column Space），是指矩阵 $\\boldsymbol{A}$ 的所有列向量的线性组合构成的向量空间（即列向量的张成）。换句话说，它是矩阵 $\\boldsymbol{A}$ 的列空间（column space），记作 $\\text{range}(\\boldsymbol{A})$ 或 $\\text{col}(\\boldsymbol{A})$。对于矩阵 $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$，其值域定义为：\\[\\begin{aligned}\\text{range}(\\boldsymbol{A}) &amp;= \\{ \\boldsymbol{A}\\boldsymbol{x} \\mid \\boldsymbol{x} \\in \\mathbb{R}^n \\}\\\\&amp;=\\{x_1\\boldsymbol{a_1} + x_2\\boldsymbol{a_2} + \\cdots + x_n\\boldsymbol{a_n}\\vert x_i\\in\\mathbb{R}\\}\\\\&amp;=span\\{\\boldsymbol{a_1}, \\boldsymbol{a_2}, \\cdots, \\boldsymbol{a_n}\\}\\end{aligned}\\]值域的维度等于矩阵 $\\boldsymbol{A}$ 的秩（rank），记作 $\\text{rank}(\\boldsymbol{A})$，其同时也是最大的线性无关列向量的个数。例：设矩阵 $A$ 为：\\(A = \\begin{bmatrix}1 &amp; 2 \\\\3 &amp; 4\\end{bmatrix}\\)则 $\\text{range}(A)$ 是 $\\mathbb{R}^2$ 中的一个子空间，具体为：\\(\\text{range}(A) = \\text{span}\\left\\{ \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix}, \\begin{bmatrix} 2 \\\\ 4 \\end{bmatrix} \\right\\}\\)1.4.4. 矩阵的零空间（nullspace）矩阵的 零空间（Null Space），也称为核空间（Kernel），是指所有满足 $\\boldsymbol{A}\\boldsymbol{x} = \\boldsymbol{0}$ 的向量 $\\boldsymbol{x}$ 构成的集合。记作 $\\text{null}(\\boldsymbol{A})$ 或 $\\text{ker}(\\boldsymbol{A})$。对于矩阵 $\\boldsymbol{A}\\ \\in \\mathbb{R}^{m \\times n}$，其零空间定义为：\\(\\text{null}(\\boldsymbol{A}) = \\{\\boldsymbol{x} \\in \\mathbb{R}^n \\mid \\boldsymbol{A}\\boldsymbol{x} = \\boldsymbol{0}\\}\\)其中 $\\boldsymbol{0}$ 是 $m$-维零向量。  零空间是矩阵 $\\boldsymbol{A}$ 的齐次线性方程组的解空间，也是矩阵 $\\boldsymbol{A}$ 的列空间的补集。  零空间的维度称为矩阵的零度（nullity），记作 $\\text{nullity}(\\boldsymbol{A})$。例：设矩阵 $A$ 为：\\[\\boldsymbol{A} = \\begin{bmatrix}1 &amp; 2 \\\\3 &amp; 6\\end{bmatrix}\\]则齐次线性方程组 $\\boldsymbol{A}\\boldsymbol{x} = \\boldsymbol{0}$ 为：\\[\\begin{cases}x_1 + 2x_2 = 0 \\\\3x_1 + 6x_2 = 0\\end{cases}\\]解得：\\[x_1 = -2x_2\\]因此，解向量为：\\[\\boldsymbol{x} = x_3\\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}\\]因此，零空间为：\\[\\text{null}(\\boldsymbol{A}) = \\text{span}\\left\\{ \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix} \\right\\}\\]同时，观察到 $\\boldsymbol{v}_2 = 2\\boldsymbol{v}_1$，因此 $\\boldsymbol{v}_1$ 和 $\\boldsymbol{v}_2$ 是线性相关的，因此该矩阵的值域 $\\text{range}(\\boldsymbol{A})$ 由 $\\boldsymbol{v}_1$ 张成：\\[\\text{range}(\\boldsymbol{A}) = \\text{span}\\left\\{ \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix} \\right\\}\\]1.4.5. 秩-零度定理矩阵的 零空间（Nullspace）和 值域（Range）是矩阵的两个重要子空间，它们之间通过 秩-零度定理（Rank-Nullity Theorem）建立了紧密的联系。对于矩阵 $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$，其秩（rank）和零度（nullity）满足以下关系：\\(\\text{rank}(\\boldsymbol{A}) + \\text{nullity}(\\boldsymbol{A}) = n\\)其中：  $\\text{rank}(\\boldsymbol{A})$ 是矩阵 $\\boldsymbol{A}$ 的秩，即值域 $\\text{range}(\\boldsymbol{A})$ 的维度。  $\\text{nullity}(\\boldsymbol{A})$ 是矩阵 $\\boldsymbol{A}$ 的零度，即零空间 $\\text{null}(\\boldsymbol{A})$ 的维度。  $n$ 是矩阵 $\\boldsymbol{A}$ 的列数。零空间和值域之间存在如下性质：  互补性：          值域 $\\text{range}(\\boldsymbol{A})$ 和零空间 $\\text{null}(\\boldsymbol{A})$ 是互补的子空间。      值域是矩阵 $\\boldsymbol{A}$ 的列空间，表示 $\\boldsymbol{A}$ 的列向量的线性组合所能生成的空间。      零空间是矩阵 $\\boldsymbol{A}$ 的齐次线性方程组 $\\boldsymbol{A}\\boldsymbol{x} = \\boldsymbol{0}$ 的解空间。        正交性：                  在 $\\mathbb{R}^n$ 中，零空间 $\\text{null}(\\boldsymbol{A})$ 和值域 $\\text{range}(\\boldsymbol{A}^\\top)$（即 $\\boldsymbol{A}$ 的行空间）是正交补空间，即：\\[\\begin{aligned}&amp;\\text{null}(\\boldsymbol{A}) \\perp \\text{range}(\\boldsymbol{A}^\\top)\\\\&amp;\\text{null}(\\boldsymbol{A})\\oplus\\text{range}(\\boldsymbol{A}^\\top)=\\mathbb{R}^n\\end{aligned}\\]                    类似地，在 $\\mathbb{R}^m$ 中，零空间 $\\text{null}(\\boldsymbol{A}^\\top)$ 和值域 $\\text{range}(\\boldsymbol{A})$ 是正交补空间，即：\\[\\begin{aligned}&amp;\\text{null}(\\boldsymbol{A}^\\top) \\perp \\text{range}(\\boldsymbol{A})\\\\&amp;\\text{null}(\\boldsymbol{A}^\\top)\\oplus\\text{range}(\\boldsymbol{A})=\\mathbb{R}^m\\end{aligned}\\]              维度关系：          值域的维度 $\\text{rank}(\\boldsymbol{A})$ 表示矩阵 $\\boldsymbol{A}$ 的列向量的线性无关性。      零空间的维度 $\\text{nullity}(\\boldsymbol{A})$ 表示齐次线性方程组 $\\boldsymbol{A}\\boldsymbol{x} = \\boldsymbol{0}$ 的自由变量的个数。      根据秩-零度定理，$\\text{rank}(\\boldsymbol{A}) + \\text{nullity}(\\boldsymbol{A}) = n$，表明值域和零空间的维度之和等于矩阵的列数。        几何意义：          值域 $\\text{range}(\\boldsymbol{A})$ 描述了矩阵 $\\boldsymbol{A}$ 的“覆盖”程度，即矩阵的列向量能够生成的空间的维度。      零空间 $\\text{null}(\\boldsymbol{A})$ 描述了矩阵 $\\boldsymbol{A}$ 的“压缩”程度，即有多少线性无关的向量被映射到零向量。      1.4.6. 矩阵的秩（rank）矩阵的 秩（Rank）是线性代数中的一个重要概念，用于描述矩阵的列向量（或行向量）的线性无关性。它反映了矩阵所包含的“信息量”或“自由度”。对于矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其秩定义为：\\[\\text{rank}(A) = \\dim(\\text{range}(A))\\]其中：  $\\text{range}(A)$ 是矩阵 $A$ 的值域（列空间）。  $\\dim(\\cdot)$ 表示向量空间的维度。换句话说，矩阵的秩是其列向量的极大线性无关组的向量个数。秩有如下性质：  秩的范围：          对于 $m \\times n$ 矩阵 $A$，其秩满足：\\(0 \\leq \\text{rank}(A) \\leq \\min(m, n)\\)        满秩矩阵：          如果 $\\text{rank}(A) = \\min(m, n)$，则称矩阵 $A$ 为 满秩矩阵。      对于方阵 $A \\in \\mathbb{R}^{n \\times n}$，如果 $\\text{rank}(A) = n$，则 $A$ 是可逆矩阵。        秩与行列式：          对于方阵 $A$，如果 $\\text{rank}(A) &lt; n$，则 $\\det(A) = 0$（矩阵不可逆）。      如果 $\\text{rank}(A) = n$，则 $\\det(A) \\neq 0$（矩阵可逆）。      1.5. 二次型1.5.1. 定义向量二次型是一个关于向量的二次齐次多项式。给定方阵 $\\boldsymbol{A} \\in \\mathbb{R}^{n \\times n}$ 和向量 $\\boldsymbol{x} \\in \\mathbb{R}^n$，定义二次型为：\\[Q(\\boldsymbol{x}) = \\boldsymbol{x}^\\top \\boldsymbol{A} \\boldsymbol{x} = \\sum_{i=1}^n x_i (\\boldsymbol{Ax}_i) = \\sum_{i=1}^n  x_i (\\sum_{j=1}^n A_{ij} x_j) = \\sum_{i=1}^n \\sum_{j=1}^n x_i A_{ij} x_j\\]  在大多数情况下，二次型的定义中要求矩阵 $A$ 是对称矩阵（即 $A = A^\\top$）。这是因为      唯一性：对于任意矩阵 $A$，可以将其分解为对称部分和反对称部分：  \\(\\boldsymbol{A} = \\frac{\\boldsymbol{A} + \\boldsymbol{A}^T}{2} + \\frac{\\boldsymbol{A} - \\boldsymbol{A}^T}{2}\\)其中 $\\frac{\\boldsymbol{A} + \\boldsymbol{A}^T}{2}$ 是对称矩阵，$\\frac{\\boldsymbol{A} - \\boldsymbol{A}^T}{2}$ 是反对称矩阵。    反对称部分的影响：反对称矩阵 $\\boldsymbol{B} = \\frac{\\boldsymbol{A} - \\boldsymbol{A}^T}{2}$ 满足 $\\boldsymbol{x}^T \\boldsymbol{B} \\boldsymbol{x} = 0$ 对所有 $\\boldsymbol{x}$ 成立。因此，反对称部分对二次型的值没有贡献。    简化分析：对称矩阵具有许多良好的性质（如实特征值、正交对角化等），这使得二次型的分析更加简便。  由于向量二次型是一个标量，它的迹就是他本身\\[\\text{tr}(\\boldsymbol{x}^\\top \\boldsymbol{A} \\boldsymbol{x}) = \\boldsymbol{x}^\\top \\boldsymbol{A} \\boldsymbol{x}\\]  扩展到矩阵形式的二次型，给定 $\\boldsymbol{X}\\in \\mathbb{R}^{n \\times m}$， 有  \\(Q(\\boldsymbol{X}) = \\boldsymbol{X}^\\top \\boldsymbol{A} \\boldsymbol{X} \\in \\mathbb{R}^{m \\times m}\\)且有 $Q(\\boldsymbol{X})$ 的第 $(i,j)$ 元素为\\([Q(\\boldsymbol{X})]_{ij} = \\boldsymbol{x_i}^\\top \\boldsymbol{A} \\boldsymbol{x_j}\\)二次型的性质包括：  正定性：如果对于所有非零向量 $ x $，都有 $ Q(x) &gt; 0 $，则称二次型是正定的。  负定性：如果对于所有非零向量 $ x $，都有 $ Q(x) &lt; 0 $，则称二次型是负定的。  半正定性：如果对于所有向量 $ x $，都有 $ Q(x) \\geq 0 $，则称二次型是半正定的。  半负定性：如果对于所有向量 $ x $，都有 $ Q(x) \\leq 0 $，则称二次型是半负定的。  不定性：如果二次型既不是正定的，也不是负定的，也不是半正定的，也不是半负定的，则称二次型是不定的。二次型在优化理论、控制理论和微分几何等领域都有重要的应用。  例：最小二乘在最小二乘法中，目标是找到向量 $x$ 使得误差的平方和最小。目标函数可以表示为二次型：\\[L(\\boldsymbol{w}) = \\| \\boldsymbol{y} - \\boldsymbol{X}\\boldsymbol{w}  \\|^2 = (\\boldsymbol{y} -  \\boldsymbol{X}\\boldsymbol{w} )^T (\\boldsymbol{y} -  \\boldsymbol{X}\\boldsymbol{w})\\]其中，$\\boldsymbol{y}$ 是真实观测矩阵（标签）,$\\boldsymbol{w}$ 是权重矩阵，$\\boldsymbol{X}$ 是样本矩阵。最小化目标函数可以得到最优解 $\\boldsymbol{w}^*$ 以最小化误差的平方和。展开后得到二次型\\[L(\\boldsymbol{w}) = \\boldsymbol{y}^T \\boldsymbol{y} - 2 \\boldsymbol{y}^T \\boldsymbol{X} \\boldsymbol{w} + \\boldsymbol{w}^T \\boldsymbol{X}^T \\boldsymbol{X} \\boldsymbol{w}\\]因为第一项是一个常数项，与$\\boldsymbol{w}$无关，可以忽略。第二项是一个线性项，关于 $\\boldsymbol{w}$ 是线性的。第三项中 $\\boldsymbol{A}^\\top \\boldsymbol{A}$ 是一个对称矩阵，所以第三项是一个二次型。虽然损失函数还包含线性项和常数项，但这些项并不改变其二次性，因为它们不会改变最优解的性质。  对于第三项，令 $\\boldsymbol{B} = \\boldsymbol{X}^\\top\\boldsymbol{X}$，参考《the Matrix Cookbook》二次型的导数\\[\\frac{\\partial \\boldsymbol{x}^\\top\\boldsymbol{B\\boldsymbol{x}}}{\\partial \\boldsymbol{x}} = (\\boldsymbol{B}+\\boldsymbol{B}^\\top)\\boldsymbol{x} \\tag{81}\\]  若 $\\boldsymbol{B}$ 满足 $\\boldsymbol{B} = \\boldsymbol{B}^\\top$，此时有\\[\\frac{\\partial \\boldsymbol{x}^\\top\\boldsymbol{B\\boldsymbol{x}}}{\\partial \\boldsymbol{x}} = 2\\boldsymbol{B}\\boldsymbol{x}\\]如果 $\\boldsymbol{X}^\\top \\boldsymbol{X}$ 是正定矩阵，则损失函数是凸函数，具有唯一的全局最优解，因此可以通过对二次型求导并令梯度为零 $\\partial L / \\partial \\boldsymbol{w} = 0$，直接得到最小二乘问题的解析解 $\\boldsymbol{w}^* = (\\boldsymbol{X}^T \\boldsymbol{X})^{-1} \\boldsymbol{X}^T \\boldsymbol{y}$。  例：Fisher 投影判别的优化目标Fisher 投影判别的的优化目标函数可以写成\\[J(\\boldsymbol{w}) = \\frac{\\boldsymbol{w}^T\\boldsymbol{S}_b\\boldsymbol{w}}{\\boldsymbol{w}^T\\boldsymbol{S}_w\\boldsymbol{w}}\\]将优化问题更改如下\\[\\begin{aligned}\\max &amp;\\; \\boldsymbol{w}^T\\boldsymbol{S}_b\\boldsymbol{w}\\\\s.t. &amp;\\; \\boldsymbol{w}^T\\boldsymbol{S}_w\\boldsymbol{w}=c\\neq 0\\end{aligned}\\]通过额外引入一个使得分子等于常数的等式约束来限制 $\\boldsymbol{w}$ 的取值，然后通过拉格朗日乘子法求解极大值，定义拉格朗日函数如下\\[\\begin{aligned}L(\\boldsymbol{w},\\lambda) &amp;= \\boldsymbol{w}^\\top\\boldsymbol{S}_b\\boldsymbol{w} - \\lambda (\\boldsymbol{w}^\\top\\boldsymbol{S}_w\\boldsymbol{w}-c)\\\\\\Rightarrow \\frac{\\partial L(\\boldsymbol{w},\\lambda)}{\\partial \\boldsymbol{w}} &amp;= 2\\boldsymbol{S}_b\\boldsymbol{w} - 2\\lambda \\boldsymbol{S}_w\\boldsymbol{w}\\\\\\end{aligned}\\]同样涉及到二次型的求导。1.5.2. 与投影的关系最小二乘的解析解为\\[\\boldsymbol{w}^* = (\\boldsymbol{X}^T \\boldsymbol{X})^{-1} \\boldsymbol{X}^T \\boldsymbol{y}\\]对应的投影向量为\\[\\boldsymbol{p} = \\boldsymbol{X} (\\boldsymbol{X}^T \\boldsymbol{X})^{-1} \\boldsymbol{X}^T \\boldsymbol{y}\\]有\\[\\boldsymbol{p} = \\boldsymbol{X} \\boldsymbol{w}^*\\]讨论如下：  投影向量 $\\boldsymbol{p}$ 描述了真实标签 $\\boldsymbol{y}$ 在样本空间 $\\boldsymbol{X}$ 中的实际投影。  二次型的解析解 $\\boldsymbol{w}^*$ 描述了如何在样本空间 $\\boldsymbol{X}$ 中找到最接近于真实标签 $\\boldsymbol{y}$ 的向量，即描述这个“影子”如何由样本空间 $\\boldsymbol{X}$ 的列向量组合而成的系数;2. 矩阵的梯度2.1. 多元函数的梯度  https://www.cnblogs.com/bigmonkey/p/8400658.html多元函数是指定义在多维空间上的标量值函数 $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$。例如，一个二元函数可以表示为 $ f(x, y) $，而一个多元函数可以表示为 $ f(x_1, x_2, \\dots, x_n) $。梯度是多元函数的一个重要概念，它是一个向量，表示函数在某一点处的最大变化率方向和大小。对于一个多元函数 $ f(x_1, x_2, \\dots, x_n) $，其梯度定义为：\\[\\nabla f = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\dots, \\frac{\\partial f}{\\partial x_n} \\right)\\]其中，$ \\frac{\\partial f}{\\partial x_i} $ 是函数 $ f $ 关于变量 $ x_i $ 的偏导数。梯度有如下性质：  方向性：梯度的方向是函数在该点处增长最快的方向。  大小：梯度的模（即向量的长度）表示函数在该点的最大变化率。      正交性：在等值面上（即 $ f(x) = c $ 的曲面上），梯度与等值面正交。    线性性：梯度运算满足线性性质，即 $ \\nabla (af + bg) = a \\nabla f + b \\nabla g $，其中 $ a $ 和 $ b $ 是常数。  与方向导数的关系：函数在某点沿单位向量 $ \\boldsymbol{u} $ 的方向导数可以表示为 $ D_{\\boldsymbol{u}} f = \\nabla f \\cdot \\boldsymbol{u} $。  方向导数是梯度向量的重要应用。$f = f(x, y)$ 的偏导数衡量了点在 $x$ 轴和 $y$ 轴移动时 $f$ 的变化率，在其它任意方向移动的变化率就是方向导数。2.2. 向量函数的梯度（雅可比矩阵）假设有一个函数 $\\boldsymbol{f}: \\mathbb{R}^n\\rightarrow \\mathbb{R}^m$，其中 $\\boldsymbol{f} = [f_1, f_2,\\cdots, f_m]^\\top$，每个 $f_i$ 都是关于 $n$ 个输入 $\\boldsymbol{x} = [x_1, x_2,\\cdots, x_n]^\\top$ 的标量函数。那么函数的梯度 $\\nabla f$ 就是一个 $m\\times n$ 的矩阵，称为雅可比矩阵（Jacobian Matrix），其元素是 $\\boldsymbol{f}$ 的各个分量对 $\\boldsymbol{x}$ 的各个分量的偏导数。\\[J = \\nabla \\boldsymbol{f} = \\begin{bmatrix}  \\frac{\\partial f_1}{\\partial x_1} &amp; \\frac{\\partial f_1}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial f_1}{\\partial x_n}\\\\  \\frac{\\partial f_2}{\\partial x_2} &amp; \\frac{\\partial f_2}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial f_2}{\\partial x_n}\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  \\frac{\\partial f_m}{\\partial x_1} &amp; \\frac{\\partial f_m}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial f_m}{\\partial x_n}\\end{bmatrix}\\]例，假设有一个函数 $\\boldsymbol{f}: \\mathbb{R}^2\\rightarrow \\mathbb{R}^2$，定义为\\[\\boldsymbol{f} = \\begin{bmatrix}  f_1\\\\  f_2\\end{bmatrix} = \\begin{bmatrix}  x_1^2 + x_2^2\\\\  x_1 x_2\\end{bmatrix}\\]那么雅可比矩阵 $J$ 为\\[J = \\begin{bmatrix}  2x_1 &amp; 2x_2\\\\  x_2 &amp; x_1\\end{bmatrix}\\]2.3. 矩阵函数的梯度矩阵梯度是多元函数和向量函数梯度概念的推广，用于处理矩阵变量的函数。对于一个关于矩阵 $\\boldsymbol{X}$ 的标量函数 $f(\\boldsymbol{X})$，其矩阵梯度定义为一个与 $\\boldsymbol{X}$ 同维度的矩阵，其每个元素为函数 $f$ 对矩阵 $\\boldsymbol{X}$ 中对应元素的偏导数。假设函数 $f: \\mathbb{R}^{m\\times n}\\rightarrow \\mathbb{R}$ 的输入为矩阵 $\\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}$，输出为一个实数，则矩阵梯度定义为：\\[\\nabla_{\\boldsymbol{X}} f(\\boldsymbol{X}) = \\begin{bmatrix}  \\frac{\\partial f}{\\partial X_{11}} &amp; \\frac{\\partial f}{\\partial X_{12}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial X_{1n}}\\\\  \\frac{\\partial f}{\\partial X_{21}} &amp; \\frac{\\partial f}{\\partial X_{22}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial X_{2n}}\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  \\frac{\\partial f}{\\partial X_{m1}} &amp; \\frac{\\partial f}{\\partial X_{m2}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial X_{mn}}\\end{bmatrix}\\in\\mathbb{R}^{m\\times n}\\]矩阵梯度有如下性质：      线性性质：若 $ f(\\boldsymbol{X}) $ 和 $ g(\\boldsymbol{X}) $ 是关于矩阵 $ \\boldsymbol{X} $ 的标量函数，$ a $ 和 $ b $ 是常数，则有：\\(\\nabla_{\\boldsymbol{X}} (af + bg) = a \\nabla_{\\boldsymbol{X}} f + b \\nabla_{\\boldsymbol{X}} g\\)        矩阵乘积的梯度：若 $ \\boldsymbol{A} $ 和 $ \\boldsymbol{B} $ 是与 $ \\boldsymbol{X} $ 无关的矩阵，则：\\[\\nabla_{\\boldsymbol{X}} \\text{tr}(\\boldsymbol{A} \\boldsymbol{X} \\boldsymbol{B}) = \\boldsymbol{A}^T \\boldsymbol{B}^T\\]    其中，$\\text{tr}(\\cdot)$ 表示矩阵的迹。        二次型的梯度（等价于二次型迹的梯度）：对于二次型函数 $ f(\\boldsymbol{x}) = \\boldsymbol{x}^T \\boldsymbol{A} \\boldsymbol{x} $，其梯度为：\\[\\nabla_{\\boldsymbol{x}} f(\\boldsymbol{x}) = \\boldsymbol{A} \\boldsymbol{x} + \\boldsymbol{A}^T \\boldsymbol{x}\\]    当 $ \\boldsymbol{A} $ 是对称矩阵时，梯度简化为 $ 2\\boldsymbol{A} \\boldsymbol{x} $。          展开二次型：\\[Q(\\boldsymbol{x}) = \\sum_{i=1}^n \\sum_{j=1}^n a_{ij} x_i x_j\\]      对 $\\boldsymbol{x}$ 求偏导数：\\[\\begin{aligned}\\frac{\\partial Q(\\boldsymbol{x})}{\\partial x_k} &amp;= \\sum_{j=1}^n a_{kj} x_j + \\sum_{i=1}^n a_{ik} x_i\\\\&amp;= \\boldsymbol{A} \\boldsymbol{x} + \\boldsymbol{A}^T \\boldsymbol{x}\\end{aligned}\\]      若 $\\boldsymbol{A}$ 是对称矩阵（$a_{ij} = a_{ji}$），上式可以简化为：\\[\\frac{\\partial Q(\\boldsymbol{x})}{\\partial x_k} = 2 \\sum_{j=1}^n a_{kj} x_j\\]      将偏导数写成向量形式：\\[\\nabla Q(\\boldsymbol{x}) = 2 \\boldsymbol{A} \\boldsymbol{x}\\]      2.4. 分子布局与分母布局在矩阵微积分中，分子布局（numerator layout）和分母布局（denominator layout）是两种常见的约定，用于定义向量和矩阵的导数，这两种布局的主要区别在于导数的表示形式和维度的安排。2.4.1. 分子布局在分子布局中，导数的维度与分子的维度一致，以分子为列向量，分母为行向量。具体来说：  标量对向量的导数：          如果 $f: \\mathbb{R}^n \\to \\mathbb{R}$ 是一个标量函数（多元函数），$\\boldsymbol{x} \\in \\mathbb{R}^n$ 是一个向量，那么导数 $\\frac{\\partial f}{\\partial \\boldsymbol{x}}$ 是一个行向量：\\(\\frac{\\partial f}{\\partial \\boldsymbol{x}} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} &amp; \\frac{\\partial f}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial x_n} \\end{bmatrix}\\)        向量对向量的导数：          如果 $\\boldsymbol{f}: \\mathbb{R}^n \\to \\mathbb{R}^m$ 是一个向量函数，$\\boldsymbol{x} \\in \\mathbb{R}^n$ 是一个向量，那么导数 $\\frac{\\partial \\boldsymbol{f}}{\\partial \\boldsymbol{x}}$ 是一个 $m \\times n$ 的矩阵：\\(\\frac{\\partial \\boldsymbol{f}}{\\partial \\boldsymbol{x}} = \\begin{bmatrix}\\frac{\\partial f_1}{\\partial x_1} &amp; \\frac{\\partial f_1}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial f_1}{\\partial x_n} \\\\\\frac{\\partial f_2}{\\partial x_1} &amp; \\frac{\\partial f_2}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial f_2}{\\partial x_n} \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\frac{\\partial f_m}{\\partial x_1} &amp; \\frac{\\partial f_m}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial f_m}{\\partial x_n}\\end{bmatrix}\\)      2.4.2. 分母布局在分母布局中，导数的维度与分母的维度一致，以分母为列向量，分子为行向量。具体来说：  标量对向量的导数：          如果 $f: \\mathbb{R}^n \\to \\mathbb{R}$ 是一个标量函数（多元函数），$\\boldsymbol{x} \\in \\mathbb{R}^n$ 是一个向量，那么导数 $\\frac{\\partial f}{\\partial \\boldsymbol{x}}$ 是一个列向量：\\(\\frac{\\partial f}{\\partial \\boldsymbol{x}} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n} \\end{bmatrix}\\)        向量对向量的导数：          如果 $\\boldsymbol{f}: \\mathbb{R}^n \\to \\mathbb{R}^m$ 是一个向量函数，$\\boldsymbol{x} \\in \\mathbb{R}^n$ 是一个向量，那么导数 $\\frac{\\partial \\boldsymbol{f}}{\\partial \\boldsymbol{x}}$ 是一个 $n \\times m$ 的矩阵：\\(\\frac{\\partial \\boldsymbol{f}}{\\partial \\boldsymbol{x}} = \\begin{bmatrix}\\frac{\\partial f_1}{\\partial x_1} &amp; \\frac{\\partial f_2}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial f_m}{\\partial x_1} \\\\\\frac{\\partial f_1}{\\partial x_2} &amp; \\frac{\\partial f_2}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial f_m}{\\partial x_2} \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\frac{\\partial f_1}{\\partial x_n} &amp; \\frac{\\partial f_2}{\\partial x_n} &amp; \\cdots &amp; \\frac{\\partial f_m}{\\partial x_n}\\end{bmatrix}\\)      选择分子布局还是分母布局通常取决于具体的应用场景和习惯。在机器学习和优化领域，分子布局更为常见，因为它与雅可比矩阵的定义一致。而在一些工程和物理领域，分母布局可能更为常见。2.5. 向量函数/矩阵函数梯度的链式法则分子布局和分母布局在矩阵函数或向量值函数的链式法则求导中会影响导数的表示形式和计算方式，链式法则的应用会根据布局的不同而有所调整。2.5.1. 基本形式链式法则用于计算复合函数的导数。假设有两个函数：  $\\mathbf{y} = \\mathbf{f}(\\mathbf{u})$，其中 $\\mathbf{f}: \\mathbb{R}^m \\to \\mathbb{R}^p$  $\\mathbf{u} = \\mathbf{g}(\\mathbf{x})$，其中 $\\mathbf{g}: \\mathbb{R}^n \\to \\mathbb{R}^m$复合函数为 $\\mathbf{y} = \\mathbf{f}(\\mathbf{g}(\\mathbf{x}))$，其导数可以通过链式法则计算：\\[\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{u}} \\cdot \\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{x}}\\]这里的关键是 $\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{u}}$ 和 $\\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{x}}$ 的维度安排，这取决于使用的是分子布局还是分母布局。2.5.2. 分子布局下的链式法则在分子布局中，导数的维度与分子的维度一致。具体来说：  $\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{u}}$ 是一个 $p \\times m$ 的矩阵。  $\\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{x}}$ 是一个 $m \\times n$ 的矩阵。因此，链式法则的矩阵乘法形式为：\\[\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{u}} \\cdot \\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{x}}\\]其中：  $\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}}$ 是一个 $p \\times n$ 的矩阵。  矩阵乘法的顺序是 $p \\times m$ 乘以 $m \\times n$，结果维度为 $p \\times n$。2.5.3. 分母布局下的链式法则在分母布局中，导数的维度与分母的维度一致。具体来说：  $\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{u}}$ 是一个 $m \\times p$ 的矩阵。  $\\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{x}}$ 是一个 $n \\times m$ 的矩阵。因此，链式法则的矩阵乘法形式为：\\(\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{u}}\\)其中：  $\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}}$ 是一个 $n \\times p$ 的矩阵。  矩阵乘法的顺序是 $n \\times m$ 乘以 $m \\times p$，结果维度为 $n \\times p$。2.5.4. 举例给定定常值矩阵 $\\boldsymbol{A}\\in \\mathbb{R}^{m\\times n}$ 和变量向量 $\\boldsymbol{x}\\in \\mathbb{R}^n$，设函数 $f:\\mathbb{R}^m\\rightarrow \\mathbb{R}$ 定义式为 $f(\\boldsymbol{z})=\\boldsymbol{z}^\\top \\boldsymbol{z}$，求 $\\nabla f(\\boldsymbol{A}\\boldsymbol{x})$。首先，题目实际要求解 $\\nabla_{\\boldsymbol{x}} f(\\boldsymbol{A}\\boldsymbol{x})$（明确梯度下标）；  分子布局下的计算过程计算 $\\nabla_{\\boldsymbol{z}} f(\\boldsymbol{z})$，按照分子布局有\\[\\begin{aligned}f(\\boldsymbol{z}) &amp;= \\sum_{i=1}^m z_i^2\\\\\\nabla_{\\boldsymbol{z}} f(\\boldsymbol{z}) &amp;= (\\frac{\\partial f}{\\partial z_1}, \\frac{\\partial f}{\\partial z_2}, \\cdots, \\frac{\\partial f}{\\partial z_m})= 2\\boldsymbol{z}^\\top \\in \\mathbb{R}^{1\\times m}\\end{aligned}\\]令 $\\boldsymbol{z} = g(\\boldsymbol{x}) = \\boldsymbol{Ax}$，可以看出其为向量函数，其梯度为（分子布局，也即 Jacobian 矩阵形式）\\[\\begin{aligned}\\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{x}} &amp;= \\begin{bmatrix}  \\frac{\\partial \\boldsymbol{z}}{\\partial x_1} &amp; \\frac{\\partial \\boldsymbol{z}}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial \\boldsymbol{z}}{\\partial x_n}\\end{bmatrix}\\\\&amp;=\\begin{bmatrix}  \\frac{\\partial z_1}{\\partial x_1} &amp; \\frac{\\partial z_1}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial z_1}{\\partial x_n}\\\\  \\frac{\\partial z_2}{\\partial x_2} &amp; \\frac{\\partial z_2}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial z_2}{\\partial x_n}\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  \\frac{\\partial z_m}{\\partial x_1} &amp; \\frac{\\partial z_m}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial z_m}{\\partial x_n}\\end{bmatrix} = \\boldsymbol{A}\\in \\mathbb{R}^{m\\times n}\\\\\\end{aligned}\\]链式法则如下\\[\\nabla_{\\boldsymbol{x}} f(\\boldsymbol{A}\\boldsymbol{x}) = \\nabla_{\\boldsymbol{z}} f(\\boldsymbol{z}) \\cdot \\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{x}} = 2\\boldsymbol{z}^\\top  \\cdot \\boldsymbol{A}\\in \\mathbb{R}^{1\\times n}\\]  分母布局下的计算过程计算 $\\nabla_{\\boldsymbol{z}} f(\\boldsymbol{z})$，按照分子布局有\\[\\begin{aligned}f(\\boldsymbol{z}) &amp;= \\sum_{i=1}^m z_i^2\\\\\\nabla_{\\boldsymbol{z}} f(\\boldsymbol{z}) &amp;= (\\frac{\\partial f}{\\partial z_1}, \\frac{\\partial f}{\\partial z_2}, \\cdots, \\frac{\\partial f}{\\partial z_m})^\\top= 2\\boldsymbol{z} \\in \\mathbb{R}^{m\\times 1}\\end{aligned}\\]令 $\\boldsymbol{z} = g(\\boldsymbol{x}) = \\boldsymbol{Ax}$，可以看出其为向量函数，其梯度为（分母布局）\\[\\begin{aligned}\\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{x}} &amp;= \\begin{bmatrix}  \\frac{\\partial \\boldsymbol{z}}{\\partial x_1} &amp; \\frac{\\partial \\boldsymbol{z}}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial \\boldsymbol{z}}{\\partial x_n}\\end{bmatrix}\\\\&amp;=\\begin{bmatrix}  \\frac{\\partial z_1}{\\partial x_1} &amp; \\frac{\\partial z_2}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial z_m}{\\partial x_1}\\\\  \\frac{\\partial z_1}{\\partial x_2} &amp; \\frac{\\partial z_2}{\\partial x_2} &amp; \\cdots &amp; \\frac{\\partial z_m}{\\partial x_2}\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  \\frac{\\partial z_1}{\\partial x_n} &amp; \\frac{\\partial z_2}{\\partial x_n} &amp; \\cdots &amp; \\frac{\\partial z_m}{\\partial x_n}\\end{bmatrix} = \\boldsymbol{A}^\\top\\in \\mathbb{R}^{n\\times m}\\\\\\end{aligned}\\]链式法则如下\\[\\nabla_{\\boldsymbol{x}} f(\\boldsymbol{A}\\boldsymbol{x}) =\\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{x}} \\cdot \\nabla_{\\boldsymbol{z}} f(\\boldsymbol{z})  = \\boldsymbol{A}^\\top  \\cdot 2\\boldsymbol{z}\\in \\mathbb{R}^{n\\times 1}\\]3. 矩阵的全微分3.1. 多元函数的全微分全微分描述了函数 $f(\\boldsymbol{x})$ 在某点 $\\boldsymbol{x}$ 处的微小变化 $\\text{d}f$ 与自变量微小变化 $d\\boldsymbol{x}=[dx_1, dx_2, \\cdots, dx_n]^T$ 的关系，定义为\\[\\begin{aligned}\\text{d}f &amp;= \\frac{\\partial f}{\\partial x_1} dx_1 + \\frac{\\partial f}{\\partial x_2} dx_2 + \\cdots + \\frac{\\partial f}{\\partial x_n} dx_n\\\\ &amp;= \\nabla f(\\boldsymbol{x})^\\top d\\boldsymbol{x}\\\\\\end{aligned}\\]解释  梯度 $ \\nabla f(\\boldsymbol{x})$ 描述了函数 $f$ 在某一点 $x$ 处对各个自变量的变化率。  全微分 $\\text{d}f$ 描述了函数 $f$ 在某一点 $x$ 处的微小变化，是梯度与自变量微小变化的线性组合。几何意义：  梯度 $ \\nabla f(\\boldsymbol{x})$ 是函数值变化最剧烈的方向。  全微分是函数值在方向 $d\\boldsymbol{x}$ 上的变化量，等于梯度在该方向上的投影。3.2. 矩阵函数的全微分回顾矩阵函数 $f: \\mathbb{R}^{m\\times n}\\rightarrow \\mathbb{R}$，输入为矩阵 $\\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}$，输出为一个实数。其全微分 $df$ 定义为：\\[\\text{d}f = \\sum_{i=1}^m\\sum_{j=1}^n \\frac{\\partial f}{\\partial X_{ij}} dX_{ij}\\]将其展开书写为\\[\\begin{aligned}\\text{d}f(\\boldsymbol{X}) =&amp; \\frac{\\partial f}{\\partial X_{11}} dX_{11} + \\frac{\\partial f}{\\partial X_{12}} dX_{12} + \\cdots + \\frac{\\partial f}{\\partial X_{1n}} dX_{1n}+\\\\&amp;\\frac{\\partial f}{\\partial X_{21}} dX_{21} + \\frac{\\partial f}{\\partial X_{22}} dX_{22} + \\cdots + \\frac{\\partial f}{\\partial X_{2n}} dX_{2n}+\\\\&amp;\\vdots\\\\&amp;\\frac{\\partial f}{\\partial X_{m1}} dX_{m1} + \\frac{\\partial f}{\\partial X_{m2}} dX_{m2} + \\cdots + \\frac{\\partial f}{\\partial X_{mn}} dX_{mn}+\\\\\\end{aligned}\\]回顾矩阵函数的梯度如下\\[\\nabla_{\\boldsymbol{X}} f(\\boldsymbol{X}) = \\begin{bmatrix}  \\frac{\\partial f}{\\partial X_{11}} &amp; \\frac{\\partial f}{\\partial X_{12}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial X_{1n}}\\\\  \\frac{\\partial f}{\\partial X_{21}} &amp; \\frac{\\partial f}{\\partial X_{22}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial X_{2n}}\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  \\frac{\\partial f}{\\partial X_{m1}} &amp; \\frac{\\partial f}{\\partial X_{m2}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial X_{mn}}\\end{bmatrix}\\in\\mathbb{R}^{m\\times n}\\]定义矩阵 $\\boldsymbol{X}$ 的微分为\\[\\text{d}\\boldsymbol{X} = \\begin{bmatrix}  dX_{11} &amp; dX_{12} &amp; \\cdots &amp; dX_{1n}\\\\  dX_{21} &amp; dX_{22} &amp; \\cdots &amp; dX_{2n}\\\\  \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  dX_{m1} &amp; dX_{m2} &amp; \\cdots &amp; dX_{mn}\\end{bmatrix}\\in\\mathbb{R}^{m\\times n}\\]可以将全微分用矩阵的形式表示为\\[\\text{d}f(\\boldsymbol{X}) = \\text{tr}(\\nabla_{\\boldsymbol{X}} f(\\boldsymbol{X})^\\top d\\boldsymbol{X})\\]利用上述等式，可以计算复杂的矩阵函数的梯度求解。基本套路如下：  首先确认 $f$ 是矩阵函数（输出为标量）  改写等式左边：$\\text{d}f(\\boldsymbol{X}) = \\text{tr}(\\text{d}f(\\boldsymbol{X}))$  改写等式右边，使用迹的性质和常见的微分性质凑出 $\\text{tr}([\\cdot] \\text{d}(\\boldsymbol{X}))$  则括号内 $[\\cdot]$ 部分记为矩阵函数梯度的转置（或其一项），将其再次转置迹可得到矩阵函数的梯度。题目1:证明\\[\\frac{\\partial{\\text{tr}(\\boldsymbol{X}^\\top \\boldsymbol{X})}}{\\partial{\\boldsymbol{X}}} = 2\\boldsymbol{X}\\]证明过程\\[\\begin{aligned}\\text{d} (\\text{tr}(\\boldsymbol{X}^\\top \\boldsymbol{X})) &amp;= \\text{tr}(\\text{d}(\\boldsymbol{X}^\\top \\boldsymbol{X}))\\\\&amp;= \\text{tr}(\\text{d}(\\boldsymbol{X}^\\top)\\boldsymbol{X}) + \\text{tr}(\\boldsymbol{X}^\\top \\text{d}(\\boldsymbol{X}))\\\\&amp;= \\text{tr}(\\boldsymbol{X}^\\top \\text{d}(\\boldsymbol{X})) + \\text{tr}(\\boldsymbol{X}^\\top \\text{d}(\\boldsymbol{X}))\\\\&amp;= 2\\text{tr}(\\boldsymbol{X}^\\top \\text{d}(\\boldsymbol{X}))\\\\\\Rightarrow &amp;\\frac{\\partial \\text{tr}(\\boldsymbol{X}^\\top \\boldsymbol{X})}{\\partial \\boldsymbol{X}^\\top} = 2\\boldsymbol{X}^\\top\\\\\\Rightarrow &amp;\\frac{\\partial \\text{tr}(\\boldsymbol{X}^\\top \\boldsymbol{X})}{\\partial \\boldsymbol{X}} = 2\\boldsymbol{X}\\end{aligned}\\]上述推导中用到的性质有\\[\\begin{aligned}&amp; \\text{d}( \\text{tr}(X)) = \\text{tr}(\\text{d}(X))\\\\&amp; \\text{d}(XY) = \\text{d}(X)Y + X\\text{d}(Y)\\\\&amp; \\text{tr}(AB) = \\text{tr}(BA)\\end{aligned}\\]题目2：求\\[\\frac{\\partial{(\\boldsymbol{a}^\\top\\boldsymbol{X}\\boldsymbol{X}^\\top\\boldsymbol{b})}}{\\partial(\\boldsymbol{X})}\\]解\\[\\begin{aligned}d(a^T XX^T b) &amp;= \\text{tr}(d(a^T XX^T b))\\\\&amp;= \\text{tr}(a^T d(XX^T)b)\\\\&amp;= \\text{tr}(a^T [d(X)X^T + Xd(X^T)]b)\\\\&amp;= \\text{tr}(a^T d(X)X^T b) + \\text{tr}(a^T Xd(X^T)b)\\\\&amp;= \\text{tr}(X^T ba^T d(X)) + \\text{tr}((a^T Xd(X^T)b)^T)\\\\&amp;= \\text{tr}(X^T ba^T d(X)) + \\text{tr}(b^T d(X)X^T a)\\\\&amp;= \\text{tr}(X^T ba^T d(X)) + \\text{tr}(X^T ab^T d(X))\\\\&amp;\\Rightarrow \\frac{\\partial (a^T XX^T b)}{\\partial X^T} = X^T ba^T + X^T ab^T\\\\&amp;\\Rightarrow \\frac{\\partial (a^T XX^T b)}{\\partial X} = ab^T X + ba^T X\\end{aligned}\\]上述推导中用到的性质有\\[d \\text{tr}(X) = \\text{tr}(dX)\\]\\[X \\in \\mathbb{R}^{m,n}, d(A_{p,m} X B_{n,p}) = A d(X) B\\]\\[d(XY) = (dX)Y + X(dY)\\]\\[\\text{tr}(A + B) = \\text{tr}A + \\text{tr}B\\]\\[\\text{tr}A = \\text{tr}A^T \\quad \\text{tr}AB = \\text{tr}BA\\]"
  },
  
  {
    "title": "模式识别（LDA和PCA）",
    "url": "/posts/Pattern-Recognition-LDA&PCA/",
    "categories": "Academic, Knowledge",
    "tags": "pattern recognition",
    "date": "2024-05-02 10:03:19 +0800",
    





    
    "snippet": "本文介绍了模式识别种常用的两种特征选择与特征降维方法，即线性判别分析（Linear Discriminant Analysis，LDA）和主成分分析（Principal Component Analysis，PCA）。  1. 特征降维  2. 线性判别分析（LDA）          2.1. Fisher 投影准则      2.2. 瑞利商与广义瑞利商      2.3. 二分类 LD...",
    "content": "本文介绍了模式识别种常用的两种特征选择与特征降维方法，即线性判别分析（Linear Discriminant Analysis，LDA）和主成分分析（Principal Component Analysis，PCA）。  1. 特征降维  2. 线性判别分析（LDA）          2.1. Fisher 投影准则      2.2. 瑞利商与广义瑞利商      2.3. 二分类 LDA      2.4. 多分类 LDA      2.5. LDA 的特点        3. 主成分分析（PCA）          3.1. 数学推导                  3.1.1. 最近重构性（K-L变换）          3.1.2. 最大可分性          3.1.3. 拉格朗日乘子法求解                    3.2. 算法流程      3.3. PCA 的特点        4. 参考文献1. 特征降维机器学习的很多算法复杂度和数据的维数有着密切关系，甚至与维数呈指数级关联。当数据的特征维度达到成千上万甚至几十万的规模时，机器学习的资源消耗是不可接受的，且有很多特征可能与要解决的分类问题关系不大，因此就会对数据采取降维的操作。降维就意味着信息的丢失，因为原本每个特征理论上都可以反映出原始数据的某些特质。但鉴于实际数据的特征之间本身常常存在相关性，所以在降维时可以采取一些办法降低信息的损失。特征降维有两种方法：  特征选择：从已有特征向量中选择出若干维度的特征组成新的特征向量，新特征向量的维度一般远小于原始特征向量；  特征提取：将原始特征向量经过某种数学变换得到新的特征向量，新特征向量的维度一般远小于原始特征向量；2. 线性判别分析（LDA）线性判别分析（Linear Discriminant Analysis，LDA）是一种监督学习的降维技术，主要用于数据预处理中的降维、分类任务。LDA的目标是最大化类间区分度的坐标轴成分，将特征空间投影到一个维度更小的 $k$ 维子空间中，同时保持区分类别的信息。简而言之，LDA投影后的数据类内方差最小，类间方差最大。2.1. Fisher 投影准则参考前述线性分类器中的 Fisher投影准则 介绍。2.2. 瑞利商与广义瑞利商定义瑞利商为\\[R(A,x)=\\frac{x^HAx}{x^Hx}\\]其中 $x$ 是非零向量，$A\\in R^{n\\times n}$ 是 Hermitan 矩阵（自共轭矩阵，矩阵中每一个第$i$行第$j$列元素都与第$j$行第$i$列元素共轭相等）。性质：瑞利商的最大值等于矩阵 $A$ 最大的特征值，最小值等于矩阵 $A$ 的最小特征值。即\\[\\lambda_{min} &lt; R(A,x) &lt; \\lambda_{max}\\]定义广义瑞利商为\\[R(A,x)=\\frac{x^HAx}{x^HBx}\\]其中 $B$ 为正定矩阵，其他定义同瑞利商。性质：广义瑞利商的最大值为矩阵 $B^{-\\frac{1}{2}}AB^{-\\frac{1}{2}}$ 或者说 是矩阵 $B^{-1}A$的最大特征值，最小值是其最小特征值。2.3. 二分类 LDA参考前述线性分类器中的 Fisher 投影准则介绍，类间离散度矩阵为\\[\\boldsymbol{S}_b = (\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_2)(\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_2)^\\top\\]为两向量的外积，其秩为1。      一个向量可以看做一个$n\\times 1$ 矩阵或者 $1\\times n$ 的矩阵，而一个矩阵 $A$ 的秩 $R(A)\\leq \\min(n,m)$，其中 $n$ 和 $m$ 是这个矩阵的行数和列数，所以单个向量的秩是1；    两向量外积也就是一个 $n\\times 1$ 矩阵和一个 $1\\times n$ 矩阵的积，又两矩阵的积的秩小于等于两者中秩最小的矩阵的秩，也就是 $R(AB)\\leq \\min(R(A),R(B))$，这里 $R(A)=R(B)=1$,所以 $R(AB)\\leq 1$，即两向量外积的秩至多是1。  类内离散度矩阵为\\[\\boldsymbol{S}_w = \\sum_{i=1}^2 \\boldsymbol{S}_{wi}=\\sum_{i=1}^2 \\sum_{x\\in w_i}(x-\\mu_i)(x-\\mu_i)^\\top\\]二分类LDA的优化目标函数可以写成\\[\\max_{\\boldsymbol{w}} J(\\boldsymbol{w}) = \\frac{\\boldsymbol{w}^\\top\\boldsymbol{S}_b\\boldsymbol{w}}{\\boldsymbol{w}^\\top\\boldsymbol{S}_w\\boldsymbol{w}}\\]目标是求使得 $J(\\boldsymbol{w})$ 最大的投影方向 $\\boldsymbol{w}$。根据前述 Fisher投影准则 的推导，上述优化问题最终可转化为求矩阵 $\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b$ 的特征值 $\\lambda$ 和特征向量 $\\boldsymbol{w}^{\\star}$。这里给出另外一种推导思路，上述目标函数正好是广义瑞利商的形式，因此其最大值为 $\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b$ 的最大特征值，那么投影方向 $\\boldsymbol{w}$ 即为 $\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b$ 对应特征值 $\\lambda$ 的特征向量。若 $\\boldsymbol{S}_w$ 不可逆，可进行如下操作进行松弛\\[\\boldsymbol{S}_w = \\boldsymbol{S}_w + \\beta \\boldsymbol{I}\\]其中 $\\beta$ 是一个很小的数。实际使用时为得到数值解的稳定性，通常对 $\\boldsymbol{S}_w$ 进行奇异值分解得到 $\\boldsymbol{S}_w^{-1}$\\[\\boldsymbol{S}_w=\\boldsymbol{U}\\Sigma \\boldsymbol{V}^\\top \\Rightarrow \\boldsymbol{S}_w^{-1} = \\boldsymbol{V}\\Sigma \\boldsymbol{U}^\\top\\]2.4. 多分类 LDA假设为 $C$ 分类，类内离散度矩阵定义保持不变，可直接扩展至 $C$ 类的情况，有\\[\\boldsymbol{S}_w = \\sum_{i=1}^C \\boldsymbol{S}_{wi}=\\sum_{i=1}^C \\sum_{\\boldsymbol{x}\\in w_i}(\\boldsymbol{x}-\\boldsymbol{\\mu}_i)(\\boldsymbol{x}-\\boldsymbol{\\mu}_i)^\\top\\]对于类间离散度矩阵，无法像之前二分类那样定义（即 $\\boldsymbol{S}_b=(\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_2)(\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_2)^\\top$，度量两类均值的散列情况），需要改为度量每类均值点相对于样本中心的散列情况，即\\[\\boldsymbol{S}_b= \\sum_{i=1}^C N_i(\\boldsymbol{\\mu}_i-\\boldsymbol{\\mu})(\\boldsymbol{\\mu}_i-\\boldsymbol{\\mu})^\\top\\]类似于将 $\\boldsymbol{\\mu}_i$ 看作样本点，$\\boldsymbol{\\mu}$ 是均值的协方差矩阵，唯一的差别是多了一个权重系数。如果某类里面的样本点较多，那么其权重稍大，权重用 $N_i/N$ 表示，但由于 $J(\\boldsymbol{w})$对倍数不敏感，因此使用 $N_i$ 即可。注意到，$\\boldsymbol{S}_b$ 是 $C$ 个秩为 1 的向量外积得到的矩阵求和，因此 $\\boldsymbol{S}_b$ 的秩不会超过 $C$。因此 LDA 最终只能得到 $C$ 个不为零的特征向量。  矩阵的秩小于等于各个相加矩阵的秩的和，即 $R(A+B)\\leq R(A)+R(B)$又因为，各个类别的均值与总样本均值之间线性相关，即\\[\\boldsymbol{\\mu} = \\frac{1}{N} \\sum_{\\forall \\boldsymbol{x}}\\boldsymbol{x} = \\frac{1}{N}\\sum_{\\boldsymbol{x}\\in w_i} N_i\\boldsymbol{\\mu}_i\\]知道了前 $C-1$ 个 $(\\boldsymbol{\\mu}_i-\\boldsymbol{\\mu})$ 后，最后一个 $(\\boldsymbol{\\mu}_C-\\boldsymbol{\\mu})$ 可以有前面的 $\\boldsymbol{\\mu}_i$ 来线性表示，因此$\\boldsymbol{S}_b$ 的秩为 $C-1$。所以在计算特征向量矩阵（类内散度矩阵 $\\boldsymbol{S}_w$ 的逆 $\\times$ 类间散度矩阵 $\\boldsymbol{S}_b$）时，可以发现只有 $C-1$ 个特征值不为零的特征向量。因此，LDA 最多将特征维度降低到 $C-1$ 维。假设样本原始特征维度为 $k$，前 $d=C-1$ 个最大特征值对应的特征向量组成的投影矩阵为 $\\boldsymbol{W}=[\\boldsymbol{w}1, \\boldsymbol{w}_2,\\cdots, \\boldsymbol{w}{d}]\\in \\mathbb{R}^{k\\times d}$，那么多分类 LDA 的优化目标函数为\\[\\max_{\\boldsymbol{W}} J(\\boldsymbol{W}) = \\frac{\\boldsymbol{W}^\\top\\boldsymbol{S}_b\\boldsymbol{W}}{\\boldsymbol{W}^\\top\\boldsymbol{S}_w\\boldsymbol{W}}\\]最终可将 $k$ 维高维特征降维至 $d$ 维\\[\\boldsymbol{z} = \\boldsymbol{W}\\boldsymbol{x}\\]2.5. LDA 的特点LDA 是一个有监督的方法，具有如下特点：  根据原始数据样本的均值进行分类  不同类数据拥有相近的协方差矩阵当然，在实际情况中，不可能满足以上两个假设。但是当数据主要是由均值来区分的时候，LDA一般都可以取得很好的效果。见下面两个对比图。上图中，两类数据的均值差异较大，但协方差矩阵十分接近，因此 LDA 分类效果好于 PCA。上图中，两类数据的均值差异很小，但协方差矩阵相差十分明显，因此 LDA 分类效果差于 PCA。LDA 的优点:  计算速度快  充分利用了先验知识LDA 的缺点:  不适合对非高斯分布的样本降维  降维之后的维数最多为类别数-1，所以当数据维度很高，但是类别数少的时候，算法并不适用  可能会过度拟合数据3. 主成分分析（PCA）主成分分析（Principal Component Analysis，PCA）是常用的特征提取数据分析方法。PCA是通过线性变换，将原始数据变换为一组各维度线性无关的数据表示方法，可用于提取数据的主要特征分量，常用于高维数据的降维。为了最大限度保留对原始数据的解释，一般会用最大方差理论或最小损失理论，使得第一主成分有着最大的方差或变异数 (就是说其能尽量多的解释原始数据的差异)；随后的每一个主成分都与前面的主成分正交，且有着仅次于前一主成分的最大方差 (正交简单的理解就是两个主成分空间夹角为90°，两者之间无线性关联，从而完成去冗余操作)。PCA 降维的原理在于，大部分方差集中在前 $k$ 个坐标轴，后续坐标轴方差接近 0，因此可忽略后者，仅保留前 $k$ 个坐标轴。这相当于保留主要特征维度，忽略方差接近 0 的特征，实现数据降维。3.1. 数学推导PCA 的推导思路在于，对于正交属性空间中的样本点，如何用一个超平面对所有样本进行恰当的表达？核心在于以下两点：  最近重构性：样本点到这个超平面的距离都足够近，也即投影前后所有样本点的总距离最小。  最大可分性：样本点在这个超平面上的投影尽可能分开，也即投影后的样本点方差最大。基于最近重构性和最大可分性，能分别得到PCA的两种等价推导，下面分别展开说明。3.1.1. 最近重构性（K-L变换）首先对 $n$ 个 $d$ 维样本进行中心化，即将所有样本变换为均值为 0，也即\\[\\sum_{i=1}^n \\boldsymbol{x}_i=0,\\quad \\boldsymbol{x}_i\\in\\mathbb{R}^{d},\\; i=1,2,\\cdots,n\\]  单个样本的角度目标是找到投影矩阵 $\\boldsymbol{W}\\in\\mathbb{R}^{d\\times k}$，将样本投影到低维空间\\[\\boldsymbol{z}_i = \\boldsymbol{W}^\\top\\boldsymbol{x}_i\\quad \\in\\mathbb{R}^k\\]再重构回原始空间\\[\\hat{\\boldsymbol{x}}_i=\\boldsymbol{W}\\boldsymbol{z}_i=\\boldsymbol{W}\\boldsymbol{W}^\\top\\boldsymbol{x}_i\\quad \\in\\mathbb{R}^d\\]对所有 $n$ 个样本均进行投影后，用重构前后的均方误差衡量重构误差，有\\[J(\\boldsymbol{W}) = \\sum_{i=1}^n\\Vert \\boldsymbol{x}_i - \\hat{\\boldsymbol{x}}_i \\Vert^2 = \\sum_{i=1}^n\\Vert \\boldsymbol{x}_i - \\boldsymbol{W}\\boldsymbol{W}^\\top\\boldsymbol{x}_i \\Vert^2\\]  样本矩阵的角度令样本矩阵（每一行是一个样本）为\\[\\boldsymbol{X}=\\begin{bmatrix}  \\boldsymbol{x}_1^\\top\\\\  \\boldsymbol{x}_2^\\top\\\\  \\vdots\\\\  \\boldsymbol{x}_n^\\top\\end{bmatrix}\\]则投影后的低维样本矩阵为\\[\\boldsymbol{Z}=\\boldsymbol{X}\\boldsymbol{W}\\quad \\in\\mathbb{R}^{n\\times k}\\]重构后的样本矩阵为\\[\\hat{\\boldsymbol{X}}=\\boldsymbol{Z}\\boldsymbol{W}^\\top=\\boldsymbol{X}\\boldsymbol{W}\\boldsymbol{W}^\\top\\quad \\in\\mathbb{R}^{n\\times d}\\]将上述误差 $J(\\boldsymbol{W})$ 按照矩阵逐元素展开写，有\\[J(\\boldsymbol{W}) = \\sum_{i=1}^n\\sum_{j=1}^d\\left(x_{ij} - \\left[\\boldsymbol{X}\\boldsymbol{W}\\boldsymbol{W}^\\top\\right]_{ij}\\right)^2\\]注意到，上式就是矩阵的 Frobenius 范数的平方形式，即\\[J(\\boldsymbol{W}) = \\Vert\\boldsymbol{X} - \\boldsymbol{X}\\boldsymbol{W}\\boldsymbol{W}^\\top\\Vert_F^2\\]根据矩阵的 Frobenius 范数的性质，有\\[\\Vert\\boldsymbol{A}\\Vert_F = \\sqrt{\\sum_{i=1}^m\\sum_{j=1}^n \\boldsymbol{A}_{ij}^2} = \\sqrt{\\text{tr}(\\boldsymbol{A}^\\top \\boldsymbol{A})}\\]\\[\\begin{aligned}\\Vert\\boldsymbol{X} - \\boldsymbol{X}\\boldsymbol{W}\\boldsymbol{W}^\\top\\Vert_F^2 &amp;= \\text{tr}\\left( (\\boldsymbol{X} - \\boldsymbol{X}\\boldsymbol{W}\\boldsymbol{W}^\\top)^\\top(\\boldsymbol{X} - \\boldsymbol{X}\\boldsymbol{W}\\boldsymbol{W}^\\top) \\right)\\\\&amp;= \\text{tr}(\\boldsymbol{X}^\\top\\boldsymbol{X}) - 2\\text{tr}(\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{W}\\boldsymbol{W}^\\top) + \\text{tr}(\\boldsymbol{W}\\boldsymbol{W}^\\top\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{W}\\boldsymbol{W}^\\top)\\\\&amp;= \\text{tr}(\\boldsymbol{X}^\\top\\boldsymbol{X}) - \\text{tr}(\\boldsymbol{W}^\\top\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{W})\\end{aligned}\\]其中第二行展开是因为迹是线性算子，可以保证分配律。第三行展开利用了正交投影矩阵的性质和迹的循环置换性。  正交投影矩阵：$\\boldsymbol{W}\\boldsymbol{W}^\\top = \\boldsymbol{I}$  迹的循环置换性：$\\text{tr}(\\boldsymbol{A}\\boldsymbol{B}\\boldsymbol{C}) = \\text{tr}(\\boldsymbol{B}\\boldsymbol{C}\\boldsymbol{A}) = \\text{tr}(\\boldsymbol{C}\\boldsymbol{A}\\boldsymbol{B})$注意到，$\\boldsymbol{X}^\\top\\boldsymbol{X}$ 是样本的协方差矩阵，对优化问题而言是常数，不影响优化结果，因此最近重构性推导的优化问题可描述为\\[\\begin{aligned}\\min_{\\boldsymbol{W}} &amp;\\quad -\\text{tr}(\\boldsymbol{W}^\\top\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{W}) \\\\s.t. &amp;\\quad \\boldsymbol{W}^\\top\\boldsymbol{W}=\\boldsymbol{I}\\end{aligned}\\]3.1.2. 最大可分性要让投影后所有样本点能尽可能分开，则投影后样本点方差最大。同样首先对 $n$ 个 $d$ 维样本进行中心化，假设中心化后样本矩阵为 $\\boldsymbol{X}\\in\\mathbb{R}^{n\\times d}$，即\\[\\boldsymbol{X}=\\begin{bmatrix}  \\boldsymbol{x}_1^\\top\\\\  \\boldsymbol{x}_2^\\top\\\\  \\vdots\\\\  \\boldsymbol{x}_n^\\top\\end{bmatrix}\\]协方差矩阵为 $\\boldsymbol{X}^\\top\\boldsymbol{X}$。给定某个投影方向 $\\boldsymbol{w}$ 满足 $\\Vert\\boldsymbol{w}\\Vert_2=1$，则投影后使样本方差最大等价于\\[\\max_{\\boldsymbol{w}} \\quad Var(\\boldsymbol{X}\\boldsymbol{w}) = \\boldsymbol{w}^\\top\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{w}\\]推广到 $k$ 个主成分（正交方向），投影矩阵 $\\boldsymbol{W}\\in\\mathbb{R}^{d\\times k}$ 满足 $\\boldsymbol{W}^\\top\\boldsymbol{W}=\\boldsymbol{I}$，优化目标为\\[\\max_{\\boldsymbol{w}_i} \\quad \\sum_{i=1}^k\\boldsymbol{w}_i^\\top\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{w}_i\\]注意到上式改写为矩阵后就是矩阵的对角元素（迹），则目标函数可改写为\\[\\max_{\\boldsymbol{W}} \\quad \\text{tr}(\\boldsymbol{W}^\\top\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{W})\\]等价于求解如下优化问题\\[\\begin{aligned}\\max_{\\boldsymbol{W}} &amp;\\quad \\text{tr}(\\boldsymbol{W}^\\top\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{W})\\\\s.t. &amp;\\quad \\boldsymbol{W}^\\top\\boldsymbol{W}=\\boldsymbol{I}\\end{aligned}\\]可以发现和最近重构性等价。3.1.3. 拉格朗日乘子法求解对于最近重构性，最小化目标函数，拉格朗日乘子项使用正号\\[J(\\boldsymbol{W}) = -\\text{tr}(\\boldsymbol{W}^\\top\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{W})+\\Lambda^\\top(\\boldsymbol{W}^\\top\\boldsymbol{W}-\\boldsymbol{I})\\]对于最大可分性，最大化目标函数，拉格朗日乘子项使用负号\\[J(\\boldsymbol{W}) = \\text{tr}(\\boldsymbol{W}^\\top\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{W})-\\Lambda^\\top(\\boldsymbol{W}^\\top\\boldsymbol{W}-\\boldsymbol{I})\\]二者等价。对上式求导（注意第一项利用迹的微分公式），令导数等于零，整理有\\[\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{W} = \\Lambda \\boldsymbol{W}\\]该方程是特征值问题的形式，$\\boldsymbol{W}$ 是协方差矩阵 $\\boldsymbol{X}^\\top\\boldsymbol{X}$ 最大的 $d$ 个特征值对应的特征向量组成。$\\Lambda$ 是对角线元素为协方差矩阵特征值的对角矩阵。根据 $\\boldsymbol{z}_i=\\boldsymbol{W}^\\top\\boldsymbol{x}_i$ 即可将特征降维。在信号处理领域，从最近重构性出发的推导过程被称为 K-L变换，用于离散信号的去相关的线性变换。从数学上看，K-L变换和PCA的核心步骤是相同的：都是对协方差矩阵进行特征值分解，然后选择最大的特征值对应的特征向量作为投影方向。K-L变换更偏向于信号处理领域，强调信号的能量集中特性，适用于随机信号的降维和压缩。PCA更偏向于统计学和机器学习领域，强调数据的方差解释能力，适用于数据的降维和可视化。两者在数学上是等价的，但在应用背景和解释方式上有所不同。3.2. 算法流程首先将 $n$ 个 $d$ 维数据排列成  $d$ 行 $n$ 列矩阵的形式，即每一列是一个样本数据。注意，为了方便从另一个角度推导，这里和前面算法优化问题推导时使用的样本矩阵定义不同，存在一个转置，最终不影响求解结果。\\[\\boldsymbol{X} = [\\boldsymbol{x}_1, \\boldsymbol{x}_2,\\cdots, \\boldsymbol{x}_n] \\in \\mathbb{R}^{d\\times n}\\]然后对数据进行中心化，即计算所有数据的均值后，将所有数据减去均值\\[\\begin{aligned}\\bar{\\boldsymbol{X}}&amp;=[\\boldsymbol{x}_1-\\boldsymbol{\\mu}, \\boldsymbol{x}_2-\\boldsymbol{\\mu},\\cdots, \\boldsymbol{x}_n-\\boldsymbol{\\mu}]\\\\&amp;=[\\bar{\\boldsymbol{x}}_1, \\bar{\\boldsymbol{x}}_2,\\cdots, \\bar{\\boldsymbol{x}}_n]\\\\&amp;=\\begin{bmatrix}\\bar x^1_1 &amp; \\bar x^2_1 &amp; \\cdots &amp; \\bar x^n_1\\\\\\bar x^1_2 &amp; \\bar x^2_2 &amp; \\cdots &amp; \\bar x^n_2\\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\bar x^1_d &amp; \\bar x^2_d &amp; \\cdots &amp; \\bar x^n_d\\\\\\end{bmatrix}\\end{aligned}\\]此时满足\\[\\sum_{i=0}^m \\bar{\\boldsymbol{x}}_i = 0\\]然后计算这个矩阵的协方差矩阵，即\\[\\begin{aligned}\\boldsymbol{\\Sigma} &amp;= \\frac{1}{n}\\bar{\\boldsymbol{X}}\\bar{\\boldsymbol{X}}^\\top \\in \\mathbb{R}^{d \\times d}\\\\&amp;=\\frac{1}{n} \\begin{bmatrix}\\sum_{i=1}^n (\\bar x^i_1)^2 &amp; \\sum_{i=1}^n \\bar x^i_1\\cdot \\bar x^i_2 &amp; \\cdots &amp; \\sum_{i=1}^n \\bar x^i_1\\cdot \\bar x^i_d\\\\\\sum_{i=1}^n \\bar x^i_2\\cdot \\bar x^i_1 &amp; \\sum_{i=1}^n (\\bar x^i_2)^2 &amp; \\cdots &amp; \\sum_{i=1}^n \\bar x^i_2\\cdot \\bar x^i_d\\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\sum_{i=1}^n \\bar x^i_d\\cdot \\bar x^i_1 &amp; \\sum_{i=1}^n \\bar x^i_d\\cdot \\bar x^i_2 &amp; \\cdots &amp; \\sum_{i=1}^n (\\bar x^i_d)^2\\\\\\end{bmatrix}\\end{aligned}\\]其中，对角线上的元素为各个随机变量（特征）的方差，非对角线上的元素为两两随机变量之间的协方差。求出协方差矩阵的特征值 $\\lambda_i$ 和对应的正交化单位特征向量 $\\boldsymbol{w}_i$。将特征向量按照对应特征值从大到小，自上而下按行排列成矩阵，取前 $k$ 行组成矩阵 $\\boldsymbol{W}$。$\\boldsymbol{Z} = \\boldsymbol{W}\\boldsymbol{X}$ 即为降维到 $k$ 维后的数据。（如果按列排列特征向量，则 $\\boldsymbol{W}$ 取转置）3.3. PCA 的特点根据上面对PCA的数学原理的解释，可以了解到一些PCA的能力和限制。PCA本质上是将方差最大的方向作为主要特征，并且在各个正交方向上将数据“离相关”，也就是让它们在不同正交方向上没有相关性。因此，PCA也存在一些限制，例如它可以很好的解除线性相关，但是对于高阶相关性就没有办法了，对于存在高阶相关性的数据，可以考虑Kernel PCA，通过Kernel函数将非线性相关转为线性相关。另外，PCA假设数据各主特征是分布在正交方向上，如果在非正交方向上存在几个方差较大的方向，PCA的效果就大打折扣了。最后需要说明的是，PCA是一种无参数技术，也就是说面对同样的数据，如果不考虑清洗，谁来做结果都一样，没有主观参数的介入，所以PCA便于通用实现，但是本身无法个性化的优化。4. 参考文献[1] CSDN【机器学习】LDA 浅谈 Linear Discriminant Analysis[2] CSDN PCA(主成分分析方法)"
  },
  
  {
    "title": "模式识别（贝叶斯决策）",
    "url": "/posts/Pattern-Recognition-Bayes/",
    "categories": "Academic, Knowledge",
    "tags": "pattern recognition",
    "date": "2024-03-12 21:22:19 +0800",
    





    
    "snippet": "本文介绍了模式识别的贝叶斯决策，包括贝叶斯公式、最小错误贝叶斯决策、最小风险贝叶斯决策。  1. 决策理论与方法          1.1. 基于先验概率的决策      1.2. 基于贝叶斯公式（后验概率）的决策        2. 最小错误贝叶斯决策          2.1. 直观举例      2.2. 类概率密度      2.3. 错误率分析      2.4. 决策规则    ...",
    "content": "本文介绍了模式识别的贝叶斯决策，包括贝叶斯公式、最小错误贝叶斯决策、最小风险贝叶斯决策。  1. 决策理论与方法          1.1. 基于先验概率的决策      1.2. 基于贝叶斯公式（后验概率）的决策        2. 最小错误贝叶斯决策          2.1. 直观举例      2.2. 类概率密度      2.3. 错误率分析      2.4. 决策规则        3. 正态分布样本的最小错误贝叶斯决策          3.1. 多元正态分布      3.2. 各类协方差矩阵相等且为特殊对角阵      3.3. 各类协方差矩阵相等      3.4. 各类协方差不等（一般情况）        4. 最小风险贝叶斯决策          4.1. 举例说明      4.2. 风险因子（损失函数）      4.3. 条件期望风险（条件平均损失）      4.4. 判决准则        5. 最小最大贝叶斯决策          5.1. 期望风险      5.2. 期望风险与先验概率的关系      5.3. 最小化最大期望风险        6. 参考文献1. 决策理论与方法如果每一类在空间中互不相交，有清晰的决策边界，这种叫做确定统计分类。如果这些类相互之间有重合，新的样本的特征落到一个重合区域，那么就要判断该样本属于某一类的概率。从而通过比较某些概率的大小来进行分类，这种叫做不确定统计分类。确定统计分类也可以通过设计线性分类器来完成分类，而对于不确定统计分类，一方面可以继续采用线性分类的思想设计分类器，另一方面也可以采用本文将要介绍的贝叶斯决策。后面我们会看到，线性分类的最优分类器是最小错误贝叶斯决策。1.1. 基于先验概率的决策记 $x$ 为观察到的样本特征，分类空间为 $A={a_1, a_2, \\cdots, a_n}$，其中 $a_i$ 为第 $i$ 类，$p(A)$ 为该空间的发生概率（先验概率分布）。  $x=[x_1, x_2, \\cdots, x_d]^\\top$ 为由 $d$ 维空间组成的特征向量。  当 $p(a_j)&gt;p(a_{others})$ 时，记决策规则 $x\\in a_j$。  当作出决策之后，单分类错误率 $p(error_j) = 1-p(a_j)$，即 $x\\notin a_j$ 的概率。  现假设你面前有10张卷子，老师告诉你有 5 份是说没有复习实际也没有复习的学渣的，有 5 份是说没有复习却复习的很好的学霸的，你从里面任意抽了一份出来，不看分数不看名字，问你卷子是学渣还是学霸的。此时由于你只知道学渣学霸的试卷各占一半，因此你只能随便猜一个答案，那么你的单分类错误率是 $0.5$。此时就是基于先验概率的决策。可以看到，一般决策过程仅依靠先验概率 $p(a_j)$，使得对 $x$ 的观察（特征，也就是试卷分数）并没有对决策过程产生影响，总体错误率仍有降低的空间。1.2. 基于贝叶斯公式（后验概率）的决策贝叶斯决策（Bayes Decision） 是十大经典机器学习算法之一，是统计机器学习的典型。通过观察到样本的特征 $x$ 后，通过贝叶斯公式，可以有效降低错误率。贝叶斯决策也被称作统计决策理论。  现假设你面前有10张卷子，老师告诉你有 5 份是说没有复习实际也没有复习的学渣的，有 5 份是说没有复习却复习的很好的学霸的，你从里面任意抽了一份出来，得分90+，不看名字，你多半会说这是学霸的卷子，或许你没有发现，在你做判断的一瞬间已经无意中使用了贝叶斯决策。贝叶斯公式旨在通过一个已知的结果，并结合一些经验性或统计性的信息来倒推出最可能产生该结果的原因，即所谓执果索因。对于一个 $c$ 分类任务，贝叶斯公式如下\\[p(\\omega_{i}\\mid x)=\\frac{p(x\\mid\\omega_{i})p(\\omega_{i})}{p(x)}=\\frac{p(x\\mid\\omega_{i})p(\\omega_{i})}{\\sum_{j=1}^{c}p(x\\mid\\omega_{j})p(\\omega_{j})},i=1,2, \\cdots c \\tag{1}\\]其中，举例说明（$c=2$）如下：  $\\omega_1,\\omega_2$：表示两个类别，此处分别为学渣、学霸；  $p(\\omega_{i})$：表示类别 $i$ 的先验概率，即每一类样本整体出现的概率，此处 $p(\\omega_{1})=0.5=p(\\omega_{2})$，表示两类试卷各占一半；  $x$：表示观测/抽样数据，假设 $x=1$ 为拿到90+分的试卷，$x=0$ 则表示拿到了不超过90分的试卷；  $p(x=1\\vert\\omega_i)$：表示类别 $i$ 的条件概率，即第$i$类中的某样本特征出现的概率，反映了在 $w_i$类中观察到特征值 $\\boldsymbol{x}$ 的可能性（likelihood），也称为似然度，一般是已知的；  $p(x=1)$：表示两类学生考 90+ 分的概率，是一个全概率；  $p(\\omega_i\\vert x=1)$：后验概率，同样也是一个条件概率，表示已知考试成绩为 90+ 分，那么该试卷属于第 $\\omega_i$ 类的概率；后验概率也是我们需要求得的概率，通过它可以实现分类，比如选取后验概率最大者对应的类别作为分类结果。可以看出，后验概率即为我们需要求取的概率。后验概率其实是在衡量各组分对结果的贡献，概率大，表示所有此结果中该组分（类）占比大。在引例中不知道那张试卷分数时，卷子可能属于10个人中的任意一人，即两个组分（类别）在概率上都贡献了5个人，各占0.5。而在知道卷面成绩90+后，贡献就悄然发生了变化。  已知学渣和学霸各占总样本的一半人数也就是5人，则先验概率为\\[p(w_1)=0.5, p(w_2)=0.5\\]  假设通过以往所有的考试信息，得出w1组得分90+的概率为0.2，w2组得分90+的概率为0.8，即条件概率（似然度）为\\[p(x=1|w_1)=0.2, p(x=1|w_2)=0.8\\]  代入贝叶斯公式即可求得后验概率\\[\\begin{aligned}p(w_1|x=1)&amp;=\\frac{0.2*0.5}{0.2*0.5+0.8*0.5}=0.2, \\\\p(w_2|x=1)&amp;=\\frac{0.8*0.5}{0.2*0.5+0.8*0.5}=0.8\\end{aligned}\\]  可以看出，成绩90+的试卷属于$w_1$ 组的概率为0.2，属于 $w_2$ 组的概率为0.8，因此这张卷子更有可能是学霸的。贝叶斯公式特点：  条件概率（似然度）是计算后验概率的基础，是通过大量统计来得到的，这就是大数定理。  许多事件的发生不具有可重复性，所以条件概率只能根据对置信度的主观判断，然后再以新获得的信息对条件概率进行修正。  贝叶斯决策是基于概率的，所以分类决策一定存在错误率，即使错误率很低。贝叶斯决策就是在贝叶斯公式计算出后验概率的基础上，进一步做归属的决定——分类，如上述引例中，决策就是决定90+或者不超过90分的卷子归于 $w_1$ 组（类）或者归于 $w_2$ 组（类）。不同的贝叶斯分类器有不同的贝叶斯决策，其主要包括两种决策方式，即最小错误贝叶斯决策，和最小风险贝叶斯决策。2. 最小错误贝叶斯决策2.1. 直观举例最小错误贝叶斯决策就是选择后验概率最大的类作为判断的决策。  上述例中，在 $x=1$ 时，由于\\[p(w_1|x=1)=0.2 &lt; p(w_2|x=1)=0.8\\]  所以将90+的卷子归属到 $w_2$，犯错的概率会最小。犯错的概率就是90+的卷子可能属于 $w_1$ 的概率，即\\(p(w_1|x=1)=0.2 = 1 - p(w_2|x=1)\\)  同理，在 $x=0$ 时，将90或者90-的卷子归属到 $w_1$，犯错的概率会最小。犯错的概率是\\[p(w_2|x=0)=0.2=1 - p(w_1|x=0)\\]  上述例子是符合直觉的，在数学上需要更为严谨的推导。2.2. 类概率密度对于前述例子，会觉得它更像是一个简单的数学问题，而不是一个模式识别问题。因为在实际模式识别中，首先，待分类数据 $x$ 往往不会只有 $[0,1]$ （此处为 90+分和不足90分）两种取值，而会是一系列取值，如得分为 $[0,1,\\cdots,99,100]$；对应的类的条件概率往往不是几个孤立的冲激，而是一个连续的概率密度函数（PDF），如下图所示：类条件概率反映出样本在特征空间的分布（学渣的卷面分数分布和学霸的卷面分数分布），这个分布一般而言是需要根据样本数据统计计算得到的。正因为不同类别的类条件概率分布在特征空间会重叠，导致了判决错误的发生。2.3. 错误率分析为什么最小错误率贝叶斯决策的错误率是最小的？从定义出发：选择后验概率最大的类作为判断的决策。以一维二分类问题进行说明。对于两类问题，统计判决的基本方法是根据前述类的概率和概率密度将模式的特征空间划分为两个子区域 $\\mathcal{R}_1, \\mathcal{R}_2$，当 $x\\in\\mathcal{R}_1$ 时判断为 $x\\in w_1$ 类，当 $x\\in\\mathcal{R}_2$ 时判断为 $x\\in w_2$ 类。则错误率取决于两个子空间的划分情况，或者说两个子空间分界面 $t$ 的选择。显然，此时会发生两种错误：  把实际是 $w_1$ 类的样本错误判断为 $w_2$ 类。这种情况发生的原因是属于 $w_1$ 类的特征分布在 $w_2$ 的特征空间区域 $\\mathcal{R}_2$ 中。这时，误判概率为（图中方格区域的面积）\\[p(e_1) = \\int_{\\mathcal{R}_2} p(x \\vert w_1)\\text{d}x\\]  另一种错误是把实际是 $w_2$ 类的样本错误判断为 $w_1$ 类。这种情况发生的原因是属于 $w_2$ 类的特征分布在 $w_1$ 的特征空间区域 $\\mathcal{R}_1$ 中。这时，误判概率为（图中斜纹区域的面积）\\[p(e_2) = \\int_{\\mathcal{R}_1} p(x \\vert w_2)\\text{d}x\\]考虑到两个类别发生的概率分别为 $p(w_1), p(w_2)$ ，则总的误判概率为\\[p(e) = p(w_1) \\cdot p(e_1)+ p(w_2) \\cdot p(e_2) = p(w_1)\\int_{\\mathcal{R}_2} p(x \\vert w_1)\\text{d}x + p(w_2)\\int_{\\mathcal{R}_1} p(x \\vert w_2)\\text{d}x\\]其中 $p(w_1), p(w_2)$ 对于积分来说是与 $x$ 无关的常数，因此可以在积分符号内或者外出现。我们希望总错误率最小，等价于希望总的正确判断的概率最大，总正确率为\\[p(c) = p(w_1)\\int_{\\mathcal{R}_1} p(x \\vert w_1)\\text{d}x + p(w_2)\\int_{\\mathcal{R}_2} p(x \\vert w_2)\\text{d}x \\tag{2}\\]注意到（$w_2$ 类别在全空间要么判断正确要么判断错误）\\[\\begin{aligned}1 &amp;= \\int_{\\mathcal{R}_1} p(x \\vert w_2)\\text{d}x + \\int_{\\mathcal{R}_2} p(x \\vert w_2)\\text{d}x \\\\\\Rightarrow \\quad p(w_2) &amp;= p(w_2)\\int_{\\mathcal{R}_1} p(x \\vert w_2)\\text{d}x + p(w_2)\\int_{\\mathcal{R}_2} p(x \\vert w_2)\\text{d}x\\\\\\Rightarrow \\textcolor{blue}{\\quad p(w_2)\\int_{\\mathcal{R}_2} p(x \\vert w_2)\\text{d}x} &amp;= p(w_2) - p(w_2)\\int_{\\mathcal{R}_1} p(x \\vert w_2)\\text{d}x \\\\\\end{aligned} \\tag{3}\\]上述等式左边代入式 $(2)$，有\\[\\begin{aligned}p(c) &amp;= p(w_1)\\int_{\\mathcal{R}_1} p(x \\vert w_1)\\text{d}x + p(w_2) - p(w_2)\\int_{\\mathcal{R}_1} p(x \\vert w_2)\\text{d}x\\\\&amp;= p(w_2) + \\int_{\\mathcal{R}_1} [\\;p(w_1)p(x \\vert w_1)-p(w_2) p(x \\vert w_2)\\;]\\text{d}x\\\\\\end{aligned}\\]式中 $\\mathcal{R}_1$ 是未知的，直接求解很困难。但考查上式可以发现，为了使其最大，$w_1$ 的决策域 $\\mathcal{R}_1$ 应该是 $R$ 中所有满足条件\\[p(w_1)p(x \\vert w_1) &gt; p(w_2)p(x \\vert w_2)\\]的样本点组成的集合。同理（对式$(2)$左右同时乘以$p(w_1)$然后代入式$(1)$ 得到另一个$p(c)$ 的表达式进行分析），决策域 $\\mathcal{R}_2$ 应该是 $R$ 中所有满足条件\\[p(w_1)p(x \\vert w_1) &lt; p(w_2)p(x \\vert w_2)\\]的样本组成的集合。易知，任何其他划分对应的正确率都要小于按照上述划分的正确率。所以，最小错误率贝叶斯决策（选择后验概率最大的类作为判断）的错误率是最小的。即最小错误贝叶斯决策 = 最大后验贝叶斯决策。此时决策面 $t$ 正好为两类的类条件概率密度函数的交点。由于概率非负，如果每一次决策错误率都最小，那么总的错误率也是最小的。根据前述决策规则，只需要比较类的概率密度函数乘以一个常数（先验概率，不随采样而变，是一个常数值）的结果。显然，图中 $t$ 为决策点，在 $x&lt;t$ 时，对产生数据 $x$ 的贡献 $w_1$ 大于 $w_2$，故最小错误贝叶斯决策将 $x$ 归属为 $w_1$，在 $x&gt;t$ 时，对产生数据 $x$ 的贡献 $w_2$ 大于 $w_1$，故最小错误贝叶斯决策将 $x$ 归属为 $w_2$。  若为 $c$ 分类问题，贝叶斯错误率为\\[p(e) = \\int[1- \\max_i p(w_i \\vert x)]p(x)\\text{d}x\\]2.4. 决策规则根据前述错误率分析，我们需要选择后验概率最大的类作为分类决策规则。对于 $c$ 分类任务，后验概率为\\[p(w_i \\vert \\boldsymbol{x}) = \\frac{p(\\boldsymbol{x} \\vert w_i)p(w_i)}{ p(\\boldsymbol{x})} = \\frac{p(\\boldsymbol{x} \\vert w_i)p(w_i)}{\\sum_{j=1}^c p(\\boldsymbol{x} \\vert w_j)p(w_j)},i=1,2, \\cdots c\\]与二分类的分类规则类似，有【决策规则1】\\[p(w_i \\vert \\boldsymbol{x}) = \\max\\; p(w_j \\vert \\boldsymbol{x}), j\\in[1,c] \\quad \\Rightarrow \\boldsymbol{x}\\in w_i\\]后验概率用贝叶斯公式展开后，由于分母的 $p(\\boldsymbol{x})$ 相同，因此可以忽略分母直接比较分子，得到等效分类规则如下【决策规则2】\\[p(\\boldsymbol{x} \\vert w_i)p(w_i) = \\max\\; [p(\\boldsymbol{x} \\vert w_j)p(w_j)], j\\in[1,c] \\quad \\Rightarrow \\boldsymbol{x}\\in w_i\\]由于先验概率 $p(w_i)$ 是事先确定的，与当前样本  $\\boldsymbol{x}$ 无关，因此人们经常把二分类问题的决策规则整理成下面的形式【决策规则3】\\[l(\\boldsymbol{x})=\\frac{p(\\boldsymbol{x}\\vert w_1)}{p(\\boldsymbol{x}\\vert w_2)} \\gtrless \\frac{p(w_2)}{p(w_1)}=\\lambda \\quad \\Rightarrow \\boldsymbol{x} \\in \\left\\{  \\begin{matrix}  w_1\\\\  w_2\\end{matrix}\\right.\\]上式中，概率密度值 $p(\\boldsymbol{x}\\vert w_i)$ 即为前面贝叶斯公式介绍时提到的似然度，两类似然度的比值 $l(\\boldsymbol{x})$ 被称为似然比（likelihood ratio）。这样可以事先计算出阈值 $\\lambda$，对每一个样本计算似然比 $l(\\boldsymbol{x})$ 并与 $\\lambda$ 比较，大于阈值则决策为第一类，反之决策为第二类。更进一步，许多情况下，用对数形式计算可能更加方便，因此人们定义了负对数似然比\\[h(\\boldsymbol{x}) = -\\ln[l(\\boldsymbol{x})] = -\\ln[p(\\boldsymbol{x}\\vert w_1)] + \\ln[p(\\boldsymbol{x}\\vert w_2)]\\]相应的决策规则为【决策规则4】\\[h(\\boldsymbol{x})\\lessgtr\\ln\\frac{p(w_1)}{p(w_2)} \\quad \\Rightarrow \\boldsymbol{x} \\in \\left\\{  \\begin{matrix}  w_1\\\\  w_2\\end{matrix}\\right.\\]负对数似然比 $h(\\boldsymbol{x})$ 是 $\\boldsymbol{x}$ 的函数，由于 $\\boldsymbol{x}$ 是一个随机向量，则 $h(\\boldsymbol{x})$ 也是随机变量，其概率分布密度函数可定义为 $p(h\\vert w_i)$。由于该函数是一维概率密度函数，易于积分，所以用它计算错误率较为方便，则二分类的错误率可表述为\\[\\begin{aligned}p(e_1) &amp;= \\int_{\\mathcal{R}_2} p(x \\vert w_1)\\text{d}x = \\int_{t}^{+\\infty} p(h \\vert w_1)\\text{d}h\\\\p(e_2) &amp;= \\int_{\\mathcal{R}_1} p(x \\vert w_2)\\text{d}x = \\int_{-\\infty}^{t} p(h \\vert w_2)\\text{d}h\\end{aligned}\\tag{4}\\]其中 $t = \\ln\\frac{p(w_1)}{p(w_2)}$。只要 $h(\\boldsymbol{x})$ 的概率密度的解析形式已知，就可以计算出错误率。需要注意的是，当 $\\boldsymbol{x}$ 是高维特征时，总错误率涉及到多重积分，计算比较困难，因此只能在一些特定简化条件下进行错误率的理论计算。比如在下一章节中，假设样本特征服从正态分布，可以对最小错误贝叶斯决策展开分析，导出分类器的解析表达式和错误率的解析形式。3. 正态分布样本的最小错误贝叶斯决策正态分布假设是工程应用中最普遍的假设，因为：  正态分布在数学上比较简单，便于进行分析  正态分布在物理上经常是总体分布的合理近似本节着重讨论样本分布属于正态分布时，最小错误率贝叶斯决策的情况。3.1. 多元正态分布对于样本特征 $\\boldsymbol{x}=[x_1,x_2,\\cdots,x_d]^\\top$ 的多元正态分布的概率密度函数定义为\\[p(\\boldsymbol{x}) = \\frac{1}{\\sqrt{(2\\pi)^d\\vert\\boldsymbol{\\Sigma}\\vert}}e^{-\\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu})}\\]其中均值向量和协方差矩阵分别为\\[\\begin{aligned}\\boldsymbol{\\mu} &amp;= \\mathbb{E}[\\boldsymbol{x}] = (\\mu_1,\\mu_2,\\cdots,\\mu_d)^\\top\\in\\mathbb{R}^{d}\\\\\\boldsymbol{\\Sigma} &amp;= \\mathbb{E}[(\\boldsymbol{x}-\\boldsymbol{\\mu})(\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top] = [\\sigma^2_{ij}]\\in\\mathbb{R}^{d\\times d}\\\\\\end{aligned}\\]正态分布有几个优良性质（后面会用到）  正态分布的边缘分布仍然是正态分布  正态分布的条件分布仍然是正态分布  正态分布各分量的线性组合仍然是正态分布已知最小错误率贝叶斯决策的判别函数为\\[g_i(\\boldsymbol{x}) = p(\\boldsymbol{x}\\vert w_i)p(w_i),\\;i=1,2,\\cdots,c\\]假设特征的先验概率符合多元正态分布，代入上式取自然对数，得到判别函数为\\[\\begin{aligned}  \\ln g_i(\\boldsymbol{x}) &amp;= \\ln p(\\boldsymbol{x}\\vert w_i) + \\ln p(w_i)\\\\  &amp;= \\ln \\frac{1}{\\sqrt{(2\\pi)^d\\vert\\boldsymbol{\\Sigma}\\vert}}  -\\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu}) + \\ln p(w_i)\\\\  &amp;= -\\frac{d}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln\\vert\\boldsymbol{\\Sigma}\\vert - \\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu}) + \\ln p(w_i)\\\\  \\end{aligned}\\]对于贝叶斯决策，决策面方程为\\[g_i(\\boldsymbol{x}) = g_j(\\boldsymbol{x})\\]即\\[-\\frac{1}{2}[(\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu}) - (\\boldsymbol{x}_j-\\boldsymbol{\\mu})^\\top\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}_j-\\boldsymbol{\\mu})]-\\frac{1}{2}\\ln\\frac{\\vert\\boldsymbol{\\Sigma_i}\\vert}{\\vert \\boldsymbol{\\Sigma_j}\\vert} + \\ln \\frac{p(w_i)}{p(w_j)} = 0\\]3.2. 各类协方差矩阵相等且为特殊对角阵假设样本的特征向量的各个分量独立且具有相同的方差 $\\sigma^2$，即 $\\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\boldsymbol{\\Sigma} = \\sigma^2\\boldsymbol{I}$，此时有\\[\\boldsymbol{\\Sigma}_i = \\sigma^2\\boldsymbol{I},\\quad\\vert\\boldsymbol{\\Sigma}_i\\vert = \\sigma^{2d},\\quad\\boldsymbol{\\Sigma}_i^{-1} = \\frac{1}{\\sigma^2}\\boldsymbol{I},\\quad i=1,2,\\cdots,c\\\\\\]判别函数简化为\\[g_i(\\boldsymbol{x}) = -\\frac{1}{2\\sigma^2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top(\\boldsymbol{x}-\\boldsymbol{\\mu})- \\frac{d}{2}\\ln {2\\pi} - \\frac{1}{2}p(w_i)\\]假设 $c$ 个类别的先验概率均相同（ $p(w_i)=p(w_j),\\forall i,j=1,2,\\cdots,c$），并且注意到贝叶斯决策要求对不同类别的判别函数进行比较，那么可以忽略所有与类别无关的常数。则判别函数进一步简化为\\[\\begin{aligned}g_i(\\boldsymbol{x}) &amp;= -\\frac{1}{2\\sigma^2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top(\\boldsymbol{x}-\\boldsymbol{\\mu}) = -\\frac{1}{2\\sigma^2}\\Vert \\boldsymbol{x}-\\boldsymbol{\\mu} \\Vert^2\\end{aligned}\\]可以看出，若要对位置样本进行分类，只需要计算该样本特征特征向量到各类均值的欧式距离，然后把样本归类到距离最近的类别即可，说明此时的最小错误率贝叶斯分类器等价于最小距离分类器或垂直平分分类器。继续对判别函数进行线性化，有\\[\\begin{aligned}g_i(\\boldsymbol{x}) &amp;=-\\frac{1}{2\\sigma^2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top(\\boldsymbol{x}-\\boldsymbol{\\mu}) \\quad \\textcolor{blue}{\\text{Euclidean Distance}}\\\\&amp;= -\\frac{1}{2\\sigma^2}(-2\\boldsymbol{\\mu}_i^\\top \\boldsymbol{x}+\\boldsymbol{\\mu}_i^\\top \\boldsymbol{\\mu}_i)\\\\&amp;= \\frac{1}{\\sigma^2}\\boldsymbol{\\mu}_i^\\top\\boldsymbol{x} - \\frac{1}{2\\sigma^2}\\boldsymbol{\\mu}^\\top \\boldsymbol{\\mu}\\\\&amp;= \\boldsymbol{w}_i^\\top\\boldsymbol{x} + w_{i0}\\quad \\textcolor{blue}{\\text{linear}}\\end{aligned}\\]可以看出决策面确实是一个超平面。如果先验概率 $p(w_i)\\neq p(w_j)$，则决策面向先验概率小的那一类平移。3.3. 各类协方差矩阵相等假设各类协方差矩阵相等（即$\\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\boldsymbol{\\Sigma}$，但不再满足 $\\boldsymbol{\\Sigma} = \\sigma^2\\boldsymbol{I}$），再假设各类先验概率相等，判别函数简化为\\[\\begin{aligned}g_i(\\boldsymbol{x}) &amp;= -\\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu}_i)^\\top\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu}_i)\\quad \\textcolor{blue}{\\text{Mahalanobis Distance}}\\\\&amp;= -\\frac{1}{2}(\\textcolor{red}{\\boldsymbol{x}^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{x}}-2\\boldsymbol{\\mu}_i^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{x} + \\boldsymbol{\\mu}_i^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_i)\\\\&amp;= -\\boldsymbol{\\mu}_i^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{x} + \\frac{1}{2}\\boldsymbol{\\mu}^\\top\\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}\\quad \\textcolor{blue}{\\text{ignore constant}}\\\\&amp;=\\boldsymbol{w}_i^\\top\\boldsymbol{x} + w_{i0}\\quad \\textcolor{blue}{\\text{linear}}\\\\\\end{aligned}\\]注意因为协方差矩阵相等，因此对于不同类别来说展开后第一项（标红）都是常数，因此可以忽略。此时决策规则为按最小马氏距离的平方进行判别。按马氏距离判别仍然是线性的。  马氏距离：$D_M(\\boldsymbol{x},\\boldsymbol{\\mu}) = \\sqrt{(\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu})} $类似地，如果先验概率相等，则决策面过均值向量连线的终点（但不再垂直）。如果先验概率 $p(w_i)\\neq p(w_j)$，则决策面向先验概率小的那一类平移。继续分析该情况下的错误率，将复对数似然比展开得到\\[\\begin{aligned}  h(\\boldsymbol{x}) &amp;= -\\ln[p(\\boldsymbol{x}\\vert w_1)] + \\ln[p(\\boldsymbol{x}\\vert w_2)] \\\\  &amp;=\\frac{1}{2}[(\\boldsymbol{x}-\\boldsymbol{\\mu}_1)^\\top\\boldsymbol{\\Sigma}_1^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu}_1) - (\\boldsymbol{x}-\\boldsymbol{\\mu}_2)^\\top\\boldsymbol{\\Sigma}_2^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu}_2)] + \\frac{1}{2}\\ln\\frac{\\vert\\boldsymbol{\\Sigma}_1\\vert}{\\vert \\boldsymbol{\\Sigma}_2\\vert}\\\\  &amp;= (\\boldsymbol{\\mu}_2 - \\boldsymbol{\\mu}_1)^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{x} + \\frac{1}{2}(\\boldsymbol{\\mu}_1^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_2^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_2)\\\\  &amp;= \\boldsymbol{a}^\\top\\boldsymbol{x} + \\boldsymbol{b}\\quad \\textcolor{blue}{\\text{linear}}\\end{aligned}\\]可以看出，负对数似然比是关于 $\\boldsymbol{x}$ 的线性函数，又已知 $\\boldsymbol{x}$ 服从正态分布，则负对数似然比也是一维正态分布。对于负对数似然比的两个类条件概率密度函数 $p(h\\vert w_1),p(h\\vert w_2)$ 也服从正态分布，分别计算其一维正态分布的均值和方差。均值为\\[\\begin{aligned}  \\eta_1 &amp;= \\mathbb{E}[h(\\boldsymbol{x})\\vert w_1] = h(\\boldsymbol{\\mu}_1)\\\\  &amp;= (\\boldsymbol{\\mu}_2 - \\boldsymbol{\\mu}_1)^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_1 + \\frac{1}{2}(\\boldsymbol{\\mu}_1^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_1-\\boldsymbol{\\mu}_2^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_2)\\\\  &amp;= \\textcolor{red}{\\boldsymbol{\\mu}_2^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_1} - \\frac{1}{2}\\boldsymbol{\\mu}_1^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_1 -\\frac{1}{2}\\boldsymbol{\\mu}_2^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_2\\\\  &amp;= - \\frac{1}{2}\\boldsymbol{\\mu}_1^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_1 + \\textcolor{red}{\\frac{1}{2}\\boldsymbol{\\mu}_1^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_2+\\frac{1}{2}\\boldsymbol{\\mu}_2^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_1} - \\frac{1}{2}\\boldsymbol{\\mu}_2^\\top\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_2\\quad (\\Sigma\\;\\text{is symmetric})\\\\  &amp;= -\\frac{1}{2}(\\boldsymbol{\\mu}_2 - \\boldsymbol{\\mu}_1)^\\top\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}_2 - \\boldsymbol{\\mu}_1)\\\\  &amp;= -\\frac{1}{2}D_M(\\boldsymbol{\\mu_2},\\boldsymbol{\\mu_1})^2 = -\\eta\\end{aligned}\\]考虑对多元正态分布的线性变换，其方差定义为：\\[\\begin{aligned}Var(h(\\boldsymbol{x})\\vert w_1) &amp;= \\boldsymbol{a}^\\top\\boldsymbol{\\Sigma}\\boldsymbol{a}\\\\&amp;= (\\boldsymbol{\\mu}_2 - \\boldsymbol{\\mu}_1)^\\top \\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\Sigma}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}_2 - \\boldsymbol{\\mu}_1)\\\\&amp;= (\\boldsymbol{\\mu}_2 - \\boldsymbol{\\mu}_1)^\\top\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}_2 - \\boldsymbol{\\mu}_1)\\\\&amp;= D_M(\\boldsymbol{\\mu_2},\\boldsymbol{\\mu_1})^2 = 2\\eta\\end{aligned}\\]所以\\[p(h(\\boldsymbol{x})\\vert w_1)\\sim N(-\\eta, 2\\eta)\\]同理可得\\[\\begin{aligned}p(h(\\boldsymbol{x})\\vert w_2)\\sim N(\\eta, 2\\eta)\\end{aligned}\\]至此，我们就得到了负对数似然比（服从一维正态分布）在两个类条件概率密度函数 $p(h\\vert w_1),p(h\\vert w_2)$ 的均值和方差。代入式 $(4)$ 可以计算两种情况下的错误率\\[\\begin{aligned}p(e_1) &amp;= \\int_t^{+\\infty} p(h\\vert w_1)dh \\\\&amp;= \\int_t^{+\\infty} \\frac{1}{(2\\pi)^{0.5}\\sigma} \\text{exp}\\left\\{\\frac{1}{2}(\\frac{h+\\eta}{\\sigma})^2\\right\\} dh\\\\&amp;= \\int_t^{+\\infty} \\frac{1}{(2\\pi)^{0.5}} \\text{exp}\\left\\{\\frac{1}{2}(\\frac{h+\\eta}{\\sigma})^2\\right\\} d(\\frac{h+\\eta}{\\sigma})\\\\&amp;= \\int_{\\frac{t+\\eta}{\\sigma}}^{+\\infty} \\frac{1}{(2\\pi)^{0.5}} \\text{exp}\\left\\{\\frac{1}{2}\\varepsilon^2\\right\\} d\\varepsilon \\sim N(0,1)\\end{aligned}\\]\\[\\begin{aligned}p(e_2) &amp;= \\int_{-\\infty}^t p(h\\vert w_2)dh \\\\&amp;= \\int_{-\\infty}^t \\frac{1}{(2\\pi)^{0.5}\\sigma} \\text{exp}\\left\\{\\frac{1}{2}(\\frac{h-\\eta}{\\sigma})^2\\right\\} dh\\\\&amp;= \\int_{-\\infty}^t \\frac{1}{(2\\pi)^{0.5}} \\text{exp}\\left\\{\\frac{1}{2}(\\frac{h-\\eta}{\\sigma})^2\\right\\} d(\\frac{h+\\eta}{\\sigma})\\\\&amp;= \\int_{-\\infty}^{\\frac{t-\\eta}{\\sigma}} \\frac{1}{(2\\pi)^{0.5}} \\text{exp}\\left\\{\\frac{1}{2}\\varepsilon^2\\right\\} d\\varepsilon \\sim N(0,1)\\end{aligned}\\]已知 $t,\\boldsymbol{\\mu}_1, \\boldsymbol{\\mu}_2, \\boldsymbol{\\Sigma}_1, \\boldsymbol{\\Sigma}_2$ 时，查标准正态分布表就能得到两个错误率。实际上，贝叶斯错误率可以写为标准正态分布的累积分布函数的形式：\\[p(e) = \\Phi(-\\frac{1}{2}D_M(\\boldsymbol{\\mu_2},\\boldsymbol{\\mu_1}))\\]标准正态分布的累积分布函数（CDF）表示标准正态分布（均值为 0，方差为 1）在 $z$ 左侧的概率\\[\\Phi(z) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{z}e^{-\\frac{x^2}{2}}dx\\]由于标准正态分布是对称的，$\\Phi(z) = 1-\\Phi(-z)$，因此\\[p(e) = 1-\\Phi(\\frac{1}{2}D_M(\\boldsymbol{\\mu_2},\\boldsymbol{\\mu_1}))\\]可分析如下：  当马氏距离为 0 时，CDF 值为 0.5，此时错误率是 0.5（原始样本特征的概率密度函数重合，相当于随机猜测）  当马氏距离增大时，CDF 值不断减小，此时错误率单调递减；  当马氏距离为正无穷时，此时错误率趋近于 0（原始样本特征的概率密度函数几乎完全分离）但是还是要注意，以上分析的前提是类条件概率密度可以被精确估计。实际上，样本量有限，无法准确估计概率密度。另外，特征增加当然可能使错误率反而增加，除了因为估计不准确之外，还可能是高斯密度这个前提本身就是不准的。而且，样本量小而特征很多，无疑会带来很多麻烦，比如过拟合等。3.4. 各类协方差不等（一般情况）判别函数（忽略常数项后）形式如下：\\[\\begin{aligned}g_i(\\boldsymbol{x}) &amp;= - \\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top\\boldsymbol{\\Sigma}_i^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu}) - \\frac{1}{2}\\ln\\vert\\boldsymbol{\\Sigma}_i\\vert + \\ln p(w_i)\\\\&amp;= -\\frac{1}{2}\\boldsymbol{\\Sigma}_i^{-1}\\boldsymbol{x} + \\boldsymbol{\\Sigma}_i^{-1}\\boldsymbol{\\mu}_i\\boldsymbol{x} -\\frac{1}{2}\\boldsymbol{\\mu}_i^\\top\\boldsymbol{\\Sigma}_i^{-1}\\boldsymbol{\\mu}_i -\\frac{1}{2}\\ln\\vert\\boldsymbol{\\Sigma}_i\\vert + \\ln p(w_i)\\\\&amp;=\\boldsymbol{x}^\\top\\boldsymbol{W}^{-1}\\boldsymbol{x} + \\boldsymbol{w}_i^\\top\\boldsymbol{x} + w_{i0}\\\\\\end{aligned}\\]这类判别函数为 $\\boldsymbol{x}$ 的二次型，决策面为二次超曲面，当 $\\boldsymbol{\\Sigma}_i,\\boldsymbol{\\mu},p(w_i)$的的取值不同时，形成的曲面形状也不一样，有超球面、超椭球面、超抛物面、超双曲面等。4. 最小风险贝叶斯决策最小错误率决策足以胜任一般的决策场景。但是如果考虑不同的决策错误会带来不同的风险，则需要赋予不同的权重。比如，如果一个人处于癌症早期，而模型判定他是正常的，那此类决策可能带来生命的代价，因此需要给此类决策高权重。而如果一个人是正常的，模型判定他为癌症早期，代价是给病人和家属带来巨大的精神负担，但相对于生命而言可能相对可以接受，因此需要给此类决策低权重。显然，判定正确没有代价，权重为0。4.1. 举例说明还是用上述引例深入分析，假设把一张学渣的（$w_1$）卷子错判成学霸的（$w_2$），会对学渣造成 10点 暴击伤害（因为导致学渣以为自己进步神速最后还是会被无情打碎幻想），反之如果把一张学霸的卷子判成学渣只有 1点 普通伤害（学霸很自信不会轻易动摇）。如果判定正确，大家则相安无事。那么我们就为学渣（$w_1$）的卷子判定成学霸（$w_2$）的决策加 10 点权值，然后为学霸（$w_2$）的卷子判定成学渣（$w_1$）的决策加 1 点权值，判断正确的权值为零，那我们可以得到如下决策表。            决策             真实类别（学渣）      真实类别（学霸）                         \\      $w_1$      $w_2$              分类结果（学渣）      $w_1$      0      1              分类结果（学霸）      $w_2$      10      0      假设同样是抽到了一张90+的卷子，即 $x=1$。对于最小错误贝叶斯决策，$p(\\omega_1\\vert x=1) = 0.2$，$p(\\omega_2\\vert x=1) = 0.8$，将该卷子判定为学霸的（$w_2$）是最佳决策。现在如果依旧判定为 $w_2$，那么其风险为 $R = 10 \\times 0.2 + 0 \\times 0.8 = 2$，而判定为 $w_1$，风险则为 $R_1 = 0* 0.2 + 0.8*1 = 0.8$。对于最小风险贝叶斯决策，判定为 $w_1$ 是最佳决策。剧情出现了 180 度大转弯，说明考虑风险后发现将学渣的卷子误判的代价更高，因此更倾向于误判学霸的卷子。4.2. 风险因子（损失函数）从决策论的角度，可将最小风险贝叶斯决策重新表述如下：  样本 $\\boldsymbol{x}$ 看作 d 维随机向量 $\\boldsymbol{x} = [x_1,x_2,\\cdots,x_d]^\\top$  状态空间 $\\Omega$ 由 $c$ 个可能的状态组成（$c$ 类）：$\\Omega={w_1,w_2,\\cdots, w_c}$      对随机向量 $\\boldsymbol{x}$ 可能采取的（分类）决策组成了决策空间，它由 $k$ 个决策组成：$A={a_1,a_2,\\cdots, a_k}$    注意，这里并没有假定 $k=c$，因为可能采取的（分类）决策除了判别为某一类外，还可能做出拒绝分类的决策，即不能判别样本属于任何一类，有时也可以在决策时把几类合并为同一个大类，等等。  定义对于实际状态为 $w_j$ 的向量 $\\boldsymbol{x}$ 采取决策 $a_i$ 所带来的风险因子（损失函数）为\\[\\lambda(a_i, w_j)=\\lambda_{ij},\\quad i= 1,\\cdots, k,\\; j=1,\\cdots, c\\]通常可以用表格的形式给出风险因子，被称为决策表。决策表是人在实际应用中根据问题的背景和知识事先给定的。在实际应用中，需要认真分析研究问题的内在特点和分类目的，与应用领域的专家共同设计出适当的决策表，才能保证模式识别发挥有效的作用。需要注意的是，通常正确分类决策的损失函数 $\\lambda(a_i, w_i)=0$，即分类正确的情况下是没有损失的。4.3. 条件期望风险（条件平均损失）条件期望风险是指在给定观测数据 $\\boldsymbol{x}$ 的条件下，采取某个决策 $a_i$（将其划分为类别 $i$）所产生的期望风险，又称为条件平均损失。对于样本 $\\boldsymbol{x}$ 的各状态后验概率为 $p(w_j \\vert \\boldsymbol{x}),\\;j=1,\\cdots,c$，对它采取决策 $a_i,\\;i=1,\\cdots,k$ 的条件期望风险是\\[R(a_i|\\boldsymbol{x})=E[\\lambda(a_i,w_j)|\\boldsymbol{x}] = \\sum_{j=1}^c \\lambda(a_i,w_j)p(w_j|\\boldsymbol{x}) \\tag{5}\\]对于特定的决策，其风险是所有后验的概率与风险因子的乘积之和，即不再仅仅考虑后验概率了，还要额外考虑风险因子。4.4. 判决准则最小风险贝叶斯决策就是对所有决策 $a_i$ 都分别求出条件期望风险，然后选择条件期望风险最小的决策。具体步骤如下：  首先，将先验概率和似然度（经过统计或经验得到）代入贝叶斯公式计算出后验概率（式 $(1)$）。  然后，利用后验概率和事先定义的决策表（表格的形式的风险因子），计算条件期望损失（式 $(5)$）。  最后，选取其中条件期望损失最小的决策，得到最小风险贝叶斯决策：\\[a = \\arg \\min_{i} R(a_i|\\boldsymbol{x}),\\; i=1,2,\\cdots,c\\]显然，对于二分类任务，当 $\\lambda(1,1)=\\lambda(2,2)=0,\\lambda(1,2)=\\lambda(2,1)=1$ 时，最小风险贝叶斯决策退化为最小错误贝叶斯决策。5. 最小最大贝叶斯决策在最小风险贝叶斯决策中，先验概率 $p(w_i)$ 被认为是确定的。然而在实际应用中，各类的先验概率有时不能精确确定（如从黑箱中拿彩色小球，采样次数不够可能导致对小球颜色估计的先验概率有偏差），或在分析过程中各类的先验概率是变动的。此时，若再用固定先验概率条件下的某个最小风险贝叶斯分类器来进行决策，其结果实际上不是最小风险的。随着先验概率的变化，这个按照之前经验确定的某个具体先验概率取值后得到的最小风险贝叶斯决策，其实际风险可能会变大。最小最大决策就是在各类的先验概率变化的情况下，取最大风险为最小的某个最小风险贝叶斯分类器作为实际使用的分类器。5.1. 期望风险设特征空间 $R$ 中判决域为 $\\mathcal{R}_i(i=1,2,\\cdots,c)$，于是求得条件期望风险关于 $\\boldsymbol{x}$ 的数学期望为\\[R = \\sum_{i=1}^c\\int_{\\mathcal{R}_i} R(\\alpha_i \\vert \\boldsymbol{x})p(\\boldsymbol{x}) \\text{d}x\\]期望风险 $R$ 反映在整个特征空间不同的 $x$ 取值 采取决策 $\\alpha(x)$ （决策可看成是随机向量 $x$ 的函数）所带来的平均风险。与之相比，条件期望风险只反映对某 $x$ 取值的决策行动 $\\alpha_i$ 所带来的风险。5.2. 期望风险与先验概率的关系对于二分类问题，设某个最小风险贝叶斯分类器将特征空间 $R$ 划分为两个子区域，记 $\\lambda_{ij}$ 为将实属 $w_j$ 类的样本判为 $w_i$ 的风险因子，则误判的期望风险为\\[\\begin{aligned}  R &amp;= \\int_R R(\\alpha \\vert \\boldsymbol{x})p(\\boldsymbol{x}) \\text{d}x\\\\  &amp;= \\int_{\\mathcal{R}_1} R(\\alpha_1 \\vert \\boldsymbol{x})p(\\boldsymbol{x}) \\text{d}x + \\int_{\\mathcal{R}_2} R(\\alpha_2 \\vert \\boldsymbol{x})p(\\boldsymbol{x}) \\text{d}x\\\\  &amp;= \\int_{\\mathcal{R}_1} \\sum_{j=1}^2\\lambda_{1j} p(\\boldsymbol{x}\\vert w_j)p(w_j) \\text{d}x + \\int_{\\mathcal{R}_2} \\sum_{j=1}^2\\lambda_{2j} p(\\boldsymbol{x}\\vert w_j)p(w_j) \\text{d}\\quad\\textcolor{blue}{\\text{using Bayes and definition of}\\; R(\\alpha\\vert x)}\\\\  &amp;= \\lambda_{11}p(w_1)\\int_{\\mathcal{R}_1} p(\\boldsymbol{x}\\vert w_1)\\text{d}x + \\lambda_{12}p(w_2)\\int_{\\mathcal{R}_1} p(\\boldsymbol{x}\\vert w_2)\\text{d}x + \\lambda_{21}p(w_1)\\int_{\\mathcal{R}_2} p(\\boldsymbol{x}\\vert w_1)\\text{d}x + \\lambda_{22}p(w_2)\\int_{\\mathcal{R}_2} p(\\boldsymbol{x}\\vert w_2)\\text{d}x\\\\\\end{aligned}\\]引入类别 $w_j$ 下样本落在 $\\mathcal{R}_i$ 的概率\\[p(\\mathcal{R}_i\\vert w_j) = \\int_{\\mathcal{R}_i} p(\\boldsymbol{x}\\vert w_j)\\text{d}x\\]将期望风险表示为\\[R = \\lambda_{11}p(w_1)p(\\mathcal{R}_1\\vert w_1) + \\lambda_{12}p(w_2)p(\\mathcal{R}_1\\vert w_2) + \\lambda_{21}p(w_1)p(\\mathcal{R}_2\\vert w_1) + \\lambda_{22}p(w_2)p(\\mathcal{R}_2\\vert w_2)\\tag{6}\\]又已知（样本要么属于 $w_1$ 类要么属于 $w_2$ 类，要么落在 $\\mathcal{R}_1$ 区域要么落在 $\\mathcal{R}_2$ 区域）\\[\\begin{aligned}p(w_1) + p(w_2) &amp;= 1\\\\p(\\mathcal{R}_1\\vert w_j) + p(\\mathcal{R}_2\\vert w_j) &amp;= 1\\\\\\end{aligned}\\]代入式 $(6)$ 有\\[\\begin{aligned}  R &amp;= \\lambda_{11}p(w_1)\\left[\\textcolor{blue}{1 - p(\\mathcal{R}_2\\vert w_1)}\\right] + \\lambda_{12}[\\textcolor{blue}{1-p(w_1)}]p(\\mathcal{R}_1\\vert w_2) + \\lambda_{21}p(w_1)p(\\mathcal{R}_2\\vert w_1) + \\lambda_{22}[\\textcolor{blue}{1-p(w_1)}]\\left[\\textcolor{blue}{1-p(\\mathcal{R}_1\\vert w_2)}\\right]\\\\  &amp;= \\textcolor{green}{\\lambda_{22} + (\\lambda_{12}-\\lambda_{22})p(\\mathcal{R}_1\\vert w_2)} + \\textcolor{red}{p(w_1)}\\textcolor{blue}{[ \\lambda_{11}-\\lambda_{22} + (\\lambda_{21}-\\lambda_{11})p(\\mathcal{R}_2\\vert w_1)+ (\\lambda_{22} -\\lambda_{12})p(\\mathcal{R}_1\\vert w_2)  ]}\\\\  &amp;= \\textcolor{green}{A} + \\textcolor{red}{p(w_1)}\\textcolor{blue}{B}\\end{aligned} \\tag{7}\\]在已知类概率密度函数 $p(x\\vert w_j)$ 的前提下，一旦 $\\mathcal{R}_1,\\mathcal{R}_2$ 确定，误判的期望风险是先验概率 $p(w_1)$ 的线性函数，此时不难计算出期望风险的上下界（一定在直线与边界的两个交点分别取得）。5.3. 最小化最大期望风险根据我们前述目标，需要最小化前面确定的期望风险的最大值，下面结合图例进行分析  外层循环      考虑到先验概率不确定性，遍历其取值区间 $[0,1]$，对于第 $i$ 个具体的取值，可以按照最小风险贝叶斯决策的原理设计出最佳的决策域 $\\mathcal{R}_1,\\mathcal{R}_2$，同时计算出此时的期望风险为 $R^{\\star}$          内层计算：      对 $p(w_1)$ 的第 $i$ 个具体的取值和对应的 $\\mathcal{R}_1,\\mathcal{R}_2$，考虑 $p(w_1)$ 偏离这个具体取值时的情况。极端情况下，先验概率可能在 $[0,1]$ 区间随意偏离。      前面式 $(8)$ 已知期望风险和先验概率 $p(w_1)$ 呈线性关系，那么根据其取值区间 $[0,1]$，代入式 $(8)$ 容易找到其上界（某个端点），记为 $R^{\\star}_{i\\max}$      比较 $R^{\\star}_{i\\max}$ 和 $R^{\\star}$ 的关系                  如果 $R^{\\star}_{i\\max}&gt;R^{\\star}$ 则表示没有找到最大误判平均风险的极小值（图中蓝线），continue。          若满足，则找到最大误判平均风险的极小值（图中红线），break。                      $i = i+1$ 确定下一个先验概率的具体取值，回到第一步。可以发现，最大的误判期望风险，其极小值情况是最小风险贝叶斯决策域 $\\mathcal{R}_1,\\mathcal{R}_2$ 使得式 $(8)$ 中的系数 $B=0$，此时无论先验概率 $p(w_1)$ 如何变化，期望风险 $R$ 与先验概率无关（因为系数 $B=0$），从而使的期望风险 $R$ 恒等于常数，最大的期望风险值是所有最小风险贝叶斯决策中最小的，对应的最小风险贝叶斯决策称为最小最大贝叶斯决策。6. 参考文献[1] 漆比特. CSDN 机器学习十大经典算法：深入浅出聊贝叶斯决策（贝叶斯公式，最小风险贝叶斯，最小错误贝叶斯）"
  },
  
  {
    "title": "模式识别（线性分类器）",
    "url": "/posts/Pattern-Recognition-Linear-Classifier/",
    "categories": "Academic, Knowledge",
    "tags": "pattern recognition",
    "date": "2024-03-03 14:25:19 +0800",
    





    
    "snippet": "本文介绍了模式识别的线性分类器，包括线性分类器的基础概念、垂直平分准则以及垂直平分分类器、Fisher 投影准则、感知准则、最小错分样本准则、最小平方误差准则、最小二乘估计。  1. 引言  2. 线性分类器基础          2.1. 线性判别函数      2.2. 广义线性判别函数      2.3. 二分类与多分类      2.4. 线性分类器设计的基本思路        3....",
    "content": "本文介绍了模式识别的线性分类器，包括线性分类器的基础概念、垂直平分准则以及垂直平分分类器、Fisher 投影准则、感知准则、最小错分样本准则、最小平方误差准则、最小二乘估计。  1. 引言  2. 线性分类器基础          2.1. 线性判别函数      2.2. 广义线性判别函数      2.3. 二分类与多分类      2.4. 线性分类器设计的基本思路        3. 垂直平分准则          3.1. 设计思路      3.2. 最小距离等价决策      3.3. 特点总结        4. Fisher 投影准则          4.1. 投影      4.2. Fisher 投影        5. 感知准则          5.1. 线性可分性      5.2. 感知准则函数      5.3. 感知器模型        6. 最小错分样本准则          6.1. 最小错分样本准则一      6.2. 最小错分样本准则二      6.3. 特点总结        7. 最小平方误差准则          7.1. 准则定义      7.2. 线性回归与最小二乘估计      7.3. 特点总结        8. 参考文献1. 引言模式识别的目的是在特征空间中设法找到两类（或多类）之间的分界面。一方面，我们可以通过估计样本的概率模型，然后采用贝叶斯决策（最大后验估计）或者最大似然估计的策略来实现分类。但是很多情况下，建立样本的概率模型和准确估计样本的概率密度函数及其他模型参数并不是一件容易的事情。实际上，估计概率密度函数也不是我们的目的。贝叶斯决策的策略分为两步，首先根据样本进行概率密度函数估计，然后再根据估计的概率密度函数求分类面。如果能直接根据样本求分类面，就可以省略对概率密度函数的估计。我们知道，当样本为正态分布且各类协方差矩阵相等的条件下，贝叶斯决策的最优分类面是线性的，二分类问题的判别函数形式为 $g(x) = \\boldsymbol{w}^\\top\\boldsymbol{x} + w_0$。那么如果我们知道判别函数的形式，可以设法从数据中直接估计这种判别函数的参数，这就是基于样本直接进行分类器设计的思想。进一步，即使不知道最优的判别函数是什么形式，仍然可以根据需要或对问题的理解设定判别函数类型，从数据直接求解判别函数。线性分类器是一种基于样本直接设计的分类器。采用不同的准则及不同的寻优算法就得到不同的线性判别方法。2. 线性分类器基础2.1. 线性判别函数模式识别的目的就是在样本特征空间中寻找两类或多类之间的分界面（决策边界），从而实现对不同模式的分类。  【决策面】在样本特征空间中，将不同种类样本区分开的决策边界也叫决策面或分类面。  【判别函数】用数学形式描述决策面的函数就是判别函数。  【超平面】使用线性判别函数描述的决策面是线性的，在低维空间中表现为点、线、面的形式，在高维空间中则称为超平面。  【线性分类器】这样的线性决策面构成的分类器称作线性分类器。注意到，特征空间种的决策面可以是线性的，可以是非线性的。只有采用线性决策面的分类器称作线性分类器。在 $n$ 维特征空间种，特征向量表示为 $\\boldsymbol{x} = [x_1, x_2, \\cdots, x_n]^{\\text{T}}$，则线性判别函数一般形式为\\[g(\\boldsymbol{x}) = \\boldsymbol{w}^{\\text{T}}\\boldsymbol{x} + w_0 = w_1x_1 + w_2x_2 + \\cdots + w_nx_n + w_0\\]其中 $w_0$ 为阈值权，$w_1, w_2, \\cdots, w_n$ 为加权因子。在二分类问题中，分别用 $\\omega_1$ 和 $\\omega_2$ 表示两类，采用上述线性判别函数进行分类，对应的判别规则为\\[\\begin{cases}\\boldsymbol{x}\\in\\omega_1 &amp; g(\\boldsymbol{x}) &gt; 0 \\\\\\boldsymbol{x}\\in\\omega_2 &amp; g(\\boldsymbol{x}) &lt; 0\\end{cases}\\]决策面方程为\\(\\boldsymbol{w}^{\\text{T}}\\boldsymbol{x} + w_0 = 0\\)  线性判别函数有如下几个几何性质：      法向量方向为 $\\boldsymbol{w}$设决策面上任意两个点 $\\boldsymbol{x}_1$ 和 $\\boldsymbol{x}_2$，它们满足 $g(\\boldsymbol{x}_1) = g(\\boldsymbol{x}_2) = 0$，两式相减得 $\\boldsymbol{w}^{\\text{T}}(\\boldsymbol{x}_1 - \\boldsymbol{x}_2) = 0$，而$\\boldsymbol{x}_1 - \\boldsymbol{x}_2$ 构成了决策面上的任意向量，因此决策面与 $\\boldsymbol{w}$ 垂直    样本 $\\boldsymbol{x}$ 到决策面的欧氏距离为\\(e=\\frac{\\vert\\boldsymbol{w}^{\\text{T}}\\boldsymbol{x} + w_0\\vert}{\\sqrt{w_1^2 + w_2^2 + \\cdots + w_n^2}}=\\frac{\\vert\\boldsymbol{w}^{\\text{T}}\\boldsymbol{x} + w_0\\vert}{\\Vert \\boldsymbol{w} \\Vert}\\)    原点（一个坐标全 0 的特殊样本点）到决策面的欧氏距离为\\(d=\\frac{\\vert w_0\\vert}{\\sqrt{w_1^2 + w_2^2 + \\cdots + w_n^2}}=\\frac{\\vert w_0\\vert}{\\Vert \\boldsymbol{w} \\Vert}\\)  2.2. 广义线性判别函数上述线性判别函数是一个一般的点/线/超平面，为了简化设计和计算，我们可以将其平移至原点，从而得到广义线性判别函数。首先定义如下增广样本向量 $\\boldsymbol{y}$ 和增广权向量 $\\boldsymbol{a}$\\[\\begin{aligned}\\boldsymbol{y} &amp;= [1, x_1, x_2, \\cdots, x_n]^{\\text{T}}\\\\\\boldsymbol{a} &amp;= [w_0, w_1, w_2, \\cdots, w_n]^{\\text{T}}\\end{aligned}\\]则广义线性判别函数为\\[g(\\boldsymbol{y}) = \\boldsymbol{a}^{\\text{T}}\\boldsymbol{y} = w_0 + w_1x_1 + w_2x_2 + \\cdots + w_nx_n\\]对应的决策面为\\[\\boldsymbol{a}^{\\text{T}}\\boldsymbol{y} = 0\\]$g(\\boldsymbol{y})$ 在增广特征向量所在的增广特征空间 $\\boldsymbol{Y}$ 确定了一个过原点的超平面，在设计某些线性分类器时，过原点的超平面便于求解和计算。增广的 $\\boldsymbol{Y}$ 特征空间比原始的 $x\\boldsymbol{X}$ 特征空间维数增加了一维，但样本间的欧氏距离保持不变，且不影响分类器的优化设计。2.3. 二分类与多分类分类问题是模式识别的基本问题。多类分类问题可以通过两种典型做法分解成若干个二分类问题，这样就可以通过组合多个二分类器、采用多个线性判别函数进行分类：  一对其余，在训练时依次把某个类别的样本归为一类，其他剩余的样本归为另一类，也就是把多类样本转化为类与“类的非”这两类。  一对一，对多个类别中每两个类别进行分类。2.4. 线性分类器设计的基本思路  给定类别已知的样本——训练样本集  选择一个准则函数 $J$，其值反映分类器性能（分类结果优劣）  采用求最优解的数学方法求准则函数 $J$ 的极值解，从而求得权向量 $w$ 和阈值权 $w_0$ ，或增广权向量 $a$3. 垂直平分准则3.1. 设计思路如图，在二维特征向量的二分类问题（$C=2，D=2$）中，垂直平分分类器设计思路是基于两类样本均值点作垂直平分线。根据垂直平分的特性求解其权向量和阈值权的方法如下：      利用垂直关系，即分类面与两类均值连线垂直，可计算得到权向量 $\\boldsymbol{w}$（参考前面线性判别函数的几何性质）\\[\\boldsymbol{w} = \\boldsymbol{m}_1 - \\boldsymbol{m}_2\\]    则线性判别函数为\\[g(\\boldsymbol{x}) = \\boldsymbol{w}^{\\text{T}}\\boldsymbol{x} + w_0 = (\\boldsymbol{m}_1 - \\boldsymbol{m}_2)^{\\text{T}}\\boldsymbol{x} + w_0\\]        利用分类面垂直平分两类均值连线，即两类均值的连线的中点在分类面上，可计算得到阈值权 $w_0$    均值连线的中点为\\[\\boldsymbol{x}_0 = \\frac{\\boldsymbol{m}_1 + \\boldsymbol{m}_2}{2}\\]    代入决策面方程 $g(\\boldsymbol{x})=0$ 可求得\\[w_0 = -\\frac{1}{2}(\\boldsymbol{m}_1 - \\boldsymbol{m}_2)^{\\text{T}}(\\boldsymbol{m}_1 + \\boldsymbol{m}_2)\\]  最终得到线性判别函数为\\[g(\\boldsymbol{x}) = (\\boldsymbol{m}_1 - \\boldsymbol{m}_2)^{\\text{T}}\\boldsymbol{x} - \\frac{1}{2}(\\boldsymbol{m}_1 - \\boldsymbol{m}_2)^{\\text{T}}(\\boldsymbol{m}_1 + \\boldsymbol{m}_2)\\]决策面方程为\\[g(\\boldsymbol{x}) = 0\\]垂直平分决策规则为\\[\\begin{cases}\\boldsymbol{x}\\in\\omega_1 &amp; g(\\boldsymbol{x}) &gt; 0 \\\\\\boldsymbol{x}\\in\\omega_2 &amp; g(\\boldsymbol{x}) &lt; 0\\end{cases}\\]推广到多维特征向量的二分类问题（$C=2，D&gt;2$）时上述形式保持不变。3.2. 最小距离等价决策上述的垂直平分决策规则，等价于最小距离等价决策（最小距离分类法），即每个样本到两类均值连线的距离最小的类被判定为该样本所属的类。定义判别函数为欧氏距离，即\\[\\begin{aligned}g_1(\\boldsymbol{x}) &amp;= d_1(x) = \\Vert \\boldsymbol{x} - \\boldsymbol{m}_1 \\Vert =  \\sqrt{(\\boldsymbol{m}_1 - \\boldsymbol{x})^{\\text{T}}(\\boldsymbol{m}_1 - \\boldsymbol{x})} \\\\g_2(\\boldsymbol{x}) &amp;= d_2(x) = \\Vert \\boldsymbol{x} - \\boldsymbol{m}_2 \\Vert =  \\sqrt{(\\boldsymbol{m}_2 - \\boldsymbol{x})^{\\text{T}}(\\boldsymbol{m}_2 - \\boldsymbol{x})}\\end{aligned}\\]那么垂直平分分类器等价的最小距离决策规则为\\[\\begin{cases}\\boldsymbol{x}\\in\\omega_1 &amp; g_1(\\boldsymbol{x}) &lt; g_2(\\boldsymbol{x}) \\\\\\boldsymbol{x}\\in\\omega_2 &amp; g_1(\\boldsymbol{x}) &gt; g_2(\\boldsymbol{x})\\end{cases}\\]3.3. 特点总结垂直平分分类器（最小距离分类器）的主要特点如下：  解决二分类问题的线性分类器  原则上对样本集无特殊要求  未采用准则函数求极值解（非最佳决策）  算法最简单，分类器设计最容易4. Fisher 投影准则Fisher 投影准则的提出有以下两方面的原因：  垂直平分分类器在面对一些样本分布情况时效果不佳（其本身是一个非最佳分类器），如下图左所示；更好的分类器如下图右所示；  如果分类时所用的特征个数太多，将形成高维特征空间，高维空间不论对分类器的理论设计还是分类器的实际运用，都会带来“灾难性”后果。特征个数越多，计算量就越大，导致分类器设计困难和分类困难。因此我们可以考虑把所有样本都投影到一个方向上，然后在这个一维空间中确定一个分类的阈值。过这个阈值点且与投影方向垂直的超平面就是两类的分类面。原始的高维空间上的分类问题被转换为一维空间上的分类问题。在不同方向上投影后，样本在一维坐标轴上的分布不同，有的适合分类，有的不适合分类。因此一维坐标轴的方向不是随意的，需进行优化求解。我们可以从下图中看出，不同的投影方向会使得两类样本的影响该方向的分类结果，左图的投影方向可以使得两类样本较好分开，而按照右图的方向投影后则两类样本混在一起。Fisher投影准则所要解决的问题就是，如何根据样本集情况，求解最佳的（最易于分类的）投影线方向。Fisher 线性判别的思想就是，选择合适的投影方向，使得投影后两类的间隔尽可能远，同时每一类内部的样本又尽可能聚集。如下图所示。4.1. 投影假设二维空间的一个特征向量 $\\boldsymbol{x}$，某个投影方向向量为 $\\boldsymbol{w}$。假设 $\\vert \\boldsymbol{w} \\vert = 1$（因为只关心投影的方向，不关心长度），那么投影向量为\\[\\frac{\\boldsymbol{w}^\\top\\cdot \\boldsymbol{x}}{\\vert \\boldsymbol{w} \\vert} = \\boldsymbol{w}^\\top\\boldsymbol{x}\\]4.2. Fisher 投影假设两类样本集，其中第 $w_i$ 类样本集为\\[\\mathcal{X}_i=[\\boldsymbol{x}_1^i,\\cdots, x_{N_i}^i]\\in \\mathbb{R}^{d\\times N_i}\\]即特征维度为 $d$，样本个数为 $N_i$。投影前，原始特征空间中第 $w_i$ 类样本的均值为\\[\\boldsymbol{m}_i=\\frac{1}{N_i}\\sum_{\\boldsymbol{x}_j\\in \\mathcal{X}_i}\\boldsymbol{x}_j, \\quad i=1,2\\]为了度量两类的间隔和每一类内部的聚集程度，可以定义各类的类内离散度矩阵（within-class scatter matrix）为\\[\\boldsymbol{S}_i=\\sum_{\\boldsymbol{x}_j\\in \\mathcal{X}_i}(\\boldsymbol{x}_j-\\boldsymbol{m}_i)(\\boldsymbol{x}_j-\\boldsymbol{m}_i)^\\top \\in \\mathbb{R}^{d\\times d},\\quad i=1,2\\]那么总类内离散度矩阵（pooled within-class scatter matrix）为\\[\\boldsymbol{S}_w = \\boldsymbol{S}_1+\\boldsymbol{S}_2\\]类间离散度矩阵（between-class scatter matrix）为\\[\\boldsymbol{S}_b = (\\boldsymbol{m}_1-\\boldsymbol{m}_2)(\\boldsymbol{m}_1-\\boldsymbol{m}_2)^\\top \\in \\mathbb{R}^{d\\times d}\\]将所有样本投影到一维空间，根据前一节的投影公式，投影后的特征向量为\\[y = \\boldsymbol{w}^\\top\\boldsymbol{x}\\]投影后两类的均值（标量）分别为\\[\\tilde{m}_i = \\frac{1}{N_i}\\sum_{y_j\\in \\mathcal{Y}_i}y_j=\\frac{1}{N_i}\\sum_{x_j\\in \\mathcal{X}_i}\\boldsymbol{w}^\\top\\boldsymbol{x}_i = \\boldsymbol{w}^\\top\\boldsymbol{m}_i, \\quad i=1,2\\]投影后的类内离散度和总类内离散度分别为\\[\\begin{aligned}\\tilde{S}_i &amp;= \\sum_{y_j\\in \\mathcal{Y}_i}(y_j-\\tilde{m}_i)^2\\\\\\tilde{S}_w &amp;= \\tilde{S}_1+\\tilde{S}_2\\\\\\end{aligned}\\]投影后的类间离散度为\\[\\tilde{S}_b = (\\tilde{m}_1-\\tilde{m}_2)^2\\]根据前述 Fisher 投影准则的优化目标（即选择合适的投影方向，使得投影后类间离散度 $S_b$ 尽可能大，同时总类内离散度 $S_w$ 尽可能小）可以写出如下分式形式的优化目标函数：\\[J(\\boldsymbol{w}) = \\frac{\\tilde{S}_b}{\\tilde{S}_w}=\\frac{(\\tilde{m}_1-\\tilde{m}_2)^2}{\\tilde{S}_1+\\tilde{S}_2}\\]为了寻找最优投影方向 $\\boldsymbol{w}$，需要将优化目标函数进行改写。由于\\[\\begin{aligned}\\tilde{S}_b &amp;= (\\tilde{m}_1-\\tilde{m}_2)^2 \\\\&amp;= (\\boldsymbol{w}^\\top\\boldsymbol{m}_1-\\boldsymbol{w}^\\top\\boldsymbol{m}_2)(\\boldsymbol{w}^\\top\\boldsymbol{m}_1-\\boldsymbol{w}^\\top\\boldsymbol{m}_2)^\\top\\\\&amp;= \\boldsymbol{w}^\\top(\\boldsymbol{m}_1-\\boldsymbol{m}_2)(\\boldsymbol{m}_1-\\boldsymbol{m}_2)^\\top\\boldsymbol{w}\\\\&amp;= \\boldsymbol{w}^\\top\\boldsymbol{S}_b\\boldsymbol{w}\\end{aligned}\\]而\\[\\begin{aligned}  \\tilde{S}_w &amp;= \\tilde{S}_1+\\tilde{S}_2\\\\  &amp;=\\sum_{y_1\\in \\mathcal{Y}_1}(y_1-\\tilde{m}_1)^2+\\sum_{y_2\\in \\mathcal{Y}_2}(y_2-\\tilde{m}_2)^2\\\\  &amp;=\\sum_{x_1\\in \\mathcal{X}_1}(\\boldsymbol{w}^\\top\\boldsymbol{x}_1-\\boldsymbol{w}^\\top\\boldsymbol{m}_1)^2+\\sum_{x_2\\in \\mathcal{X}_2}(\\boldsymbol{w}^\\top\\boldsymbol{x}_2-\\boldsymbol{w}^\\top\\boldsymbol{m}_2)^2\\\\  &amp;=\\boldsymbol{w}^\\top[\\sum_{x_1\\in \\mathcal{X}_1}(\\boldsymbol{x}_1-\\boldsymbol{m}_1)(\\boldsymbol{x}_1-\\boldsymbol{m}_1)^\\top+\\sum_{x_2\\in \\mathcal{X}_2}(\\boldsymbol{x}_2-\\boldsymbol{m}_2)(\\boldsymbol{x}_2-\\boldsymbol{m}_2)^\\top]\\boldsymbol{w}\\\\  &amp;= \\boldsymbol{w}^\\top(\\boldsymbol{S}_1+\\boldsymbol{S}_2)\\boldsymbol{w}\\\\  &amp;= \\boldsymbol{w}^\\top\\boldsymbol{S}_w\\boldsymbol{w}\\end{aligned}\\]那么优化目标函数可以写成\\[J(\\boldsymbol{w}) = \\frac{\\boldsymbol{w}^\\top\\boldsymbol{S}_b\\boldsymbol{w}}{\\boldsymbol{w}^\\top\\boldsymbol{S}_w\\boldsymbol{w}}\\]上式被称为广义瑞利（Rayleigh）商。从优化目标来看，如果直接对上式（分子分母都是二次型）进行优化，有无穷个满足要求的解。为了解决多解问题，我们需要额外增加一个约束条件，限制解的个数。由于我们只关心投影的方向，对投影方向向量的模长不关心，并且上式分子分母的向量 $\\boldsymbol{w}$ 数乘缩放不影响比值。  在我们求导之前，需要对分母进行归一化，因为不做归一的话，$\\boldsymbol{w}$ 扩大任何倍，都成立，我们就无法确定 $\\boldsymbol{w}$。这里 $\\boldsymbol{w}$ 并不是唯一的，倘若 $\\boldsymbol{w}$ 对应 $J(\\boldsymbol{w})$ 的极大值点，则 $a\\cdot \\boldsymbol{w}$ 仍旧可以达到 $J(\\boldsymbol{w})$ 的极大值点。因此将优化问题更改如下\\[\\begin{aligned}\\max &amp;\\; \\boldsymbol{w}^\\top\\boldsymbol{S}_b\\boldsymbol{w}\\\\s.t. &amp;\\; \\boldsymbol{w}^\\top\\boldsymbol{S}_w\\boldsymbol{w}=c\\neq 0\\end{aligned}\\]通过额外引入一个使得分子等于常数的等式约束来限制 $\\boldsymbol{w}$ 的取值，然后通过拉格朗日乘子法求解极大值，定义拉格朗日函数如下\\[\\begin{aligned}L(\\boldsymbol{w},\\lambda) &amp;= \\boldsymbol{w}^\\top\\boldsymbol{S}_b\\boldsymbol{w} - \\lambda (\\boldsymbol{w}^\\top\\boldsymbol{S}_w\\boldsymbol{w}-c)\\\\\\Rightarrow \\frac{\\partial L(\\boldsymbol{w},\\lambda)}{\\partial \\boldsymbol{w}} &amp;= 2\\boldsymbol{S}_b\\boldsymbol{w} - 2\\lambda \\boldsymbol{S}_w\\boldsymbol{w}\\\\\\end{aligned}\\]  《the Matrix Cookbook》二次型的导数\\[\\frac{\\partial \\boldsymbol{x}^\\top\\boldsymbol{B\\boldsymbol{x}}}{\\partial \\boldsymbol{x}} = (\\boldsymbol{B}+\\boldsymbol{B}^\\top)\\boldsymbol{x} \\tag{81}\\]  而类间方差矩阵根据其定义，满足 $\\boldsymbol{S}_b = \\boldsymbol{S}_b^\\top$，此时有\\[\\frac{\\partial \\boldsymbol{x}^\\top\\boldsymbol{B\\boldsymbol{x}}}{\\partial \\boldsymbol{x}} = 2\\boldsymbol{B}\\boldsymbol{x}\\]令上式等于零，取到极大值 $\\boldsymbol{w}^{\\star}$，即\\[\\boldsymbol{S}_b\\boldsymbol{w}^{\\star} = \\lambda \\boldsymbol{S}_w\\boldsymbol{w}^{\\star}\\]当样本数大于特征维度时，$\\boldsymbol{S}_w$ 通常是非奇异矩阵，可求逆，因此有\\[\\lambda \\boldsymbol{w}^{\\star} = \\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b\\boldsymbol{w}^{\\star}\\]即上述最优化问题转化为求矩阵 $\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b$ 的特征值 $\\lambda$ 和特征向量 $\\boldsymbol{w}^{\\star}$。对于二分类 LDA 问题，最佳投影方向是矩阵 $\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b$ 的最大特征值对应的特征向量。对于多分类 LDA 问题，最佳投影矩阵的列是 $\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b$ 的前 $d$ 个最大特征值对应的特征向量。需要注意的是，Fisher 投影的最优解本身只给出了一个投影方向，并没有给出我们需要的分类面。要得到分类面，需要再投影后的方向（一维空间）上确定一个分类阈值 $w_0$ 并采取决策规则\\[\\begin{aligned}g(\\boldsymbol{x})=\\boldsymbol{w}^\\top\\boldsymbol{x} + w_0 &gt; 0 \\Rightarrow \\boldsymbol{x}\\in y_1 \\\\g(\\boldsymbol{x})=\\boldsymbol{w}^\\top\\boldsymbol{x} + w_0 &lt; 0 \\Rightarrow \\boldsymbol{x}\\in y_2\\end{aligned}\\]  这里给出另外一种推导思路，上述目标函数正好是广义瑞利商的形式，因此其最大值为 $\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b$ 的最大特征值，那么投影方向 $\\boldsymbol{w}$ 即为 $\\boldsymbol{S}_w^{-1}\\boldsymbol{S}_b$ 对应最大特征值 $\\lambda$ 的特征向量。5. 感知准则5.1. 线性可分性前面介绍垂直平分准则和 Fisher 投影准则中，我们并没有对样本集进行任何要求。实际上，样本集是否线性可分是一个有必要讨论的问题，因此有了感知准则。样本集的线性可分性指的是，至少存在一个权向量（即决策面），能将样本集中的每个样本都正确分类，否则就是线性不可分的。  规范化可设想，在二分类问题中，假设样本线性可分，将属于 $\\omega_2$ 类的样本各分量同时乘以 $-1$，这个过程称为线性可分样本集的规范化。规范化以后，样本集所有样本均满足 $\\boldsymbol{a}^{\\text{T}}\\boldsymbol{y}&gt;0$，这本质上是一个有约束的优化问题，可采取一些方法求出最优的解向量 $\\boldsymbol{a}^*$。  解区更进一步，在增广样本空间的基础上，我们定义如下：  解向量：能将线性可分样本集中的每个样本都正确分类的权向量 $\\boldsymbol{a}$。  解区：解向量往往不是一个，而是由无穷多个解向量组成的（角度）区域，称为解区。在二维二分类问题中，解区（$\\boldsymbol{a}^{\\text{T}}\\boldsymbol{y}&gt;0$）如下图蓝色部分所示。  余量解区中任意一个向量都是解向量，都能把样本正确分开。但如果一个解向量靠近解区的边缘，某些样本的判别函数可能刚刚大于零。考虑到噪声、计算误差等，靠近解区中间的解向量更加可靠。因此，提出余量概念，即把解区向中间缩小，不取靠近边缘的解，引入余量b，解向量满足\\[\\boldsymbol{a}^{\\text{T}}\\boldsymbol{y}_i&gt;b, \\quad i=1,2,\\cdots,n\\]如下图所示。5.2. 感知准则函数对于规范化的增广样本集，感知准则函数可以选取为：\\[J_p(\\boldsymbol{a}) = \\sum_{y\\in{Y_e}}(-\\boldsymbol{a}^{\\text{T}}y)\\]其中\\[Y_e: \\{\\boldsymbol{y}\\in Y_e | \\boldsymbol{a}^{\\text{T}}\\boldsymbol{y}&lt;0\\}\\]表示样本集中被权向量 $\\boldsymbol{a}$ 错分的样本集合。对于规范化增广样本集，若权向量 $a$ 使样本集中的样本 $\\boldsymbol{y}$ 错误分类，则 $\\boldsymbol{a}^{\\text{T}}\\boldsymbol{y}&lt;0$ 或 $-\\boldsymbol{a}^{\\text{T}}\\boldsymbol{y}\\geq 0$。所以 $J_p(\\boldsymbol{a}) \\geq 0$。对于感知准则函数 $J_p(\\boldsymbol{a})$，其最小值对应着最优解 $\\boldsymbol{a}^*$。由此可以得到梯度下降法迭代公式\\[\\begin{aligned}\\Delta J_p(\\boldsymbol{a}) &amp;= \\frac{\\partial J_p(\\boldsymbol{a})}{\\partial\\boldsymbol{a}} = -\\sum_{\\boldsymbol{y}\\in{Y_e}}\\boldsymbol{y}\\\\\\Rightarrow \\boldsymbol{a} &amp;= \\boldsymbol{a} - \\alpha\\Delta J_p(\\boldsymbol{a})=\\boldsymbol{a}+\\beta\\sum_{\\boldsymbol{y}\\in{Y_e}}\\boldsymbol{y}\\end{aligned}\\]5.3. 感知器模型感知器是一个具有单层计算单元的神经元模型，感知器具有多输入和单输出。（如上图和下式所示）\\[y = f(\\boldsymbol{w}^{\\text{T}}\\boldsymbol{x} - \\theta)\\]如果该神经元没有内部状态的转变，且 $f$ 为一个阶跃函数，其输出表达式为\\[y = f(\\boldsymbol{w}^{\\text{T}}\\boldsymbol{x} - \\theta) = \\begin{cases} 1, &amp; \\boldsymbol{w}^{\\text{T}}\\boldsymbol{x} - \\theta &gt; 0 \\\\ -1, &amp; \\text{otherwise} \\end{cases}\\]权值向量 $\\boldsymbol{w}$ 和阈值 $\\theta$ 为感知器的参数，可以通过梯度下降法进行训练。当感知器用于两类模式的分类时，相当于在高维样本的特征空间中，用一个超平面把两类样本区分开，如果两类模式是线性可分的，则算法一定收敛。6. 最小错分样本准则感知准则函数只适用于线性可分的情况。对于样本集线性不可分的情况，算法不收敛，即 $\\boldsymbol{a}^{\\text{T}}\\boldsymbol{y}&gt;0\\;(i=1,2,\\cdots, n)$ 是矛盾不等式组，只能求满足不等式个数最多的解，或者最小错分样本数的解。对于线性不可分情况，定义一个准则函数，其极值解对应两类样本集中错分数最少的权向量 $𝑎^*$，这种准则称为最小错分样本数准则。最后，采用梯度下降法等优化算法可完成求解。6.1. 最小错分样本准则一将 $n$ 个不等式 $\\boldsymbol{a}^{\\text{T}}\\boldsymbol{y}&gt;0\\;(i=1,2,\\cdots, n)$ 联立，并引入余量 $\\boldsymbol{b}=[b_1,b_2,\\cdots,b_n]^{\\text{T}}$，可得\\[\\boldsymbol{Y}\\boldsymbol{a}-\\boldsymbol{b} &gt; 0\\]其中余量可取值为 $\\boldsymbol{b}=[1,1,\\cdots,1]^{\\text{T}}$。设计如下最小错分样本准则\\[J_{q_1}(\\boldsymbol{a}) = \\Vert (\\boldsymbol{Y}\\boldsymbol{a}-\\boldsymbol{b})-\\vert (\\boldsymbol{Y}\\boldsymbol{a}-\\boldsymbol{b}) \\vert \\Vert^2\\]  如果样本被正确分类，则 $(\\boldsymbol{Y}\\boldsymbol{a}-\\boldsymbol{b})$ 与 $\\vert (\\boldsymbol{Y}\\boldsymbol{a}-\\boldsymbol{b}) \\vert$ 同号，有 $J_{q_1}(\\boldsymbol{a})=0$。  反之，如果样本被错误分类，则异号，有 $J_{q_1}(\\boldsymbol{a})&gt;0$。不满足的样本（即错分的样本）越多，$J_{q_1}(\\boldsymbol{a})$ 越大。$J_{q_1}(\\boldsymbol{a})$ 取极小值时的权向量 $\\boldsymbol{a}$ 就为最优解 $\\boldsymbol{a}^*$ 。6.2. 最小错分样本准则二\\[J_{q_1}(\\boldsymbol{a})=\\sum_{i=1}^n\\frac{1+\\text{sign}(y_i^\\top \\boldsymbol{a})}{2}\\]  如果样本被正确分类，则 $\\text{sign}(y_i^\\top \\boldsymbol{a})=+1$，对应的项为正。  反之，如果样本被错误分类，$\\text{sign}(y_i^\\top \\boldsymbol{a})=-1$，对应的项为 0。因此，正确分类越多，$J_{q_1}(\\boldsymbol{a})$ 越大，$J_{q_1}(\\boldsymbol{a})$ 取极大值求得最优解。6.3. 特点总结  解决两类问题的线性分类器  样本集不限，可以是线性不可分的  求满足不等式个数最多的权向量（最优）  分类器设计过程复杂7. 最小平方误差准则7.1. 准则定义对于线性不可分情况，定义一个准则函数，其极值解对应两类样本集中错分误差平方和最小的权向量 $\\boldsymbol{a}^*$，这种准则称为最小平方误差准则。最小平方误差准则与最小错分样本准则相同，都可以用于样本线性可分和线性不可分的情况。但最小平方误差准则的极值解对应两类样本集中错分误差平方和最小的权向量 $\\boldsymbol{a}^*$，是工程中常用的优化准则。将 $n$ 个不等式 $\\boldsymbol{a}^{\\text{T}}\\boldsymbol{y}&gt;0\\;(i=1,2,\\cdots, n)$ 联立，并引入余量 $\\boldsymbol{b}=[b_1,b_2,\\cdots,b_n]^{\\text{T}}$，可得\\[\\boldsymbol{Y}\\boldsymbol{a}-\\boldsymbol{b} &gt; 0\\]联立线性方程组，并简写为矩阵形式\\[\\begin{aligned}\\boldsymbol{Y}\\boldsymbol{a}&amp;=\\boldsymbol{b}\\\\\\text{where} \\quad \\boldsymbol{Y}&amp;=\\left(\\begin{array}{c}y_{1}^{\\mathrm{T}} \\\\y_{2}^{\\mathrm{T}} \\\\\\vdots \\\\y_{n}^{\\mathrm{T}}\\end{array}\\right)=\\left(\\begin{array}{cccc}y_{11} &amp; y_{12} &amp; \\cdots &amp; y_{1 d} \\\\\\vdots &amp; &amp; &amp; \\\\y_{n 1} &amp; y_{n 2} &amp; \\cdots &amp; y_{n d}\\end{array}\\right)\\end{aligned}\\]前述已知上式是矛盾方程组，这里采用最小二乘法求解。首先定义误差 $\\boldsymbol{e} = \\boldsymbol{Y}\\boldsymbol{a}-\\boldsymbol{b}$，则平方误差准则函数为\\[J_s(\\boldsymbol{a}) = \\Vert \\boldsymbol{e} \\Vert^2 = \\Vert \\boldsymbol{Y}\\boldsymbol{a} - \\boldsymbol{b} \\Vert^2\\\\\\]根据最小二乘法，最优权向量为\\[\\boldsymbol{a}^{\\star} = (\\boldsymbol{Y}^\\top\\boldsymbol{Y})^{-1}\\boldsymbol{Y}^\\top\\boldsymbol{b}\\]注意，最优权向量的求取与余量 $\\boldsymbol{b}$ 的选择有关。7.2. 线性回归与最小二乘估计多元线性回归是通过 $(\\boldsymbol{x},y), \\boldsymbol{x}\\in \\mathbb{R}^d, y\\in \\mathbb{R}$ 的一系列观测样本，估计他们之间的线性关系\\[y=w_0+w_1x_1+w_2x_2+\\cdots+w_dx_d = \\sum_{i=0}^d w_ix_i = \\boldsymbol{w}^\\top\\boldsymbol{x}\\]其中， $\\boldsymbol{w} = [w_0, w_1, \\cdots, w_d]^\\top$ 是待定参数。从机器学习第角度分析线性回归估计，就是用训练样本集估计模型中第参数，使得模型在最小平方误差意义下能够最好地拟合训练样本。即\\[\\begin{aligned}\\text{sample batch:}\\quad &amp; {(\\boldsymbol{x}_1, y_1),\\cdots, (\\boldsymbol{x}_N, y_N)}\\\\\\text{regression model:}\\quad &amp; f(\\boldsymbol{x}) = w_0+w_1x_1+w_2x_2+\\cdots+w_dx_d = \\sum_{i=0}^d w_ix_i = \\boldsymbol{w}^\\top\\boldsymbol{x}\\\\\\text{MSE loss function:}\\quad &amp; \\min_{\\boldsymbol{w}} L = \\frac{1}{N}\\sum_{j=1}^N(f(\\boldsymbol{x}_j)-y_j)^2\\end{aligned}\\]目标函数可以写成以下矩阵形式（忽略系数因为其不影响最优方向）\\[\\begin{aligned}L(\\boldsymbol{w}) &amp;= \\sum_{j=1}^N(f(\\boldsymbol{x}_j)-y_j)^2\\\\&amp;=\\Vert \\boldsymbol{X}\\boldsymbol{w}-\\boldsymbol{y} \\Vert^2\\\\&amp;=( \\boldsymbol{X}\\boldsymbol{w}-\\boldsymbol{y} )^\\top ( \\boldsymbol{X}\\boldsymbol{w}-\\boldsymbol{y} )\\end{aligned}\\]其中 $\\boldsymbol{X}=[\\boldsymbol{x}_1^\\top, \\cdots, \\boldsymbol{x}_N^\\top]^\\top\\in \\mathbb{R}^{d\\times N}$ 是全部训练样本的特征变量组成的矩阵，$\\boldsymbol{y}=[y_1, \\cdots, y_N]^\\top$ 是全部训练样本的观测变量（分类标签）组成的向量。展开后得到二次型\\[L(\\boldsymbol{w}) = \\boldsymbol{y}^\\top \\boldsymbol{y} - 2 \\boldsymbol{y}^\\top \\boldsymbol{X} \\boldsymbol{w} + \\boldsymbol{w}^\\top \\boldsymbol{X}^\\top \\boldsymbol{X} \\boldsymbol{w}\\]使得上述目标函数最小化的参数 $\\boldsymbol{w}$ 应满足\\[\\frac{\\partial{L(\\boldsymbol{w})}}{\\partial{\\boldsymbol{w}}} = 0\\]  第一项：与 $\\boldsymbol{w}$ 无关，求导后为 $0$；第二项：\\[\\frac{\\partial}{\\partial{\\boldsymbol{w}}}(- 2 \\boldsymbol{y}^\\top \\boldsymbol{X} \\boldsymbol{w}) = - 2 \\boldsymbol{X}^\\top \\boldsymbol{y}\\\\\\]  第三项：令 $\\boldsymbol{B} = \\boldsymbol{X}^\\top\\boldsymbol{X}$，参考《the Matrix Cookbook》二次型的导数\\[\\frac{\\partial \\boldsymbol{x}^\\top\\boldsymbol{B\\boldsymbol{x}}}{\\partial \\boldsymbol{x}} = (\\boldsymbol{B}+\\boldsymbol{B}^\\top)\\boldsymbol{x} \\tag{81}\\]  若 $\\boldsymbol{B}$ 满足 $\\boldsymbol{B} = \\boldsymbol{B}^\\top$，此时有\\[\\frac{\\partial \\boldsymbol{x}^\\top\\boldsymbol{B\\boldsymbol{x}}}{\\partial \\boldsymbol{x}} = 2\\boldsymbol{B}\\boldsymbol{x}\\]那么有\\[\\begin{aligned}&amp;-2 \\boldsymbol{X}^\\top\\boldsymbol{y} + 2 \\boldsymbol{X}^\\top \\boldsymbol{X} \\boldsymbol{w}=0\\\\&amp;\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{w}=\\boldsymbol{X}^\\top\\boldsymbol{y} \\end{aligned}\\]当 $\\boldsymbol{X}^\\top\\boldsymbol{X}$ 可逆时（这在大多数实际应用中是成立的），最优参数的解为\\[\\boldsymbol{w}^{\\star}=(\\boldsymbol{X}^\\top\\boldsymbol{X})^{-1}\\boldsymbol{X}^\\top\\boldsymbol{y}\\]该方法就是经典的 〖最小二乘法〗 线性回归，其中的矩阵 $(\\boldsymbol{X}^\\top\\boldsymbol{X})^{-1}\\boldsymbol{X}^\\top$ 被称作 $\\boldsymbol{X}$ 的伪逆矩阵（加号逆），记作 $\\boldsymbol{X}^+$。采用上述算法，加入真实的样本是服从之前给出的线性关系的物理规律产生的，只是在观测中带有噪声或误差，则最小二乘线性回归就通过数据学习到了系统本来的模型，而在我们对数据背后的物理模型并不了解的情况下，线性回归给出了在最小平方误差意义下对解释变量与观测变量之间线性关系的最好估计。7.3. 特点总结  解决两类问题的线性分类器  样本集不限，可以是线性不可分的  求最小平方误差的权向量（最优）  分类器设计过程相对简单8. 参考文献[1] 漆比特. CSDN 机器学习十大经典算法：深入浅出聊贝叶斯决策（贝叶斯公式，最小风险贝叶斯，最小错误贝叶斯）"
  },
  
  {
    "title": "强化学习（策略梯度法）",
    "url": "/posts/reinforcement-learning-Policy-Gradient/",
    "categories": "Academic, Knowledge",
    "tags": "reinforcement learning",
    "date": "2023-11-27 16:43:19 +0800",
    





    
    "snippet": "本文介绍了强化学习的策略梯度法（Policy Gradient）。  1. 回顾基于价值的强化学习  2. 策略梯度          2.1. 策略函数      2.2. 策略函数的分布形式      2.3. 策略梯度                  2.3.1. 回顾价值梯度          2.3.2. 策略梯度                      3. 策略梯度的计算 ...",
    "content": "本文介绍了强化学习的策略梯度法（Policy Gradient）。  1. 回顾基于价值的强化学习  2. 策略梯度          2.1. 策略函数      2.2. 策略函数的分布形式      2.3. 策略梯度                  2.3.1. 回顾价值梯度          2.3.2. 策略梯度                      3. 策略梯度的计算          3.1. 基于累计奖励的策略梯度      3.2. 基于初始状态价值的策略梯度      3.3. 策略梯度定理        4. 基于策略梯度的参数更新          4.1. REINFORCE      4.2. REINFORCE with baseline      4.3. Actor-Critic (related to V)      4.4. Actor-Critic (related to Q)      4.5. Advantage Actor-Critic (A2C)                  4.5.1. 探索与利用          4.5.2. 与 VAC 的关系                    4.6. 重要性采样                  4.6.1. 重要性用于期望估计          4.6.2. 重要性用于策略梯度                      5. 确定性策略梯度（DPG）  6. 参考文献1. 回顾基于价值的强化学习基于价值函数的强化学习方法  动态规划方法（Dynamic Programming, DP）  蒙特卡洛方法（Monte Carlo, MC）  时序差分方法（Temporal-Difference, TD）这三种方法存在共同特点：  在求解强化学习任务时，最终目标是求解满足规则的最优策略 $\\pi$。但以上三种方法并 没有直接求解 策略 $\\pi$ 这个变量，而是先计算状态价值函数 $v_\\pi(s)$ 或状态-动作价值函数 $q_\\pi(s,a)$；然后再基于价值函数结果改进策略 $\\pi$，是一种间接方式;  在策略改进过程中，本质上均选择最优价值函数对应的动作作为新的策略；  均为表格式强化学习的代表方法。特别地，对于 DQN 方法，神经网络的输入是原始的状态信息，如游戏画面，输出是在这种状态下执行各种动作的回报，即价值函数（Q函数）。训练完成之后，神经网络逼近的是最优 $q(s,a)$。          +----+ ----&gt; Q(s,a1)                       +----+  s  ---&gt; |f(x)| ----&gt; Q(s,a2)       or     s,ai ---&gt;|f(x)| ----&gt; Q(s,ai)          +----+ ----&gt; Q(s,a3)                       +----+以 DQN 为代表的值函数近似方法，虽然在某些问题上取得了成功，但存在以下问题：      无法表示随机策略。某些问题的最优策略是随机策略，需要以不同的概率选择不同的动作。而基于价值的强化学习算法在实现时采用了贪心策略，给定一个状态 ，选择的策略是确定性的，显然无法实现这种按照概率执行各种候选动作的要求。比如石头剪刀布的最优策略是以 (1/3, 1/3, 1/3）的概率来选择石头/剪刀/布，基于价值的强化学习无法实现这种策略。        无法处理高维动作空间。DQN 要求动作空间是离散的，且只能是有限个，这样才能寻找使动作值函数最大化的动作的操作。但在很多问题特别是物理控制任务中，具有连续实值和高维的动作空间，例如要控制在 x y z 方向的速度、加速度。DQN 不能直接应用。        难以收敛。基于价值的强化学习方法输出的价值（如各个动作的最优 Q 函数值）的微小改变会导致某一动作被选中或不选中，这种不连续的变化会影响算法的收敛。这很容易理解，假设一个动作a的Q函数值本来在所有动作中是第 2 大的，把它增加 0.0001，就变成最大的，那这种微小的变化会导致策略完全改变。因为之前它不是最优动作，现在变成最优动作了。        存在徘徊。在观察受限的情况下，基于价值的强化学习方法会出现徘徊现象。即出现不同状态导致的观察相同，使得对应相同的 “最佳” 策略，但明显不符合任务实际情况的现象。  本质上，以 DQN 为代表的值函数近似方法，已经能够较好地将价值函数通过神经网络进行逼近，但最终进行策略选取时，还是只能适用于表格形式的离散策略。我们是否能够借鉴值函数近似方法，采用函数来直接近似策略呢？2. 策略梯度2.1. 策略函数直接借鉴值函数近似的方法，使用神经网络作为策略函数，输出某个状态 $s$ 下执行各种动作的概率值，即将策略参数化为\\[\\pi(a\\vert s) = p(a \\vert s;\\theta)\\]这种做法的原理如下图所示          +----+ ----&gt; p(a1|s;θ)  s  ---&gt; |f(x)| ----&gt; p(a2|s;θ)          |  θ | ----&gt; ...          +----+ ----&gt; p(a3|s;θ)此时，动作 $a$ 服从某一概率密度函数 $p(a\\vert s;\\theta)$ ，也即将动作 $a$ 理解成从概率模型 $p(a\\vert s;\\theta)$ 产生的样本。我们的目标也就从直接求解 $p(a\\vert s;\\theta)$ 转换成求解参数 $\\theta$。将含参数 $\\theta$ 的策略称为策略函数，记作 $\\pi(a \\vert s;\\theta)$，通常情况下可简写成 $\\pi_{\\theta}$。2.2. 策略函数的分布形式前面假设动作 $a$ 服从某一概率密度函数 $p(a\\vert s;\\theta)$，这里对其概率密度函数形式进行一些额外的讨论。      如果动作 $a$ 是离散随机变量，使用 $\\text{softmax}$ 函数将其映射为 指数族分布    这里并不是一定要使用 $\\text{softmax}$ 函数进行映射，而是只要能够映射为 “指数族分布” 即可。定义 $h(s,a;\\theta)$ 函数为 “动作偏好值”，将离散型的策略 $\\pi(a \\vert s;\\theta)$ 视为关于 $\\theta$ 的一个函数，有\\[\\pi(a \\vert s;\\theta) \\rightarrow \\frac{e^{h(s,a;\\theta)}}{\\sum_{a'}e^{h(s,a';\\theta)}}\\]        如果动作 $a$ 是连续随机变量，服从的分布可以有很多种，不妨认为服从 高斯分布    这里将高斯分布中的 $\\mu,\\sigma$ 看作参数 $\\theta$ 的函数，若 $\\theta$ 能够求解， $\\mu,\\sigma$ 同样也可以被求解，最终求解整个分布\\[\\mu=\\mu(s;\\theta),\\sigma=\\sigma(s;\\theta)\\]    若 $a$ 是服从 1 维随机变量的高斯分布，策略函数 $\\pi(a \\vert s;\\theta)$ 表示如下\\[\\pi(a \\vert s;\\theta) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(a-\\mu)^2}{2\\sigma^2}}\\]  为了改进策略函数，需要围绕参数 $\\theta$ 构建一个目标函数 $J(\\theta)$，然后通过梯度下降（上升）的方式更新参数。  在后面我们会发现，最终需要计算目标函数的梯度，相当于计算策略函数的对数的梯度，但通常我们不会直接使用策略函数的对数的梯度，因为可以采用成熟的深度学习框架（PyTorch或者TensorFlow）自动求导来完成。2.3. 策略梯度确定策略函数后，下一步就是建立策略梯度的概念。我们首先从价值函数的梯度出发，引出策略梯度的定义。2.3.1. 回顾价值梯度首先回顾 Q-Learning 的核心思想，通过一步采样更新 Q 值\\[q(s_t,a_t)\\leftarrow q(s_t,a_t)+\\alpha[r_{t+1}+\\gamma\\max_a q(s_{t+1},a)−q(s_t,a_t)]\\]上述更新过程可以收敛，意味着 TD-Error 最终收敛至零\\[r_{t+1}+\\gamma\\max_a q(s_{t+1},a)−q(s_t,a_t) \\rightarrow 0\\]那么我们可以构造一个参数为 $\\theta$ 的深度神经网络，用来估计价值函数，即 DQN 方法\\[q(s,a) = q(s,a; \\theta)\\]则训练用的损失函数可设计为\\[L(\\theta) = \\mathbb{E} \\{[r_{t+1}+\\gamma\\max_a q(s_{t+1},a; \\theta)−q(s_t,a_t; \\theta)]^2\\}\\]然后，通过梯度下降更新神经网络的参数，使得损失函数 $L(\\theta)$ 最小。\\(\\theta \\leftarrow \\theta - \\alpha \\nabla_{\\theta} L(\\theta)\\)其中，$\\alpha$ 是学习率。采用分离拷贝思路后，损失函数的梯度可以写为\\[\\nabla_{\\theta} L(\\theta) = \\alpha[r_{t+1}+\\gamma\\max_a q(s_{t+1},a; \\theta)−q(s_t,a_t; \\theta)]\\nabla_{\\theta}  q(s_t,a_t; \\theta)\\]可以看出，我们从 Q-Learning 的 TD Error 出发定义出损失函数，对损失函数求梯度可得价值梯度。通过梯度下降找到最优参数 $\\theta$，进而得到最优价值函数。实际上，价值梯度并没有严格的定义，因为我们并不关心其具体形式，上述损失函数已经可以保证我们找到最优网络参数。可以粗略的认为，狭义的价值梯度是 $\\nabla_{\\theta} q(s_t,a_t; \\theta)$，而广义的价值梯度即为损失函数的梯度。2.3.2. 策略梯度类似地，我们需要定义一个策略梯度来更新神经网络的参数，最终使得策略达到最优。神经网络的输出是前面定义的策略函数 $\\pi(a \\vert s;\\theta)$，那么损失函数的表达式中必然要「显式包含」策略函数，这样才能衡量输出和真值之间的误差，即\\[J(\\theta) = J(\\pi(a\\vert s;\\theta))\\]如果能给出上述损失函数的表达式，更进一步如果能直接给出损失函数梯度的表达式，就可以直接进行梯度下降（上升？）更新网络参数\\[\\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta J(\\pi(a\\vert s ; \\theta))\\]若我们定义 策略梯度 为上述损失函数的梯度，那么问题就转化为：  损失函数 $J(\\pi(a\\vert s;\\theta))$ 的具体形式是什么？  损失函数的梯度（即策略梯度）$\\nabla_\\theta J(\\pi(a\\vert s;\\theta))$ 的具体形式是什么？  如何计算损失函数的梯度（即策略梯度）？梯度下降还是梯度上升？3. 策略梯度的计算3.1. 基于累计奖励的策略梯度回想强化学习的目标是使得获得的奖励最大化，因此计算策略梯度的目的，也是为了更新神经网络的参数，使神经网络产生的能够得到大的奖励的动作的概率变大，即得到更优的策略使得获得的奖励最大化。神经网络的输出为策略函数 $\\pi(a\\vert s;\\theta)$，其中 $\\theta$ 是神经网络的参数。假设采样一条马尔科夫轨迹如下\\[\\tau = {s_1,a_1,r_1,s_2,a_2,r_2,...,s_T,a_T,r_T}\\]那么该轨迹发生的概率为\\[p_{\\theta}(\\tau) = p(s_1)\\prod_{t=1}^T \\pi(a_t\\vert s_t;\\theta)p(s_{t+1}\\vert s_t,a_t)\\]其中，$p(s_1)$ 为初始状态的概率；$p(s_{t+1}\\vert s_t,a_t)$ 为环境转移概率。注意这两个概率均与网络参数无关。不考虑折扣衰减，该轨迹获得的累计奖励为\\[R(\\tau) = \\sum_{t=0}^T r_t\\]因此我们可以定义目标函数为\\[\\textcolor{blue}{J(\\theta) = \\mathbb{E} [R(\\tau)] = \\mathbb{E}\\left[\\sum_{t=1}^T r_t\\right]}\\]由于马尔科夫链是采样得到的，因此当前策略可获得的期望奖励为\\[\\mathbb{E} [R(\\tau)] = \\sum_{\\tau} p_{\\theta}(\\tau)R(\\tau)\\]定义策略梯度为\\[\\nabla_{\\theta}J(\\theta) = \\nabla_{\\theta}\\mathbb{E} [R(\\tau)] = \\nabla_{\\theta}\\sum_{\\tau} p_{\\theta}(\\tau) R(\\tau) = \\sum_{\\tau} \\nabla_{\\theta}p_{\\theta}(\\tau) R(\\tau)\\]注意，强化学习的目的是最大化这个期望奖励，因此需要用梯度上升来更新神经网络参数。\\[\\theta \\leftarrow \\theta + \\alpha \\nabla_{\\theta} J(\\theta)\\]  问题转化为：如何计算 $\\nabla_{\\theta}p_{\\theta}(\\tau)$注意到 $p_{\\theta}(\\tau)$ 是许多概率连乘的形式，如果直接计算其梯度，势必存在数据下溢（概率都是小于等于 1 的，多个概率连乘后数值会非常小），需要想办法避免。一种直觉思路是通过取 对数 把连乘转化为连加。对 $\\ln f(x)$ 函数求梯度具备如下性质\\[\\nabla_{x} \\ln f(x) = \\frac{\\nabla_{x} f(x)}{f(x)}\\]因此有\\[\\nabla_{x} f(x) = f(x)\\nabla_{x} \\ln f(x)\\]将 $p_{\\theta}(\\tau)$ 带入即可得\\[\\nabla_{\\theta}p_{\\theta}(\\tau) = p_{\\theta}(\\tau)\\nabla_{\\theta} \\ln p_{\\theta}(\\tau)\\]因此有\\[\\begin{aligned}\\nabla_{\\theta}J(\\theta) &amp;= \\sum_{\\tau} \\nabla_{\\theta}p_{\\theta}(\\tau) R(\\tau)\\\\&amp;= \\sum_{\\tau} p_{\\theta}(\\tau)\\nabla_{\\theta} \\ln p_{\\theta}(\\tau) R(\\tau) \\\\&amp;=\\mathbb{E}_{\\tau\\sim p_{\\theta(\\tau)}}[\\nabla_{\\theta} \\ln p_{\\theta}(\\tau) R(\\tau)]\\end{aligned}\\]  问题转化为：如何计算 $\\nabla_{\\theta} \\ln p_{\\theta}(\\tau)$首先通过蒙特卡洛方法进行 $N$ 次采样来近似估计期望\\[\\begin{aligned}\\nabla_{\\theta}J(\\theta) &amp;=\\mathbb{E}_{\\tau\\sim p_{\\theta(\\tau)}}[\\nabla_{\\theta} \\ln p_{\\theta}(\\tau) R(\\tau)]\\\\&amp;=\\frac{1}{N} \\sum_{n=1}^N \\nabla_{\\theta} \\ln p_{\\theta}(\\tau_n) R(\\tau_n)\\end{aligned}\\]其中，$\\tau_n$ 是第 $n$ 次采样得到的轨迹。那么对于这条具体的轨迹有\\[\\begin{aligned}\\nabla_{\\theta} \\ln p_{\\theta}(\\tau_n) &amp;= \\nabla_{\\theta} \\left[\\ln p(s_1) + \\sum_{t=1}^T \\ln \\pi_{\\theta}(a_t\\vert s_t) +\\sum_{t=1}^T \\ln p(s_{t+1}\\vert s_t,a_t)\\right]_n\\\\&amp;= \\nabla_{\\theta}\\sum_{t=1}^T\\ln \\pi_{\\theta}(a_t^n\\vert s_t^n)= \\sum_{t=1}^T\\nabla_{\\theta}\\ln \\pi_{\\theta}(a_t^n\\vert s_t^n)\\\\\\end{aligned}\\]上式可以看出，利用对数函数把连乘转为连加的好处在于。中第一项和第三项与网络参数 $\\theta$ 无关，因此对其求梯度为 0，仅剩第二项。带回前式可得到如下更新式\\[\\nabla_{\\theta}J(\\theta) = \\frac{1}{N}\\sum_{n=0}^N \\sum_{t=1}^T \\nabla_{\\theta}\\ln \\pi_{\\theta}(a_t^n\\vert s_t^n) R(\\tau_n)\\]最后，重新把策略梯度写为期望的形式，有\\[\\textcolor{red}{\\nabla_{\\theta}J(\\theta)=\\mathbb{E} [\\nabla_{\\theta}\\ln \\pi_{\\theta}(A\\vert S) R]}\\]上述策略梯度存在一个局限，即只适用于蒙特卡洛采样能够采样到终止状态的情况，此时累计奖励可以计算得到特定的值。如果采样无法达到终止状态，轨迹就无限延申，就无法计算累计奖励了。3.2. 基于初始状态价值的策略梯度为了解决基于累计奖励的策略梯度在蒙特卡洛采样无限时无法求解问题，引入折扣因子，对应的目标函数为\\[\\textcolor{blue}{J(\\theta) = \\mathbb{E} [R(\\tau)]=  \\mathbb{E}[\\sum_{t=1}^T \\gamma^{t-1} r_t]}\\]注意到，上式右侧的求和就是回报的定义式（累计奖励的折扣和），带上期望就是价值函数的定义式，相当于利用初始状态的状态价值函数来衡量轨迹的优劣，因此有\\[J(\\theta) = V_{\\pi}(s)\\]那么有\\[\\nabla_{\\theta}J(\\theta) = \\nabla_{\\theta}V_{\\pi}(s)\\]上述策略梯度没有显式包含策略函数 $\\pi_{\\theta}(a\\vert s)$，需要通过策略梯度定理将其进一步展开。3.3. 策略梯度定理首先使用贝尔曼期望方程对 $V_{\\pi}(s)$ 进行展开\\[\\nabla_{\\theta}V_{\\pi}(s) = \\nabla_{\\theta}\\sum_{a\\in \\mathcal{A(s)}} \\pi(a\\vert s)q_{\\pi}(s,a) = \\sum_{a\\in \\mathcal{A(s)}}\\nabla_{\\theta}[\\pi(a\\vert s)q_{\\pi}(s,a)]\\]注意到求梯度是对网络参数 $\\theta$ 进行的，而所有和策略 $\\pi$ 有关的项均隐含 $\\theta$，所以上述式子需要采用乘法求导的形式展开\\[\\begin{aligned}\\nabla_{\\theta}V_{\\pi}(s) &amp;= \\sum_{a\\in \\mathcal{A(s)}}\\nabla_{\\theta} [\\pi(a\\vert s)q_{\\pi}(s,a)]\\\\&amp;= \\sum_{a\\in \\mathcal{A(s)}} [\\nabla_{\\theta}\\pi(a\\vert s) q_{\\pi}(s,a) + \\pi(a\\vert s) \\nabla_{\\theta}q_{\\pi}(s,a)]\\\\\\end{aligned}\\]其中第二项\\[\\begin{aligned}\\nabla q_{\\pi} (s,a) &amp;= \\nabla \\sum_{s^\\prime,r} P(s^\\prime,r\\vert s,a)[r+\\gamma V_{\\pi}(s^\\prime)]\\\\&amp;=\\nabla \\sum_{s^\\prime,r}^{s^\\prime,r}  P(s^\\prime,r|s,a)  r + \\nabla \\sum_{s^\\prime,r} \\gamma P(s^\\prime,r|s,a)V_{\\pi}(s^\\prime)\\\\&amp;=\\nabla \\sum_{s^\\prime,r} \\gamma P(s^\\prime,r|s,a)V_{\\pi}(s^\\prime)\\\\&amp;=\\gamma \\sum_r P(r\\vert s,a)\\sum_{s^\\prime} P(s^\\prime\\vert s,a) \\nabla V_{\\pi}(s^\\prime)\\\\&amp;=\\gamma \\sum_{s^\\prime} P(s^\\prime\\vert s,a) \\nabla V_{\\pi}(s^\\prime)\\end{aligned}\\]带回梯度式子，即\\[\\nabla_{\\theta}V_{\\pi}(s) = \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert s) q_{\\pi}(s,a) + \\sum_{a\\in \\mathcal{A(s)}} \\pi(a\\vert s)\\gamma \\sum_{s^\\prime} P(s^\\prime\\vert s,a) \\nabla_{\\theta} V_{\\pi}(s^\\prime)\\]可以看出，上式呈现出 $\\nabla_{\\theta}V_{\\pi}(s)$ 的迭代形式。为了更进一步确定迭代关系，再次对 $\\nabla_{\\theta}V_{\\pi}(s^\\prime)$ 展开，有\\[\\nabla_{\\theta}V_{\\pi}(s^\\prime) = \\sum_{a^\\prime\\in \\mathcal{A(s^\\prime)}} \\nabla_{\\theta}\\pi(a^\\prime\\vert s^\\prime) q_{\\pi}(s^\\prime,a^\\prime) + \\sum_{a^\\prime\\in \\mathcal{A(s^\\prime)}} \\pi(a^\\prime\\vert s^\\prime)\\gamma \\sum_{s^{\\prime\\prime}} P(s^{\\prime\\prime}\\vert s^\\prime,a^\\prime) \\nabla_{\\theta} V_{\\pi}(s^{\\prime\\prime})\\]带回梯度式子并且完全展开，有  第一项\\[\\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert s) q_{\\pi}(s,a)\\]      第二项\\[\\begin{aligned}      &amp;\\sum_{a\\in \\mathcal{A(s)}} \\pi(a\\vert s)\\gamma \\sum_{s^\\prime} P(s^\\prime\\vert s,a)\\cdot \\sum_{a^\\prime\\in \\mathcal{A(s^\\prime)}} \\nabla_{\\theta}\\pi(a^\\prime\\vert s^\\prime) q_{\\pi}(s^\\prime,a^\\prime) \\\\      =&amp;\\gamma \\sum_{s^\\prime}\\sum_{a\\in \\mathcal{A(s)}} \\pi(a\\vert s) P(s^\\prime\\vert s,a)\\cdot \\sum_{a^\\prime\\in \\mathcal{A(s^\\prime)}} \\nabla_{\\theta}\\pi(a^\\prime\\vert s^\\prime) q_{\\pi}(s^\\prime,a^\\prime) \\\\      =&amp;\\gamma \\sum_{s^\\prime} \\mathcal{P}(s^\\prime\\vert s)\\cdot \\sum_{a^\\prime\\in \\mathcal{A(s^\\prime)}} \\nabla_{\\theta}\\pi(a^\\prime\\vert s^\\prime) q_{\\pi}(s^\\prime,a^\\prime)\\\\      \\end{aligned}\\]    上式仅包含前后状态的变量 $s,s^\\prime$ 和转移次数常量 $k=1$（$a$ 最终会被求和吸收积分掉），因此可进一步写为通项式：\\[\\gamma \\sum_{x\\in S} \\mathcal{P}(s\\rightarrow x, k, \\pi)\\cdot \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert x) q_{\\pi}(x,a)\\]    同时，注意到第一项也符合上述通项式（$k=0,\\gamma = 1$）        第三项    \\(\\sum_{a\\in \\mathcal{A(s)}} \\pi(a\\vert s)\\gamma \\sum_{s^\\prime} P(s^\\prime\\vert s,a) \\cdot \\sum_{a^\\prime\\in \\mathcal{A(s^\\prime)}} \\pi(a^\\prime\\vert s^\\prime)\\gamma \\sum_{s^{\\prime\\prime}} P(s^{\\prime\\prime}\\vert s^\\prime,a^\\prime) \\nabla_{\\theta} V_{\\pi}(s^{\\prime\\prime})\\)注意到第三项仍然是个迭代式，可以继续展开，且展开除了最后一项，前面均符合前述通项式。  至此， $\\nabla_{\\theta} V_\\pi(s)$ 的迭代式表示如下\\[\\nabla_{\\theta}V_{\\pi}(s) = \\sum_{s\\in S} \\sum_{k=0}^{\\infty} \\gamma^{k} \\mathcal{P}(s\\rightarrow x, k, \\pi)\\cdot \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert x) q_{\\pi}(x,a)\\]将公式中所有 $s$ 替换为初始状态 $s_0$，将所有 $x$ 替换为 $s$，可得\\[\\nabla_{\\theta}V_{\\pi}(s_0) = \\sum_{s\\in S} \\sum_{k=0}^{\\infty} \\gamma^{k} \\mathcal{P}(s_0\\rightarrow s, k, \\pi)\\cdot \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert s) q_{\\pi}(s,a)\\]其中，  $\\mathcal{P}(s_0\\rightarrow s, k, \\pi)$ 表示初始状态 $s_0$ 经过 $k$ 次状态转移最终到达 $s$ 的概率；  $\\sum_{k=0}^{\\infty} \\mathcal{P}(s_0\\rightarrow s, k, \\pi)$ 表示在整条轨迹序列中，状态 $s$ 出现的平均次数，将其记为 $\\eta(s)$；  那么状态 $s$ 出现的概率 $\\mu(s)$ 可定义为其出现的平均次数除以所有状态出现的平均次数的和，即 $\\mu(s) = {\\eta(s)}/{\\sum_{s^\\prime} \\eta(s^\\prime)}$则\\[\\begin{aligned}\\nabla_{\\theta}V_{\\pi}(s_0) &amp;= \\sum_{s\\in S}  \\gamma^{k} \\eta(s) \\cdot \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert s) q_{\\pi}(s,a)\\\\&amp;= \\sum_{s\\in S}  \\gamma^{k} \\mu(s)\\sum_{s^\\prime\\in S} \\eta(s^\\prime)  \\cdot \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert s) q_{\\pi}(s,a)\\\\&amp;= \\sum_{s^\\prime\\in S}\\left(\\sum_{s\\in S} \\eta(s^\\prime) \\gamma^{k} \\mu(s) \\right) \\cdot \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert s) q_{\\pi}(s,a)\\\\\\end{aligned}\\]我们希望把前面对状态 $s$ 的求和重新表示为某种期望的形式\\[\\nabla_{\\theta}J(\\theta) =\\mathbb{E}_{?}\\left[ \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert s) q_{\\pi}(s,a) \\right]\\]问题转化为，确定期望符号中的概率分布是什么（也即上式中的 ? 部分）。既然是分布，不妨假设其概率分布为 $\\rho_\\pi(s)$，该分布不仅和策略函数 $\\pi(a\\vert s;\\theta)$ 相关，还与环境（状态转移概率）相关，那么策略梯度变为\\[\\begin{aligned}\\nabla_{\\theta}V_{\\pi}(s_0) &amp;\\doteq \\sum_{s^\\prime\\in S}\\rho_{\\pi}(s^\\prime) \\cdot \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert s) q_{\\pi}(s,a)\\\\&amp;= \\sum_{s\\in S}\\rho_{\\pi}(s) \\cdot \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert s) q_{\\pi}(s,a)\\end{aligned}\\]则\\[\\nabla_{\\theta}J(\\theta) = \\mathbb{E}_{s\\sim \\rho_{\\pi}(s)}\\left[ \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert s) q_{\\pi}(s,a) \\right]\\]继续观察，上式还存在一个求和符号，因此存在一个想法是将该部分也化为期望的形式。但该求和符号的消除需要借助策略函数，因此需要对 $\\nabla_{\\theta}\\pi(a\\vert s;\\theta)$ 进行变换，借助之前 $\\ln f(x)$ 函数梯度的性质，有\\[\\begin{aligned}\\nabla_{\\theta}J(\\theta) = &amp; \\mathbb{E}_{s\\sim \\rho_{\\pi}(s)}\\left[ \\sum_{a\\in \\mathcal{A(s)}} \\nabla_{\\theta}\\pi(a\\vert s;\\theta) q_{\\pi}(s,a) \\right]\\\\= &amp; \\mathbb{E}_{s\\sim \\rho_{\\pi}(s)}\\left[ \\sum_{a\\in \\mathcal{A(s)}} \\pi(a\\vert s;\\theta)\\nabla_{\\theta}\\ln\\pi(a\\vert s;\\theta) q_{\\pi}(s,a) \\right]\\\\= &amp; \\mathbb{E}_{s\\sim \\rho_{\\pi}(s), a\\sim \\pi} \\left[ \\nabla_{\\theta}\\ln\\pi(a\\vert s;\\theta) q_{\\pi}(s,a) \\right]\\\\\\end{aligned}\\]将期望的下标进行简化，最终我们得到了一般形式的基于初始状态价值的策略梯度\\[\\textcolor{red}{\\nabla_{\\theta}J(\\theta) = \\mathbb{E} \\left[ \\nabla_{\\theta}\\ln\\pi(A\\vert S;\\theta) q_{\\pi}(S,A) \\right]}\\]  上式中的 “=” 并非严格意义的相等，而是包含 ”相等、约等于、正比于“ 三种形式，具体形式与折扣因子取值、初始状态分布有关。  有关策略改进定理还可参考：https://zhuanlan.zhihu.com/p/491647161注意，同样需要用梯度上升来更新神经网络参数\\[\\theta \\leftarrow \\theta + \\alpha \\nabla_{\\theta} J(\\theta)\\]4. 基于策略梯度的参数更新梯度上升算法中，将待更新参数的下标加上，得到如下更加严谨的形式\\[\\begin{aligned}  \\theta_{t+1} &amp;= \\theta_t + \\alpha \\nabla_{\\theta_t} J(\\theta)\\\\ &amp;= \\theta_t + \\alpha \\mathbb{E} \\left[ \\nabla_{\\theta_t}\\ln\\pi(A\\vert S;\\theta_t) q_{\\pi}(S,A) \\right]\\\\\\end{aligned}\\]期望符号可以通过「随机梯度下降」的方式来消除\\[\\theta_{t+1} = \\theta_t + \\alpha \\nabla_{\\theta_t}\\ln\\pi(a\\vert s;\\theta_t) q_{\\pi}(s,a)\\]期望符号包含了对 $S,A$ 的采样，其中  $S \\sim d $ 或 $S \\sim \\rho$ 是策略 $\\pi$ 下的长期分布，但实际上我们有样本就不错了，所以实际应用中不考虑；  $A \\sim \\pi(A\\vert S;\\theta)$ 需要实际采样才能得到，因此策略梯度法是个 on-policy 方法。虽然消除了期望符号，但其中涉及的 $q_{\\pi}(s, a)$ 仍然未知，有两种近似求解的思路：  MC：使用 Monte-Carlo 采样得到真实回报 $G_t$ 来近似估计，称其为 REINFORCE；  TD：使用时序差分算法，对应 Actor-Critic 等一系列方法。4.1. REINFORCE根据 Q 函数的定义有\\[q_{\\pi_{\\theta}}(s_t, a_t) = \\mathbb{E} [G_t\\vert s_t, a_t]\\]带入策略梯度定理有\\[\\nabla_{\\theta}J(\\theta) \\propto \\mathbb{E} \\left[ \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta) G_t \\right]\\]至此，我们可以通过采样 $\\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta) G_t$ 神经网络参数 $\\theta$ 进行更新。这就是 REINFORECE。REINFORCE 的本质就是用 $G_t$ 代替 $q_{\\pi}(s_t, a_t)$。用于估计最优策略的REINFORCE算法表示如下（采用增量更新的方式）  输入：可微策略函数 $\\pi(a \\vert s;\\theta)$，衰减因子 $\\gamma$，学习率 $\\alpha$  初始化：策略函数的参数 $\\theta$  训练过程：          repeat 根据 $\\pi_{\\theta}$ 采样一条轨迹：$s_0, a_0, r_1, s_2, a_2, r_3, \\cdots$      loop $t=T-1, T-2, \\cdots, 1,0$                  $\\quad G\\leftarrow \\gamma G + r_{t+1}$          $\\quad \\theta \\leftarrow \\theta + \\alpha \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta) G $                    根据定义，因为 $G_t$ 是 $Q(s,a)$ 的无偏估计，所以基于蒙特卡洛采样的方式进行参数更新的 REINFORCE 算法，得到的结果就是策略梯度的无偏估计，那么其方差呢？结论：基于蒙特卡洛采样的方式进行参数更新的 REINFORCE 算法方差很大。通过观察策略梯度式\\[\\nabla_{\\theta}J(\\theta) \\propto \\mathbb{E} \\left[ \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta) G_t \\right]\\]我们可以看出，$\\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta)$ 相当于 $G$ 的一个系数或者说权重，对于方差而言只起到放缩作用（根据公式 $Var(aX) = a^2Var(X)$），实际方差还是取决于 $G$ 本身。而 $G$ 的方差\\[Var(G_t) = Var(R_{t+1}) + Var(R_{t+2}) + \\cdots\\]由此可以看出，方差大来源于两个原因：  若不同 $s$ 对应的 $R$ 范围相差较大，再加上 MC 的随机性，那么每一步的 $R$ 都会有较大的方差;  因为采样轨迹长度的原因，出现方差累积。相应的解决方法如下：  通过添加基线缓解;  使用 TD 方法代替 MC 方法，即通过Actor-Critic方法解决。4.2. REINFORCE with baseline通过添加基线（baseline）可以减小方差。具体形式如下\\[\\nabla_{\\theta}J(\\theta) \\propto \\mathbb{E} \\left[ \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta) G_t \\right]\\]添加基线 $b(s)$ 后，目标函数的梯度变为\\[\\nabla_{\\theta}J(\\theta) \\propto \\mathbb{E} \\left[ \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta) (G_t-b(s_t)) \\right]\\]参数更新方式变为\\[\\theta \\leftarrow \\theta + \\alpha (G_t - b(s_t)) \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta)\\]基线 $b(s)$ 可为不与动作 $a$ 有关的任意变量或者函数，因为它并不会改变策略梯度的期望，证明如下\\[\\begin{aligned}\\nabla_{\\theta}J(\\theta) &amp;\\propto \\mathbb{E} \\left[ \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta) (G_t-b(s_t)) \\right]\\\\&amp;\\propto \\sum_{a}\\pi(a\\vert s) \\nabla_{\\theta}\\ln \\pi(a\\vert s;\\theta)(G_t-b(s_t))\\\\&amp;\\propto \\sum_{a} \\nabla_{\\theta}\\pi(a\\vert s;\\theta)(G_t-b(s_t))\\end{aligned}\\]因为 $b(s)$ 与动作 $a$ 无关，可以提到求和符号外面，但注意 $G_t$ 不可以提到求和符号外面\\[\\begin{aligned}\\nabla_{\\theta}J(\\theta) &amp;\\propto \\sum_{a} \\nabla_{\\theta}\\pi(a\\vert s;\\theta)(G_t-b(s_t))\\\\&amp;\\propto \\sum_{a}  G_t \\nabla_{\\theta}\\pi(a\\vert s;\\theta) - b(s_t) \\sum_{a} \\nabla_{\\theta}\\pi(a\\vert s;\\theta)\\\\\\end{aligned}\\]对于后一项，交换梯度符号和求和符号，有\\[b(s_t) \\sum_{a} \\nabla_{\\theta}\\pi(a\\vert s;\\theta) =b(s_t)\\nabla_{\\theta} \\sum_{a} \\pi(a\\vert s;\\theta)  = b(s_t)\\nabla_{\\theta} 1 = 0\\]得证。  关于基线的更多内容参考：https://zhuanlan.zhihu.com/p/636907461为什么引入基线可以减小方差？证明如下：首先根据方差的定义\\[Var(X) = E(X^2)-E(X)^2\\]那么有\\[Var(\\nabla_{\\theta}J(\\theta)) = Var(\\nabla_{\\theta}^2)-\\nabla_{\\theta}^2 E(\\nabla_{\\theta})\\]我们又知道引入基线不改变期望，因此方差的第二项取值与是否包含基线无关，则只需要关注第一项即可\\[\\begin{aligned}Var \\nabla_{\\theta}J(\\theta)^2 &amp;= E[\\nabla_{\\theta}\\ln\\pi_{\\theta}(a_t\\vert s_t)^2\\cdot (G_t - b(s_t))^2] \\\\ &amp;= E[\\nabla_{\\theta}\\ln\\pi_{\\theta}(a_t\\vert s_t)^2]\\cdot E[(G_t - b(s_t))^2]\\end{aligned}\\]思考：什么基线能使上式取到最小值？$\\to$ 这是一个求极值问题 $\\to$ 上式对基线求偏导并另其为零。\\[\\begin{aligned}&amp;\\frac{\\partial}{\\partial b(s_t)}Var\\nabla_{\\theta}J( \\theta )^2=\\mathbb{E}\\{2\\left( G_t-b( s_t ) \\right) [ \\nabla _{\\theta}\\ln \\pi _{\\theta}( a_t|s_t ) ^2 ] \\}=0\\\\\\Rightarrow &amp; \\mathbb{E}\\{G_t [ \\nabla _{\\theta}\\ln \\pi _{\\theta}( a_t|s_t ) ^2 ] \\}=\\mathbb{E}\\{b( s_t ) [ \\nabla _{\\theta}\\ln \\pi _{\\theta}( a_t|s_t ) ^2 ] \\}\\end{aligned}\\]则\\[b(s_t) = \\frac{\\mathbb{E}\\{G_t [ \\nabla _{\\theta}\\ln \\pi _{\\theta}( a_t|s_t ) ^2 ] \\}}{\\mathbb{E}[ \\nabla _{\\theta}\\ln \\pi _{\\theta}( a_t|s_t ) ^2 ]}\\]当基线是关于 $G_t$ 期望的上述估计时，方差最小。上述估计是一个对 $G_t$ 的带权重估计值，但其中权重的求解需要用到梯度信息，这是未知的。因此实际情况中我们也不会用这个理论最优的基线。实际情况中，我们直接忽略权重，将基线设置为次优的情况\\[\\begin{aligned}&amp;b(s) = \\mathbb{E}[G_t] = \\mathbb{E}(G_t \\vert s=s_t) = v_\\pi(s)\\\\\\text{or}\\quad &amp;b(s) = \\mathbb{E}[G_t] = \\mathbb{E}(G_t \\vert s=s_t,a=a_t) = q_{\\pi}(s,a)\\end{aligned}\\]  对于第一种次优情况，相当于将基线设为「状态价值函数」；  对于第二种次优情况，相当于将基线设为「状态-动作价值函数」。4.3. Actor-Critic (related to V)当基线函数选为 状态价值函数时，更进一步，因为 REINFORCE 本身是基于蒙特卡洛方法，那么自然而然可以同样使用蒙特卡洛方法来学习该状态价值函数，即\\[b(s) = {v}(s_t;{w})\\]其中 $w$ 是另一套习得的参数。此时，策略梯度的表达式变为\\[\\nabla_{\\theta}J(\\theta) \\propto \\mathbb{E} \\left[ \\nabla_{\\theta}\\ln\\underbrace{\\pi(a_t\\vert s_t;\\theta)}_{\\text{actor}} (G_t-\\underbrace{v(s_t;w)}_{\\text{critic}}) \\right]\\]到此为止，我们就可以将 REINFORCE 算法转化为 Actor-Critic 算法，其中参数 $\\theta$ 对应策略梯度部分的神经网络，扮演 Actor 的角色；而 $w$ 对应价值估计部分的神经网络，扮演 Critic 的角色。更进一步，类似于基于价值的强化学习方法中，MC 到 TD 方法的逻辑演变，这里我们同样不需要采样完整的一条轨迹，而是仅采样一步，后续通过自举的方式逐步估计完整的轨迹，对应策略梯度表达式变为\\[\\nabla_{\\theta}J(\\theta) \\propto \\mathbb{E} \\left[ \\nabla_{\\theta}\\ln\\underbrace{\\pi(a_t\\vert s_t;\\theta)}_{\\text{actor}} (R_{t+1}+\\gamma \\underbrace{v(s_{t+1};w)-v(s_t;w)}_{\\text{critic}}) \\right]\\]此时价值网络的更新形式为\\[\\begin{aligned}\\delta_t &amp;= R_{t+1}+\\gamma v(s_{t+1};\\omega)-v(s_t;\\omega)\\\\J(\\omega) &amp;= \\frac{1}{2} \\delta_t^2\\\\\\omega &amp;\\leftarrow \\omega - \\alpha_{\\omega} \\delta_t \\nabla_{\\omega}v(s;\\omega)\\end{aligned}\\]此时策略网络的更新形式为\\[\\begin{aligned}\\delta_t &amp;= R_{t+1} + \\gamma {v}(s_{t+1};w)-{v}(s_t;{w})\\\\\\nabla_{\\theta}J(\\theta) &amp;\\propto \\mathbb{E} \\left[ \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta) \\delta_t \\right]\\\\\\theta &amp;\\leftarrow \\theta + \\alpha \\delta_t \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta)\\end{aligned}\\]算法的训练的伪代码如下，该算法又被简称为 「V Actor-Critic（VAC）算法」  输入：          可微策略函数 $\\pi(a \\vert s;\\theta)$      可微的价值函数 ${v}(s;w)$      衰减因子 $\\gamma$，学习率 $\\alpha_\\theta,\\alpha_w$        初始化：          策略函数的参数 $\\theta$      价值函数的参数 $w$        训练过程：          loop 状态 $s$ 没有结束时                  根据策略采样：$a\\sim \\pi(\\cdot, s;\\theta)$          执行动作 $a$， 得到奖励 $R$，转移状态到 $s^\\prime$          $\\delta \\leftarrow R + \\gamma {v}(s^\\prime;w) - {v}(s;w)$          $w \\leftarrow w + \\alpha_w \\delta\\nabla_{w}{v}(s;w)$          $\\beta \\leftarrow \\gamma \\delta$          $\\theta \\leftarrow \\theta + \\alpha \\beta \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta)$                    4.4. Actor-Critic (related to Q)若采用状态-动作价值函数 $q(s,a)$ 作为基线函数，并使用神经网络对其进行估计，有\\[b(s_t) = q(s_t, a_t;\\omega)\\]此时策略梯度表达式为\\[\\nabla_{\\theta}J(\\theta) \\propto \\mathbb{E} \\left[ \\nabla_{\\theta}\\ln\\underbrace{\\pi(a_t\\vert s_t;\\theta)}_{\\text{actor}} (R_{t+1}+\\gamma \\underbrace{q(s_{t+1},a_{t+1};w)-q(s_t,a_t;w)}_{\\text{critic}}) \\right]\\]此时价值网络的更新形式为\\[\\begin{aligned}\\delta_t &amp;= R_{t+1}+\\gamma q(s_{t+1}, a_{t+1};\\omega)-q(s_t, a_t;\\omega)\\\\J(\\omega) &amp;= \\frac{1}{2} \\delta_t^2\\\\\\omega &amp;\\leftarrow \\omega - \\alpha_{\\omega} \\delta_t \\nabla_{\\omega}q(s,a;\\omega)\\end{aligned}\\]  注意到，这里实际上就是采用 SARSA 值函数近似 来进行价值网络更新。对于策略网络的目标函数的梯度，应该使用原始的策略梯度形式，此时策略网络的更新形式为\\[\\begin{aligned}\\nabla_{\\theta}J(\\theta) &amp;\\propto \\mathbb{E} [ \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta) q(s_t,a_t;\\omega)]\\\\\\theta &amp;\\leftarrow \\theta + \\alpha_{\\theta}{q(s,a;\\omega)}\\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta) \\end{aligned}\\]该算法又被简称为 「Q Actor-Critic（QAC）算法」。4.5. Advantage Actor-Critic (A2C)前面介绍 REINFORCE 的时候，我们通过引入基线降低方差，并且表明将基线函数设为价值函数是一个较优的选择。本着这种思想，我们再次回顾策略梯度的原始目标函数梯度式，然后对其引入状态价值函数 $v_{\\pi}(s_t)$ 作为基线，有\\[\\nabla_{\\theta}J(\\theta) \\propto \\mathbb{E} \\left[ \\nabla_{\\theta}\\ln\\pi(a_t\\vert s_t;\\theta) (q_{\\pi}(s_t,a_t)-v_{\\pi}(s_t)) \\right]\\]我们称 $\\textcolor{red}{\\delta_t(s_t,a_t) = q_{\\pi}(s_t,a_t)-v_{\\pi}(s_t)}$ 为 优势函数。优势函数表示在状态 $s$ 下采取动作 $a$ 相对于平均水平的优势。  如果优势函数大于零，则说明该动作比平均动作好  如果优势函数小于零，则说明当前动作还不如平均动作好。因此原先用 Critic 网络对 $q$ 函数的估计就可以改成对优势函数的估计，估算每个 $q(s_t,a_t)$ 对相对于平均值 $V(s_t)$ 的优势。这种算法就是 Advantage Actor Critic ，即 A2C。4.5.1. 探索与利用根据 $\\ln f(x)$ 梯度性质\\[\\nabla_\\theta \\ln\\pi(a\\vert s;\\theta) = \\frac{\\nabla_\\theta \\pi(a\\vert s;\\theta)}{\\pi(a\\vert s;\\theta)}\\]则 A2C 的梯度上升式可改写为\\[\\begin{aligned}\\theta_{t+1} &amp;= \\theta_t + \\alpha \\nabla_{\\theta_t} \\ln\\pi(a_t\\vert s_t;\\theta_t)\\delta_t(a_t,s_t)\\\\&amp;= \\theta_t + \\alpha \\left(\\frac{\\delta_t(a_t,s_t)}{\\pi(a_t\\vert s_t;\\theta_t)}\\right) \\nabla_\\theta \\pi(a_t\\vert s_t;\\theta_t)\\\\&amp;= \\theta_t + \\alpha \\textcolor{red}{\\beta_t} \\nabla_\\theta \\pi(a_t\\vert s_t;\\theta_t)\\end{aligned}\\]这个式子其实在优化 $\\pi(a_t\\vert s_t;\\theta_t)$。因为根据微分的性质，当 $\\theta_{t+1}-\\theta_t$ 足够小时，下面的式子成立\\[\\pi(a_t\\vert s_t;\\theta_{t+1}) \\approx \\pi(a_t \\vert s_t;\\theta_t)+(\\nabla_\\theta \\pi(a_t\\vert s_t;\\theta_t))^\\top (\\theta_{t+1}-\\theta_t)\\]把前面的梯度上升式带进去，得\\[\\begin{aligned}\\pi(a_t\\vert s_t;\\theta_{t+1}) &amp;\\approx \\pi(a_t \\vert s_t;\\theta_t)+(\\nabla_\\theta \\pi(a_t\\vert s_t;\\theta_t))^\\top (\\theta_{t+1}-\\theta_t)\\\\&amp;=\\pi(a_t \\vert s_t;\\theta_t)+(\\nabla_\\theta \\pi(a_t\\vert s_t;\\theta_t))^\\top \\alpha \\beta_t \\nabla_\\theta \\pi(a_t\\vert s_t;\\theta_t)\\\\&amp;=\\pi(a_t \\vert s_t;\\theta_t)+ \\alpha \\beta_t \\Vert \\nabla_\\theta \\pi  a_t\\vert s_t;\\theta_t\\Vert^2\\end{aligned}\\]当 $\\alpha_t\\beta_t&gt;0$ 但值比较小时，有\\[\\pi(a_t\\vert s_t;\\theta_{t+1}) &gt; \\pi(a_t\\vert s_t;\\theta_t)\\]反之当 $\\beta_t &lt; 0$ 时，有\\[\\pi(a_t\\vert s_t;\\theta_{t+1}) &lt; \\pi(a_t\\vert s_t;\\theta_t)\\]注意到，$\\beta_t$ 和 $\\textcolor{red}{\\delta_t(a_t,s_t)}$ 成正比，和 $\\pi(a_t\\vert s_t;\\theta_t)$ 成反比，因此  当 $\\delta_t(a_t,s_t)$ 较大时，$\\beta_t$ 较大，新策略会更加倾向于选择该动作，即「利用」；  当 $\\pi(a_t\\vert s_t;\\theta_t)$ 较小时，$\\beta_t$ 也较大，新策略会更加倾向于选择原本小概率被选择的动作，即「探索」；所以 $\\beta_t$ 可以巧妙地平衡探索和利用。并且其使用的是优势函数，其衡量了当前所选动作相对于平均基准的相对值，因此在探索和利用的平衡上更为合理。4.5.2. 与 VAC 的关系注意到，A2C 在具体实现的时候需要同时估计 $q(s_t, a_t)$ 和 $v(s_t)$，估计一个价值函数已经会存在误差了，估计两个价值函数误差会更大。但是我们知道 $q(s_t, a_t)$ 和 $v(s_t)$ 之间是存在关系的，在具体采样时，有\\[q(s_t, a_t) = r_{t+1} + \\gamma v(s_{t+1})\\]此时我们发现，A2C 就是前面介绍过的 VAC 算法，价值网络只用估计 $v(s_t)$ 的值就够了。4.6. 重要性采样前面介绍的所有策略梯度方法都是 on-policy 方法，即实际进行动作采样的行为策略与待更新的目标策略相同，都是同一个神经网络。我们可以借鉴前面课程中（Q-Learning）介绍的方法，将其转为 off-policy 方法，这样可以更加充分利用已经采样得到的历史样本数据。此处，我们引入重要性采样来实现上述转换。更加一般的情况下，重要性采样可以解决所有期望求解问题。4.6.1. 重要性用于期望估计假设样本 ${x_i}$ 是由其原始分布 $p_0$ 采样得到的，其期望和方差为\\[\\mathbb{E}[x_i] = \\mathbb{E}[X],\\quad var[x_i] = var[X]\\]通过大数定律来近似期望，有\\[\\begin{aligned}&amp;\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i\\to \\mathbb{E}[X],\\quad \\text{as } n\\to \\infty\\\\&amp; var(\\bar{x}) = \\frac{1}{n}var[X]\\end{aligned}\\]假设样本 $x_i$ 是由根据另外一个分布 $p_1$ 采样得到的，问题变为：能否用 $x_i\\sim p_i$ 来估计样本的原始分布？为什么要做上述事情？因为对于 off-policy 方法而言，样本采样来自分布行为策略 $\\beta$（$p_1$），但是目标函数（使用策略梯度）中的期望是针对目标策略的，即 $\\mathbb{E}_{A\\sim \\pi}[\\star]$。重要性采样的一般流程如下：\\[\\mathbb{E}_{X\\sim p_0}[X] = \\int p_0(x)x\\text{d}x = \\int p_1(x)\\underbrace{\\frac{p_0(x)}{p_1(x)}x}_{f(x)}\\text{d}x = \\mathbb{E}_{X\\sim p_1}[f(X)]\\]即可以通过右边的期望来估计原始分布下的期望。相比原始分布下的期望，新的期望更加好求\\[\\begin{aligned}\\mathbb{E}_{X\\sim p_1}[\\bar{f}(X)] &amp;= \\mathbb{E}_{X\\sim p_1}[f(X)]=\\frac{1}{n}\\sum_{i=1}^n f(x_i),\\quad \\text{where } x\\sim p_1\\\\var_{X\\sim p_1}[\\bar{f}(X)] &amp;= \\frac{1}{n}var_{X\\sim p_1}[f(X)]\\end{aligned}\\]其中 $\\textcolor{red}{p_0(x)/p_1(x)}$ 被称为「重要性权重」。注意到，重要性权重中出现了 $p_0(x)$，这要求 $p_0$ 已知。那既然都已知了为什么不直接求期望呢？因为就算样本原始分布是已知的，其期望求解也可能是十分困难的。比如：  当 $p_0$ 的表达式十分复杂时，求积分（期望）难以计算；  当 $p_0$ 是一个神经网络时，求积分（期望）求不出来；对重要性采样总结如下\\[\\begin{aligned}  &amp;{x_i}\\sim p_1,\\\\  \\bar{x} &amp;= \\frac{1}{n}\\sum_{i=1}^n x_i\\to \\mathbb{E}_{X\\sim p_1}[X]\\\\  \\bar{f} &amp;= \\frac{1}{n}\\sum_{i=1}^n \\frac{p_0(x_i)}{p_1(x_i)}x_i\\to \\mathbb{E}_{X\\sim p_0}[f(X)]\\\\\\end{aligned}\\]4.6.2. 重要性用于策略梯度回顾基于初始状态价值的策略梯度式，策略梯度为\\[\\nabla_{\\theta}J(\\theta) = \\mathbb{E}_{s\\sim \\rho_{\\pi}(s), \\textcolor{blue}{a\\sim \\pi}} \\left[ \\nabla_{\\theta}\\ln\\pi(a\\vert s;\\theta) q_{\\pi}(s,a) \\right]\\]引入重要性采样后，假设行为策略为 $\\beta$ 用于产生样本，则策略梯度为\\[\\nabla_\\theta J(\\theta) = \\mathbb{E}_{S\\sim \\rho,\\textcolor{red}{A\\sim \\beta}}\\left[ \\frac{\\pi(A\\vert S;\\theta)}{\\beta(A\\vert s)} \\nabla_\\theta \\pi(A\\vert S;\\theta) q_\\pi(S,A) \\right]\\]重要性采样保证了我们在将策略梯度方法变为 off-policy 后，策略梯度的期望估计依然保持不变。因此，我们可以不用和环境紧密绑定在一次，每次更新都要重新采样。前面我们也提过，有时候相比梯度上升计算，与环境进行采样交互反而耗时更长。通过重要性采样，我们完全可以使用行为策略（$\\theta^\\prime=\\theta_{\\text{frozen}}$）与环境进行大批次采样后，得到样本更新目标策略，经过若干次迭代再进行硬拷贝。如下图所示：进一步，根据优势函数的定义，我们将重要性采样嵌入，则 A2C 的梯度上升式可改写为\\[\\begin{aligned}\\theta_{t+1} &amp;= \\theta_t + \\alpha \\textcolor{red}{\\frac{\\pi(a_t\\vert s_t;\\theta)}{\\beta(a_t\\vert s_t)}} \\nabla_{\\theta_t} \\ln\\pi(a_t\\vert s_t;\\theta_t)\\delta_t(a_t,s_t)\\\\&amp;= \\theta_t + \\alpha \\left(\\frac{\\delta_t(a_t,s_t)}{\\beta(a_t\\vert s_t)}\\right) \\nabla_\\theta \\pi(a_t\\vert s_t;\\theta_t)\\end{aligned}\\]此时，对于 off-policy 方法，策略梯度方法中的行为策略 $\\beta$ 不再发生变化，整个式子只剩下充分利用行为策略产生的样本（当 $\\delta_t$ 比较大时增加对应的采样概率）。相应的，价值网络的更新形式为\\[\\begin{aligned}\\delta_t &amp;= R_{t+1}+\\gamma v(s_{t+1};\\omega_t)-v(s_t;\\omega_t)\\\\J(\\omega) &amp;= \\frac{1}{2} \\delta_t^2\\\\\\omega_{t+1} &amp;= \\omega_t - \\alpha_{\\omega} \\textcolor{red}{\\frac{\\pi(a_t\\vert s_t;\\theta)}{\\beta(a_t\\vert s_t)}} \\delta_t \\nabla_{\\omega}v(s_t;\\omega_t)\\end{aligned}\\]5. 确定性策略梯度（DPG）前面介绍的所有策略梯度都是随机策略，即要求 $\\pi(a\\vert s;\\theta) &gt; 0,\\; \\forall(s,a)$，缺点在于其对动作 $a$ 的个数是有限的（回顾如下网络结构）          +----+ ----&gt; Q(s,a1)  s  ---&gt; |f(x)| ----&gt; Q(s,a2)          |  θ | ----&gt; ...          +----+ ----&gt; Q(s,a3)当然，我们也可以使用确定性策略，这样做的好处是可以适应连续无限的动作空间。对于随机性策略和确定性策略两种情况，策略定义为 $\\pi(a\\vert s;\\theta)\\in[0,1]$，那么对于确定性策略，即给定一个状态输出一个确定的动作，其可定义为\\[a=\\mu(s;\\theta)\\doteq \\mu_\\theta(s)\\]此时策略网络直接把状态映射到动作：$\\mu:S\\to A$，即          +----+  s  ---&gt; |μ(x)| ----&gt; a          |  θ |           +----+ 由于策略发生了变化，原来推导得到的策略梯度只适用于随机性策略，不再适用于确定性策略，需要重新推导。同样考虑基于初始状态价值的策略梯度，此时目标函数为\\[J(\\theta) = V_{\\mu}(s)\\]则相应的策略梯度为（推导略）\\[\\nabla_\\theta J(\\theta) = \\mathbb{E}_{S\\sim \\rho_\\beta}[\\nabla_\\theta \\mu(S)\\left(\\nabla_a q_\\mu(S,a)\\right)_{\\vert a=\\mu(S)}]\\]注意到其中并没有包含动作的分布 $A$，也就是说，确定性策略梯度是一个 off-policy 算法。并不要求我们必须按照哪个采样某个动作，因此可以使用任意行为策略 $\\beta$ 进行采样。  DPG 的缺点很明显，对于每个状态，下一步的动作是确定的。这就导致只能做利用而不能做探索。这可能也是为什么要做 off-policy 的原因。我们可以设置行为策略为一个随机策略，采样后优化确定性的目标策略。  更进一步，行为策略往往被设置为 $\\beta = \\mu + N$ 的形式，其中 $N$ 为随机噪声。此时就可以避免周期性的硬拷贝，随着确定性目标策略 $\\mu$ 得到优化，行为策略也随之得到优化。当价值函数用线性函数近似时，即为 DPG 论文给出的原始方法。当使用深度神经网络时，该方法就变为 DDPG。对于 DDPG 方法，其价值网络的更新部分不变\\[\\omega_{t+1} = \\omega_t - \\alpha_{\\omega} \\delta_t \\nabla_{\\omega}q(s_t,a_t;\\omega_t)\\]而策略网络的参数更新式为\\[\\theta_{t+1} = \\theta_t + \\alpha_\\theta \\nabla_\\theta \\mu(s;\\theta)\\left( \\nabla_a q(s_t, a; w_{t+1}) \\right)_{\\vert a=\\mu(s_t)}\\]6. 参考文献[1] 静静的喝酒. CSDN 策略梯度方法介绍——Value-Based强化学习方法 VS Policy-Based强化学习方法[2] 静静的喝酒. CSDN 策略梯度方法介绍——策略梯度定理推导过程[3] 静静的喝酒. 策略梯度方法介绍——蒙特卡洛策略梯度方法(REINFORCE)[4] Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction"
  },
  
  {
    "title": "如何清理 .git 文件夹来减小 github 仓库大小",
    "url": "/posts/linux-reduce-repo-size-through-git-folder/",
    "categories": "Knowledge",
    "tags": "github, git, linux, windows",
    "date": "2023-09-18 13:58:19 +0800",
    





    
    "snippet": "本文介绍了如何清理github本地缓存文件夹来减小 github 仓库大小。  1. github          1.1. git 命令      1.2. github 桌面      1.3. .git 文件夹        2. .git 文件夹清理          2.1. Linux 环境命令行清理      2.2. 跨平台 BFG 工具清理        3. 参考文献1...",
    "content": "本文介绍了如何清理github本地缓存文件夹来减小 github 仓库大小。  1. github          1.1. git 命令      1.2. github 桌面      1.3. .git 文件夹        2. .git 文件夹清理          2.1. Linux 环境命令行清理      2.2. 跨平台 BFG 工具清理        3. 参考文献1. github1.1. git 命令1.2. github 桌面1.3. .git 文件夹git 是增量更新模式，所有改动都会保存在 .git 隐藏文件夹内。.git 文件夹清理不会把仓库中已有的文件夹和里面的内容删除，会保留最新的一次提交，并且默认最近的一次提交是干净无误的提交。2. .git 文件夹清理2.1. Linux 环境命令行清理需要 Linux 环境。      检查仓库是否存在未提交的更改    如果仓库存在未提交的更改，会在后续操作中提示提示 Cannot rewrite branches: You have unstaged changes. 表明尝试重写分支时，有一些未暂存的更改。这意味着你在Git版本控制中，工作目录或者暂存区有一些更改还没有被添加到暂存区。因此，Git不能进行重写操作，因为这可能会导致你丢失这些未提交的更改。    可以通过以下命令检查本地仓库与云端仓库的差异，定位未提交的更改      git diff        执行命令后按 q 退出。    可以通过以下命令提交更改      git add . # 将所有文件添加到暂存区  git commit -m \"Your commit message\" # 提交你的更改        或丢弃更改      git checkout -- . # 丢弃工作目录中的所有更改            查看占用仓库大小最大的文件    bash 下执行以下命令      git rev-list --objects --all | grep -f &lt;(git verify-pack -v .git/objects/pack/*.idx| sort -k 3 -n | cut -f 1 -d \" \" | tail -N)        举例      git rev-list --objects --all | grep -f &lt;(git verify-pack -v .git/objects/pack/pack-3a121311b111a111c11111x1111f111111111111.idx| sort -k 3 -n | cut -f 1 -d \" \" | tail -10)        将在控制台输出类似如下：      344ee5dcae1xxxxx3d80daa8714ed7d16b21dxxx src/vehicles/cls_Spacecraft.cpp  98eecfdf58a0c0dc33bbfae46bxxxe5d837d5xxx src/vehicles/cls_Spacecraft_Docker.cpp  a8a5bca95b08084xxxx7160c4c5d98631f1cdxxx config/usrSpacecraft.json  e1cf4bf431f82d788fcaaaaac4ecca05503248xx winDSSimulator.exe  8932ce1bca5ba3c1ae39cxxxx054d14f15ad8xxx winDSSimulator.exe  17965fde8b22564a73addxxx10e77a815ef89xxx src/SimDynamics.cpp  33e7714xxxxaa033326648609f614837f49d2xxx winDSSimulator.exe  f3c41a010b75743fbb111161d84ebcc57ae85xxx winDSSimulator.exe  058da4754e97e910a72xxxxxxxa4d6f6513f5xxx winDSSimulator.exe  351e85631xxxx609d92523a67ca5d1e3e7f47xxx src/class/clsEarthDynamics.cpp            从历史中移除大文件    使用以下命令检查仓库中的文件个数（在执行 filter-branch 清理命令后个数会减少）      git count-objects -v        对于每次提交操作，filter-branch 命令都会使用给定的过滤器重写仓库的历史。    以下命令删除历史中存在的图像（例如 *.exe、*.json、*.jpg、*.png 和 *.gif），这些文件类型是常见的无需跟踪和回退修改的文件。      git filter-branch -f --index-filter 'git rm --cached --ignore-unmatch \"config/**.json\" \"**.exe\" \"**.jpg\" \"**.png\" \"**.gif\"' --prune-empty --tag-name-filter cat -- --all        需要注意以下几点：          git rm --cached：这个命令会从Git的索引中移除指定的文件，而不是从工作目录中移除。这意味着你的工作目录中仍然会保留这些文件的副本。如果你希望从工作目录和索引中都删除这些文件，你应该使用git rm –cached -r –ignore-unmatch…这样的命令。      文件模式：你使用的文件模式，例如 \"config/**.jpg\" 和 \"**.png\" 等，是用双引号包围的。这通常是可以正常工作的，但是如果你在文件名中有一些特殊字符或者空格，可能会导致问题。你需要确定这些模式正确匹配了你想要删除的文件。      --prune-empty：这个选项会导致Git丢弃那些没有任何修改的提交。因为你的操作可能导致一些提交没有任何修改，所以这个选项可能会被用到。      --tag-name-filter cat：这个选项会重命名所有的标签。cat命令会直接输出标签名，这意味着你的标签名字可能会改变。你需要考虑这是否是你想要的行为。      --all：这个选项会让Git处理所有的引用，包括所有分支和标签。如果你只想处理特定的分支或标签，你可以去掉这个选项。            清理仓库    清楚旧提交中不需要的日志和文件。      rm -Rf .git/refs/original  rm -Rf .git/logs/  git gc --aggressive --prune=now        将清理后的本地仓库更新到云端。      git push origin --force --all  git push origin --force --tags      2.2. 跨平台 BFG 工具清理  https://rtyley.github.io/bfg-repo-cleaner/BFG Repo-Cleaner 是一个原生 git-filter-branch 的更加简单快速的替代，基于 JDK 8+首先前往官网安装 JDK（https://www.oracle.com/java/technologies/downloads/）。然后下载 BFG（https://rtyley.github.io/bfg-repo-cleaner/）。一切准备就绪后，进入清理环节      克隆一个全新的 repo 裸仓库到本地（通过 --mirror 参数）      git clone --mirror https://github.com/[user_name]/[repo_name].git              【注意】，基于https的命令行克隆需要授权，若安装 Git 时候没有选择附带 Git Credential Manager，需要手动独立安装（https://github.com/git-ecosystem/git-credential-manager/releases），否则会失败，因为 Github 在 2021 年移除了通过账户名和密码授权的方式。裸仓库：https://git-scm.com/docs/gitglossary.html#def_bare_repository， 裸存储库通常是一个适当命名的目录，后缀为.git，没有任何受修订控制的文件的本地签出副本。也就是说，所有通常会出现在隐藏的.Git子目录中的Git管理和控制文件都直接出现在repository.Git目录中，而不包含其他文件。        将下载好的 bfg-1.14.0.jar 放置在克隆裸仓库 [repo_name].git 相同的路径，如：    ./mirror/[repo_name].git./mirror/bfg-1.14.0.jar            根据文件大小批量清除历史记录    例：清理大小超过 1M 的二进制文件      java -jar bfg-1.14.0.jar --strip-blobs-bigger-than 1M [repo_name].git            根据指定文件名清除历史记录    例：清理所有后缀为 .zip 的文件      java -jar bfg-1.14.0.jar --delete-files *.zip [repo_name].git            根据文件夹清除历史记录    例：清理文件夹 build      java -jar bfg-1.14.0.jar --delete-folders build [repo_name].git            进入 .git 目录，执行垃圾回收      cd [your_repo].git  git reflog expire --expire=now --all &amp;&amp; git gc --prune=now --aggressive            最后，执行提交操作    git push        【注意】 最后的最后，必须移除所有该仓库的本地同步内容重新同步，包括自己和他人已经同步过的该仓库。因为旧的同步仓库包含未被清理过的所有脏记录，如果某个本地同步仓库在使用 BFG 清理后进行提交，会将重新造成记录污染。因此需要删除本地同步仓库后重新同步抓取，保证清理过程不会因为其它该仓库的历史本地信息因下一次提交而被污染。当然，不要忘记，重新同步到本地后，试试 repo 能否编译通过 0.0。清理完毕，可以删除 mirror/[your_repo].git 文件夹。3. 参考文献[1] Junyong Lee. How to clean up .git folder for reducing repository size"
  },
  
  {
    "title": "在 Windows 中部署和使用 WSL 并进行跨平台 C/C++ 开发",
    "url": "/posts/linux-WSL/",
    "categories": "Knowledge",
    "tags": "c/c++, linux, wsl, windows subsystem for linux, vscode",
    "date": "2023-09-07 15:32:19 +0800",
    





    
    "snippet": "本文介绍了如何在 Windows 操作系统中适用微软官方提供的 WSL（Windows Subsystem for Linux） 工具部署 Linux 子系统。  1. 什么是 WSL          1.1. WSL 1 和 WSL 2      1.2. 例外情况（使用 WSL 1 而不是 WSL 2）        2. 安装 WSL          2.1. 安装 C/C++ 开...",
    "content": "本文介绍了如何在 Windows 操作系统中适用微软官方提供的 WSL（Windows Subsystem for Linux） 工具部署 Linux 子系统。  1. 什么是 WSL          1.1. WSL 1 和 WSL 2      1.2. 例外情况（使用 WSL 1 而不是 WSL 2）        2. 安装 WSL          2.1. 安装 C/C++ 开发环境依赖      2.2. 安装 Python 开发环境依赖                  2.2.1. 依靠第三方安装（推荐）          2.2.2. 在系统环境下安装                    2.3 配置 GUI 开发环境        3. 配置 VSCode  4. 跨系统文件存储和访问  5. 参考文献1. 什么是 WSL官方文档：https://learn.microsoft.com/zh-cn/windows/wsl/适用于 Linux 的 Windows 子系统 (WSL) 可让开发人员直接在 Windows 上按原样运行 GNU/Linux 环境（包括大多数命令行工具、实用工具和应用程序），且不会产生传统虚拟机或双启动设置开销。1.1. WSL 1 和 WSL 2            功能      WSL 1      WSL 2                  托管 VM                          完整的 Linux 内核                          完全的系统调用兼容性                          跨 OS 文件系统的性能                  WSL 1 和 WSL 2 之间的主要区别在于，是否在托管 VM 内使用实际的 Linux 内核、支持完整的系统调用兼容性以及跨 Linux 和 Windows 操作系统的性能。 WSL 2 是安装 Linux 发行版时的当前默认版本，它使用最新最好的虚拟化技术在轻量级实用工具虚拟机 (VM) 内运行 Linux 内核。从上面的比较表中可以看出，WSL 2 架构在几个方面优于 WSL 1，但跨 OS 文件系统的性能除外，对于这种情况，可通过将项目文件存储在与处理项目时运行的工具相同的操作系统上进行处理。  https://learn.microsoft.com/en-us/windows/wsl/tutorials/gui-apps注意！如果需要使用 Linux 的 GUI 程序，只能使用 WSL 2。1.2. 例外情况（使用 WSL 1 而不是 WSL 2）我们建议使用 WSL 2，因为它提供更快的性能和100% 的系统调用兼容性。 但是，在某些特定情况下，你可能会更倾向于使用 WSL 1。 在以下情况下，请考虑使用 WSL 1：  你的项目文件必须存储在 Windows 文件系统中。 WSL 1 可以更快地访问从 Windows 装载的文件。如果你将使用 WSL Linux 分发版来访问 Windows 文件系统上的项目文件，并且这些文件无法存储在 Linux 文件系统上，那么，通过使用 WSL 1，你将跨 OS 文件系统实现更快的性能。  一个项目要求对相同的文件使用 Windows 和 Linux 工具进行交叉编译。在 WSL 1 中，跨 Windows 和 Linux 操作系统的文件性能比 WSL 2 中更快，因此如果要使用 Windows 应用程序来访问 Linux 文件，则目前通过 WSL 1 可实现更快的性能。  你的项目需要访问串行端口或 USB 设备。 但是，现在可通过 USBIPD-WIN 项目为 WSL 2 提供 USB 设备支持。 有关设置步骤，请参阅连接 USB 设备。  WSL 2 不支持访问串行端口。 有关详细信息，请参阅常见问题解答或 WSL GitHub 存储库中有关串行支持的问题。  有严格的内存要求WSL 2 的内存使用量会随使用而缩放。 当进程释放内存时，这会自动返回到 Windows。 但从现在开始，在关闭 WSL 实例前，WSL 2 还不会将内存中缓存的页面释放回 Windows。 如果你有长时间运行的 WSL 会话或访问非常大量的文件，此缓存可能会耗尽 Windows 内存。 我们通过 WSL GitHub 存储库问题 4166 跟踪工作以改善此体验。  对于使用 VirtualBox 的用户，你可能需要考虑你正在运行的版本以及它是否与 WSL 2 兼容。 （有关完整讨论，请参阅 WSL GitHub 存储库问题 798。VirtualBox v6.1.16 似乎适用于 WSL 2，但其他版本可能遇到问题。）  如果依赖 Linux 发行版在与主机相同的网络中拥有 IP 地址，则可能需要设置一种替代方法来运行 WSL 2。 WSL 2 作为 hyper-v 虚拟机运行。 这是对 WSL 1 中使用的桥接网络适配器的更改，这意味着 WSL 2 使用网络地址转换 (NAT) 服务作为其虚拟网络，而不是将其桥接到主机网络接口卡 (NIC)，从而生成唯一的将在重启时更改的 IP 地址。 要详细了解将 WSL 2 服务的 TCP 端口转发到主机 OS 的问题和缓解措施，请参阅 WSL GitHub 存储库问题 4150，NIC 桥接模式（TCP 缓解措施）。2. 安装 WSL启动运行（Win+R）依次输入以下命令。  开启 WSL 服务dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart  开启虚拟化服务dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart  设置 WSL 的默认架构为 WSL 2，这将使你安装的任何新发行版初始化为 WSL 2 发行版（WSL 1 类似）。wsl set-default-version 2      选用下面两种命令中的一种直接安装 WSL                  直接安装 WSL（依赖系统更新来更新 WSL）        wsl --installwsl --install -d Ubuntu-22.04    //&lt;--可能需要指定distribution                            或者 直接安装 WSL 2（依赖 Windows Store 更新包来更新 WSL）        wsl.exe --install                            若提示 安全频道支持出错 则启动运行（Win+R）输入 inetcpl.cpl，在弹出的 Internet属性 窗口，切换至 高级 选项卡，找到设置中的 使用TLS 1.2 最后点 应用 保存，然后重新尝试上述命令安装即可。                  设置密码    使用 WSL 安装 Linux 发行版的过程完成后，会弹出一个新的控制台窗口，创建 Linux 账户和密码。若没有自动弹出，可以使用 “开始” 菜单打开该发行版（默认情况下为 Ubuntu）。 系统将要求你为 Linux 发行版创建“用户名”和“密码”。          此用户名和密码特定于安装的每个单独的 Linux 分发版，与 Windows 用户名无关。      请注意，输入 密码时，屏幕上不会显示任何内容。 这称为盲人键入。 你不会看到你正在键入的内容，这是完全正常的。      创建用户名和密码后，该帐户将是分发版的默认用户，并将在启动时自动登录。      此帐户将被视为 Linux 管理员，能够运行 sudo (Super User Do) 管理命令。      在 WSL 上运行的每个 Linux 发行版都有其自己的 Linux 用户帐户和密码。 每当添加分发版、重新安装或重置时，都必须配置帐户。      忘记用户账户密码可以通过在 Windows 下进入 root 账户重新设置        wsl.exe --user rootpasswd [your_user_name]                          更新 WSL（若要使用GUI程序请务必更新）  在 Windows 下wsl --updatewsl --shutdown在 WSL 中sudo apt update &amp;&amp; sudo apt upgrade2.1. 安装 C/C++ 开发环境依赖在 WSL 控制台（VScode远程模式下的终端）安装如下程序包，配置 Linux 下的 C/C++ 开发环境：sudo apt-get install build-essentialsudo apt-get install gdbsudo apt-get install cmake2.2. 安装 Python 开发环境依赖2.2.1. 依靠第三方安装（推荐）参考官网（https://docs.conda.io/projects/miniconda/en/latest/） 安装 miniconda 环境mkdir -p ~/miniconda3wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.shbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3rm -rf ~/miniconda3/miniconda.sh安装完毕后输入以下命令初始化控制台~/miniconda3/bin/conda init bash查询 conda 版本，确认是否安装成功conda -V换源nano ~/.condarc然后在弹出的编辑界面粘贴以下代码channels:  - defaultsshow_channel_urls: truechannel_alias: https://mirrors.tuna.tsinghua.edu.cn/anacondadefault_channels:  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2custom_channels:  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud最后使用 CTRL + X 保存退出，然后更新缓存sudo apt-get update然后依次执行以下常用命令# 更新condaconda update conda # 查看虚拟环境列表conda env list# 创建虚拟环境conda create --name &lt;env_name&gt; [python_version] [package_name]conda create --name li python=3.9 # 例子# 启动环境（注意以后安装包都要先启动环境）conda activate li# 查看--安装--更新--删除包conda listconda search &lt;package_name&gt; # 查询包conda install &lt;package_name&gt;conda install package_name=1.5.0conda update package_nameconda remove package_name# pytorch 可以用pip安装，方便快捷，默认gpu版本pip3 install torch2.2.2. 在系统环境下安装如果要从 Python 源代码开始编译 Python 解释器，则需要安装如下依赖sudo apt install zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libbz2-dev liblzma-dev sqlite3 libsqlite3-dev tk-dev uuid-dev libgdbm-compat-dev如果从第三方 PPA（Personal Package Archive）安装 Pythonsudo add-apt-repository ppa:deadsnakes/ppa然后再次更新 aptsudo apt update可以看到新增的 PPA 也加入更新来源列表了Hit:1 http://security.ubuntu.com/ubuntu jammy-security InReleaseHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease                           Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                   Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease                 Hit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InReleaseReading package lists... DoneBuilding dependency tree... DoneReading state information... DoneAll packages are up to date.然后就可以安装 Python，以 3.9 版本为例（PYthon 3.10 是 Ubuntu 22.04 LTS 自带的默认 Python 3 版本因此不提供下载，但 WSL2 默认似乎没有 Python）sudo apt install python3.9然后通过以下命令确认安装是否成功（成功的话应该能看到 Python 版本号）python3.9 --version以后即可用 python3.9 来运行脚本，而不是使用 python 或者 python3。2.3 配置 GUI 开发环境安装 mesa，mesa 可以支持 glxinfo 命令，这个命令可以查看很多与显卡、OpenGL 相关的信息sudo apt-get install mesa-utils然后查看显卡是否能够识别glxinfo | grep rendering获取显卡 OpenGL 版本信息glxinfo | grep OpenGLsudo apt-get install libglfw3-dev3. 配置 VSCode  https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-vscodeVisual Studio Code以及 WSL 扩展使你能够直接从 VS Code 将 WSL 用作全职开发环境。通过下面两种方式中的一种在 WSL 下启动 VSCode：  在启动运行（Win+E）中输入 wsl 然后输入 code . 启动远程模式下的 VScode。  在Windows 中打开 VScode 然后点击左下角蓝色的 打开远程窗口 按钮。  注：在 WSL 中打开 Windows 本地的项目，Windows 中的所有路径默认在 /mnt/ 下。指令检查版本确认是否安装成功gcc -vg++ -vcmake --Versiongdb -v在 WSL 中安装需要的扩展（与 Windows 本地扩展不共享，因此需要重新安装）。根据项目需要自行选择安装：  Chinese Simplifed  WSL  C/C++  CMake  Cmake Tools  Python4. 跨系统文件存储和访问      若要在 Windows 文件资源管理器中打开 WSL 项目，请输入：explorer.exe .请确保在命令的末尾添加句点以打开当前目录。        将项目文件与计划使用的工具存储在相同的操作系统上。若想获得最快的性能速度，请将文件存储在 WSL 文件系统中，前提是使用 Linux 工具在 Linux 命令行（Ubuntu、OpenSUSE 等）中处理这些文件。 如果是使用 Windows 工具在 Windows 命令行（PowerShell、命令提示符）中工作，请将文件存储在 Windows 文件系统中。 可以跨操作系统访问文件，但这可能会显著降低性能。  例如，在存储 WSL 项目文件时：  使用 Linux 文件系统根目录：\\\\wsl$\\&lt;DistroName&gt;\\home\\&lt;UserName&gt;\\Project（比如 \\\\wsl$\\Ubuntu-22.04\\home\\zhangsan）  而不使用 Windows 文件系统根目录：C:\\Users\\&lt;UserName&gt;\\Project 或 /mnt/c/Users/&lt;UserName&gt;/Project$5. 参考文献[1] Reichtum. 【知乎】vscode wsl子系统 c++环境配置基础篇[2] 东庭揽月. 【知乎】WSL+VSCode食用指南[3] Ethan Shen. 【知乎】搭配 VS Code Remote 远程开发扩展在 WSL 下开发[4] luckyum. 【知乎】在Windows下通过VSCode和WSL编译C++程序"
  },
  
  {
    "title": "航天中的四元数以及姿态运动学",
    "url": "/posts/space-quaternion/",
    "categories": "Knowledge",
    "tags": "space, quaternion, attitude kinematics",
    "date": "2023-06-02 18:38:19 +0800",
    





    
    "snippet": "本文介绍了航天器姿态描述、姿态变换和姿态运动学中涉及的四元数表示法。  1. 基础          1.1. 矢量的正交分解      1.2. 叉乘矩阵      1.3. 坐标系定义        2. 轴角旋转  3. 姿态四元数          3.1. 四元数定义      3.2. 四元数表示旋转      3.3. 姿态四元数        4. 向量的坐标变换  5. 姿...",
    "content": "本文介绍了航天器姿态描述、姿态变换和姿态运动学中涉及的四元数表示法。  1. 基础          1.1. 矢量的正交分解      1.2. 叉乘矩阵      1.3. 坐标系定义        2. 轴角旋转  3. 姿态四元数          3.1. 四元数定义      3.2. 四元数表示旋转      3.3. 姿态四元数        4. 向量的坐标变换  5. 姿态变换与四元数乘法  6. 参考文献1. 基础1.1. 矢量的正交分解对一个矢量​ $\\boldsymbol{v}$ 进行沿单位参考轴 $\\boldsymbol{e}$ ​正交分解为两个分量，分别为平行于 $\\boldsymbol{e}$ ​的轴向分量和垂直于 $\\boldsymbol{e}$ ​的垂直分量。如下图所示。有\\[\\begin{aligned}\\boldsymbol{v}_{\\parallel} &amp;= (\\boldsymbol{e}^\\top\\boldsymbol{v})\\boldsymbol{e} = \\boldsymbol{e}\\boldsymbol{e}^\\top\\boldsymbol{v}\\\\\\boldsymbol{v}_{\\perp} &amp;= \\boldsymbol{v} - \\boldsymbol{v}_{\\parallel} = (\\boldsymbol{I} - \\boldsymbol{e}\\boldsymbol{e}^\\top)\\boldsymbol{v}\\\\\\end{aligned}\\]若平面 $\\boldsymbol{\\pi}$ 的法向量为 $\\boldsymbol{e}$，那么矢量 $\\boldsymbol{v}$ 在平面上的投影矢量 $\\boldsymbol{v}^\\prime$ 即为\\[\\boldsymbol{v}^\\prime = \\boldsymbol{v}_{\\perp} = (\\boldsymbol{I} - \\boldsymbol{e}\\boldsymbol{e}^\\top)\\boldsymbol{v}\\]从而正交投影变化矩阵为\\[\\boldsymbol{R} = \\boldsymbol{I}-\\boldsymbol{e}\\boldsymbol{e}^\\top\\]1.2. 叉乘矩阵设 $\\boldsymbol{a} = [a_1,a_2,a_3]^\\top\\in\\mathbb{R}^3,\\; \\boldsymbol{b} = [b_1,b_2,b_3]^\\top\\in\\mathbb{R}^3$，那么向量 $\\boldsymbol{a}$ 叉乘向量 $\\boldsymbol{b}$ 可表示为\\[\\boldsymbol{a}\\times\\boldsymbol{b} = \\boldsymbol{a}^\\times\\boldsymbol{b}\\]其中叉乘矩阵满足\\[\\boldsymbol{a}^\\times = \\frac{\\partial(\\boldsymbol{a}\\times\\boldsymbol{b})}{\\partial \\boldsymbol{b}} = \\begin{bmatrix}    0 &amp; -a_3 &amp; a_2\\\\    a_3 &amp; 0 &amp; -a_1\\\\    -a_2 &amp; a_1 &amp; 0\\end{bmatrix}\\]  七绝一首，速求法向量向量横着写两遍，掐头去尾留中间，交叉相乘再相减，求得向量再化简。或者写成行列式方便记忆\\(\\left |\\begin{matrix}    i &amp; j &amp; k\\\\    a_1 &amp; a_2 &amp; a_3\\\\    b_1 &amp; b_2 &amp; b_3\\\\\\end{matrix}\\right |\\)1.3. 坐标系定义在航天器相对位姿跟踪任务中，需要明确各个坐标系，并以此来描述刚体的位姿和受力情况。通常会涉及到以下几个相关坐标系。  地心惯性坐标系 $I$；  追踪航天器本体坐标系 $B$；  目标航天器本体坐标系 $T$；  期望坐标系 $D$。2. 轴角旋转  欧拉(Euler)转动定理：刚体绕定点的有限转动可以合成为绕经过该定点的某一直线的一次转动。因此，刚体的简单转动可以由旋转轴和旋转角唯一确定。旋转矩阵​ $\\boldsymbol{R}$ 可以由旋转轴和旋转角唯一确定。假设位置矢量​ $\\boldsymbol{p}$ 绕定点旋转到位置矢量 $\\boldsymbol{p}^\\prime$，旋转轴为 $\\boldsymbol{n}$，旋转角为 $\\theta$，如下图所示。可以证明，$\\boldsymbol{R}$ 可由 $\\boldsymbol{n},\\theta$ 显示表示。 从图中可以看出\\[\\boldsymbol{p}^\\prime = \\vec{OQ} + \\vec{QP^\\prime}\\]其中 $\\vec{OQ}$ 是 $\\boldsymbol{p}$ 平行于轴 $\\boldsymbol{n}$ 的轴向分量，由正交分解有\\[\\begin{aligned}\\vec{OQ} &amp;= \\boldsymbol{n}\\boldsymbol{n}^\\top\\boldsymbol{p}\\\\\\vec{QP^\\prime} &amp;= (\\cos\\theta)\\vec{QP} + (\\sin\\theta)\\vec{QP^{\\prime\\prime}}\\end{aligned}\\]又因为 $\\vec{QP}$ 是 $\\boldsymbol{p}$ 与垂直于轴 $\\boldsymbol{n}$ 的垂向分量，由正交分解有\\[\\vec{QP} = (\\boldsymbol{I} - \\boldsymbol{n}\\boldsymbol{n}^\\top)\\boldsymbol{p}\\]根据矢量叉乘运算的几何意义，有\\[\\vec{QP^{\\prime\\prime}} = \\boldsymbol{n}\\times\\boldsymbol{p} = \\boldsymbol{n}^\\times\\boldsymbol{p}\\]带入可得\\[\\vec{QP^\\prime} = \\cos{\\theta}(\\boldsymbol{I} - \\boldsymbol{n}\\boldsymbol{n}^\\top)\\boldsymbol{p}+\\sin{\\theta}\\boldsymbol{n}^\\times\\boldsymbol{p}\\]综上\\[\\boldsymbol{p}^\\prime = \\boldsymbol{n}\\boldsymbol{n}^\\top\\boldsymbol{p}+\\cos{\\theta}(\\boldsymbol{I} - \\boldsymbol{n}\\boldsymbol{n}^\\top)\\boldsymbol{p}+\\sin{\\theta}\\boldsymbol{n}^\\times\\boldsymbol{p} = \\boldsymbol{R}\\boldsymbol{p}\\]则旋转矩阵为\\[\\boldsymbol{R} = \\boldsymbol{n}\\boldsymbol{n}^\\top+\\cos{\\theta}(\\boldsymbol{I} - \\boldsymbol{n}\\boldsymbol{n}^\\top)+\\sin{\\theta}\\boldsymbol{n}^\\times\\]3. 姿态四元数3.1. 四元数定义四元数由Hamilton在1843年提出，它可以看做是复数向 $\\mathbb{R}^4$ 的推广。一个四元数定义为\\(\\mathbb{H}=\\{q:q=q_0+q_1i+q_2j+q_3k,\\; q_0,q_1,q_2,q_3\\in\\mathbb{R}\\}\\)四元数还可以表示为 $q=(q_0,\\bar{q})$，其中 $q_0\\in\\mathbb{R}$ 是标量部分，$\\bar{q} = [q_1, q_2, q_3]^\\top\\in\\mathbb{R}^3$ 是矢量部分。四元数的基本运算定义如下：共轭：$q^* = (q_0,-\\bar{q})\\in\\mathbb{H}$范数（的平方）：$\\Vert q\\Vert^2 = qq^* = q^*q=q\\cdot q=(q_0^2+\\bar{q}\\cdot \\bar{q},\\bar{0})$当四元数的范数限制为 1 时，就叫单位四元数，即\\[\\mathbb{H}^u=\\{q\\in \\mathbb{H}: q\\cdot q=(1,0,0,0)\\}\\]3.2. 四元数表示旋转三维空间中的旋转可以被认为是一个函数 $\\phi$ ，从 $\\mathbb{R}^3$ 到自身的映射。函数 $\\phi$ 要想表示一个旋转，必须在旋转过程中保持向量长度（lengths）、向量夹角（angles）和 handedness 不变。handedness 和左右手坐标系有关，例如左手坐标系中向量旋转后，仍要符合左手坐标系规则。3.3. 姿态四元数单位四元数可以用来表示两个坐标系之间的相对姿态，此时又可称其为旋转四元数。若本体坐标系 $B$ 相对于惯性系 $I$ 的姿态用欧拉旋转轴角表示为 $(\\bar{n},\\theta)$，即本体坐标系 $B$ 绕着单位轴 $\\bar{n}$ 旋转角度 $\\theta$ 到达惯性坐标系 $I$。那么本体坐标系 $B$ 相对于惯性坐标系 $I$ 的姿态四元数为\\[q_{B/I}=(cos(\\frac{\\theta}{2}),\\ sin(\\frac{\\theta}{2})\\bar{n})\\]如果旋转角度被限制在 $-180^{\\circ}&lt; \\theta &lt; 180^{\\circ}$，那么四元数标量部分可以由下式计算\\[q_0 = \\sqrt{(1-\\vert\\vert \\bar{q} \\vert\\vert ^2)}\\]注意，相对姿态轴角表示中， $(-\\bar{n},-\\theta)$ 和 $(\\bar{n},\\theta)$ 起到的旋转效果相同。带入姿态四元数定义式，可以得到惯性系相对于本体系的姿态四元数\\[q_{I/B} = q_{B/I}^*\\]即姿态四元数（单位四元数）本身与其共轭四元数互为逆变换。4. 向量的坐标变换【定理1】假设坐标系 $Y$ 相对于坐标系 $X$ 的姿态四元数为 $q_{Y/X}$，矢量 $\\bar{v}$ 再两个坐标系内的表示分别为 $\\bar{v}^Y$ 和 $\\bar{v}^X$，则有如下转换关系成立\\[v^Y = q^*_{Y/X}\\cdot v^X \\cdot q_{Y/X},\\quad v^X = q^*_{X/Y}\\cdot v^Y \\cdot q_{X/Y}\\]其中 $v^Y = [0,\\bar{v}^Y],\\ v^X = [0,\\bar{v}^X]$。上式等价为\\[v^Y = R_X^Y\\cdot v^X,\\quad v^X = R_Y^X\\cdot v^Y\\]其中，坐标系 $Y$ 到坐标系 $X$ 的坐标旋转矩阵为\\[R_Y^X = \\bar{n}\\bar{n}^\\top+\\cos\\theta(I_3-\\bar{n}\\bar{n}^\\top)+\\sin\\theta \\bar{n}^{\\times}\\]5. 姿态变换与四元数乘法假设坐标系 $A$ 相对于坐标系 $B$ 的四元数为 $q_{A/B}$，坐标系 $B$ 相对于坐标系 $C$ 的四元数为 $q_{B/C}$，那么坐标系 $A$ 相对于坐标系 $C$ 的四元数为\\[q_{A/C} = q_{A/B} \\otimes q_{B/C}\\]6. 参考文献[1] 皮皮夏. 【知乎】刚体的转动和旋转变换[2] 皮皮夏. 【知乎】四元数代数以及姿态动力学建模[3] lxycg. 【知乎】四元数和旋转(Quaternion &amp; rotation)"
  },
  
  {
    "title": "使用CMake开发C++工程",
    "url": "/posts/c-cmake-development/",
    "categories": "Tutorial, Coding",
    "tags": "vscode, c/c++, cmake, cpack, mingw64",
    "date": "2023-05-15 23:59:19 +0800",
    





    
    "snippet": "本文介绍了使用 CMake（CPack） 和 NSIS 构建并打包 C/C++ 工程项目的基本流程和方法，核心在于 CMakeLists.txt 文件的编写。  1. 引言          1.1. 传统编译      1.2. Make 编译      1.3. CMake 编译        2. 安装 CMake  3. 编写 CMakeLists.txt          3.1....",
    "content": "本文介绍了使用 CMake（CPack） 和 NSIS 构建并打包 C/C++ 工程项目的基本流程和方法，核心在于 CMakeLists.txt 文件的编写。  1. 引言          1.1. 传统编译      1.2. Make 编译      1.3. CMake 编译        2. 安装 CMake  3. 编写 CMakeLists.txt          3.1. 版本与编译选项配置      3.2. 可执行程序配置      3.3. 头文件搜索      3.4. 源文件搜索      3.5. 子项目（WIP）      3.6. others（WIP）      3.7. 生成（Generate）      3.8. 构建（Build）      3.9. 运行和调试（Debug）        4. 基于 CMake 的打包          4.1. CPack      4.2. NSIS      4.3. 基于 CPack 和 NSIS 的打包        5. 参考文献1. 引言假如我们有一个大型的 C++ 项目，由非常多的互相调用的工程共同组成，一些用于生成库文件，一些用于实现逻辑功能。他们之间的调用关系复杂而严格，如果想在这样复杂的框架下进行二次开发，显然只拥有它的源码是远远不够的，还需要清楚的明白这几十个项目之间的复杂关系。即使是原作者给出了相关的结构文档，对新手来说建立工程的过程依旧是漫长而艰辛的，开发人员的核心业务是软件开发，而不是软件构建。Cmake目的是实现软件构建流程的自动化，并且是跨平台的。原作者只需要生成一份 CMakeLists.txt 文档，框架的使用者们只需要在下载源码的同时下载作者提供的 CMakeLists.txt，就可以利用 CMake，在原作者的帮助下进行工程的搭建。Cmake 编程的过程实际上是编写 CMakeLists.txt的过程，使用的是 “Cmake” 语言和语法。1.1. 传统编译将一个C++项目从源文件编译得到可执行程序文件，需要使用C/C++编译器。较广泛使用的是 GCC（GNU Compiler Collection，GNU编译器套件），它可以编译很多种编程语言(包括C、C++、Objective-C、Fortran、Java等等)。GCC 编译的核心是 gcc 命令。对于源文件数量较少且路径单一的情况，可以直接在终端输入编译命令进行编译，示意如下：g++ -c demo.cpp -I /aaa/bbb/ -o demo.exe1.2. Make 编译当源文件越来越多时，调用 gcc/g++ 命令逐个去编译时，就很容易混乱而且工作量大。特别地，当只改动工程项目中的某一些源程序文件时，单纯使用命令编译会把所有源程序文件重新编译一遍，而逐文件编译为 .o 文件再手动确定是否需要更新和编译工作量巨大。为了简化编译操作，GNU 推出了 Make 工具。它是一个自动化编译工具，我们可以使用一条命令实现完全编译，但是需要编写一个规则文件，Make 工具依据它来批量处理编译，这个文件就是 Makefile 文件。一个典型的 Makefile 文件如下a.out: hello.o main.o    g++ hello.o main.o -o a.outhello.o: hello.cpp    g++ -c hello.cpp -o hello.omain.o: main.cpp    g++ -c main.cpp -o main.oMakefile 文件规定了每个文件的依赖关系和生成各文件的规则。这样，当某个文件的所有依赖并没有发生变化时，即可不用重新编译该文件，而是直接利用之前编译好得到的 .o 文件即可。Makefile 带来的好处就是——“自动化编译”，一旦写好，只需要一个 make 命令，整个工程完全自动编译，极大的提高了软件开发的效率。make 是一个命令工具，是一个解释 Makefile 中指令的命令工具，一般来说，大多数的 IDE 都有这个命令，比如：Delphi 的 make，Visual C++ 的 nmake，Linux 下 GNU 的 Makefile 都成为了一种在工程方面的编译方法。Makefile 在一些简单的工程完全可以人工手写，但是当工程非常大的时候，手写 Makefile 也是非常麻烦的，如果换了个平台 Makefile 又要重新修改。另一方面，若想要更换开发环境，如需要将工程迁移到 Visual Studio IDE 进行开发，需要构建基于 VS 的项目框架，生成 .sln 和 .vcproj 文件，此时 Makefile 就无能为力了。  .sln 文件（解决方案文件） 是 Visual Studio 的解决方案文件，用于组织和管理一个或多个项目。它可以包含一个或多个项目，以及这些项目之间的关系和配置信息。一个 .sln 文件本身并不包含任何代码或文件，它只是包含引用到该解决方案中所有项目的信息和设置。.sln 文件可以存储在版本控制系统中，以便多个开发人员共享和协作。.vcxproj 文件（项目文件） 是 Visual C++ 项目文件，包含项目的设置和配置信息，例如编译器选项、预处理器选项、文件列表和库依赖项等。它通常是随着每个项目的创建而生成的，并存储在项目的根目录下。每个项目都有一个单独的 .vcxproj 文件，而解决方案只包含对每个项目的引用。Makefile 的局限性还包括：  make 在 UNIX 类系统上是通用的，但是 Windows 不支持；  需要准确指出每个项目之间的依赖关系，有头文件时特别头疼；  make 语法非常简单，无法实现 shell 或 python 那样做很多判断等；  不同编译器有不同的 flag 规则，为 g++ 准备的参数可能对 msvc 并不适用。1.3. CMake 编译为了解决 make 的问题，出现了 CMake 这个跨平台工具。CMake 能够输出各种各样的 Makefile 或者 project 文件，从而帮助程序员减轻负担。CMake 通过编写 CMakeLists.txt 文件，实现跨平台生成对应能用的 Makefile 或工程文件，我们不需要自己再去修改。CMakeLists.txt 是一种平台无关的文件，用来定制整个编译流程，然后再根据目标用户的平台进一步生成所需的本地化 Makefile 和工程文件，如 Unix 的 Makefile 或 Windows 的 Visual Studio 工程。从而做到 “Write once, run everywhere”。一些使用 CMake 作为项目架构系统的知名开源项目有 VTK、ITK、KDE、OpenCV、OSG 等。2. 安装 CMake前提，已经安装有至少一个C/C++编译器，如 MinGW-W64。可以通过gcc --version 查看版本来确认安装是否成功。在 Windows 环境下，CMake 可以在官网（https://cmake.org）下载，安装后包括一个控制台程序和一个 GUI 程序。可以通过 cmake --version 检查安装情况和版本情况。在 VScode 中，需要安装以下两个插件：  CMake  CMake Tools在 Cmake Tools 插件设置中将 Cmake 的 make.exe 可执行程序完整路径设置到 cmake.cmakePath。同时将 make.exe 所在的路径添加到系统的环境变量中（因为后续用 cpack.exe 打包时候也要找路径）。使用 CMake 插件创建 CMakeLists.txt 文件（文件名一个字都不能错）。两种创建方式：      手动创建，直接在工程项目的根目录下新建一个 CMakeLists.txt 文件；        自动创建，在 VSCode 中打开工程项目文件夹，输入快捷键组合 Ctrl + Shift + P 然后输入 cmake quick start 进行快速设置。首次设置会弹出 Select a Kit 需要选择一个编译器，若正确安装 MinGW-W64 并添加了环境变量，一般会自动检索到类似 GCC XX.X.X x86-64-w64-mingw32 的编译器，注意检查后面的路径是否正确，然后选择即可。选择后即会在项目根目录下自动创建CMakeLists.txt 文件。  3. 编写 CMakeLists.txt一个 CMakeLists.txt 文件有自己的格式和命令，下面以基本的 CMakeLists.txt 为例，按照文件内从上到下的顺序逐一介绍。3.1. 版本与编译选项配置# 指定 cmake 的最低版本cmake_minimum_required(VERSION 3.10)# 设置 cmake 的 C 版本为 C99set(CMAKE_C_STANDARD 99)# 设置 cmake 的 C++ 版本为 C++11set(CMAKE_CXX_STANDARD 11)# 要求强制执行C++版本检查，若不符合则报错set(CMAKE_CXX_STANDARD_REQUIRED True)# 设置 cmake 默认编译选项为 Releaseset(CMAKE_BUILD_TYPE \"Release\" CACHE STRING \"\" FORCE)# 在控制台打印编译选项message(STATUS \"[INFO] Set to ${CMAKE_BUILD_TYPE} build.\")在 CMakeLists.txt 文件中：  采用 set(变量 文件名/路径/...) 函数给文件名/路径名或其他字符串起别名，用 ${变量} 获取变量内容；  采用 ${xxx} 来取变量的值；3.2. 可执行程序配置一个大型 C++ 项目一般包括多个子项目路径，分别实现较为独立的不同功能，假设项目路径为//test文件夹|--3rdpaty    |--glm        |--rotate.h|--include    |--a.h    |--b.h|--path1    |--add.cpp    |--add.h    |--CMakeLists.txt // path1|--function.h|--function.cpp|--main.cpp|--CMakeLists.txt // main根目录下存在 main.cpp 和 function.cpp/.h，假设他们可以完整编译为可执行程序，但需要依赖 include 文件夹中的头文件和 3rdparty 文件夹中的头文件，那么在 CMakeLists.txt(main) 中内容可写为# 指定项目名称为 testproject(test)# 编译可执行程序(test)，以及生成该程序需要的源文件add_executable(test function.cpp main.cpp    function.h include/a.h include/b.h 3rdparty/glm/rotate.h)指定了项目名后，后面可能会有多个地方用到这个项目名，如果更改了这个名字，就要改多个地方，比较麻烦，那么可以使用 PROJECT_NAME 来表示项目名。即add_executable(${PROJECT_NAME} function.cpp main.cpp    function.h include/a.h include/b.h 3rdparty/glm/rotate.h)至此，就可以构建和运行项目了，即先运行 cmake 命令来构建项目，然后使用编译工具进行编译。以 Windows 平台控制台为例，输入以下命令即可完成构建。mkdir buildcd buildcmake -G\"MinGW Makefiles\" ..cmake --build .其中，  第一行命令：手动创建了 build 文件夹；  第二行命令：前往 build 目录下；  第三行命令：进行工程项目的构建。          Windows 下，CMake 默认使用微软的 MSVC 作为编译器，若想使用 MinGW 编译器，可以通过 -G 参数来进行指定，只有第一次构建项目时需要指定；      构建系统需要指定项目 CMakeLists.txt（main）所在路径，所以用 .. 表示 CMakeLists.txt 在上一级目录（因为第二行命令已经进入了 build 目录）。        第四行命令：在 build 目录下会生成 Makefile 文件，最后调用编译器来实际编译和链接项目。          --build 指定编译生成的文件存放目录，其中就包括可执行文件；      . 表示存放目录为当前目录。如果一切顺利，在 build 目录下会生成 test.exe 可执行文件。      3.3. 头文件搜索为了避免繁琐的头文件列写过程，我们可以 add_executable() 后，指定其头文件搜索路径add_executable(${PROJECT_NAME} function.cpp main.cpp)# 添加当前根目录为头文件搜索路径target_include_directories(${PROJECT_NAME} PRIVATE .)# 添加 include 目录为头文件搜索路径target_include_directories(${PROJECT_NAME} PRIVATE include)# 添加 include/glm 目录为头文件搜索路径target_include_directories(${PROJECT_NAME} PRIVATE 3rdparty/glm)PRIVATE 表示隐式包含，此时后面给出的头文件搜索路径只能被当前 ${PROJECT_NAME} 所使用。如果选择 PUBLIC 则后续其他可执行程序等也都可以使用。为了保证高内聚低耦合的特点，建议尽量使用 PRIVATE。可以看出，为了包含头文件搜索路径，我们需要写很多次重复语句，其实也可以一条语句里面包含若干个路径。为了简化头文件搜索路径定义，我们可以采用如下两种方式      （1）自动导出头文件路径列表    add_executable(${PROJECT_NAME} function.cpp main.cpp)# 从根目录下开始遍历寻找所有头文件，存到 all_h 列表file(GLOB_RECURSE all_h ./*.h)foreach(HEADER ${all_h})# 对于每一个头文件，得到其路径 h_pathget_filename_component(h_path ${HEADER} DIRECTORY)# 将路径添加到 h_dirs 列表 list(APPEND h_dirs ${h_path})endforeach()# 对 h_dirs 列表去除重复项list(REMOVE_DUPLICATES h_dirs)# 将 h_dirs 添加项目 test 的头文件搜索路径target_include_directories(${PROJECT_NAME} PRIVATE ${h_dirs})        优点：当新添加头文件时，可以自动更新搜索路径    缺点：若源程序文件中显式给出了头文件的相对路径包含关系，如#include &lt;glm/rotate.h&gt;，此时需要的头文件搜索路径为 ./3rdparty。但是因为该路径下没有头文件，自动导出的路径不会包含该路径。这种情况下会出现链接错误，提示找不到头文件。        （2）手动设置头文件路径列表    add_executable(${PROJECT_NAME} function.cpp main.cpp)# 显式添加头文件搜索路径到列表 h_dirslist(APPEND h_dirs  ./  ./include  ./3rdparty)# 将 h_dirs 添加项目 test 的头文件搜索路径target_include_directories(${PROJECT_NAME} PRIVATE ${h_dirs})        优点：可以更好配合头文件引用关系    缺点：需要手动维护头文件路径列表，路径多了列表会很长  一般鼓励大家第二种方法，因为项目的头文件列表就推荐显式维护，便于开发者掌控项目的头文件依赖关系，避免引入不需要使用的头文件。特别是当项目依赖多种多样的第三方库时，每个第三方库对其头文件的包含形式都不一样，如#include \"aaa.h\"#include &lt;bb/ccc.h&gt;#include &lt;../cc/ddd.h&gt;这种情况下，就需要特别注意头文件搜索路径，保证每个头文件都能搜索到。3.4. 源文件搜索可以看到，add_executable() 仍然需要列写很多源文件，这在大型工程项目中也十分繁琐，可以采用与头文件类似的方法对源文件进行搜索，同样也包含两种搜索方式，这里以第一种方式举例说明。file(GLOB_RECURSE all_c ./*.c ./*.cpp) # 遍历搜索 .c 和 .cpp 文件添加到 all_cadd_executable(${PROJECT_NAME} ${all_c})target_include_directories(${PROJECT_NAME} PRIVATE ${h_dirs})注意，源文件不是遍历其路径，而是需要直接显式指定到文件，因此不再需要 get_filename_component() 操作。针对源文件还有一种新的搜索方式如下。aux_source_directory(./ ./path1 all_c) # 将目录 ./ 和 ./path 中的所有源文件添加到 all_cadd_executable(${PROJECT_NAME} ${all_c})target_include_directories(${PROJECT_NAME} PRIVATE ${h_dirs})aux_source_directory 函数会搜索指定目录下的所有源文件，并将它们的文件名（包括路径）存储在变量variable中。这个函数会自动将所有符合条件的源文件添加到变量中，所以你不需要手动一个一个地列举所有的源文件。最后，若某个路径下存在项目不需要的源文件，可以手动指定去除。以去除 add.cpp 为例，在 add_executable() 之前插入以下命令list(REMOVE_ITEM all_c ./path1/add.cpp)3.5. 子项目（WIP）CMake 同样可以管理多个子项目路径构成的复杂 C/C++ 工程。通过子项目路径下的 CMakeLists.txt（path1）文件联合根目录下的  CMakeLists.txt（main）进行配置####### CMakeLists.txt (main)# 添加子项目路径 path1add_subdirectory(path1)add_executable(test function.cpp main.cpp function.h ${path1src})####### CMakeLists.txt (path1)set(path1src path1/add.cpp path1/add.h)3.6. others（WIP）  project(xxx)，必须  add_subdirectory(子文件夹名称)，若父目录包含多个子目录则必须  add_library(库文件名称 STATIC 文件)，通常子目录(二选一)  add_executable(可执行文件名称 文件)，通常父目录(二选一)  include_directories(路径)，必须  link_directories(路径)，非必须  target_link_libraries(库文件名称/可执行文件名称 链接的库文件名称)，必须一个典型的 CMakeLists.txt 文件如下：cmake_minimum_required(VERSION 3.0.0) # 设置最小的cmake版本号set(PROJECT_NAME \"myproject\") # 设置工程名称project(${PROJECT_NAME} VERSION 0.2.0) # 设置工程版本set(CMAKE_C_STANDARD 99) # 设置C标准set(CMAKE_CXX_STANDARD 11) # 设置C++标准include(CTest)enable_testing()set(CMAKE_VERBOSE_MAKEFILE \"ON\") # 启用详细打印，方便查看bug### 通过遍历来搜寻所有 .h 文件，并保存到 all_h 变量中# ${PROJECT_SOURCE_DIR} 是默认的工程根目录file(GLOB_RECURSE all_h        ${PROJECT_SOURCE_DIR}/src/**.h)### 遍历每个 .h 文件（这段抄的网上的）foreach(file  ${all_h})    # 找到文件的上级路径    string(REGEX REPLACE \"/$\" \"\" CURRENT_FOLDER_ABSOLUTE ${file})    string(REGEX REPLACE \"(.*/)(.*)\" \"\\\\1\" CURRENT_FOLDER ${CURRENT_FOLDER_ABSOLUTE})    list(APPEND include_h  ${CURRENT_FOLDER})endforeach()### 删除冗余路径list(REMOVE_DUPLICATES  include_h) # 得到去冗的所有包含 .h 文件的路径，存到 include_h 变量# MESSAGE(\"include_directories\"  ${include_h}) # 打印所有包含 .h 文件的路径# 规定 .h 文件的路径include_directories(${include_h})### 遍历所有 .c/.cpp 文件，存到 ALL_SRC 变量中file(GLOB_RECURSE ALL_SRC    ${PROJECT_SOURCE_DIR}/src/**.c    ${PROJECT_SOURCE_DIR}/src/*.cpp    )# MESSAGE(\"add_executable\"  ${ALL_SRC}) # 打印# 把所有.c/.cpp 文件添加到名字为 ${PROJECT_NAME} 的可执行程序中if(WIN32)    set(RESOURCE_FILES res.rc) # add iconendif()add_executable(${PROJECT_NAME} ${ALL_SRC} ${RESOURCE_FILES})### 定义宏定义来控制工程中的一些功能# 比如代码里通过 #ifdef AASSAA aaa #else bbb# 那么就可以通过 `-DAASSAA` 传给编译器进行宏定义# 等价于代码中写 `#define DAASSAA`add_definitions(-D__INFO__)add_definitions(-D__CLEAN__)### 如果是Windows环境if(WIN32)    # 对 add_library 或 add_executable 生成的文件进行链接操作    # 这里额外链接 TCP 通讯所需的 winsock2.h 依赖的 ws2_32.lib    target_link_libraries(${PROJECT_NAME} ws2_32)    ### 安装（linux中的sudo apt install 的概念，win中不知道是啥）    if(MINGW) # 根据Windows的环境变量得到mingw64的安装位置，然后得到bin文件夹        find_program(MINGW_EXECUTABLE mingw32-make.exe PATH $ENV{PATH} REQUIRED)        get_filename_component(MINGW_BIN ${MINGW_EXECUTABLE} DIRECTORY)        set(EXTRA_DLL # 注意，这里最好使用Depends工具来查看exe程序依赖哪些第三方dll，然后逐一添加            \"${MINGW_BIN}/libstdc++-6.dll\"            \"${MINGW_BIN}/libgcc_s_seh-1.dll\"            \"${MINGW_BIN}/libwinpthread-1.dll\"        )        # 将依赖的dll文件拷贝到安装路径（目前支持seh异常模型版本的mingw64）        install(FILES ${EXTRA_DLL} DESTINATION .)    endif()    # 将可执行程序打包到（将来安装位置的）根目录    install(TARGETS ${PROJECT_NAME} DESTINATION .)    # 将一些额外的资源文件夹，配置文件（夹）等拷贝到目标目录    # 文件夹用 'DIRECTORY' ， 文件用 'FILES'    install(DIRECTORY ${PROJECT_SOURCE_DIR}/data/ DESTINATION data)    install(DIRECTORY ${PROJECT_SOURCE_DIR}/config/ DESTINATION config)    install(DIRECTORY ${PROJECT_SOURCE_DIR}/res/ DESTINATION res)    set(CMAKE_INSTALL_SYSTEM_RUNTIME_DESTINATION \".\") # 不知道有没有用，先放着了    include(InstallRequiredSystemLibraries) # 不知道有没有用，应该有用，把系统dll打包到exe    ### 打包    # set(CPACK_INSTALL_PREFIX \"/home/DSS\") # 给linux用的，大概把？    # 设置一些名字    set(CPACK_PACKAGE_NAME ${PROJECT_NAME})    set(CPACK_PROJECT_NAME ${PROJECT_NAME})    set(CPACK_PROJECT_VERSION ${PROJECT_VERSION})    set(CPACK_CMAKE_GENERATOR \"MinGW Makefiles\") # 如果前面用了自动生成CMakeLists.txt，这里也可以不写    set (CPACK_RESOURCE_FILE_LICENSE          \"${CMAKE_CURRENT_SOURCE_DIR}/LICENSE\") # 如果工程没有License文件也可以不写    set(CPACK_PACKAGE_VERSION_MAJOR \"${${PROJECT_NAME}_VERSION_MAJOR}\") # 大版本号    set(CPACK_PACKAGE_VERSION_MINOR \"${${PROJECT_NAME}_VERSION_MINOR}\") # 小版本号    set(CPACK_SOURCE_GENERATOR \"TGZ\") # 压缩方式，我随便写了一个，支持很多种    ### 在 Windows 环境种，采用开源的 NSIS 来构建安装程序    set(CPACK_GENERATOR NSIS)    set(CPACK_NSIS_PACKAGE_NAME \"${PROJECT_NAME}\")    set(CPACK_NSIS_DISPLAY_NAME \"${PROJECT_NAME}\")    # 添加ico文件给打包的安装程序    set(CPACK_PACKAGE_ICON \"${CMAKE_CURRENT_SOURCE_DIR}\\\\\\\\DSSimulator.ico\")    set(CPACK_NSIS_MUI_ICON \"${CMAKE_CURRENT_SOURCE_DIR}\\\\\\\\DSSimulator.ico\")    ### 用来告诉安装程序，卸载的时候需要额外删掉前面 install 时额外加入的 资源文件（夹）和 dll 等    # 这里采用函数的形式（百度抄的），也可以在外部编写 '.nsi'文件然后引用进来（听着就麻烦）    function(uninstall_extra)        foreach(file IN LISTS ARGN)            if(IS_DIRECTORY \"${file}\")                set(command \"rmdir /s /q \\\"$INSTDIR\\\\\\\\${file}\\\"\")            else()                set(command \"del /f /q \\\"$INSTDIR\\\\\\\\${file}\\\"\")            endif()            set(CPACK_NSIS_EXTRA_UNINSTALL_COMMANDS \"${CPACK_NSIS_EXTRA_UNINSTALL_COMMANDS}\\n !system '${command}'\")        endforeach()    endfunction()    if(MINGW) # delete all things in install directory        uninstall_extra(\"$INSTDIR\")    endif()endif()# 这句话必须要有哦include(CPack)### 这是用来提示自己的命令行的命令，不然老年痴呆记不住# cmake --build . --target install --verbose# cpack.exe .\\CPackConfig.cmake  采用 aux_source_directory(路径 变量) 可获取路径下所有的.cpp/.c/.cc文件（不包括子目录），并赋值给变量;  采用 add_compile_definitions(xxx=1) 可以给宏具体值，但是只有高版本的cmake支持，等价于 #define xxx 1；  采用 add_subdirectory(子文件夹名称) 编译子文件夹的 CMakeLists.txt；  如果需要将工程编译为静态库，那么使用 add_library(库文件名称 STATIC 文件)。注意，库文件名称通常为 libxxx.so，在这里要去掉前后缀写 xxx 即可；  规定 .so/.a 库文件路径使用 link_directories(路径)；3.7. 生成（Generate）我们一般会在 CMakeLists.txt 所在的目录下（一般也就是工程项目的根目录）手动新建一个 build 文件夹，这将用于存储 CMake 构建的中间文件和生成的目标文件。这种方式实际上是 cmake 的 out-of-source 构建方式。这种方法可以保证生成中间产物与源代码分离（即生成的所有目标文件都存储在 build 文件夹中，因此不会干扰源代码中的任何文件）。采用命令行的方式可操作如下mkdir buildcd buildcmake ..make若使用 VSCode 并安装了合适的插件，那么在使用快捷键 Ctrl+S 保存 CMakeLists.txt 时，会自动生成生成项目构建所需的中间文件。配置和生成过程如下图所示。生成完毕得到的中间文件如下图所示。3.8. 构建（Build）采用 CMake 构建项目有三种方式：  方式1：打开命令板（Ctrl+Shift+P）并运行 CMake：Build；  方式2：或从底部状态栏中点击”build”按钮；  方式3：打开命令行窗口（快捷键 Ctrl + ~ ）输入 cmake --build build；下图是采用方式2进行构建的示意图。3.9. 运行和调试（Debug）运行和调试项目，打开某个源代码文件，并设置一个断点。然后打开命令板（Ctrl+Shift+P），并运行 CMake： debug，然后按 F5 继续调试。或者点击 VSCode 下方的 【虫子】 图标进行 DEBUG 调试。4. 基于 CMake 的打包4.1. CPackCPack 是 CMake 2.4.2 之后的一个内置工具，用于创建软件的二进制包和源代码包。CPack 在整个 CMake 工具链的位置如下图所示。CPack 支持打包的包格式有以下种类：  7Z (7-Zip file format)  DEB (Debian packages)  External (CPack External packages)  IFW (Qt Installer Framework)  NSIS (Null Soft Installer)  NSIS64 (Null Soft Installer (64-bit))  NuGet (NuGet packages)  RPM (RPM packages)  STGZ (Self extracting Tar GZip compression  TBZ2 (Tar GZip compression)  TXZ (Tar XZ compression)  TZ (Tar Compress compression)  ZIP (ZIP file format)为什么要用打包工具：软件程序想要在生产环境快速被使用，就需要一个一键安装的安装包，这样生产环境就可以很方便的部署和使用。生成一键安装的安装包的工具就是打包工具。其中 NSIS 是 Windows 环境下使用的打包工具。选择 CPack 的原因：C++ 工程大部分都是用 CMake 配置编译， 而 CPack 是 CMake 内置的工具，支持打包成多种格式的安装包。因为是 CMake 的内置工具，所以使用的方式也是通过在 CMakeLists.txt 配置参数，就能达到我们的需求。使用起来很方便，容易上手。如何安装 CPack：安装 CMake 的时候会把 CPack 一起安装了。4.2. NSIS官网下载最新版本并安装：https://nsis.sourceforge.io/Download。NSIS是开发人员创建 Windows 下安装程序的工具。它可以创建能够安装、卸载、设置系统设置、提取文件等的安装程序。NSIS允许您创建从只复制文件的基本安装程序到处理许多高级任务（如编写注册表项、设置环境变量、从internet下载最新文件、自定义配置文件等）的非常复杂的安装程序的所有内容。NSIS基于脚本文件，支持变量、函数和字符串操作，就像一种普通的编程语言一样，但它是为创建安装程序而设计的。在默认选项下，它的开销只有34kb。同时由于其强大的脚本语言和对外部插件的支持，仍然提供了许多选项。安装完成后，NSIS 具备一个 GUI，但是我一般不用，而是直接通过 CMakeLists.txt 文件调用 NSIS 进行打包。如果需要使用 GUI 来辅助生成打包脚本，参考 此处。4.3. 基于 CPack 和 NSIS 的打包完成项目构建后, 你会发现 build 目录下面多了两个文件 CPackConfig.cmake 和 CPackSourceConfig.cmake。在终端执行以下命令完成打包，得到可执行安装程序。cpack.exe .\\CPackConfig.cmake将安装程序分发到其它 Windows 平台即可完成安装。注意，若发布的安装程序在完成安装后，提示缺少某个 dll 文件，那么需要重新更改 CMakeLists.txt 文件，将相应的 dll 文件进行安装。最好使用dll依赖查询工具来查看编译得到的可执行程序（.exe）依赖哪些第三方dll，然后逐一添加。可选的工具包括 Dependencies。5. 参考文献[1] maskerII. 【简书】CMakeLists 入门[2] TomKing-tm. vsCode+CMake开发环境搭建[3] 双笙子佯谬. 现代C++中的高性能并行编程与优化[4] 魔豆的BLOG. 使用NSIS制作安装包"
  },
  
  {
    "title": "强化学习（值函数近似）",
    "url": "/posts/reinforcement-learning-Value-Approximation/",
    "categories": "Academic, Knowledge",
    "tags": "artificial intelligence, reinforcement learning",
    "date": "2023-01-02 18:12:19 +0800",
    





    
    "snippet": "本文首先介绍了值函数近似（Value Approximation），然后分别结合 SARSA 和 Q-Learning 给出了两种 Q 函数近似的方法。通过分析线性函数作为估计函数的局限性，自然引入神经网络来进行非线性函数近似，引出了基于深度学习的 Q 函数估计网络：Deep Q-Network（DQN）。  1. 引言  2. 状态价值函数近似          2.1. 目标函数    ...",
    "content": "本文首先介绍了值函数近似（Value Approximation），然后分别结合 SARSA 和 Q-Learning 给出了两种 Q 函数近似的方法。通过分析线性函数作为估计函数的局限性，自然引入神经网络来进行非线性函数近似，引出了基于深度学习的 Q 函数估计网络：Deep Q-Network（DQN）。  1. 引言  2. 状态价值函数近似          2.1. 目标函数      2.2. 优化算法      2.3. 估计函数设计                  2.3.1. 采用线性函数          2.3.2. 线性函数实例分析          2.3.3. 采用神经网络                      3. 状态动作价值函数近似          3.1. SARSA 值函数近似      3.2. Q-Learning 值函数近似        4. Deep Q-Learning（DQN）          4.1. 损失函数      4.2. 优化方法                  4.2.1. 分离拷贝          4.2.2. 经验回放（experience replay）                    4.3. 算法流程      4.4. 实例分析      4.5. 过高估计（Double DQN）      1. 引言前面介绍的 TD 算法都仅针对对离散的（表格形式的）状态和动作进行研究，但实际应用中的场景可能会很复杂，很难定义出离散的状态；即使能够定义，数量也非常大，无法用数组存储。对于强化学习来说，很多实际应用问题的输入数据是高维的，如图像，声音，算法要根据它们来选择一个动作执行以达到某一预期的目标。比如，对于自动驾驶算法，要根据当前的画面决定汽车的行驶方向和速度。经典的强化学习算法如 Q-Learning 需要列举出所有可能的情况（称为状态，这是对当前所处环境的抽象），然后进行迭代。 Q-Learning 的经典实现是列举出所有的状态和动作，构建 Q-Table，这是一个二维的表，然后迭代计算各种状态下执行各种动作的预期回报的最大值。对于高维的输入数据，显然是不现实的，因为如果直接以原始数据作为状态，维数太高，而且状态数量太多。另一种方案是用一个函数来逼近价值函数，函数的输入是原始的状态数据，函数的输出是价值函数值。在有监督学习中，我们用神经网络来拟合分类或回归函数，因此当然也可以用神经网络可来拟合强化学习中的价值函数。2. 状态价值函数近似给定策略 $\\pi$，假设 $v_\\pi(s)$ 和 $\\hat{v}_\\pi(s,w)$ 分别为状态 $s$ 的价值函数与其函数估计。我们的目标是找到最优的参数 $w$，使得在任意状态 $s$ 下，状态价值函数的估计 $\\hat{v}(s,w)$ 都接近其真实值。这本质上是一个策略估计问题，具体可分为以下两步：  定义目标函数；  找到合适的算法优化这个目标函数；  确定状态价值函数的估计 $\\hat{v}(s,w)$ 的具体实现方式（线性？非线性？神经网络？）。2.1. 目标函数很显然，我们希望所有状态的状态价值函数的估计 $\\hat{v}(s,w)$ 接近其真实值，这是一种距离度量，那么目标函数设计为\\[J(w) = \\mathbb{E}_{\\mathcal{S}}[(v_\\pi(s)-\\hat{v}(s,w))^2] = \\Vert v_\\pi - \\hat{v} \\Vert^2_D\\]  $D$ 为状态的分布 $D_\\pi$，则上式还可写为 $(v_\\pi - \\hat{v})^\\top D (v_\\pi - \\hat{v})$下面讨论如何采取合适的近似方法消除期望符号。一种直觉方法是对所有状态进行平均。如果我们认为所有状态的权重都相同，那么采用 均匀分布（uniform distribution）进行加权，目标函数可以改写为\\[J(w) =\\textcolor{red}{\\frac{1}{\\vert\\mathcal{S}\\vert}}\\sum_{s\\in\\mathcal{S}} (v_\\pi(s)-\\hat{v}(s,w))^2\\]但在强化学习中，很明显状态的重要性是不一样的，比如 Grid World 场景中的终点状态和靠近终点的状态显然更加重要，而远离终点的某些状态可能没那么重要。因此，我们需要采用 平稳分布（stationary distribution）进行加权，目标函数改写为\\[J(w) = \\sum_{s\\in\\mathcal{S}} \\textcolor{red}{d_\\pi(s)} (v_\\pi(s)-\\hat{v}(s,w))^2\\]其中，  $d_\\pi(s)$ 为策略 $\\pi$ 下马尔可夫过程的平稳分布，其定义为 $d_\\pi(s)\\geq 0,\\; \\sum_{s\\in\\mathcal{S}}d_\\pi(s) = 1$；          平稳分布刻画了马尔可夫过程长期迭代后，各个状态出现的（被访问的）概率；      平稳分布描述了马尔可夫过程的长期行为（long-run behaviour）；      马尔可夫链可能存在唯一平稳分布，无穷多个平稳分布，或不存在平稳分布；        上述目标函数是一个带权重的均方误差，某个状态的出现概率越大，其误差的权重越大。根据上述定义，策略 $\\pi$ 下经过长马尔可夫采样回合后，假设状态 $s$ 被采样到了 $n_\\pi(s)$ 次，平稳分布可由下式估计\\[d_\\pi(s) \\approx \\frac{n_\\pi(s)}{\\sum_{s^\\prime\\in\\mathcal{S}}n_\\pi(s^\\prime)}\\]从其经过长期状态转移后的不变性的角度考虑，已知状态转移矩阵 $P_\\pi = p(s^\\prime \\vert s, a)$，平稳分布必然满足如下等式\\[d_\\pi^T = d_\\pi^T P_\\pi\\]也即，平稳分布就是状态转移矩阵特征值为 1 的特征向量。2.2. 优化算法由于我们希望最小化上述目标函数，很自然想到使用 梯度下降法\\[w_{k+1} = w_k - \\alpha_w \\nabla J(w_k)\\]其中梯度为\\[\\begin{aligned}\\nabla_w J(w) &amp;= \\nabla_w\\mathbb{E}[(v_\\pi(s)-\\hat{v}(s,w))^2]\\\\&amp;= \\mathbb{E}[\\nabla_w(v_\\pi(s)-\\hat{v}(s,w))^2]\\\\&amp;= -2\\mathbb{E}[(v_\\pi(s)-\\hat{v}(s,w))\\nabla_w\\hat{v}(s,w)]\\end{aligned}\\]为了避免在真实梯度计算中计算期望，很自然想到采用 随机梯度 代替 真实梯度，即\\[\\begin{aligned}w_{t+1} &amp;= w_t + 2\\alpha_t\\mathbb{E}[(v_\\pi(s)-\\hat{v}(s,w))\\nabla_w\\hat{v}(s,w)]\\\\\\Rightarrow w_{t+1} &amp;= w_t + 2\\alpha_t(v_\\pi(s_t)-\\hat{v}(s_t,w_t))\\nabla_w\\hat{v}(s_t,w_t)\\end{aligned}\\]注意到，实际使用中，上述梯度下降迭代式要求状态价值函数 $v_\\pi(s_t)$ 已知，但我们本身就是在做状态价值函数估计，所以肯定不可能提前知道其真值。因此，我们需要将其替换为某种估算形式，具体方式包括：      采用 MC 的方式迭代优化，被称为 MC with Value Approximation：\\[w_{t+1} = w_t + 2\\alpha_t(\\textcolor{red}{G_t}-\\hat{v}(s_t,w_t))\\nabla_w\\hat{v}(s_t,w_t)\\]        采用 TD 的方式迭代优化，被称为 TD with Value Approximation：\\[w_{t+1} = w_t + 2\\alpha_t[\\textcolor{red}{r_{t+1}+\\gamma \\hat{v}_\\pi(s_{t+1},w_t)}-\\hat{v}(s_t,w_t)]\\nabla_w\\hat{v}(s_t,w_t)\\]    严格来说，采用 TD 的方式迭代优化后，求解的问题不再是原始目标（称其为 True Value Error）函数的最小化，而是优化 Projected Bellman Error。此处不再展开，可参考《Mathmatical Foundations of Reinforcement Learning》。2.3. 估计函数设计2.3.1. 采用线性函数早期广泛使用线性函数作为状态值函数的估计方法\\[\\hat{v}(s,w) = aw_1+w_2 = \\underbrace{[s,1]}_{\\phi^\\top(s)}\\underbrace{\\begin{bmatrix}  w_1\\\\w_2\\end{bmatrix}}_{w}=\\phi^\\top(s)w\\]可以看出，$\\hat{v}(s,w)$ 是关于 $w$ 的线性函数，$\\phi(s)$ 是特征向量，可以是一组多项式基、傅里叶基、…等等，但合适的基比较难选择。  从模式识别的角度，这里的线性函数本质上是设计一组能够反应状态价值函数特征的向量，且维数要小于原始状态价值函数的维数，后面的实例可以更好的反映这一点。线性函数估计的梯度为\\[\\nabla_w \\hat{v}(s,w) = \\nabla_w [\\phi^\\top(s)w] = \\phi(s)\\]将上述两式代入前述 TD 形式的迭代优化式中，有\\[w_{t+1} = w_t + \\alpha_t[r_{t+1}+\\gamma \\textcolor{red}{\\phi^\\top(s_{t+1})w_t}-\\textcolor{red}{\\phi^\\top(s_t)w_t}] \\textcolor{red}{\\phi(s_t)}\\]上述迭代式可被称为 TD-Linear。更加特殊的情况下，我们选择如下线性函数\\[\\phi(s) = e_s\\in\\mathbb{R}^{\\vert S \\vert}\\]其中 $e_s$ 是一个第 $s$ 个分量为 1，其余分量为 0 的向量（也即独热向量），那么\\[\\hat{v}(s,w) = e_s^\\top w = w(s)\\]就相当于取到 $w$ 的第 $s$ 个分量用来对 $v_\\pi(s)$ 进行估计。将其代入 TD-Linear 有\\[w_{t+1} = w_k + \\alpha_k[r_{t+1}+\\gamma \\textcolor{red}{w(s_{t+1})}-\\textcolor{red}{w(s_t)}] \\textcolor{red}{e_{s_t}}\\]注意到 $e_{s_t}$ 是一个第 $s_t$ 个分量为 1，其余分量为 0 的向量，那么上面的向量等式中，只有分量为 1 的那个（行）等式有意义，把这行提取出来有\\[w_{t+1}(s_t) = w_t(s_t) + \\alpha_t[r_{t+1}+\\gamma w_t(s_{t+1}) - w_t(s_t)]\\]可以看出，只要把 $w$ 换成 $v$，上式与前述 TD 方法的迭代式一模一样。也就是说，（对表格性任务而言）TD 方法与采用独热函数的值函数估计等价。2.3.2. 线性函数实例分析下面通过一个 Grid World 实例来表明，采用线性函数估计能够降低状态价值函数估计的参数个数。在实例中，采取均匀随机分布的策略 $\\pi(a\\vert s) = 0.2,\\forall s,a$，我们对所有 25 个状态的价值函数进行估计，本质是一个策略评估过程。实例中用到的参数为 $r_{\\text{forbidden}}=r_{\\text{boundary}}=-1,r_{\\text{target}}=1, \\gamma = 0.9$。我们首先使用动态规划方法，得到在该策略下，每个状态的真实最优状态价值函数，如图所示。中间子图表明了二维情况下的各个状态价值函数，右侧子图则将其形象展示到了三维空间中：接着我们采用线性函数进行价函数估计，通用实验设置如下：  采样 500 个 episodes；  每个 episode 包含 500 步，初始状态-动作均匀随机选取；下面开始实验：      采用独热函数的值函数估计（Tabular TD）        可以看出，随着迭代次数逐渐增加，价值函数估计值与真实值间的均方根误差收敛（右侧子图），估计结果（中间子图）逐渐逼近真实值（左侧子图）。    独热函数本质上是采用与状态个数同阶的线性函数估计，因此当然能够逼近最优值。        采用三阶线性函数的值函数估计    注意到该实例中状态可以坐标形式给出：$s={x,y}$，那么设计线性函数为\\[\\phi(s) = [1, x, y]^\\top \\in \\mathbb{R}^3\\]    则状态价值函数估计值为一个平面\\[\\hat{v}(s,w) = \\phi^\\top(s)w = [1,x,y]\\begin{bmatrix}  w_1\\\\w_2\\\\w_3\\end{bmatrix} = w_1+w_2x+w_3y\\]    最终结果为        可以看出，收敛后价值函数估计值与真实值间的均方根误差存在一个常值偏差（右侧子图），估计结果（中间子图）的趋势和真实值（左侧子图）相同，但因为本质上是用一个平面估计非平面，因此近似能力有限，必然存在误差。        采用高阶性函数的值函数估计    采用\\[\\begin{aligned}\\phi(s) &amp;= [1,x,y,x^2,y^2,xy]^\\top\\in\\mathbb{R}^6\\\\\\phi(s) &amp;= [1,x,y,x^2,y^2,xy,x^3,y^3,x^2y,xy^2,]^\\top\\in\\mathbb{R}^{10}\\end{aligned}\\]    则状态价值函数估计值为一个二次/三次曲面，最终结果为    二次曲面：        三次曲面：        可以看出，随着参数个数的增多，其曲面的拟合能力越好。同时也注意到，即使继续增加阶数也不一定能保证完全消除估计误差，因为线性函数结构本身能力存在限制，这也是为什么如今更加广泛采用神经网络来估计值函数，因为神经网络从理论上来说可以近似任意一个非线性函数。  2.3.3. 采用神经网络目前被广泛使用的是神经网络作为一个非线性估计函数，其输入为状态 $s$，输出为 $\\hat{v}(s,w)$，其中 $w$ 是神经网络的权重参数。关于神经网络估计函数这里不再展开介绍，后续对状态-动作价值函数进行估计时会详细介绍。3. 状态动作价值函数近似前面介绍 TD 方法时，我们首先以状态价值函数（V 函数）为例引入了基本的 TD 思想，然后将其推广至状态动作价值函数（Q 函数），并结合不同的策略改进方法，分别得到 SARSA 和 Q-Learning 两种具体的时序差分方法。这一节我们将采用类似的思想，将前述介绍的状态价值函数近似的基本思想，分别与 SARSA 和 Q-Learning 结合。3.1. SARSA 值函数近似直接将状态价值函数近似的梯度下降迭代式中的 $v$ 替换为 $q$ 我们就得到\\[w_{t+1} = w_t + \\alpha_t[r_{t+1}+\\gamma \\hat{q}(s_{t+1},a_{t+1};w_t)-\\hat{q}(s_t,a_t;w_t)]\\nabla_w\\hat{q}(s_t,a_t;w_t)\\]结合策略改进算法，形成伪代码如下：  Initialize $Q(s,a)$ arbitrarily, choose start state $s$, given a behaviour policy $\\pi_t$ (e.g., $\\varepsilon$-greedy)  Repeat (for each episode)          Repeat (if current $s_t$ is not terminal state)                  collect experience:                          choose action $a_t$ at $s_t$ following $\\pi_t(s_t)$              Take action $a$, get $r$, transfer to $s_{t+1}$              choose action $a_{t+1}$ at $s_{t+1}$ following $\\pi_t(s_{t+1})$                                parameter update:                          $w_{t+1} = w_t + \\alpha_t[r_{t+1}+\\gamma \\hat{q}(s_{t+1},a_{t+1};w_t)-\\hat{q}(s_t,a_t;w_t)]\\nabla_w\\hat{q}(s_t,a_t;w_t)$              ${s_t\\leftarrow}s_{t+1}; a_t\\leftarrow a_{t+1}$                                policy improvement:                          (update same $\\varepsilon$-greedy as target policy)              $\\pi_{t+1}(a\\vert s) = 1-\\frac{\\varepsilon}{\\vert \\mathcal{A} \\vert}(\\mathcal{A}-1)$ if $a=\\arg\\max_a \\textcolor{red}{\\hat{q}(s,a;w_t)}$              $\\pi_{t+1}(a\\vert s) = \\frac{\\varepsilon}{\\vert \\mathcal{A} \\vert}$ otherwise              $t \\leftarrow t+1$                                          上述伪代码中标红部分即为 SARSA 值函数近似方法，与传统 SARSA 方法不同的地方。设计一个采用 5 阶傅里叶基函数函数的 SARSA 值函数近似方法，在 Grid World 实例下的训练结果。其中实例设置为： $r_{\\text{boundary}}=r_{\\text{forbidden}}=-10,r_{\\text{target}}=1,\\alpha=0.001,\\gamma=0.9$。从左上角初始状态出发，迭代500步，结果如下图所示3.2. Q-Learning 值函数近似同样直接将状态价值函数近似的梯度下降迭代式中的 $v$ 替换为 $q$ 我们就得到\\[w_{t+1} = w_t + \\alpha_t[r_{t+1}+\\gamma \\textcolor{red}{\\max_{a\\in\\mathcal{A}(s_{t+1})}}\\hat{q}(s_{t+1},a;w_t)-\\hat{q}(s_t,a_t;w_t)]\\nabla_w\\hat{q}(s_t,a_t;w_t)\\]结合策略改进算法，形成伪代码如下（注意其策略评估迭代式并没有直接照搬上面的式子，而是将取最大 $q$ 函数部分放到经验采集环节）：  Initialize $Q(s,a)$ arbitrarily, choose start state $s$, given a behaviour policy $\\pi_b$ (e.g., $\\varepsilon$-greedy, uniform, human, etc)  Repeat (for each episode):          Repeat (if $s$ is not terminal state):                  collect experience:                          choose action $a_t$ at $s_t$ following $\\pi_t(s_t)$              Take action $a$, get $r$, transfer to $s_{t+1}$              choose $a_{t+1}= \\arg\\max_a \\textcolor{red}{\\hat{q}(s_{t+1}, a;w_t)}$                                parameter update:                          $w_{t+1} = w_t + \\alpha_t[r_{t+1}+\\gamma \\hat{q}(s_{t+1},a_{t+1};w_t)-\\hat{q}(s_t,a_t;w_t)]\\nabla_w\\hat{q}(s_t,a_t;w_t)$                                policy improvement:                          (update greedy policy as target policy)              $\\pi_{t+1}(a\\vert s) = 1$ if $a=\\arg\\max_a \\textcolor{red}{\\hat{q}(s,a;w_t)}$              $\\pi_{t+1}(a\\vert s) = 0$ otherwise              ${s\\leftarrow}s^\\prime; a\\leftarrow a^\\prime$                                $t \\leftarrow t+1$                    上述伪代码中标红部分即为 Q-Learning 值函数近似方法，与传统 Q-Learning 方法不同的地方。设计一个采用 5 阶傅里叶基函数的 Q-Learning 值函数近似方法（采样 on-policy 而不是上面介绍的 off-policy 版本），在 Grid World 实例下的训练结果。其中实例设置为： $r_{\\text{boundary}}=r_{\\text{forbidden}}=-10,r_{\\text{target}}=1,\\alpha=0.001,\\gamma=0.9$。从左上角初始状态出发，迭代500步，结果如下图所示可以看出，即使采用 on-policy 的 Q-Learning 也比 SARSA 更激进，收敛速度更快（因为里面的第二次动作采样使用 greedy 策略）。4. Deep Q-Learning（DQN）前面我们使用线性函数来做值函数近似，其本质是从高维数据中抽象出特征，作为状态，然后用强化学习建模，但这种做法很大程度上依赖于人工特征的设计（也即线性函数基的选取）。因此，更加广泛的做法是使用一个非线性函数——乃至神经网络——来做值函数近似。Deep Q-Learning（原文称为 Deep Q-Network，DQN）就是源于上述思想，它也是强化学习领域最早且最成功将深度神经网络引入强化学习的尝试之一。  DQN 由DeepMind公司在2013年提出，2015年其改进型发表在Nature上。这种方法用卷积神经网络拟合价值函数，一般是Q函数。网络的输入为原始场景数据，如游戏的画面图像，输出为在这种场景下执行各种动作时所能得到的Q函数的极大值。如果使用一个神经网络来做值函数近似，可以有以下两种形式：       +----+ ----&gt;Q(s,a1)                         +----+s ---&gt; |f(θ)| ----&gt;Q(s,a2)         or        s ---&gt;|f(θ)| ----&gt;Q(s,ai)       |    | ----&gt;...                       ai---&gt;|    |        +----+ ----&gt;Q(s,an)                         +----+那么应该采取哪种网络形式呢？上面两种形式都可能出现，但一般而言，DQN 采用左边形式。因为：  左边形式：          DQN 需要找到 $\\max_a q(s,a)$，左边输入一次就能得到所有动作的价值，而右边输入则需要多次输入，增加了计算复杂度；      强化学习问题可能包含大量的动作选项。将动作作为网络输入会使网络的复杂度急剧增加，不利于训练和收敛。相反，通过仅输入状态，网络可以更专注地学习状态与价值之间的关系，而不必考虑如何直接处理动作空间的复杂性。        右边形式：          有时候，将动作作为网络输入是有必要的，比如在某些连续动作空间中，动作空间的维度可能比状态空间的维度还要高。      4.1. 损失函数神经网络的损失函数用 Q-Learning 的 TD Error 构造。回顾 Q-Learning 的策略评估迭代式\\[q(s,a) \\leftarrow q(s,a)-\\alpha\\{q(s,a)-[r+\\gamma \\max_a q(s^\\prime,a)]\\}\\]当 $q(s,a)$ 收敛时必然有后一项为零。那么损失函数可以写为\\[L(\\theta) = \\mathbb{E}[(r+\\gamma \\mathop{\\text{max}}\\limits_{a^\\prime} q(s^\\prime,a^\\prime;\\textcolor{red}{\\theta})-q(s,a;\\textcolor{red}{\\theta}))^2]\\]这个损失函数是神经网络的输出值与 Q 函数一步估计值之间的误差。其之所以能够成立的原因，是因为其本质上是在求解 $Q$ 函数形式的贝尔曼最优方程（前述马尔可夫决策4.7章节有过介绍）\\[q(s,a) = \\mathbb{E}[R_{t+1}+\\gamma \\max_a q(s_{t+1},a)\\vert s,a], \\forall s,a\\]那么在期望形势下，上面的损失函数自然应该趋向于零。4.2. 优化方法神经网络的损失函数自然该采用梯度下降法求解，梯度下降要计算损失函数的梯度，但注意到，损失函数中有两项都包含网络参数 $\\theta$，其中 TD Target 含参部分还含有求最大值操作，这个梯度求解比较困难，因此引出第一个技巧：分离拷贝。另一方面，和 Q-Learning 类似，DQN 通过执行动作来生成经验数据 $S_t, A_t, R_{t+1},S_{t+1}$ 作为样本来进行训练的。具体而言，给定一个状态，用当前的神经网络进行预测，得到所有动作的 Q 函数，然后按照策略选择一个动作执行，得到下一个状态以及回报值，以此构造训练样本。从监督学习的角度，一般要求训练样本之间是相互独立的，但在强化学习中，一次采样得到的序列中，取出的经验数据是前后高度相关。为了解决训练样本之间存在相关性，DQN 采用了经验回放机制。下面分别介绍上述两个技巧。4.2.1. 分离拷贝分离拷贝指的是在求损失函数梯度的过程中，短时间内冻结 TD Target 中的网络权重参数，此时我们假设被冻结的参数为 $\\theta_T$，那么损失函数就可以写为如下形式：\\[L(\\theta) = \\mathbb{E}[(\\underbrace{r+\\gamma \\mathop{\\text{max}}\\limits_{a^\\prime} q(s^\\prime,a^\\prime;\\textcolor{red}{\\theta_T})}_{\\text{TD Target}}-q(s,a;\\theta))^2]\\]此时梯度只与最后一项有关，可求解得到\\[\\nabla_\\theta L(\\theta) = -[ r+\\gamma \\max_{a^\\prime}q( s^\\prime,a^\\prime;\\textcolor{red}{\\theta_T} ) -q( s,a;\\theta ) ] \\nabla _{\\theta}q( s,a;\\theta )\\]相应的网络参数更新式为\\[\\theta \\leftarrow \\theta - \\alpha \\nabla_\\theta L(\\theta)\\]上述过程中，$\\theta_T$ 只能冻结较短的时间，否则 TD Target 长时间得不到更新，梯度下降会偏离最优方向，导致算法失效。因此我们每隔一段时间就要对 $\\theta_T$ 进行一次更新。DQN 采用的分离拷贝思想就源于此，在训练开始时刻设计两个 Q-Network 而不是一个，他们的参数分别为 $\\theta,\\theta_T$，其中被持续更新的网络称为 主网络，被周期性冻结的网络称为 目标网络。  主网络：$\\hat{q}(s,a;\\theta)$  目标网络：$\\hat{q}(s,a;\\theta_T)$初始时刻二者相等。每隔一段时间，直接将主网络较新的网络参数，直接拷贝给目标网络参数，然后再次冻结目标网络，继续更新主网络，如此循环直至训练结束。示意图如下：4.2.2. 经验回放（experience replay）经验回放的具体做法是，训练时不再沿着采样的顺序逐个经验数据训练，而是先把经验数据存储到一个集合 $\\mathcal{B}\\doteq { (s,a,r,s^\\prime) }$，称其为 回放缓冲（replay-buffer）。训练 DQN 时，每次从这个集合中均匀随机（uniformly）抽取出部分样本作为 mini-batch 训练样本，以此打破样本之间的相关性。  经验回放同样可以用于原始 Q-Learning 算法，因为它本身也是 off-policy 方法，行为策略和目标策略不一致。可以先用行为策略采样一批经验数据，然后再用目标策略进行训练。甚至引入经验回放后，可以进一步提高 Q-Learning 的数据利用效率，因为一组经验样本可能会被抽取和使用很多次。4.3. 算法流程DQN 的伪代码如下：  Given a behaviour policy $\\pi_b$ (e.g., $\\varepsilon$-greedy, uniform, human, etc)  Store experience samples generated by $\\pi_b$ in replay buffer $\\mathcal{B}={(s,a,r,s^\\prime)}$  Initialize two network with parameters $\\theta,\\theta_T$ randomly  Repeat (for each iteration):          Uniformly draw a mini-batch of $N$ samples from $\\mathcal{B}$      For each sample $(s,a,r,s^\\prime)$ in the mini-batch:                  Compute TD Target: $y=r+\\gamma \\max_{a^\\prime} \\hat{q}(s^\\prime,a^\\prime;\\theta_T)$          Compute TD Error: $\\delta = y-\\hat{q}(s,a;\\theta)$          Compute loss: $L(\\theta) = \\frac{1}{2}\\delta^2$          Update $\\theta$ by minimizing $L(\\theta)$                    $\\theta_T \\leftarrow \\theta$ every $C$ iterations        Get greedy policy from $\\hat{q}(s,a;\\theta)$4.4. 实例分析下面我们使用 DQN 算法来解决一个简单的 Grid World 问题，我们希望得到所有状态下的最优策略，实例设置如下：  只采样 1 个episode，智能体达到目标状态后继续采样；  该 episode 设置为 1000 步，采样 1000 步后停止；  行为策略采用 $\\pi(a\\vert s) = 0.2,\\forall s,a$ 策略；  使用单隐层的浅层网络作为非线性近似器来估计 $\\hat{q}(s,a;\\theta)$，隐层有 100 个神经元。仿真结果如下：可以看出，  图（a）：初始均匀随机策略；  图（b）：经过 1000 步采样得到的数据已经基本覆盖了所有的状态动作对；  图（d）：训练 DQN，其损失函数能够收敛，表明其很好地拟合了已有样本；  图（c）：基于 DQN 的值函数估计给出的策略确实是最优策略；  图（e）：DQN 对所有值函数的估计也收敛到真实值函数。将迭代步长降低到 100 步，相当于样本数量减少至原来的十分之一，结果如下：可以看出，  图（b）：经过 100 步采样得到的数据难以所有的状态动作对；  图（d）：训练 DQN，其损失函数能够收敛，表明其很好地拟合了已有样本；  图（c）：基于 DQN 的值函数估计给出的策略远不是最优策略；  图（e）：DQN 对所有值函数的估计无法收敛到真实值函数。上述结果表明，即使 DQN 很强大，数据量不够或者采样不充分也没法保证其效果。4.5. 过高估计（Double DQN）DQN 算法在深度强化学习领域取得了不俗的成绩，不过其并不能保证一直收敛，研究表明这种估计目标价值的算法过于乐观的高估了一些情况下的行为价值（主要原因在于 max 操作），导致算法会将次优行为价值一致认为最优行为价值，最终不能收敛至最佳价值函数。为了解决这个问题，Double Q-learning 率先使用了两个值函数进行解耦，其互相随机的更新两个值函数，并利用彼此的经验去更新网络权重 $\\theta$ 和 $\\theta_T$。对应的损失函数为\\[L(\\theta) = \\mathbb{E}[(r+\\gamma \\textcolor{blue}{q(s^\\prime,\\textcolor{red}{\\mathop{\\text{argmax}}\\limits_{a^\\prime}q(s^\\prime,a^\\prime,\\theta)};\\theta_T)}-q(s,a;\\theta))^2]\\]其可拆分为如下两个等式\\[\\begin{aligned}  L(\\theta) &amp;= \\mathbb{E}[(r+\\gamma \\textcolor{blue}{q(s^\\prime,\\textcolor{red}{a^\\prime};\\theta_T)}-q(s,a;\\theta))^2]\\\\  \\textcolor{red}{a^\\prime} &amp;=\\mathop{\\text{argmax}}\\limits_{a^\\prime}q(s^\\prime,a^\\prime,\\theta)\\end{aligned}\\]其网络示意图如下：带来的效果如下："
  },
  
  {
    "title": "强化学习（时序差分法）",
    "url": "/posts/reinforcement-learning-Temporal-Differences/",
    "categories": "Academic, Knowledge",
    "tags": "python, reinforcement learning",
    "date": "2022-12-18 14:59:19 +0800",
    





    
    "snippet": "本文首先引入了随机近似理论，然后通过比较动态规划和蒙特卡洛，引出结合二者优势的时序差分法。通过分析可知，时序差分法是随机近似理论的一个特例。随后详细介绍了同轨策略下的时序差分控制（SARSA）、离轨策略下的时序差分控制（Q-Learning）和期望SARSA。最后介绍了基于价值的深度强化学习方法：Deep Q-Network（DQN）。  1. 引言  2. 随机近似理论          ...",
    "content": "本文首先引入了随机近似理论，然后通过比较动态规划和蒙特卡洛，引出结合二者优势的时序差分法。通过分析可知，时序差分法是随机近似理论的一个特例。随后详细介绍了同轨策略下的时序差分控制（SARSA）、离轨策略下的时序差分控制（Q-Learning）和期望SARSA。最后介绍了基于价值的深度强化学习方法：Deep Q-Network（DQN）。  1. 引言  2. 随机近似理论          2.1. 求期望的增量更新式      2.2. Robbins-Monro（RM） 算法                  2.2.1. 算法推导          2.2.2. 收敛性分析          2.2.3. 回顾增量更新                    2.3. 随机梯度下降（SGD）                  2.3.1. SGD 算法推导          2.3.2. SGD 收敛性分析          2.3.3. 回顾增量更新          2.3.4. SGD 的确定性形式          2.3.5. BGD、MBGD 和 SGD                      3. 时序差分法          3.1. 时序差分思想（Temporal Difference）                  3.1.1. 从蒙特卡洛的角度分析          3.1.2. 从 RM 算法的角度分析          3.1.3. 从贝尔曼期望方程的角度分析          3.1.4. TD 与 MC 的比较                    3.2. 同策略时序差分（SARSA）                  3.2.1. SARSA          3.2.2. Expected SARSA          3.2.3. n-step SARSA                    3.3. 异策略时序差分（Q-Learning）                  3.3.1. Q-Learning          3.3.2. 同策略与异策略          3.3.3. 不同行为策略的探索性                    3.4. 总结                  3.4.1. 表述形式总结          3.4.2. 求解方程总结          3.4.3. 行为表现总结                      4. 参考文献1. 引言回顾强化学习的目标：价值估计（预测问题）和策略寻优（控制问题）。在前面的的介绍中，我们分别介绍了两种基于价值的方法，动态规划法和蒙特卡洛法：  动态规划法（DP）：是基于模型的方法，包含策略评估和策略改进两步，策略评估用来进行价值估计（即预测问题），策略改进用来进行策略优化（控制问题）。  蒙特卡洛法（MC）：是无模型的方法，我们无法得到具体模型（动态特性）时，通过采样完整序列后，通过计算 $G_t$ 的均值来近似价值函数。本节介绍第三种基于价值的方法：时序差分法（TD）。首先回顾一下价值函数的等式：\\[\\begin{aligned}v_\\pi(s) &amp;= \\mathbb{E}_\\pi[G_t\\vert S_t=s] &amp; {MC}\\\\&amp;= \\mathbb{E}_\\pi[R_{t+1}+\\gamma v_\\pi(S_{t+1})\\vert S_t=s] &amp; {TD}\\\\&amp;= \\sum_a\\pi(a\\vert s) \\sum_{s^\\prime,r}p(r^\\prime,r \\vert s,a)(r+\\gamma v_\\pi(s^\\prime)) &amp; {DP}\\\\end{aligned}\\]可以看出，基于价值的方法可以根据价值函数的等式不同来划分，其中：  动态规划（DP）：是一种自举的方法。更新 $v_{k+1}$ 时采用上一步的 $v_k$ 进行组装，缺点：环境动态特性必须已知；  蒙特卡洛（MC）：是一种采样的方法。依据大数定律，让样本均值逼近期望，缺点：必须完整采集一回合；  时序差分（TD）：本章节介绍的方法。2. 随机近似理论2.1. 求期望的增量更新式在蒙特卡洛中介绍增量更新时，我们给出了根据每次采样得到的新 $G_t$ 求取 $G(S_t)$ 均值的增量更新形式如下：\\[\\begin{cases}N &amp;\\leftarrow N+1\\\\G(S_t) &amp;\\leftarrow G(S_t) - \\frac{1}{N} (G(S_t) - G_t)\\end{cases}\\]将 $\\frac{1}{N(S_t)}$ 替换为 $\\alpha$，将待求量 $G(S_t)$ 写为 $w$，将即时获取的量记作 $x_k$，我们可以将其写为更加简洁的一般的形式\\[w_{k+1} \\leftarrow w_k - \\textcolor{red}{\\alpha} (w_k - x_k)\\]其中，$\\alpha$ 为步长参数，用来控制更新的速度。随着迭代次数 $k$ 的增加，$w_k$ 逐渐逼近 $x_k$ 的期望 $\\mathbb{E}[X]$。这种算法的优势在于它是渐进式的。一旦收到一个样本，就可以立即获得平均值估计值。然后，平均估算值就可以立即用于后续其他计算。在第 $k$ 步的时候，我不需要把前面所有的样本全部加起来再求平均，只需要通过上式一步的计算就可以得到一个新的平均数。但是，在更新开始的时候因为数据量比较小，$w_k$ 难以非常精确的逼近 $\\mathbb{E}[X]$。即由于样本不足，平均值估计在开始时并不准确。不过，有总比没有好，总比一直等到最后才能有一个数来得到一个平均数要强。在这个过程中就算不精确，也可以先凑合用着。随着样本的增多，数据越来越大，只要保证逐渐能够逼近期望就行。随之而来的问题是：  上述计算是否仍能保证收敛至 $\\mathbb{E}[X]$？；  上述计算属于什么类型的算法？这里可以告诉大家，上述计算是 随机近似理论（Stochastic Approximation, SA） 的一个特殊形式，也是 随机梯度下降（Stochastic Gradient Descent, SGD） 的一个特殊形式。我们将在分别后面详细介绍。2.2. Robbins-Monro（RM） 算法2.2.1. 算法推导随机近似理论是解决寻根（方程求解）或优化问题的一大类随机迭代算法的总称。与许多其他寻根（方程求解）算法（如基于梯度的方法，梯度下降或梯度上升）相比，其的强大之处在于它不需要知道目标函数的表达式，也不需要知道目标函数梯度的表达式。其中，Robbins-Monro（RM）算法，是随机近似理论中的先驱性工作，它由 John Robbins 和 Paul Monro 在 1951 年提出。著名的随机梯度下降算法则是 RM 算法的一个特殊形式。该算法也可用来分析上述提到的均值估计的收敛性。【问题描述】：假设需要求解 $g(w) = 0$ 的根，其中 $w\\in\\mathbb{R}, g:\\mathbb{R}\\rightarrow \\mathbb{R}$。注意到：  这个简单的寻根问题是许多其他复杂问题的最终形式，如假设 $J(w)$ 是一个待优化的目标函数，我们需要求解 $J(w)$ 的极值，问题就转化为 $g(w) = \\nabla_w J(w)=0$（必要条件）；  对于 $g(w)=c$ 这类问题的寻根也可转化为 $g(w) - c = 0$ 的寻根问题。如果函数 $g$ 的表达式已知，那么采取很多数值方法就可以求解。但如果函数表达式未知，比如是一个神经网络，那么问题就变成我输入什么样的 $w$ 能够使神经网络的输出为 0 ？【RM 算法】：是一种迭代式算法，的求解方法为\\[w_{k+1} = w_k-\\alpha \\tilde{g}(w_k,\\eta_k), \\quad k=1,2,\\ldots\\]其中  $w_k$ 是第 $k$ 步的根的估计值；  $\\tilde{g}(w_k,\\eta_k) = g(w_k) + \\eta_k$ 为第 $k$ 步的含噪观测；  $\\alpha$ 为正的步长参数。注意，上述求解过程不涉及 $g(w)$ 的表达式，他是一个黑箱。与之相对，算法的求解依赖数据，即  输入序列：${w_k}$  测量到的含噪输出序列：${\\tilde{g}(w_k,\\eta_k)}$  例：求解 $g(w) = \\tanh(w-1)$真实根易知为 $w=1$采用 RM 算法，假设 $w_1=3,a_k=\\frac{1}{k},\\eta_k=0$，不含噪便于简化分析。那么迭代式如下\\[w_{k+1} = w_k-\\frac{1}{k} g(w_k)\\]  迭代结果如图所示，可以发现确实能收敛到真实根  2.2.2. 收敛性分析下面给出收敛性证明的严格数学推导。如果满足以下三条约束，那么，RM 算法中 $w_k$ 可依概率（with probability 1, w.p.1）收敛至方程 $g(w^\\star) = 0$ 的根 $w^\\star$。（1）梯度约束：\\[0&lt;c_1\\leq \\nabla_w g(w)\\leq c_2\\]      对于梯度约束，其要求梯度为某一个正值区间内，此时 $g(w)$ 单调递增， $g(w)=0$ 的根存在且唯一（注意，类似 $g(w) = e^w$ 是不满足此条件的，因为其导数在 $w\\rightarrow -\\infty$ 时趋于零，对于任意 $c_1&gt;0$ 总能找到其导数小于 $c_1$ 的情况）；        单调递增是一个严格约束，对于神经网络而言，假设 $J(w)$ 是一个待优化的目标函数，我们需要求解 $J(w)$ 的极值，问题就转化为 $g(w) = \\nabla_w J(w)=0$，则梯度要求为 $\\nabla_w^2 J(w) &gt; 0$ 即 Hessian 矩阵是正定矩阵，对应原始函数是凹函数（不同约定下也可能定义为凸函数，本质上是单调且存在极值解的）；  （2）系数约束\\[\\sum_{k=1}^{\\infty} \\alpha_k=\\infty,\\;\\sum_{k=1}^{\\infty}\\alpha_k^2&lt;\\infty\\]  $\\sum_{k=1}^{\\infty} \\alpha_k^2&lt;\\infty$ 要求在 $k\\rightarrow \\infty$ 时系数 $a_k\\rightarrow 0$ 即收敛至零；          对于 RM 算法迭代式进行移项：$w_{k+1} - w_k = -\\alpha_k\\tilde{g}(w_k,\\eta_k)$      只有 $a_k\\rightarrow 0$ 才能保证 $a_k\\tilde{g}(w_k,\\eta_k) \\rightarrow 0$      即 $w_{k+1} - w_k \\rightarrow 0$        $\\sum_{k=1}^{\\infty} \\alpha_k = \\infty$ 要求系数 $\\alpha_k\\rightarrow 0$ 的收敛速度不能太快；          对于 RM 算法迭代式进行移项累加后有：$w_{\\infty} - w_1 = -\\sum_{k=1}^\\infty \\alpha_k\\tilde{g}(w_k,\\eta_k)$      假设 $w_{\\infty}=w^\\star$，那么若 $\\sum_{k=1}^{\\infty} \\alpha_k &lt; \\infty$ 表明上式右项是有界的（若 $g(w)$ 恰好也有界）      如果初始猜测 $w_1$ 距离根 $w^\\star$ 特别远，$w_{\\infty} - w_1$ 就会超出上面的界限，产生矛盾      因此要求 $\\sum_{k=1}^{\\infty} \\alpha_k = \\infty$，保证我们可以任意选取 $w_1$        最常见的可选系数序列是调和级数：$\\alpha_k = \\frac{1}{k}$（3）误差约束：\\[\\mathbb{E}[\\eta_k\\vert\\mathcal{H}_k]=0,\\;\\mathbb{E}[\\eta_k^2\\vert\\mathcal{H}_k]&lt; \\infty,\\quad \\mathcal{H}_k=\\{w_k, w_{k-1},\\cdots\\}\\]      要求误差的均值是0，且方差是有界的；        常见的观测误差是一系列独立同分布（iid）的随机噪声序列中进行采样，但不要求噪声是高斯的。    即使不满足上述三条约束中的某一条，RM 算法也可能有效，但是不能保证一定收敛，如：      对于 $g(w) = w^3-5$ 不满足第一条梯度约束，但如果初始猜测比较好，算法依然能够（局部）收敛；    在强化学习算法中经常令 $a_k$ 等于一个很小的值（学习率）而不是调和级数，显然不满足第二条系数约束，但是算法依然有效。  RM 算法收敛性证明需要用到更加古老的 Dvoretzky 收敛定理。其表述如下：考虑一个随机过程 $w_{k+1} = (1-\\alpha_k)w_k+\\beta_k\\eta_k$，其中\\[\\{\\alpha_k\\}_{k=1}^{\\infty},\\{\\beta_k\\}_{k=1}^{\\infty},\\{\\eta\\}_{k=1}^{\\infty}\\]都是随机序列，且 $\\alpha_k\\geq 0, \\beta_k \\geq 0$，那么当满足以下约束时，$w_k$ 依概率收敛至 0。（1）系数约束：\\[\\sum_{k=1}^{\\infty} \\alpha_k = \\infty,\\; \\sum_{k=1}^{\\infty} \\alpha_k^2 &lt; \\infty,\\; \\text{and} \\sum_{k=1}^{\\infty} \\beta_k^2 &lt; \\infty\\; \\text{uniformly w.p.1}\\]（2）误差约束：\\[\\mathbb{E}[\\eta_k\\vert \\mathcal{H}_k]=0,\\;\\mathbb{E}[\\eta_k^2\\vert \\mathcal{H}_k] \\leq C\\; \\text{w.p.1},\\quad \\mathcal{H}_k=\\{w_k, w_{k-1},\\cdots, \\eta_{k-1},\\cdots, \\alpha_{k-1},\\cdots,\\eta_{k-1}\\}\\]证明略，可参考如下链接。  Stochastic Approximation 随机近似方法的详解之（三）Dvoretzky’s convergence theorem网页链接：https://blog.csdn.net/weixin_37726222/article/details/1293068712.2.3. 回顾增量更新考虑一个简单的均值估计问题，我们想要从一组独立统分不采样得到的样本 ${x}_i\\in X$ 中计算均值\\[w = \\mathbb{E}[X]\\]将原始问题转变为如下寻根问题，定义函数\\[g(w) \\doteq w - \\mathbb{E}[X]\\]我们的目标是求解 $g(w) = 0$，如果可以求解，相当于变相求出了期望。由于期望是未知的，我们只能够获取到状态量的具体测量 $x$，那么定义对函数 $g(w)$ 的含噪观测为\\[\\tilde g(w,x) \\doteq w - x\\]注意到，上式可以进行如下变换\\[\\begin{aligned}\\tilde g(w,x) &amp;\\doteq w - x \\\\&amp;= w-x+\\mathbb{E}[X]-\\mathbb{E}[X]\\\\&amp;= (w-\\mathbb{E}[X])+(\\mathbb{E}[X]-x)\\\\&amp;= g(w) + \\eta\\\\&amp;= \\tilde{g}(w,\\eta)\\end{aligned}\\]根据 RM 算法，求解方程 $g(w)=0$ 的根可以通过如下迭代式进行\\[w_{k+1} = w_k - \\alpha \\tilde g(w_k,\\eta_k) = w_k - \\alpha_k (w_k - x_k)\\]观察发现其正好就是均值估计的增量更新算法迭代式。所以均值估计的增量更新算法是一种 RM 算法的特殊形式，自然收敛。2.3. 随机梯度下降（SGD）2.3.1. SGD 算法推导考虑一个如下的一般优化问题\\[\\min_w J(w) = \\mathbb{E}[f(w,X)]\\]其中 $f(w,X)$ 的输出为标量，$X$ 是输入随机变量，$w$ 是待优化参数。求期望符号是针对 $X$ 的，即希望找到某个参数使得期望最小。使用 梯度下降法（Gradient Descent, GD）进行求解\\[w_{k+1} = w_k - \\alpha \\nabla_w \\mathbb{E}[f(w,X)] = w_k - \\alpha \\mathbb{E}{[\\nabla_w f(w,X)]}\\]其中 $\\alpha$ 是控制步长的参数。注意到求期望的本质就是求和，因此求梯度符号可以移到期望符号内。上述求解过程的难点在于对梯度求期望，如果我们没有映射函数的显示表达式，那么我们无法直接求解。因此我们需要借助数据，采用批量梯度下降法或随机梯度下降法进行求解。使用 批量梯度下降法（Batch Gradient Descent, BGD），梯度的期望可以近似表示如下\\[\\begin{aligned}\\mathbb{E}{[\\nabla_w f(w,X)]} &amp;\\approx \\frac{1}{N}\\sum_{i=1}^N \\nabla_w f(w_k,x_i)\\\\w_{k+1} &amp;= w_k-\\alpha_k \\frac{1}{N}\\sum_{i=1}^N \\nabla_w f(w_k,x_i)\\end{aligned}\\]上述求解过程仍然唇在一个不足，即需要采样 $N$ 次获得梯度数据才能迭代计算一步。我们进一步采用随机梯度下降法解决这个不足。使用 随机梯度下降法（Stochastic Gradient Descent, SGD），直接移除 $N$ 个梯度样本的求和，直接使用单个样本的梯度进行迭代\\[w_{k+1} = w_k-\\alpha_k  \\nabla_w f(w_k,x_k)\\]可以看出，随机梯度下降是批量梯度下降取 $N=1$ 的一种特殊情况，相当于将真实梯度的期望替换为单个样本（随机）梯度。2.3.2. SGD 收敛性分析对于如下的一般优化问题\\[\\min_w J(w) = \\mathbb{E}[f(w,X)]\\]我们称 $g(w) = \\mathbb{E}[\\nabla_w f(w,X)]$ 为 true gradient，称其某次采样 $\\nabla_w f(w_k,x_k)$ 为 stochastic gradient。易知，原始优化问题可以转化为一个梯度等于零 $g(w) = 0$ 这个方程求根问题，因为后者是前者能取到最优解的必要条件。由于我们不知道 $\\nabla_w f(w,X)$ 的表达式，我们可以测量到其含噪近似（本质就是 stochastic gradient）\\[\\begin{aligned}  \\tilde{g}(w,\\eta) &amp;= \\nabla_w f(w,x)\\\\  &amp;=\\textcolor{blue}{\\mathbb{E}[\\nabla_w f(w,X)]} + \\textcolor{red}{\\nabla_w f(w,x) - \\mathbb{E}[\\nabla_w f(w,X)]}\\\\&amp;= \\textcolor{blue}{g(w)} + \\textcolor{red}{\\eta}\\end{aligned}\\]根据 RM 算法，求根问题的迭代解法如下\\[w_{k+1} = w_k - \\alpha_k \\tilde{g}(w_k,\\eta_k)\\]而前面说了 $\\tilde{g}(w,\\eta)$ 就是随机梯度，那么上式就是 SGD 的迭代表达式，因此 SGD 是一个特殊的 RM 算法，当满足三条约束时可收敛。定义其第 $k$ 步迭代时的相对误差为\\[\\delta_k = \\frac{\\vert \\nabla_w f(w_k,x_k) - \\mathbb{E}[\\nabla_w f(w_k,X)]\\vert}{\\vert \\mathbb{E}[\\nabla_w f(w_k,X)] \\vert}\\]又因为 $\\mathbb{E}[\\nabla_w f(w^\\star,X)]=0$，代入得到\\[\\delta_k = \\frac{\\vert\\nabla_w f(w_k,x_k) - \\mathbb{E}[\\nabla_w f(w_k,X)]\\vert}{\\vert\\mathbb{E}[\\nabla_w f(w_k,X)]-\\mathbb{E}[\\nabla_w f(w^\\star,X)] \\vert} = \\frac{\\vert\\nabla_w f(w_k,x_k) - \\mathbb{E}[\\nabla_w f(w_k,X)]\\vert}{\\vert\\mathbb{E}[\\nabla_w^2 f(\\tilde{w}_k,X)(w_k-w^\\star)] \\vert}\\]其中，分母部分的变换利用了中值定理，使得 $w_k-w^\\star$ 项出现。  中值定理：$f(x_1) - f(x_2) = f^\\prime(x_3)(x_1 - x_2)$ 其中 $x_3\\in[x_1, x_2]$假设分母的二阶梯度 $\\nabla_w^2f(w_k,X)\\geq c &gt;0$，其中 $c$ 是一个正的常值。那么分母可进一步化简得\\[\\begin{aligned}  \\vert\\mathbb{E}[\\nabla_w^2 f(\\tilde{w}_k,X)(w_k-w^\\star)] \\vert &amp;= \\vert\\mathbb{E}[\\nabla_w^2 f(\\tilde{w}_k,X)]\\cdot (w_k-w^\\star) \\vert\\\\  &amp;= \\vert\\mathbb{E}[\\nabla_w^2 f(\\tilde{w}_k,X)]\\vert \\cdot \\vert w_k-w^\\star \\vert\\\\  &amp;\\geq c \\cdot \\vert w_k-w^\\star \\vert\\end{aligned}\\]带如相对误差的表达式有\\[\\delta_k \\leq \\frac{\\overbrace{\\vert\\nabla_w f(w_k,x_k)}^{\\text{stochastic gradient}} - \\overbrace{\\mathbb{E}[\\nabla_w f(w_k,X)]\\vert}^{\\text{true gradient}}}{\\underbrace{c \\cdot \\vert w_k-w^\\star \\vert}_{\\text{distance to optimal solutiion}}}\\]上式给出了 SGD 算法有趣的收敛模式：  如果 $w_k$ 距离最优解 $w^\\star$ 越远，那么相对误差 $\\delta_k$ 越小，即 SGD 算法的收敛速度越快；  如果 $w_k$ 距离最优解越近，那么相对误差 $\\delta_k$ 越大，即 SGD 算法的收敛速度越慢。这意味着，初始时刻 SGD 算法与 GD 算法很类似，随机梯度与真实梯度之间的相对误差较小，SGD 算法会快速收敛到最优解附近；随着迭代次数的增加，$w_k$ 收敛至最优解 $w^\\star$ 时 SGD 的收敛速度反而变慢，收敛过程的随机性增加。2.3.3. 回顾增量更新考虑如下优化问题\\[\\min_w J(w) = \\mathbb{E}[f(w,X)]=\\mathbb{E}\\left[\\frac{1}{2}\\vert\\vert w-X \\vert\\vert^2\\right]\\]令梯度 $\\nabla_w J(w)$ 等于零，考虑到 $w$ 不是随机变量，显然有 $\\mathbb{E}[w-x]=0 \\Rightarrow w^\\star = \\mathbb{E}[X]$。如果假设不知道函数的显示表达式，使用 GD 和 SGD 来求解，有\\[\\begin{aligned}GD: \\quad &amp;w_{k+1} = w_k - \\alpha \\nabla_w \\mathbb{E}[f(w,X)] = w_k - \\alpha \\mathbb{E}[w_k-X]\\\\SGD: \\quad &amp;w_{k+1} = w_k - \\alpha \\nabla_w f(w,x_i) = w_k - \\alpha [w_k-x_k]\\end{aligned}\\]观察发现第二式其正好就是均值估计的增量更新迭代式，所以均值估计的增量更新算法是 SGD 算法的特殊形式，自然收敛。2.3.4. SGD 的确定性形式在前述 SGD 定义中，我们涉及到随机变量 $X$ 及其期望 $\\mathbb{E}[X]$，而我们在实际任务中会经常遇到另一种很类似但是不涉及随机变量的确定形式。考虑如下一般的优化问题\\[\\min_w J(w) = \\frac{1}{N}\\sum_{i=1}^N f(w,x_i),\\quad x_i\\in\\{x_i\\}_{i=1}^N\\]其中，$x_i$ 是一组确定的样本，不再是随机变量的采样。又假设样本数据集中没取出一个数代价很大（很慢或者很耗费成本），我们每次只能取出一个数进行计算，那么我们可以将迭代求解的形式写为\\[w_{k+1} = w_k - \\alpha \\nabla_w f(w_k,x_k)\\]上述过程和 SGD 形式几乎完全一样，只是 $x_i$ 从随机变量变为了确定的样本。此时有如下几个问题思考：  上面的迭代式是否是 SGD？  每次采样一个样本时需要对其进行大小排列后采样，还是随机采样？实际上，我们可以人为引入一个定义在样本数据集 ${x_i}_{i=1}^N$ 上的随机变量 $X$ 且其概率分布为均匀分布（$p(X=x_i)=\\frac{1}{N}$），此时确定性优化问题就转变为一个随机优化问题\\[\\min_w J(w) =\\frac{1}{N}\\sum_{i=1}^N f(w,x_i) =  \\mathbb{E}[f(w,X)]\\]其中，  后一个等式是严格成立的而不是近似，因此上述确定性形式的问题就是 SGD 算法；  随机变量 $X$ 需要从样本集中均匀随机抽取。2.3.5. BGD、MBGD 和 SGD在 SGD 的算法推导中我们按照 GD、BGD 到 SGD 的过程逐步推导。现在我们进一步分析其中 BGD 与 SGD 和一种新的 Mini-batch Gradient Descent（MBGD）算法的关系。考虑如下一般形式的优化问题\\[\\min_w J(w) = \\mathbb{E}[f(w,X)]\\]使用 BGD、SGD 和 MBGD 算法求解上述问题的迭代式分别如下：\\[\\begin{aligned}\\text{BGD}:\\quad w_{k+1} &amp;= w_k - \\alpha \\nabla_w \\frac{1}{n} \\sum_{i=1}^n f(w_k,x_i)\\\\\\text{MBGD}:\\quad w_{k+1} &amp;= w_k - \\alpha \\nabla_w \\frac{1}{m} \\sum_{j\\in\\mathcal{I}_k} f(w_k,x_k)\\\\\\text{SGD}:\\quad w_{k+1} &amp;= w_k - \\alpha \\nabla_w f(w_k,x_k)\\end{aligned}\\]其中，MBGD 中的 $\\mathcal{I}_k$ 是样本空间的一个子集，是从样本空间中独立随机采样 $m$ 次得到的样本集合。  相比 SGD，MBGD 因为用到了更多的样本数据，从而使其随机性更小。当 $m=1$ 时 MBGD 就退化成了 SGD；  相比 BGD，MBGD 由于采样的样本数目更少，因此其效率更高；  注意，当 $m=n$ 时 MBGD 并不等同于 BGD，因为 MBGD 的数据是从原始样本集中均匀随机采样的（某样本可能没被采样到也可能被使用多次），而 BGD 是对所有样本数据都仅使用一次。下面分别采用上述三种方法，给出对 $ x,y\\in [-10, +10] $ 区间的 100 个样本（均值为 $(0,0)$ 的随机撒点）求均值的结果示意图。其中左图是三种方法的迭代收敛路径，有图为三种方法迭代过程中预测值与真实均值的距离变化情况。需要关注的是不同方法的收敛速度。3. 时序差分法3.1. 时序差分思想（Temporal Difference）3.1.1. 从蒙特卡洛的角度分析根据前面的章节我们知道，即使采用增量更新技巧，蒙特卡洛方法也必须要等整个回合采样结束之后才能计算得到这一次的回报 $G_{t}$。那么有没有一种方法能够无须完整采样一个回合就能更新价值函数呢？我们以状态价值函数为例，观察回报的定义式：\\[\\begin{aligned}G_t \\doteq \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1} &amp;= R_{t+1}+\\sum_{k=0}^{\\infty} \\gamma^{k} R_{t+k+2}\\\\&amp;= R_{t+1}+\\gamma V_{t+1}    \\end{aligned}\\]然后带入蒙特卡洛的价值函数增量更新策略，即\\[\\begin{aligned}\\text{MC}:\\quad &amp; v(S_t) \\leftarrow v(S_t)+\\alpha({\\color{red}G_t}-v(S_t)) \\\\\\text{TD}:\\quad &amp; v(S_t) \\leftarrow v(S_t)+\\alpha({\\color{red}R_{t+1}+\\gamma v(S_{t+1})}-v(S_t))\\end{aligned}\\]上述第二行递推式就是本章所要介绍的 时序差分法（Temporal Difference Learning, TD）。可以发现，时序差分法只需要采样一次，即可利用下一时刻下一状态的状态价值函数，来更新我们当前时刻当前状态的状态价值函数，注意这里涉及到了两种关于时间的概念（当前时刻 vs 下一时刻、当前状态 vs 下一状态），为避免混淆，详细展开如下：  当前时刻 $t$，每一个当前状态 $S_t$ 对应状态价值函数 $V(s_t)$；  下一时刻 $t+1$，每一个下一时刻状态 $S_{t+1}$ 对应状态价值函数 $V(s_{t+1})$；  在当前时刻从某个具体状态 $S_t=s_t$ 出发，下一时刻转移至 $S_{t+1}=s_{t+1}$ 后，使用 $v_{\\textcolor{red}{t}}(\\textcolor{blue}{s_{t+1}})$ 来计算 $v_{\\textcolor{red}{t+1}}(\\textcolor{blue}{s_t})$；  其他不涉及状态转移的状态，他们的价值函数保持不变，即 $v_{t+1}(s)=v_{t}(s),\\; s\\neq s_t$综上，经过一些移项，时序差分法的迭代公式为\\[\\begin{cases}v_{t+1}(s_t) = v_t(s_t)-\\alpha_t(s_t)\\big[v_t(s_t)-[r_{t+1}+\\gamma v_t(s_{t+1})]\\big]\\\\v_{t+1}(s) = v_t(s),\\; s\\neq s_t\\end{cases}\\tag{1}\\]我们将时序差分法迭代式的各个部分做如下标注\\[\\underbrace{v_{t+1}(s_t)}_{\\text{new estimate}} = \\underbrace{v_t(s_t)}_{\\text{old estimate}}-\\alpha_t(s_t)\\big[\\overbrace{v_t(s_t)-[\\underbrace{r_{t+1}+\\gamma v_t(s_{t+1})}_{\\text{TD target }\\bar{v}_t}}^{\\text{TD error }\\delta_t}]\\big]\\]  TD Target时序差分法的迭代式中，迭代目的就是将 $v(s_t)$ 朝着 $\\bar{v}_t$ 的方向改进，所以称其为 TD Target。将迭代式改写如下\\[\\begin{aligned}  &amp;v_{t+1}(s_t) = v_t(s_t)-\\alpha_t(s_t)[v_t(s_t) - \\bar{v}_t]\\\\  \\Rightarrow \\; &amp;v_{t+1}(s_t) - \\textcolor{red}{\\bar{v}_t} = v_t(s_t)-\\textcolor{red}{\\bar{v}_t}-\\alpha_t(s_t)[v_t(s_t) - \\bar{v}_t]\\\\  \\Rightarrow \\; &amp;v_{t+1}(s_t) - \\textcolor{red}{\\bar{v}_t}= [1-\\alpha_t(s_t)] \\cdot [v_t(s_t) - \\textcolor{red}{\\bar{v}_t}]\\\\  \\Rightarrow \\; &amp;\\vert v_{t+1}(s_t) - \\textcolor{red}{\\bar{v}_t}\\vert = \\vert 1-\\alpha_t(s_t)\\vert\\cdot \\vert v_t(s_t) - \\textcolor{red}{\\bar{v}_t}\\vert\\\\\\end{aligned}\\]由于 $0&lt;1-\\alpha_t(s_t)&lt;1$，所以有\\[\\vert v_{t+1}(s_t) - \\textcolor{red}{\\bar{v}_t}\\vert \\leq \\vert v_t(s_t) - \\textcolor{red}{\\bar{v}_t}\\vert\\]也即 $v_{t+1}(s_t)$ 距离 TD Target 更近！  TD ErrorTD Error 定义为\\[\\delta_t = v_t(s_t)-[r_{t+1}+\\gamma v_t(s_{t+1})]\\]其反应了两个连续时刻前后状态的价值函数的差分（difference）。更进一步，我们需要分析该差分随着迭代的变化。假设在当前策略 $\\pi$ 下我们已经迭代收敛，价值函数已经收敛至 $v_\\pi(s)$，将 TD Error 定义式的下标进行改写，有\\[\\delta_{\\pi,t} = v_\\pi(s_t) - [r_{t+1}+\\gamma v_\\pi(s_{t+1})]\\]分别对上式左右两边求期望，有\\[\\mathbb{E}[\\delta_{\\pi,t}] = v_\\pi(s_t) - \\mathbb{E}[r_{t+1} + \\gamma v_\\pi(s_{t+1})] = 0\\]右侧等号成立的原因是因为，对于收敛的状态价值函数，其定义式就是\\[v_{\\pi}(s_t) = \\mathbb{E}[r_{t+1} + \\gamma v_\\pi(s_{t+1})]\\]因此，TD Error 衡量了 $v_t$ 和 $v_\\pi$ 的偏差，同时其也反应了一步采样后从序列 $(s_t, r_{t+1}, s_{t+1})$ 中得到的新的信息，这个新的信息与当前旧的估计之间存在偏差，就可以利用这个偏差来更新 $v_t$。3.1.2. 从 RM 算法的角度分析可以证明时序差分算法迭代计算的状态价值函数 $v(s)$ 最终收敛至 $v_{\\pi}(s)$，这需要用到我们前述介绍的 RM 算法，具体分析如下：考虑如下的期望估计问题\\[w = \\mathbb{E}[R+\\gamma v(X)]\\]其中 $R,X$ 都是随机变量，$\\gamma$ 是一个常数（折扣因子），$v(\\cdot)$ 是一个函数（状态价值函数）。假设我们能够采样得到样本 ${x}\\in X,{r}\\in R$，可定义函数 $g(w)$ 和其含噪观测 $g(w,\\eta)$ 如下\\[\\begin{aligned}g(w) &amp;= w-\\mathbb{E}[R+\\gamma v(X)]\\\\\\tilde{g}(w,\\eta) &amp;= w-[r+\\gamma v(x)]\\\\&amp;=(w-\\mathbb{E}[R+\\gamma v(x)])+(\\mathbb{E}[R+\\gamma v(x)])-[r+\\gamma v(x)]\\\\&amp;\\doteq g(w) + \\eta\\end{aligned}\\]上述问题变为方程 $g(w)=0$ 的寻根问题，对应的 RM 算法求解如下\\[w_{k+1} = w_{k} - \\alpha_k \\tilde{g}(w_k,\\eta_k) = w_k - \\alpha_k[w_k-(r_k+\\gamma v(x_k))]\\tag{2}\\]对比式（1）与式（2）可以发现形式完全一样，因此 TD 算法是收敛的。3.1.3. 从贝尔曼期望方程的角度分析虽然前面我们通过一个特殊形式的期望估计问题推导出 TD 算法是一种特殊形式的 RM 算法，并得到了收敛性保证，但我们并没有明确其一定能够收敛至 $v_\\pi(s)$。下面我们从贝尔曼期望方程的角度分析 TD 算法的收敛性，只有通过贝尔曼期望方程才能严格证明这一点。对于状态价值函数，贝尔曼期望方程如下\\[v_\\pi(s) = \\mathbb{E}[R+\\gamma v_\\pi(S^\\prime)\\vert s], \\;s\\in S\\]使用 RM 算法求解贝尔曼期望方程，需要转化为 $g(v(s))=0$ 的求根问题 ，其中函数 $g(v(s))$ 如下\\[g(v(s)) = v(s) - \\mathbb{E}[R+\\gamma v_\\pi(S^\\prime)\\vert s]\\]我们仅能采样得到 $s,r, s^\\prime$，则含噪观测 $g(v(s),\\eta)$ 如下\\[\\begin{aligned}\\tilde{g}(v(s),\\eta) &amp;= v(s) - [r+\\gamma v_\\pi(s^\\prime)]\\\\&amp;= v(s) - \\mathbb{E}[R+\\gamma v_\\pi(s^\\prime)\\vert s] + \\mathbb{E}[R+\\gamma v_\\pi(s^\\prime)\\vert s] - [r+\\gamma v_\\pi(s^\\prime)]\\\\&amp;= g(v(s)) + \\eta\\end{aligned}\\]那么 RM 算法的迭代式如下\\[\\begin{aligned}v_{k+1}(s) &amp;= v_k(s) - \\alpha_k \\tilde{g}(v_k(s),\\eta_k)\\\\&amp;= v_k(s) - \\alpha_k [v_k(s) - [\\textcolor{blue}{r_k}+\\gamma \\textcolor{blue}{v}_{\\textcolor{red}{\\pi}}(\\textcolor{blue}{s^\\prime_k})]]\\end{aligned}\\]虽然上述迭代式已经和 TD 算法的迭代式很相似，但是需要注意以下两点不同：  在每一步迭代中，我们需要频繁采样多次同样的序列 $(s,r, s^\\prime)$ 才能完成对状态 $v(s)$ 的更新（蓝色标记）；  在每一步迭代中，注意式中要求 $v_\\pi(s^\\prime)$ 是已知的，但实际上是不知道的！（红色标记）。对于第一个假设，我们实际采样一个回合后，对于其中每一个片段 $(r_t, r_{t+1},s_{t+1})$ 替代 $(s,r, s^\\prime)$，采到谁我们就更新谁的价值函数。对于第二个假设，我们就用当前时刻的 $v_k(s^\\prime_k)$ 替换掉 $v_\\pi(s^\\prime)$（开放式思考，替换后能保证收敛么？）。TD 算法的严格收敛证明依赖 RM 算法，此处略。最后我们可以发现，TD 算法就是用于求解贝尔曼期望方程的一种特殊的 RM 算法。3.1.4. TD 与 MC 的比较  在线与离线：          TD 方法：在线；      MC 方法：离线；        无限采样与有限采样：          TD 方法：支持无限采样；      MC 方法：仅支持有限采样；        自举与否：          TD 方法：自举；      MC 方法：非自举；        方差与偏差：          TD 方法：高偏差，低方差。因为 TD 方法只需要一次采样，其中涉及到的随机变量少，随机性少，因此方差小。但是由于其依赖初值估计，如果估计不准会带来很大的偏差，虽然最终随着采样次数的增多也能收敛到正确的值。      MC 方法：低偏差，高方差。因为 MC 方法不涉及任何初值估计，其均值的估计是对期望的无偏估计，因此在迭代过程中偏差比较小，但因为他每一次采样都是“天马行空”的，因此不同的采样可能差距非常大，方差就会很大。      3.2. 同策略时序差分（SARSA）3.2.1. SARSA前述 TD 算法针对状态价值函数进行估计，将其推广至状态-动作价值函数估计后，得到本节介绍的时序差分方法的一个具体算法，即 SARSA 算法：\\[q(s_t,a_t)  \\leftarrow q(s_t,a_t)-\\alpha\\{q(s_t,a_t)-[r_{t+1}+\\gamma q(s_{t+1},a_{t+1})]\\}\\\\\\]注意到，上述迭代式需要与进行两次动作采样才能得到足够的经验数据进行一步迭代：\\[s_t\\mathop{\\longrightarrow}\\limits^{\\pi}a_t\\mathop{\\longrightarrow}\\limits^{\\text{model}}r_t,s_{t+1}\\mathop{\\longrightarrow}\\limits^{\\pi}a_{t+1}\\]观察经验数据的一般形式 $(S_t,A_t, R_{t+1}, S_{t+1}, A_{t+1})$，取首字母放在一起命名本方法。  行为策略经验获取过程需要进行两次动作采样，对于 SARSA 而言，两次动作采样时使用的策略是相同的。延续我们之前在 Monte Carlo 方法中讨论的结果，策略一般选取为 $\\varepsilon$-greedy 策略，兼顾探索和利用。由于这个策略的第一次采样需要实际执行产生环境交互，因此称其为 「行为策略」。具体而言：  第一步根据策略进行动作采样后实际执行动作，即 $s_t\\mathop{\\longrightarrow}\\limits^{\\pi}a_t\\mathop{\\longrightarrow}\\limits^{\\text{model}}r_t,s_{t+1}$ 过程；  第二步根据策略进行动作采样只是为了能够得到具体的 $Q(S_{t+1},A_{t+1})$ 用于迭代式的求解，并不实际执行采样得到的动作 $A_{t+1}$。所以严格来说，行为策略指的是第一次实际执行动作所采用的策略。上述迭代式仍然是一个策略评估过程，即在 给定策略 $\\pi$ 的条件下，给出状态-动作价值函数 $q_\\pi(s,a)$ 的估计。将其与特定的策略改进方法结合可以得到完整的 TD 形式的方法。  目标策略我们定义策略改进时被改进的策略叫 「目标策略」，那么对于 SARSA 而言，目标策略和行为策略是同一个策略。也就是说，SARSA 算法的自然流程表明，策略改进是针对前面的 $\\varepsilon$-greedy 行为策略进行改进。  有人可能会问，为什么目标策略和行为策略是相同的？能不同么？大家可以尝试脑补一下：      上一轮迭代已有旧的 $Q$ 函数；    在策略评估阶段，基于 $\\varepsilon$-greedy 行为策略采集经验更新 $Q$ 函数；    在策略改进阶段，如果更新一个新的目标策略，可选的无非就是 greedy 策略；    在下一时刻策略评估阶段，再次基于 $\\varepsilon$-greedy 行为策略采集经验，这时需要用到新的 $Q$ 函数按照 $\\varepsilon$ 概率来选择动作，不就相当于隐式更新了 $\\varepsilon$-greedy 行为策略自身么？额外更新的 greedy 策略没有任何意义；    所以，并不是人们强行设定 SARSA 在策略改进时，必须针对 行为策略=目标策略 来改进，而是整个算法自然的流程导致的结果如此。对 SARSA 算法的行为策略和目标策略总结如下：  行为策略：          第一次动作采样： $\\varepsilon$-greedy 策略      第二次动作采样： 相同的 $\\varepsilon$-greedy 策略        目标策略：          相同的 $\\varepsilon$-greedy 策略      最终形成 SARSA 方法的伪代码如下：  Initialize $q(s,a)$ arbitrarily, choose start state $s$, given a behaviour policy $\\pi_t$ (e.g., $\\varepsilon$-greedy)  Repeat (for each episode):          Repeat (if $s$ is not terminal state):                  collect experience:                          choose $a$ at $s$ following $\\pi_t$              take action $a$, get $r$, transfer to $s^\\prime$                              choose $a^\\prime$ at $s^\\prime$ following $\\pi_t$                                              policy evaluation:                          ${q(s,a)\\leftarrow q(s,a)-\\alpha[q(s,a) - (r+\\gamma q(s^\\prime,a^\\prime))]}$                                policy improvement:                          (update same $\\varepsilon$-greedy as target policy)                              $\\pi_{t+1}(a\\vert s) = 1-\\frac{\\varepsilon}{\\vert \\mathcal{A} \\vert}(\\mathcal{A}-1)$ if $a=\\arg\\max_a q(s,a)$                                            $\\pi_{t+1}(a\\vert s) = \\frac{\\varepsilon}{\\vert \\mathcal{A} \\vert}$ otherwise                            ${s\\leftarrow}s^\\prime; a\\leftarrow a^\\prime$                                $t \\leftarrow t+1$                    使用 SARSA 方法在 Grid World 中进行实验。设定初始状态为左上角格子，相关参数设置为 $r_{target}=0, r_{forbidden}=r_{boundary} = -10, r_{other}=-1,\\gamma = 0.9,\\alpha = 0.1$，迭代 500 步如下图所示：  左子图表明，          经过 500 步迭代，从左上角格子出发已经找到了对应的较优的路径；      除了左上角格子外，其他格子对应的策略明显不是最优的，需要经过更多步探索才能收敛到最优策略。        右子图表明，          随着迭代次数的增加，每个 episode 探索的步长逐渐降低，对应的总奖励逐渐升高；      总奖励值依然为负数，因为采用 $\\varepsilon$-greedy 策略会引入大量非最优探索，导致状态价值的估计偏低。      3.2.2. Expected SARSA我们可以对 SARSA 的策略评估部分进行改进，不再进行采样得到动作 $a^\\prime$，而是使用 $q$ 的期望（也就是 $v$），此时的迭代式即为 期望 SARSA\\[\\begin{aligned}q(s,a) &amp;\\leftarrow q(s,a)-\\alpha\\{q(s,a)-(r+\\gamma \\mathbb{E}_\\pi[q(s^\\prime,A)])\\}\\\\q(s,a) &amp;\\leftarrow q(s,a)-\\alpha[q(s,a)-(r+\\gamma V(s^\\prime))]\\\\\\end{aligned}\\]  优势：偏差更小（因为只需要 $(s,a,r,s^\\prime)$，不需要做第二次动作采样得到 $a^\\prime$，随机性更小）  劣势：计算量大幅增加（因为需要计算多个 $q$ 值后取平均）。期望 SARSA 本质上是求解如下贝尔曼期望方程\\[q_\\pi(s,a) = \\mathbb{E}[R+\\gamma v_\\pi(s^\\prime)\\vert s,a]\\]3.2.3. n-step SARSASARSA 的策略评估部分是一种一步更新的方法，即每次更新只使用一步的采样数据。我们可以将 SARSA 的策略评估部分泛化到 $n$ 步更新，即每次更新使用 $n$ 步的采样数据。这本质上是将 SARSA 和 MC 方法进行融合。考虑回报的不同展开形式\\[\\begin{aligned}  \\text{SARSA} \\; \\leftarrow \\; G_t^{(1)} &amp;= R_{t+1}+\\gamma Q(S_{t+1},A_{t+1})\\\\  G_t^{(2)} &amp;= R_{t+1}+\\gamma R_{t+2}+\\gamma^2 Q(S_{t+2},A_{t+2})\\\\  \\vdots\\\\  \\text{n-step SARSA} \\; \\leftarrow \\; G_t^{(n)} &amp;= R_{t+1}+\\gamma R_{t+2}+\\cdots+\\gamma^{n-1} R_{t+n}+\\gamma^n Q(S_{t+n},A_{t+n})\\\\  \\vdots\\\\  \\text{MC} \\; \\leftarrow \\; G_t^{(\\infty)} &amp;= R_{t+1}+\\gamma R_{t+2}+\\cdots+\\gamma^{n-1} R_{t+n}+\\cdots\\end{aligned}\\]将上述不同的回报展开形式代入 $q(s,a)$ 关于回报的定义式，然后再代入期望 SARSAR 迭代式，可以得到 $\\boldsymbol{n}$-step SARSA 这种介于 SARSA 和 MC 方法之间的迭代式\\[q_\\pi(s,a)\\leftarrow q_\\pi(s,a)-\\alpha[q_\\pi(s,a) - G_t^{(n)}]\\]  当 $n=1$ 时，$n$-step SARSA 等价于 SARSA（很显然）；  当 $n=\\infty$ 时，$n$-step SARSA 等价于 MC 方法（请尝试推导，需要额外定义 $\\alpha=1$）。3.3. 异策略时序差分（Q-Learning）3.3.1. Q-Learning在 SARSAR 算法的行为策略是 $\\varepsilon$-greedy 策略，但在第二次动作采样时，我们只是为了计算后续 $Q$ 值而并不需要与环境进行交互。此时继续采用 $\\varepsilon$-greedy 策略并不会对探索产生影响。实际上，在下一时刻状态 $s^\\prime$ 下，明显存在一个理论更优的确定性策略（也即贪婪策略）可供我们选择动作\\[a^\\star=\\pi(s^\\prime) = \\arg\\max_a\\; q(s^\\prime, a)\\]此时我们不需要进行第二次动作采样，而是直接找到下一时刻状态下已知的最大 $q(s^\\prime, a)$，就使用这个值对应的 $a$ 来更新 $q(s,a)$。这种方法即为 Q-Learning。对应的策略评估迭代式如下\\[q(s,a) \\leftarrow q(s,a)-\\alpha\\{q(s,a)-[r+\\gamma q(s^\\prime,a^\\star)]\\}\\]当然我们也可以避免定义中间的 $a^\\star$，直接使用 $\\max_a q(s^\\prime,a)$ 来简化策略评估迭代式\\[q(s,a) \\leftarrow q(s,a)-\\alpha\\{q(s,a)-[r+\\gamma \\max_a q(s^\\prime,a)]\\}\\]经过上述操作，迭代式就不再是求关于某个策略 $\\pi$ 的状态-动作价值函数值 $q_\\pi(s,a)$，而是直接求 最优状态-动作价值函数 $q_\\star(s,a)$ 的的估计，最终收敛后直接对应的贪婪策略就是最优策略。因此，Q-Learning 在策略改进时更新的 「目标策略」 自然就是 贪婪策略。注意到，上述内容只是围绕第二次动作采样展开的，并没有对第一次动作采样使用的 「行为策略」 做出任何约束，我们可以沿用 SARSA 的 $\\varepsilon$-greedy 策略，也可以使用一些别的策略，如均匀随机采样策略，甚至直接使用人类决策来进行采样都可以。为便于与 SARSA 算法对比，将 Q-Learning 的目标策略和行为策略总结如下：  行为策略：          第一次动作采样： $\\varepsilon$-greedy 策略、uniform 策略、人类等；      第二次动作选取： greedy 策略        目标策略：          greedy 策略      Q-Learning 的伪代码如下：  Initialize $Q(s,a)$ arbitrarily, choose start state $s$, given a behaviour policy $\\textcolor{red}{\\pi_b}$ (e.g., $\\varepsilon$-greedy, uniform, human, etc)  Repeat (for each episode):          Repeat (if $s$ is not terminal state):                  collect experience:                          choose $a$ at $s$ following $\\textcolor{red}{\\pi_b}$              take action $a$, get $r$, transfer to $s^\\prime$                              choose $a^\\prime= \\arg\\max_a q(s^\\prime, a)$                                              policy evaluation:                          ${q(s,a)\\leftarrow q(s,a)-\\alpha[q(s,a) - (r+\\gamma q(s^\\prime,a^\\prime))]}$                                policy improvement:                          (update greedy policy as target policy)                              $\\pi_{t+1}(a\\vert s) = 1$ if $a=\\arg\\max_a q(s,a)$                                            $\\pi_{t+1}(a\\vert s) = 0$ otherwise                            ${s\\leftarrow}s^\\prime; a\\leftarrow a^\\prime$                                $t \\leftarrow t+1$                    标红的部分即为 Q-Learning 与 SARSA 算法伪代码中的区别所在。注意到，伪代码中 policy improvement 实际上是不用写出来的，因为其目标策略是贪婪策略，当 $q(s,a)$更新时自然会按照最大的 Q 值进行策略更新，不需要额外显式说明。3.3.2. 同策略与异策略为了更加清晰地区分 SARSA 和 Q-learning，我们对这两种典型的 TD 算法中提到的目标策略和行为策略再次明确定义如下：  行为策略：用于和环境交互产生样本的策略；  目标策略：基于价值函数一直保持更新直至最优的策略。当行为策略和目标策略相同时，称其为 同策略（on-policy）时序差分方法，不论是和环境交互还是被持续改进，都是同一个策略。当行为策略和目标策略不同时，就称其为 异策略（off-policy）时序差分方法。为了便于比较，我们再次将 SARSA 和 Q-Learning 的策略列表对比如下：            SARSA      Q-Learning                  行为策略      行为策略              第一次动作采样： $\\varepsilon$-greedy 策略      第一次动作采样： $\\varepsilon$-greedy 策略、uniform 策略、人类等              第二次动作采样： $\\varepsilon$-greedy 策略      第二次动作采样： greedy 策略              目标策略      目标策略              $\\varepsilon$-greedy 策略      greedy 策略      可以看出，SARSA 是一种同策略（on-policy）时序差分方法，因为其采样和更新的均为同一个策略（都是 $\\varepsilon$-greedy 策略），而 Q-Learning 是一种异策略（off-policy）时序差分方法，因为其行为策略不是 greedy 策略，但更新的策略是 greedy（贪婪）策略，二者不同。使用 off-policy 的好处在于，我们可以使用与目标策略不同的更加激进更加具备探索性的行为策略来与环境交互获得经验。行为策略越激进，那么能够探索到的状态动作对就越多，相应价值函数更新的频次就更高，探索效率就自然更高。注意，在 off-policy中，只要求行为策略与目标策略不同。行为策略本身可以随意选取，比如当目标策略是贪婪策略时，行为策略可以是 $\\varepsilon$-greedy 策略，也可以是均匀随机策略（探索性更强），甚至是人在回路决策策略。最后给出两个延伸问题供大家思考：  思考1：MC 方法是同策略还是异策略？（同策略）  思考2：怎么把 Q-Learning 改造成 on-policy 方法？（第一次动作采样使用$\\varepsilon$-greedy，第二次动作选取使用greedy，目标策略使用 $\\varepsilon$-greedy）3.3.3. 不同行为策略的探索性下面给出两种不同行为策略下 Q-Learning 探索 Grid World 的示例，场景设置与前述介绍 SARSA 时相同，唯一区别在于此处我们想找到所有状态下的最优策略，而不是某个初始状态的最优轨迹。首先给出最优策略和其对应的状态价值函数作为参考，如下图所示  行为策略是均匀随机策略设置行为策略是均匀随机策略，每个状态的五个动作 选取概率为 25%，采用异策略的 Q-Learning 方法迭代 100 万步，得到的结果如下图所示可以看出，均匀随机策略的探索性比较强，100 万步迭代后每个状态动作对都被多次采样到了。最终得到的最优策略估计（贪婪策略）如下图所示，下图右侧给出了状态价值函数与最优状态价值函数的差随迭代次数变化的曲线可以看出，最终得到的最优策略估计与真实的最优策略非常接近。  行为策略是有倾向的随机策略接着，我们采用另外一个行为策略，设置所有状态下 向右走的概率提高至 50%，剩下 50% 概率由其他动作平分。很明显，这个策略的探索性不如上一个全部动作都均匀随机选择的策略，因为他多了一个向右的倾向性。得到的结果如下图所示可以看出，经过 100 万步迭代，仍然有很多状态动作对从没有被探索到，得到的状态价值函数估计与真实的最优值相差较大。继续提高向右走的概率，探索性会变得更弱，Q-Learning 方法的收敛速度更慢。3.4. 总结3.4.1. 表述形式总结所有的 TD 算法可以表述为一个统一的形式\\[q_{t+1}(s_t,a_t) = q_t(s_t,a_t) - \\alpha [q_t(s_t,a_t) - \\textcolor{red}{\\bar{q}_t}]\\]不同 TD 算法的差异都可以体现在对 TD Target（$\\bar{q}_t$）的不同选择上\\[\\begin{aligned}\\text{SARSA:}\\quad\\bar{q}_t &amp;= r_{t+1}+\\gamma q_t(s_{t+1},a_{t+1})\\\\n\\text{-step SARSA:}\\quad \\bar{q}_t &amp;= r_{t+1} + r_{t+2}+\\cdots +\\gamma^n q_t(s_{t+n},a_{t+n})\\\\\\text{Expected SARSA:}\\quad\\bar{q}_t &amp;= r_{t+1}+\\gamma \\sum_a \\pi(a\\vert s_{t+1})q(s_{t+1},a)\\\\\\text{Q-Learning:}\\quad\\bar{q}_t &amp;= r_{t+1}+\\gamma \\max_a q(s_{t+1},a)\\\\\\text{MC:}\\quad\\bar{q}_t &amp;= r_{t+1} + \\gamma r_{t+2} + \\cdots + \\gamma^{T-t-1} r_T,\\text{ where }\\alpha = 1\\end{aligned}\\]3.4.2. 求解方程总结从求解贝尔曼方程的角度也可总结如下\\[\\begin{aligned}\\text{SARSA:}\\quad \\text{BE:} \\quad&amp;q_\\pi(s,a) = \\mathbb{E}[R_{t+1}+\\gamma q_\\pi(S_{t+1},A_{t+1})\\vert St+s, A_t=a]\\\\n\\text{-step SARSA:}\\quad \\text{BE:} \\quad&amp;q_\\pi(s,a) = \\mathbb{E}[R_{t+1}+\\gamma^2R_{t+2}+\\cdots+\\gamma^n q_\\pi(S_{t+n},A_{t+n})\\vert St+s, A_t=a]\\\\\\text{Expected SARSA:}\\quad \\text{BE:} \\quad&amp;q_\\pi(s,a) = \\mathbb{E}[R_{t+1}+\\gamma \\mathbb{E}_{A_{t+1}}[q_\\pi(S_{t+1},A_{t+1})]\\vert St=s, A_t=a]\\\\\\text{Q-Learning:}\\quad \\textcolor{red}{\\text{BOE:}} \\quad&amp;q_\\pi(s,a) = \\mathbb{E}[R_{t+1}+\\gamma \\max_a q_\\pi(S_{t+1},a)\\vert St=s, A_t=a]\\\\\\text{MC:}\\quad \\text{BE:} \\quad&amp;q_\\pi(s,a) = \\mathbb{E}[R_{t+1}+\\gamma R_{t+2}+\\cdots+\\gamma^{T-t-1} R_T\\vert St=s, A_t=a]\\end{aligned}\\]3.4.3. 行为表现总结      Q-Learning：包含 greedy 策略中取 max 操作，也就是不考虑可能走到很大负奖励的状态-动作，只考虑会不会最终获得最大奖励的状态-动作。如果某状态下某动作可以获得很大的奖励，那这条路就牛逼，所以 Q-Learning更勇猛，不害怕错，更激进;        SARSA：只要某状态周围有错（很大的负奖励），那么就有机会（$\\varepsilon/\\vert\\mathcal{A}\\vert$）获得这个不好的奖励，那么整条路反馈都会评分很差，之后会尽量避开。最终导致Sarsa会对犯错更敏感，会远离犯错的状态-动作，更保守。  4. 参考文献[1] shuhuai008. bilibili【强化学习】(SARSA) 时序差分-同轨策略TD控制[2] 莫烦. 什么是 Sarsa (强化学习)"
  },
  
  {
    "title": "强化学习（蒙特卡洛法）",
    "url": "/posts/reinforcement-learning-Monte-Carlo/",
    "categories": "Academic, Knowledge",
    "tags": "python, reinforcement learning",
    "date": "2022-11-29 17:07:19 +0800",
    





    
    "snippet": "本文介绍了强化学习的 model-free 方法——蒙特卡洛法。  1. 引言  2. 蒙特卡洛法          2.1. 大数定律与蒙特卡洛思想      2.2. 蒙特卡洛基础算法                  2.2.1. 蒙特卡洛采样          2.2.2. 蒙特卡洛价值估计          2.2.3. 算法流程                    2.3. 蒙...",
    "content": "本文介绍了强化学习的 model-free 方法——蒙特卡洛法。  1. 引言  2. 蒙特卡洛法          2.1. 大数定律与蒙特卡洛思想      2.2. 蒙特卡洛基础算法                  2.2.1. 蒙特卡洛采样          2.2.2. 蒙特卡洛价值估计          2.2.3. 算法流程                    2.3. 蒙特卡洛改进算法（MC Exploring Starts）                  2.3.1. 首次访问与每次访问          2.3.2. 序列拆分与重复利用          2.3.3. 探索起点（Exploring Starts）          2.3.4. 增量更新（incremental update）                    2.4. 蒙特卡洛改进算法（MC e-greedy）                  2.4.1. 探索和利用          2.4.2. 探索性分析          2.4.3. 最优性分析                    2.5. 蒙特卡洛的局限性        3. 参考文献1. 引言在前面介绍的动态规划方法中，我们假设已知模型的动态特性 $p(s^\\prime,r \\vert s,a)$，此时可以对下一步的状态和回报做出预测。而在很多实际案例中，我们无法得知模型的动态特性，此时动态规划方法就不适用了。注意到动态规划方法中的核心是对两类最优价值函数的估计，而当模型的动态特性未知时，我们不能通过迭代的形式计算最优价值函数，只能回归至价值函数原本的定义（期望），那么有什么办法对期望进行估计呢？这就是本章介绍的蒙特卡洛法，其通过大数定律保证在经过足够次数的采样后，可以通过求取价值函数的均值来逼近其期望。2. 蒙特卡洛法2.1. 大数定律与蒙特卡洛思想大数定律：对于随机样本 $X$，假设 ${x_j}_{j=1}^N$ 是独立同分布（independent and identically distributed, iid）随机变量样本集，定义\\[\\bar{x} = \\frac{1}{N}\\sum_{j=1}^N x_j\\]为样本集的均值，那么\\[\\begin{aligned}\\mathbb{E}[\\bar{x}] &amp;= \\mathbb{E}[X]\\\\Var[\\bar{x}] &amp;= \\frac{1}{N}Var[X]\\end{aligned}\\]当 $N\\rightarrow \\infty$ 时，方差趋于零，此时样本均值收敛至期望值。大数定律表明，当随机事件发生的次数足够多时，随机事件发生的频率趋近于预期的概率。可以简单理解为样本数量越多，其平概率越接近于期望值。大数定律生效的前提条件是：1、独立重复事件；2、重复次数足够多。蒙特卡洛法（Monte Carlo）方法，又称随机抽样或统计试验方法，思想是“当所求解问题是某种随机事件出现的概率，或者是某个随机变量的期望值时，通过某种“实验”的方法，以这种事件出现的频率估计这一随机事件的概率，或者得到这个随机变量的某些数字特征，并将其作为问题的解。是一种基于大数定律的统计方法。  这一方法诞生于上世纪40年代美国的”曼哈顿计划”，名字来源于赌城蒙特卡罗(Monte Carlo)——位于法国的国中之国摩纳哥的一个以赌博业闻名的城市。而赌博象征概率；蒙特卡罗方法正是以概率为基础的方法，属于非确定性算法。蒙特卡洛方法解决强化问题的本质，是基于通过采样大量数据来进行学习的经验方法实现的，因此，即便是在环境模型 $p(s^\\prime,r \\vert s,a)$ 未知/未完全可知的情况下，采用时间步骤有限的、完整序列(episode)中进行采样，并通过平均采样回报来解决强化学习问题。2.2. 蒙特卡洛基础算法2.2.1. 蒙特卡洛采样在一次交互过程中，从特定的状态-动作（$s_0, a_0$）出发，可采样得到一条序列\\[s_0, a_0, r_1, s_1, a_1, r_2, s_2,\\cdots\\]计算对应的回报\\[G_t = \\sum_{k=0} \\gamma^k R^{t+k+1}\\]2.2.2. 蒙特卡洛价值估计采集 $N$ 条序列，对于其中每条序列都算出回报后，对于首次或每次命中给定状态 $s_0$ 的轨迹，根据大数定律计算状态价值函数为\\[v_\\pi(s_0) \\doteq \\mathbb{E}_\\pi[G_t \\vert S_t = s] =\\frac{1}{N}\\sum_{i=1}^N G_t^{(i)}\\]同理，对于首次或每次命中（$s_0,a_0$）的轨迹，根据大数定律计算状态-动作价值函数为\\[q_\\pi(s_0, a_0) \\doteq \\mathbb{E}_\\pi[G_t \\vert S_t = s_0, A_t = a_0] =\\frac{1}{N}\\sum_{i=1}^N G_t^{(i)}\\]在实际中，计算状态-动作价值函数的意义更大，方便策略改进。但注意，状态序列采样时需要同时命中 $S_t=s,A_t = a$ 条件时才能采集对应的 $G_t$，这对样本量需求更大，操作难度更高。2.2.3. 算法流程在策略迭代的基础上，给定出示策略 $\\pi_0$，对于第 $k$ 次迭代，蒙特卡洛基础算法如下：  策略评估：对于所有的 $(s, a)$ 都需要进行足够多次的采样（二重循环遍历），采样得到足够多次的回合后计算首次或每次命中对应的 $G_t$，根据大数定律，$G_t$ 的均值可用来近似状态-动作价值函数 $q_{\\pi_k}(s,a)$；  策略迭代：求解 $\\pi_{k+1}(s) = \\arg\\max_{\\pi}\\sum_a \\pi(a \\vert s) q_{\\pi_k}(s,a)$，最优策略是贪心策略，即只有当 $a_k^\\star = \\arg\\max q_{\\pi_k}(s \\vert a)$ 时 $\\pi_{k+1}(a_k^\\star\\vert s) = 1$。可以看出，与策略迭代方法相比，蒙特卡洛基础算法直接估计状态-动作价值函数 $q_\\pi(s,a)$ 并用于改进策略，而不依赖于（也没办法）先迭代求解 $v_\\pi(s)$ 再计算 $q_\\pi(s,a)$。最后，蒙特卡洛方法的收敛性保证依赖于策略评估的收敛性的，因为蒙特卡洛方法仅仅将其中策略评估部分中价值函数的计算改为大数定律保证的采样估计。蒙特卡洛基础算法的局限性：      对 $G_t$ 采样的过程中，样本必须在一幕（从 $t$ 时刻开始，$T$ 时刻结束）全部执行结束的状态下，才能获取 $R_{t+1},R_{t+2},…,R_{t+T}$ 的具体结果，并最终获得1个 $G_t$ 结果，采样数据利用率低。        最终需要获取足够量的（$N$ 个） $G_t$ 结果才能够执行均值操作，整个过程绝大部分时间浪费在了采样过程，时间利用率低。  2.3. 蒙特卡洛改进算法（MC Exploring Starts）2.3.1. 首次访问与每次访问在蒙特卡洛基础算法中，我们假设序列是由给定的状态动作对 $(s_0, a_0)$ 开始采样得到的。注意到，同样的状态动作对除了首次出现外，也可能在后续采样过程中出现多次。以下面的一次采样序列为例，其中 $(s_0, a_0)$ 命中了两次\\[\\textcolor{red}{s_0 \\mathop{\\rightarrow}\\limits^{a_0}} s_1\\mathop{\\rightarrow}\\limits^{a_4} \\textcolor{red}{s_0 \\mathop{\\rightarrow}\\limits^{a_0}} s_1 \\mathop{\\rightarrow}\\limits^{a_2} s_5\\mathop{\\rightarrow}\\limits^{a_3}\\cdots\\]因此计算回报的方式也分为以下两种：      首次访问型（first visit）：只采集第一个出现（$s_0,a_0$）时对应的 $G_t$（蒙特卡洛基础算法）        每次访问型（every visit）：采集每次出现（$s_0, a_0$）时对应的 $G_t$  首次访问型的优势与每次访问型的劣势：  采样序列与序列之间相互独立，首次访问型产生的回报样本同样也是经过独立试验产生的相互独立的样本；  相比之下，每次访问型中，后续回报计算只是首次回报的子集，回报计算之间是存在依赖的（非独立），当然如果两次访问之间距离很远则依赖也很弱；首次访问型的劣势与每次访问型的优势：  首次访问型只能从一个采样序列中获取一个回报，数据利用率很低；  相比之下，每次访问型可能仅需要更少的序列数量就可以得到足够多的样本，数据利用率高；2.3.2. 序列拆分与重复利用更进一步，观察分析上述采样序列\\[\\begin{aligned}\\textcolor{red}{s_0 \\mathop{\\rightarrow}\\limits^{a_0}} s_1\\mathop{\\rightarrow}\\limits^{a_4} \\textcolor{red}{s_0 \\mathop{\\rightarrow}\\limits^{a_0}} s_1 \\mathop{\\rightarrow}\\limits^{a_2} s_5\\mathop{\\rightarrow}\\limits^{a_3}\\cdots &amp;\\Rightarrow G_t(s_0, a_0) \\times 2\\\\\\textcolor{blue}{s_1\\mathop{\\rightarrow}\\limits^{a_4}} s_0 \\mathop{\\rightarrow}\\limits^{a_0} s_1 \\mathop{\\rightarrow}\\limits^{a_2} s_5\\mathop{\\rightarrow}\\limits^{a_3}\\cdots &amp;\\Rightarrow G_t(s_1, a_4)\\\\\\textcolor{blue}{s_1 \\mathop{\\rightarrow}\\limits^{a_2}} s_5\\mathop{\\rightarrow}\\limits^{a_3}\\cdots &amp;\\Rightarrow G_t(s_1, a_2)\\\\\\textcolor{blue}{s_5\\mathop{\\rightarrow}\\limits^{a_3}} \\cdots &amp;\\Rightarrow G_t(s_5, a_3)\\\\\\end{aligned}\\]可以发现，除了状态动作对 $(s_0, a_0)$ 可以计算其对应的回报外，同一条采样序列还可以用来计算很多其他状态动作对的回报，这种操作可以极大提高数据的利用效率。2.3.3. 探索起点（Exploring Starts）即使用到了序列拆分，上述过程依然存在某种弊端。注意到序列依然是指定特定的状态动作对作为起始点的，且随着迭代进进行，中间会有一些状态动作对的价值函数 $q(s,a)$ 取值变低。又因为因为策略迭代算法的策略改进过程是采取贪婪策略来选取动作的，这样会导致某些状态 $s$ 对应的低价值动作 $a$ 永远无法被采样选中，最终使得其状态-动作价值函数 $q(s,a)$ 无法得到更新，不利于策略改进。因此，每次采样前不指定特定状态动作，而是以相同的概率随机选择初始的状态动作，可以保证每一个状态-动作对都能得到更新。再结合前述两项改进（每次访问、序列拆分），最终得到改进的蒙特卡洛方法，又被统称为 MC Exploring Starts。  为何方法命名为 Exploring Starts 而不提 Visit？以下为猜测分析：首先明确，理论上能够保证寻找到最优策略的前提是所有的状态动作对都要能够被探索到，这可以通过两种方式实现      探索起点（随机初始化）：每次采样时，随机选择一个状态动作对作为起始点，可保证所有状态动作对都有概率被选中；    每次访问：在采样序列中提高数据利用率，只能寄希望于当前策略下能够采样到所有状态动作对；    很显然，第二种方式在遍历状态动作对上是更加不确定的，因为其本质是提高数据利用效率，采样过程还是遵循贪婪策略，无法保证状态动作对一定有概率被采样到。因此，只能采取更加直接的第一种方式来命名，而只把第二种方式作为提高数据使用效率的技巧。实际算法流程中，我们采用 从后往前的倒序 进行迭代计算，并引入增量更新（下一节介绍）的技巧，进一步提高计算效率，即Sample an episode of length T by randomly select a starting state-action pair as the starting pointInitialize Gt = 0for each step of episode, t = T-1, ..., 0, do:    (=== policy evaluation ===)    Gt = γ*Gt + r    N(st,at) = N(st,at) + 1    Q(st,at) = Q(st,at) + (Gt - Q(st,at)) / N(st,at)    (=== policy improvement ===)    π(a|st) = 1 if a = argmax Q(st,a), π(a|st) = 0 otherwise2.3.4. 增量更新（incremental update）不论是蒙特卡洛基础算法还是其改进算法（MC Exploring Starts），计算回报 $G_t$ 时都需要采样足够多次数（$N$ 次）后才能保证计算得到的均值比较接近价值函数的期望。在实际计算中，我们可以使用增量更新技巧提高计算均值的效率。  计算均值的增量更新示例：已知一个数列中包含3个数值 $[3,4,5]$，当采样两次，第一次采到3、第二次采到4时，前后两次计算的均值为\\[\\begin{aligned}\\text{(use 1{st} sample)}\\; u_1 &amp;= \\frac{1}{1}\\sum_{i=1}^1 x_i = 3\\\\\\text{(use 1st+2nd sample)}\\; u_2 &amp;= \\frac{1}{2}\\sum_{i=1}^2 x_i = \\frac{3+4}{2} = 3.5\\\\\\text{(use 1st+2nd+3rd sample)}\\; u_3 &amp;= \\frac{1}{3}\\sum_{i=1}^3 x_i = \\frac{3+4+5}{2} = 3.5\\\\\\end{aligned}\\]  可以将均计算式改写成如下形式的迭代形式，每一次迭代只需要用到上次计算的均值，而不需要用到所有历史样本值\\[\\begin{aligned}\\text{(use last average(u1) + current(x2))}\\;u_2 &amp;= u_1-\\frac{1}{2}(u_1-x_2) = 3+\\frac{1}{2} = 3.5\\\\\\text{(use last average(u2) + current(x3))}\\;u_3 &amp;= u_2-\\frac{1}{3}(u_2-x_3) = 3.5+\\frac{1}{2} = 4\\end{aligned}\\]蒙特卡洛增量更新方法如下\\[\\begin{cases}N &amp;\\leftarrow N+1\\\\G(S_t) &amp;\\leftarrow G(S_t) - \\frac{1}{N} (G(S_t) - G_t)\\end{cases}\\]这样只需要每次得到 1个 新的 $G_t$ 即可更新一次回报均值 $G(S_t)$（也即价值函数的估计），即便和期望存在差异，但更新时间更短，更容易观察到收敛结果，且可以随着时间的推移逐步接近均值（在后续时序差分法中详细介绍）。更进一步，我们可以每次迭代都需要变化的 $\\frac{1}{N}$，改为用一个常数小量 $\\alpha$ 来代替，即\\[G(s_t) = G(s_t) - \\alpha (G(s_t) - G_t)\\]在后续介绍随机近似理论和时序差分法中，我们通过 RM 算法的收敛性来保证上述增量更新形式是收敛的。2.4. 蒙特卡洛改进算法（MC e-greedy）2.4.1. 探索和利用虽然探索起点（Exploring Starts）理论上可以保证每个状态动作对都有概率被采样到，但实际中很难实现，特别在一些需要与物理系统进行交互的应用中，有些状态动作可能很难作为初始状态进行设置。前面在探索起点的章节中我们介绍过，通过每次访问仍然无法保证所有状态动作对都有概率被采样到，因为他本质上还是遵循贪婪策略，所以无法保证所有状态动作对都能被采样到。那如果我们不采用贪婪策略这么极端的呢？事实上，我们可以设计一种 $\\varepsilon$-greedy 策略，即在每次访问时，在大概率选到贪婪动作的同时，以某个较小概率随机选择一个动作。在这个策略下，随着采样序列的变长和采样次数的增多，所有状态动作对都有概率被采样到，也就达到了我们的目标。$\\varepsilon$-greedy 策略可数学表示如下\\[\\pi(a|s) = \\begin{cases}1-\\frac{\\varepsilon}{\\vert A \\vert}(\\vert A \\vert-1)= \\frac{\\varepsilon}{\\vert A \\vert} + 1-\\varepsilon &amp; \\text{if } a = \\arg\\max_a Q(s,a)\\\\\\frac{\\varepsilon}{\\vert A \\vert} &amp; \\text{other }\\vert A \\vert-1\\text{ actions}\\end{cases}\\]其中 $\\varepsilon\\in[0,1]$，$\\vert A \\vert$ 表示当前状态下可选动作的个数。上述策略平衡了 探索（exploration）和 利用（exploitation）：  当 $\\varepsilon = 0$ 时，策略完全贪婪，只选择当前价值函数下最优的动作，这样可以最大化利用已有的价值函数，但可能会错过一些未知的最优动作；  当 $\\varepsilon = 1$ 时，策略完全随机（策略变成均匀分布，即每个动作的概率相同），这样可以最大化探索未知的动作，但可能会错过已知的最优动作。采用 $\\varepsilon$-greedy 策略的蒙特卡洛方法，称为 MC e-greedy。该方法不要求对起点进行探索了，只要在每次访问时，按照 $\\varepsilon$-greedy 策略随机选择一个动作，就可以保证所有状态动作对都有概率被采样到，后面的探索性分析章节可以进一步佐证此结论。2.4.2. 探索性分析下面给出一个 $\\varepsilon$-greedy 策略的探索能力与参数 $\\varepsilon$ 的关系的极端案例。设置场景如下：  智能体从左上角状态采取特定动作出发；  智能体遇到终点不停止，而是继续前进，意味着持续采样 1 个 episode；  其他参数设置为：$r_{\\text{boundary}}=-1，r_{\\text{forbidden}}=-10,r_{\\text{target}}=1,\\gamma=0.9$。设置 $\\varepsilon = 1$，即均匀随机选择动作，此时策略的探索能力最大。下图展示了探索 100 步（图(a)）、探索 1000步（图(b)）、探索 10000 步（图(c)）的探索结果，可以看出在 1000 步时智能体已经采样到了绝大部分状态动作对。同时，图(d)展示了探索 100 万步后，所有 125 个状态动作对中每个状态动作对被访问的次数，次数相差不大，表明符合均匀随机选择动作的结果。设置 $\\varepsilon = 0.1$，相应结果如下图所示。上下对比可以看出：（1）对比图 (a) 和图 (b) 发现：同样采样至第 100/1000 步，智能体探索到的状态动作对远没有前面 $\\varepsilon = 1$ 时的多；（2）对比图 (c) 发现：探索足够多的次数后，二者均能逐渐探索到所有状态动作对，只不过 $\\varepsilon = 0.1$ 需要的步数更长，探索速度更慢；（3）对比图 (d) 发现：设置比较小的 $\\varepsilon$，策略的探索能力会下降，有些较优的状态动作对可能会大量重复地被访问。（4）虽然探索能力不如均匀随机选择动作（$\\varepsilon=1$），但其在步数足够长的时候，依然能够探索到所有状态动作对，相比贪婪策略，其探索能力依然更强。（5）虽然（$\\varepsilon=1$）探索性更强，但也存在弊端，在后续最优性分析章节详细阐述。至此可以给出一个**重要结论**，采用 $\\varepsilon$-greedy 策略，不用随意初始化起点，也能保证所有状态动作对都可以被采样到。这在实际使用时非常有意义，因为他可以避免设置一些在与实际物理系统交互过程中难以稳定保持的状态（或状态动作对）作为起点，降低了对探索起点设置的门槛。比如：  复杂游戏的关卡开头是固定的，而中间状态千差万别，难以随意设置中间状态作为起点；  某些被控系统都是以相同的状态开机，但中间运行过程根本无法暂停用于初始化；$\\varepsilon$-greedy 策略不但影响着 MC 方法，后续还进一步用于时序差分法（TD）和策略梯度法（PG）、乃至二者结合的 Actor-Critic 方法，影响十分深远。2.4.3. 最优性分析在实际应用中，我们会在采用 $\\varepsilon$-greedy 策略训练完毕得到策略后，将其转为贪婪策略使用。因此有必要分析上述转换得到的贪婪策略是否为理论上的最优策略。或者换句话说，设置的 $\\varepsilon$ 对策略的最优性有什么影响。针对上述同样的 Grid world 场景，在其他参数相同的条件下（$r_{\\text{boundary}}=-1，r_{\\text{forbidden}}=-10,r_{\\text{target}}=1,\\gamma=0.9$），分别设置$ \\varepsilon = 0, 0.1, 0.2, 0.3$，分析计算得到的策略与最优策略的关系，如下图所示。图中一共有四组参数取值对应的子图，每组子图的左侧为策略，右侧为对应的状态价值函数。  当 $\\varepsilon = 0$ 时（左上图），其退化为贪婪策略，其价值函数和策略都是最优策略，最优性是由策略迭代的收敛性保证的；  当 $\\varepsilon = 0.1$ 时（右上图），得到的策略和最优策略的依然是一致的，但状态价值函数已经偏离了最优值；  随着 $\\varepsilon$ 的增加，得到的策略逐渐变差，价值函数也急剧偏离最优价值函数。当 $\\varepsilon$ 较大时，一个典型的情形是，终点的价值函数居然是一个十分大的负数，这显然违背逻辑（在贝尔曼方程中终点价值函数肯定是最大的），这是因为在抵达终点后，其上方和左右都是陷阱区域，采用较大 $\\varepsilon$ 取值的 $\\varepsilon$-greedy 策略会频繁进入到这些区域（选择了较差的动作），导致获得较多负奖励，这使得策略评估该状态的价值很低。因此，$\\varepsilon$-greedy 策略通过牺牲最优性来提高探索性。上述分析给了我们设置参数 $\\varepsilon$ 的重要启示：  在算法训练的早期阶段，可以设置较大的 $\\varepsilon$ 以提高探索快速性；  随着算法训练过程的持续，应当逐渐减小 $\\varepsilon$ 的取值以保证近似最优性。2.5. 蒙特卡洛的局限性虽然蒙特卡洛方法及其各种改进方法已经能够较好克服各种缺点，实现在无模型条件下的强化学习，但其仍然要求采样一条完整的序列直到结束时刻 $T$ 才能以 倒序 的形式计算出回报 $G_t$。如果采样可以无限进行下去而无法停止，就根本无法计算出回报，更别提策略改进了。因此，我们还需要继续寻找可行的方法实现无模型强化学习，这就是后面介绍时序差分法（Temporal Difference，TD）。3. 参考文献[1] shuhuai008. bilibili蒙特卡洛方法-强化学习-合集[2] 韵尘. 知乎：5.1 —— 蒙特卡洛预测（Monte Carlo Prediction）[3] 静静的喝酒. 强化学习之SARSA"
  },
  
  {
    "title": "强化学习（动态规划）",
    "url": "/posts/reinforcement-learning-Dynamic-Programming/",
    "categories": "Academic, Knowledge",
    "tags": "python, reinforcement learning",
    "date": "2022-11-26 11:24:19 +0800",
    





    
    "snippet": "本文介绍了强化学习的动态规划法（Dynamic Programming，DP），采用动态规划的思想，分别介绍策略迭代和价值迭代方法。  1. 强化学习问题的求解  2. 动态规划          2.1. 策略迭代                  2.1.1. 策略评估          2.1.2. 策略改进          2.1.3. 算法流程                  ...",
    "content": "本文介绍了强化学习的动态规划法（Dynamic Programming，DP），采用动态规划的思想，分别介绍策略迭代和价值迭代方法。  1. 强化学习问题的求解  2. 动态规划          2.1. 策略迭代                  2.1.1. 策略评估          2.1.2. 策略改进          2.1.3. 算法流程                    2.2. 价值迭代                  2.2.1. 算法流程          2.2.2. 策略提升          2.2.3. 价值提升                    2.3. 截断策略迭代      2.4. 对动态规划过程进行改进        3. 参考文献1. 强化学习问题的求解强化学习的最终目标是为了求解最优策略，而最优策略一定对应着最优的价值函数（只要知道了最优价值函数就能很轻松的得到最优策略），因此可将强化学习的目标分解为以下两个基本问题：  预测问题，也即预测给定策略的状态价值函数。给定强化学习的6个要素：状态集$S$, 动作集$A$, 模型状态转移概率矩阵$P$, 即时奖励$R$，衰减因子$\\gamma$,  给定策略$\\pi$， 求解该策略的状态价值函数$v_\\pi(s)$ 或动作价值函数 $q_\\pi(s,a)$；  控制问题，也即求解最优的价值函数和策略。给定强化学习的5个要素：状态集$S$, 动作集$A$, 模型状态转移概率矩阵$P$, 即时奖励$R$，衰减因子$\\gamma$, 求解最优的状态价值函数$v_{\\star}$ 和最优策略 $\\pi_{\\star}$。　2. 动态规划动态规划（Dynamic Programming，DP）是一种将复杂问题简单化的思想，而不是指某种具体的算法。DP算法通过把复杂问题分解为子问题，通过求解子问题进而得到整个问题的解。在解决子问题的时候，其结果通常需要存储起来被用来解决后续复杂问题。一个复杂问题可以使用DP思想来求解，只要满足两个性质就可以：(1)一个复杂问题的最优解由数个小问题的最优解构成，可以通过寻找子问题的最优解来得到复杂问题的最优解；(2)子问题在复杂问题内重复出现，使得子问题的解可以被存储起来重复利用。巧了，强化学习要解决的问题刚好满足这两个条件。还记得贝尔曼方程吗？\\[\\begin{aligned}v(s)&amp; \\leftarrow\\mathbb{E}_\\pi[R_{t+1}+\\gamma v(s^\\prime)]\\\\\\Rightarrow v(s) &amp; = \\sum_{a\\in A}\\pi(a\\vert s)[R_s^a+\\gamma \\sum_{s^\\prime \\in S}P_{ss^\\prime}^a v(s^\\prime)]\\\\\\end{aligned}\\]不难发现，当模型已知时（即 $A,P_{ss^\\prime}^a, R_s^a$ 已知），我们可以定义出子问题求解每个状态的状态价值函数，同时这个式子又是一个递推的式子, 意味着利用它，我们可以使用上一个迭代周期内的状态价值来计算更新当前迭代周期某状态 $s$ 的状态价值（详见策略迭代）。可见，使用动态规划来求解强化学习问题是比较自然的。  此处有一个概念：值函数的计算用到了bootstapping的方法。所谓bootstrpping本意是指自举，此处是指当前值函数的计算用到了后继状态的值函数，也即用后继状态的值函数计算当前值函数。动态规划要求马尔可夫决策过程五元组完全已知，即 $&lt;S,A,P,R,\\gamma&gt;$ 是完全确定的。在求解强化学习问题时，动态规划方法就是一种基于模型的方法（model-based）。2.1. 策略迭代知道了动态规划与强化学习的联系，我们就能用DP的思想去求解强化学习问题。策略迭代包括策略评估（Policy Evaluation）和策略改进（Policy Improvement），其基本过程是从一个初始化的策略出发，先进行策略评估，然后策略改进，评估改进的策略，再进一步改进策略，经过不断迭代更新，直到策略收敛。下面具体介绍策略评估和策略改进。2.1.1. 策略评估  解析求解记\\[\\begin{aligned}v_\\pi &amp;\\doteq [v_\\pi(s_1)\\; v_\\pi(s_2)\\; \\cdots]^T_{n\\times 1}\\\\r_\\pi &amp;\\doteq [r_\\pi(s_1)\\; r_\\pi(s_2)\\; \\cdots]^T_{n\\times 1}\\\\P_\\pi &amp;\\doteq [P_\\pi(s,s^\\prime)]_{n\\times n}\\end{aligned}\\]根据贝尔曼期望方程，可以看出其是一个关于 $v_\\pi(s)$ 的线性方程\\[\\begin{aligned}v_\\pi(s) =&amp; \\sum_a \\pi(a\\vert s) \\sum_{s^\\prime}\\sum_r p(s^\\prime,r \\vert s,a) [  r+\\gamma v_\\pi(s^\\prime)  ]\\\\=&amp;\\sum_a \\pi(a\\vert s) \\sum_{s^\\prime}\\sum_r p(s^\\prime,r \\vert s,a)r + \\gamma \\sum_a \\pi(a\\vert s) \\sum_{s^\\prime}\\sum_r p(s^\\prime,r \\vert s,a)v_\\pi(s^\\prime)\\\\\\end{aligned}\\]根据前一章内容我们知道，对系统动态特性 $p(s^\\prime,r \\vert s,a)$ 可以分解为两个概率：奖励概率和状态转移概率。其中第一项（积掉 $s^\\prime$，对应奖励概率）\\[\\begin{aligned}\\sum_a \\pi(a\\vert s) \\sum_{s^\\prime}\\sum_r p(s^\\prime,r \\vert s,a)r &amp;=\\sum_a \\pi(a\\vert s) \\sum_r p(r \\vert s,a) r\\\\&amp;= \\sum_a \\pi(a\\vert s) \\mathbb{E}_\\pi[R_{t+1}\\vert s,a]\\\\&amp;\\doteq \\sum_a \\pi(a\\vert s) r(s,a)\\quad \\textcolor{blue}{（定义r(s,a)）}\\\\ &amp;\\doteq r_\\pi(s)\\quad \\quad \\quad \\quad \\quad \\quad \\textcolor{blue}{（定义r_\\pi(s)）}\\end{aligned}\\]其中第二项（积掉 $r$，对应状态转移概率）\\[\\begin{aligned}\\gamma \\sum_a \\pi(a\\vert s) \\sum_{s^\\prime}\\sum_r p(s^\\prime,r \\vert s,a)v_\\pi(s^\\prime) &amp;=\\gamma \\sum_a \\pi(a\\vert s) \\sum_{s^\\prime} p(s^\\prime \\vert s,a)v_\\pi(s^\\prime)\\\\&amp;=\\gamma \\sum_{s^\\prime} \\sum_a \\pi(a\\vert s) p(s^\\prime \\vert s,a)v_\\pi(s^\\prime)\\\\&amp;\\doteq\\gamma \\sum_{s^\\prime} P_\\pi(s,s^\\prime)v_\\pi(s^\\prime)\\quad \\textcolor{blue}{（积掉a，定义P_\\pi(s,s^\\prime)）}\\\\\\end{aligned}\\]于是有\\[\\begin{aligned}v_\\pi(s) =&amp; r_\\pi(s) + \\gamma \\sum_{s^\\prime} P_\\pi(s,s^\\prime) v_\\pi(s^\\prime)\\end{aligned}\\]这里我们发现，正好可以得到上一章提到的贝尔曼方程的矩阵形式，令 $s_i = s, s_j = s^\\prime$ 有\\[\\begin{aligned}v_\\pi(s_i) =&amp; r_\\pi(s_i) + \\gamma \\sum_{j=1}^n P_\\pi(s_i,s_j) v_\\pi(s_j)\\\\\\Rightarrow V_\\pi &amp;= R_\\pi + \\gamma P_\\pi V_\\pi \\quad （上式即为该式第i行）\\\\\\Rightarrow V_\\pi &amp;= (I-\\gamma P_\\pi)^{-1}R_\\pi\\end{aligned}\\]上述计算复杂度为 $O(n^3)$（$n$ 阶矩阵求逆时间复杂度为$O(n^3)$，相乘时间复杂度为$O(n^3)$，二者顺序执行时间复杂度为$2O(n^3)$，但考虑计算复杂度时不用考虑系数）。当状态维度较高时，上述计算过于复杂，因此用后面的迭代求解方法。  迭代求解策略评估迭代求解的基本思路是从任意初始的策略和初始的状态价值函数开始，结合贝尔曼方程、状态转移概率和奖励，同步迭代更新状态价值函数，直至其收敛，得到该策略下最终的状态价值函数。策略评估旨在求解预测问题。假设给定一个策略 $\\pi$，和初始时刻所有状态的状态价值 $v_0(s)$。第 $k$ 轮迭代，已经计算出所有状态价值，则第 $k+1$ 轮迭代如何计算？可以结合贝尔曼方程构造第 $k+1$ 轮迭代的状态价值函数如下\\[\\begin{aligned}v_{\\color{red}{k+1}}(s)  \\doteq &amp; \\sum_{a\\in A}\\pi(a\\vert s)[R_s^a+\\gamma \\sum_{s^\\prime \\in S}P_{ss^\\prime}^a v_{\\color{red}k}(s^\\prime)]\\\\&amp; = \\sum_{a\\in A}\\pi(a\\vert s)\\sum_{s\\prime, r}p(s^\\prime,r \\vert s, a)[r+\\gamma v_{\\color{red}k}(s^\\prime)]    \\end{aligned}\\]问题转化为上式是否收敛？是否收敛到 $v_\\pi$？前面的章节我们已经介绍了，使用不动点定理可以证明其解的唯一性和收敛性，另可参考：  知乎：Model-Based方法：策略迭代与价值迭代：https://zhuanlan.zhihu.com/p/699134142 ，包含收敛性证明为了使用顺序执行的计算机程序实现策略评估，我们需要构造两个数组：一个用于存储旧的价值函数 $v_k(s)$，一个用于存储新的价值函数 $v_{k+1}(s)$。这样，在旧的价值函数不变的情况下，新的价值函数可以一个个被计算出来。同样，也可以简单使用一个数组来进行就地更新（in-place），即每次直接使用新的价值函数替换旧的价值函数。这种就地更新的方式依然可以保证收敛到$v_\\pi$，并且收敛速度更快。就地更新时的价值函数迭代式子如下：\\[{\\color{red}v(s)} \\leftarrow \\sum_a \\pi(a\\vert s) \\sum_{s^\\prime,r}p(s^\\prime,r\\vert s,a)[r+\\gamma {\\color{red}v(s^\\prime)}]\\]下面给出一个经典的 Grid World 例子。假设有一个4x4的16宫格。只有左上和右下的格子是终止格子。该位置的价值固定为0，个体如果到达了该两个格子，则停止移动，此后每轮奖励都是0。注意个体每次只能移动一个格子，且只能上下左右4种移动选择，不能斜着走, 如果在边界格往外走，则会直接移动回到之前的边界格。下面对问题进行定义：  $R_s^a=-1$，即个体在16宫格其他格的每次移动，得到的即时奖励都为-1。  $\\gamma=1$，即奖励的累计不衰减。  $P_{ss^\\prime}^a=1$，即每次移动到的下一格都是固定的（如往上走一定到上面的格子），不考虑转移不确定的情况；  $\\pi(a\\vert s) = 0.25, \\forall a\\in A$，即给定随机策略，每个格子里有25%的概率向周围的4个格子移动。至此，马尔可夫决策过程的所有参数均已知，下面进行状态价值函数预测。$k=1$ 时，带入贝尔曼方程，计算第二行第一个格子的价值（其他的格子类似）\\[v_1^{21}=0.25[(-1+0(up))+(-1+0(down))+(-1+0(left))+(-1+0(right))]=-1\\]$k=2$ 时，继续计算第二行第一个格子的价值（其他的格子类似）\\[v_2^{21}=0.25[(-1+0(up))+(-1-1(down))+(-1-1(left))+(-1-1(right))]=-1.75\\]如此迭代直至每个格子的状态价值改变很小为止。这时我们就得到了所有格子的基于随机策略的状态价值。可以看到，动态规划的策略评估计算过程并不复杂，但是如果我们的问题是一个非常复杂的模型的话，这个计算量还是非常大的。2.1.2. 策略改进在给定策略 $\\pi$ 的条件下，通过上面的策略评估可以迭代计算得到价值函数，但仍然没有得到最优策略。因为如果从状态 $s$ 开始执行现有策略，最终结果就是 $v_\\pi(s)$，但我们不知道是否有更好的策略。那么如何进行策略改进呢？我们可以利用 “策略改进定理” 来实现。  策略改进定理  策略改进定理给定 $\\pi,\\pi^\\prime$，如果 $\\forall s\\in S, q_\\pi(s,\\pi^\\prime(s))\\geq v_\\pi(s)$，那么有 $\\forall s\\in S, v_{\\pi^\\prime}(s)\\geq v_\\pi(s)$，即 $\\pi^\\prime \\geq \\pi$。证明如下：\\[\\begin{aligned}v_\\pi(s) &amp;\\leq q_\\pi(s,\\pi^\\prime(s))\\\\&amp;=\\mathbb{E}[R_{t+1}+\\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\cdots\\vert S_t=s,A_t = \\pi^\\prime(s)]\\\\&amp;=\\mathbb{E}[R_{t+1}+\\gamma v_\\pi(S_{t+1})\\vert S_t=s,A_t = \\pi^\\prime(s)]\\\\&amp;=\\mathbb{E}_{\\pi^\\prime}[R_{t+1}+\\gamma v_\\pi(S_{t+1})\\vert S_t=s]\\quad (走1步：R_{t+1}由\\pi^\\prime 控制，后面由\\pi控制)\\\\&amp;\\textcolor{red}{\\leq} \\mathbb{E}_{\\pi^\\prime}[R_{t+1}+\\gamma \\textcolor{red}{q_\\pi(S_{t+1},\\pi^\\prime(S_{t+1}))}\\vert S_t=s]\\quad （条件带入）\\\\&amp;=\\mathbb{E}_{\\pi^\\prime}[R_{t+1}+\\gamma \\textcolor{blue}{\\mathbb{E}_{\\pi^{\\prime}}[R_{t+2}+\\gamma v_\\pi(S_{t+2})\\vert S_{t+1}]}   \\vert S_t=s]\\quad （前式带入）\\\\&amp;=\\mathbb{E}_{\\pi^\\prime}[R_{t+1}+\\gamma \\mathbb{E}_{\\pi^{\\prime}}[R_{t+2}\\vert S_{t+1}]+\\gamma^2 \\mathbb{E}_{\\pi^{\\prime}} [v_\\pi(S_{t+2}) \\vert S_{t+1} ]  \\vert S_t=s]\\\\&amp;=\\mathbb{E}_{\\pi^\\prime}[R_{t+1}+R_{t+2}+\\gamma^2 v_\\pi(S_{t+2})\\vert S_t=s] \\quad （走2步）\\\\&amp;\\leq\\cdots\\\\&amp;=\\mathbb{E}_\\pi^\\prime[R_{t+1}+\\gamma R_{t+2}+\\cdots \\vert S_t=s] \\\\&amp;= v_{\\pi^\\prime}(s)\\end{aligned}\\]  参考推导见：策略改进定理及证明中隐式期望的处理基于以上证明，我们知道策略改进是切实可行的，那么究竟怎么做才能更新策略呢？  贪心方法我们知道：\\[v_{\\pi}(s) = \\mathbb{E}_{a}[q_{\\pi}(s,a)]\\]而根据期望的定义，最大的 $q$ 函数肯定是大于等于其期望的，即\\[q_\\pi(s,a)_{max} \\geq v_\\pi(s)\\]那么我们每次都选择使得 $q_\\pi(s,a)$ 最大的那个动作，构成新策略 $\\pi^\\prime$，就可以保证满足策略改进定理，构成的策略就是更好的策略了！这就是贪心方法。具体而言，在当前策略对应的状态价值函数下，智能体在每个状态都计算一下所有动作各自的状态-动作价值函数，选出值最大的执行就可以。贪心方法如下：\\[\\forall s\\in S,\\;  \\pi^\\prime(s) =\\left\\{\\begin{aligned}1, \\quad &amp; a=\\mathop{\\text{argmax}}\\limits_a\\; q_\\pi(s,a) \\\\0, \\quad &amp; \\text{otherwise}\\end{aligned}\\right.\\]此时\\[\\forall s\\in S,\\; v_\\pi(s) = \\mathbb{E}_a[q_\\pi(s,a)] \\leq \\max_a q_\\pi(s,a) = \\max_a q_\\pi(s,\\pi^\\prime(s))\\]满足策略改进定理条件，因此有\\[\\forall s\\in S,\\;v_{\\pi^\\prime}(s) \\geq v_\\pi(s)\\]得证。因此，策略改进定理提供了一种更新策略的方式：对每个状态 $s$ ，寻找贪婪动作 $\\mathop{\\text{argmax}}\\limits_a q_\\pi(s,a)$ ，以贪婪动作作为新的策略 $\\pi^\\prime$ ，根据策略改进定理必然有 $\\pi^\\prime \\geq \\pi$ 。依然是 Grid World 例子，前面我们给定一个随机策略 $\\pi(a\\vert s) = 0.25, \\forall a\\in A$，并得到了其对应的状态价值函数。根据前面的策略改进定理，可以采用贪婪法来改进我们的这个策略。具体而言，个体在某个状态下选择的行为是其能够到达后续所有可能的状态中状态价值最大的那个状态，如上图右侧所示，最终求解控制问题。当我们计算出最终的状态价值后，我们发现：  第二行第一个格子周围的价值分别是0,-18,-20，此时我们用贪婪法，则我们调整行动策略为向状态价值为0的方向（上方）移动，而不是随机移动。而此时  第二行第二个格子周围的价值分别是-14,-14,-20, -20。那么我们整行动策略为向状态价值为-14的方向（左或者上）移动。  ……以此类推。  注意到：上述过程的策略是基于最大的 $v_\\pi(s)$，但实际上应该根据 $q_\\pi(s,a)$ 来调整策略 $q_\\pi(s,a) = \\mathbb{E}[R_{t+1}+\\gamma v_\\pi(s^\\prime) ]$但由于本例中，所有可行的的状态转化概率P=1，瞬时奖励都是-1，衰减因子定义为1，所以其实 $q$ 函数的值就是下一个状态的状态价值 $v$，这也就是为什么直接往状态价值最大的那个状态移动就可以的原因。总结，策略迭代就是在循环进行两部分工作，第一步是使用当前策略 $\\pi$ 评估计算当前策略的最终状态价值 $v$，第二步是根据状态价值 $v$ 根据一定的方法（比如贪婪法）更新策略 $\\pi$，接着回到第一步，一直迭代下去，最终得到收敛的策略 $\\pi_{\\star}$ 和状态价值 $v_∗$。2.1.3. 算法流程最终的策略迭代的算法表述如下：  初始化          对于所有 $s\\in S$，任意初始化$V(s)$ 和 $\\pi(s)$      给定 $p(s^\\prime,r\\vert s,a)$ 和 $r$ 和 $\\gamma$      给定一个很小的正整数 $\\theta$        策略评估          循环($k$)：                  $\\Delta = 0$          对于每个 $s\\in S$：                          $v \\leftarrow v_k(s)$              $v_{k+1}(s) =\\sum_a \\pi(a\\vert s) \\sum_{s^\\prime,r}p(s^\\prime,r\\vert s,a)[r+\\gamma v_{k}(s^\\prime)]\\qquad\\textcolor{red}{贝尔曼方程}$              $\\Delta = \\max(\\Delta, v-v_{k+1}(s))$                                          直至 $\\Delta &lt; \\theta$  （$v(s)$收敛）        策略改进          $policy\\;stable \\leftarrow true$      对于每个 $s\\in S$：                  $a_{old} = \\pi(s)$          $q_\\pi(s,a) = \\sum_{s^\\prime,r}p(s^\\prime,r\\vert s,a)[r+\\gamma v(s^\\prime)]$          $\\pi(s)\\leftarrow \\mathop{\\text{argmax}}\\limits_a\\; q_\\pi(s,a) $ （贪婪法）          如果 $a_{old} \\neq \\pi(s)$ 那么 $policy\\;stable \\leftarrow false$                    如果 $policy\\;stable \\leftarrow true$，停止迭代，得到 $v_\\star\\approx v, \\pi_\\star\\approx \\pi$；否则返回步骤 2      算法的流程示意图如下（含有 $v$ 迭代和 $\\pi$ 迭代两层迭代）：\\[\\begin{aligned}&amp; v_1 \\rightarrow \\cdots \\rightarrow v_{1fin} \\rightarrow \\pi_1 &amp;\\text{第1次策略迭代}\\\\\\rightarrow &amp; v_2 \\rightarrow \\cdots \\rightarrow v_{2fin} \\rightarrow \\pi_2 &amp;\\text{第2次策略迭代}\\\\\\\\rightarrow &amp; \\cdots &amp;\\\\\\rightarrow &amp;v_i \\rightarrow \\cdots \\rightarrow v_\\star \\rightarrow \\pi_\\star &amp;\\text{第n次策略迭代}\\\\end{aligned}\\]2.2. 价值迭代在策略迭代中，状态价值函数在策略评估过程中时通过迭代的形式计算的，收敛后再通过策略改进更新策略，策略发生变化后需要再次迭代状态价值函数，如此往复迭代非常耗时。注意到，在迭代计算状态价值函数的时候策略并不是最优的，用一个非最优的策略来计算完全准确的状态价值函数并没有太大意义。另外，整个策略迭代通常在迭代几次后就可以收敛（如上文中的 Grid World 例子，第三次迭代（$k=3$）后，策略就已经达到最优），因此我们可以提前截断迭代过程。一种重要的特殊的情况是，只进行一次策略迭代后即刻停止（对每一个状态进行一轮迭代更新），该算法被称为价值迭代。价值迭代的本质是利用 贝尔曼最优方程 来进行价值函数的迭代优化，其能保证最终收敛到最优价值函数，此时对应的策略也是最优的。价值迭代算法是策略评估过程只进行一次迭代的策略迭代算法，其过程为 ：对每一个当前状态 $s$ ，对每个可能的动作 $a$ 都计算一下采取这个动作后到达的下一个状态的期望价值。选择最大的期望价值函数作为当前状态的价值函数 $v(s)$ ，循环执行这个步骤，直到价值函数收敛。2.2.1. 算法流程价值迭代的算法表述如下：  初始化          对于所有 $s\\in S$，任意初始化$V(s)$ 和 $\\pi(s)$      给定 $p(s^\\prime,r\\vert s,a)$ 和 $r$ 和 $\\gamma$      给定一个很小的正整数 $\\theta$        策略评估          循环($k$)：                  $\\Delta = 0$          对于每个 $s\\in S$：                          $v \\leftarrow v_k(s)$              $v_{k+1}(s) \\leftarrow {\\color{red}\\max_a} \\sum_{s^\\prime,r}p(s^\\prime,r\\vert s,a)[r+\\gamma v_{k}(s^\\prime)]\\qquad\\textcolor{red}{贝尔曼最优方程}$              $\\Delta = \\max(\\Delta, v-v_{k+1}(s))$                                          直至 $\\Delta &lt; \\theta$  （$v(s)$收敛）        策略改进          $q_\\pi(s,a) = \\sum_{s^\\prime,r}p(s^\\prime,r\\vert s,a)[r+\\gamma v(s^\\prime)]$      $\\pi(s)\\leftarrow \\mathop{\\text{argmax}}\\limits_a\\; q_\\pi(s,a) $      可以看出：  更新目标：根据 max 操作符我们可以发现，价值迭代的更新目标不再是 $v_\\pi$ ，公式中没有任何显示的策略 $\\pi$ 的影子，反之，其更新目标正是最优价值函数（也即最优策略），一旦价值迭代收敛，基于其产生的贪婪策略就是最优策略；  更新方式： 从 $\\sum_{s^\\prime,r}p(s^\\prime,r\\vert s,a)$ 项我们可以看出，依然是期望更新的方式，这一点和策略评估是一致的。不同之处在于策略评估中的 $\\pi(s)$ 被更换为了具有最大价值的 $a$ ，即策略迭代中策略评估估计状态价值采用了关于策略分布的期望，而价值迭代中的策略评估采用了最大值；线性化示意图如下（只含有 $v$ 迭代）：\\[v_1 \\rightarrow \\cdots \\rightarrow v_2 \\rightarrow \\cdots \\rightarrow v_{\\star} \\rightarrow \\pi_{\\star}\\]可以看出，价值迭代是极端情况下的策略迭代。重新回顾价值迭代中的策略评估部分，如果从更加常用的状态-动作价值函数的角度考虑，可以拆分成两步：2.2.2. 策略提升首先根据初始化或者上一步迭代得到的状态价值函数 $v_k(s), v_k(s^\\prime)$，确定新的贪婪策略\\[\\pi_{k+1}(a\\vert s) = \\arg\\max_\\pi \\sum_{s^\\prime,r}p(s^\\prime,r\\vert s,a)[r+\\gamma v(s_k^\\prime)] = \\arg\\max_a q_k(s,a)\\]2.2.3. 价值提升然后根据新的贪婪策略确定新的状态价值函数，由于策略是贪婪的，相当于选择最大的状态-动作价值函数作为状态价值函数\\[v_{k+1}(s) = \\max_a \\sum_{s^\\prime,r}p(s^\\prime,r\\vert s,a)[r+\\gamma v(s_k^\\prime)] = \\max_a q_k(s,a)\\]2.3. 截断策略迭代对于价值迭代而言，前述策略提升和策略改进合并简化后，即为前述价值迭代的算法流程中的一行（贝尔曼最优方程）迭代表示。注意到，从算法流程的角度，二者存在两种解读视角，如下图所示此时，【价值迭代】可以看作是策略评估【只进行一步计算的特殊策略迭代】。那么，有没有一种中间方式，既不会只算一次这么极端，又不要一直计算到收敛那么极端呢？有，即截断策略迭代。截断策略迭代的初衷是理论的策略评估过程需要计算无穷步，这在实际计算中代价太大。因此，在传统的策略迭代（贝尔曼方程）的基础上，对策略评估过程进行人为截断，比如设置 $n=3$ 进行截断，从而在保证依然可以收敛的前提下加速计算。收敛性证明比较复杂，可参考赵世钰老师的《Mathematical Foundation of Reinforcement Learning》。几种不同算法收敛结果如下图所示：2.4. 对动态规划过程进行改进      异步动态规划：每次进行价值估计和更新时都要对全部的状态进行一次遍历，这未免太过繁琐，尤其是当状态空间足够大时，消耗在遍历上的资源就不尽人意了。那能不能一次更新只针对部分状态进行呢？只更新部分状态还能保证价值更新的收敛吗？可以的，在异步动态规划算法中，每一次迭代并不对所有状态的价值进行更新，而是依据一定的原则有选择性地更新部分状态的价值，这种算法能显著节约计算资源，并且只要所有状态能够得到持续的访问更新，那么也能确保算法收敛至最优解。                  优先级动态规划        (prioritised sweeping)：对每一个状态进行优先级分级，优先级越高的状态其状态价值优先得到更新。                    实时动态规划        (real-time dynamic programming)：直接使用个体与环境交互产生的实际经历来更新状态价值，对于那些个体实际经历过的状态进行价值更新。                  原位动态规划 (in-place dynamic programming)：直接利用当前状态的后续状态的价值来更新当前状态的价值，可以大幅降低动态规划过程中的资源消耗，同样也可以收敛至最优解。比如，价值迭代中同样需要存储两份状态价值函数 $v_{k+1}(s),\\; v_k(s)$，实际上也可以只保存一份，即采用就地更新方法，此时迭代式变为 \\({\\color{red}v(s)} \\leftarrow \\max_a \\sum_{s^\\prime,r}p(s^\\prime,r\\vert s,a)[r+\\gamma {\\color{red}v(s^\\prime)}]\\)  3. 参考文献[1] 刘建平Pinard. 强化学习（三）用动态规划（DP）求解.[2] Zeal. 知乎：强化学习二：策略迭代法[3] shuhuai008. bilibili【强化学习】动态规划【白板推导系列】[4] 韵尘. 知乎：4.2 —— 策略改进（Policy Improvement）（含收敛性证明）[5] 韵尘. 知乎：4.5 —— 异步动态规划（Asynchronous Dynamic Programming）"
  },
  
  {
    "title": "强化学习（马尔可夫决策过程）",
    "url": "/posts/reinforcement-learning-markov-process/",
    "categories": "Academic, Knowledge",
    "tags": "python, reinforcement learning",
    "date": "2022-11-09 12:36:19 +0800",
    





    
    "snippet": "本文介绍了强化学习的基本概念和模型，主要包括马尔可夫过程、马尔可夫奖励过程和马尔可夫决策过程。  1. 强化学习          1.1. 状态空间                  1.1.1. 状态          1.1.2. 观测                    1.2. 动作空间      1.3. 策略        2. 马尔可夫过程（MP）          2.1...",
    "content": "本文介绍了强化学习的基本概念和模型，主要包括马尔可夫过程、马尔可夫奖励过程和马尔可夫决策过程。  1. 强化学习          1.1. 状态空间                  1.1.1. 状态          1.1.2. 观测                    1.2. 动作空间      1.3. 策略        2. 马尔可夫过程（MP）          2.1. 基本概念      2.2. 环境        3. 马尔可夫奖励过程（MRP）          3.1. 奖励（Reward）                  3.1.1. 奖励的定义          3.1.2. 与动作的关系          3.1.3. 与下一时刻状态的关系                    3.2. 回报（Return）      3.3. 价值函数      3.4. 贝尔曼方程        4. 马尔可夫决策过程（MDP）          4.1. 动作（Action）      4.2. 策略（Policy）      4.3. 动态特性                  4.3.1. 状态转移概率          4.3.2. 奖励概率                    4.4. 价值函数                  4.4.1. 状态价值函数          4.4.2. 动作价值函数          4.4.3. 二者的意义          4.4.4. 回溯图与回溯操作                    4.5. 贝尔曼方程                  4.5.1. 状态价值函数的贝尔曼方程          4.5.2. 矩阵化表述与迭代求解          4.5.3. 状态-动作价值函数的贝尔曼方程                    4.6. 贝尔曼最优方程                  4.6.1. 最优策略          4.6.2. 最优价值函数          4.6.3. 贝尔曼最优方程          4.6.4. 最优策略的求解                    4.7. 贝尔曼期望方程        5. 参考文献1. 强化学习强化学习是机器学习领域之一，受到行为心理学的启发，主要关注智能体如何在环境中采取不同的行动，以最大限度地提高累积奖励。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。与监督学习不同的是，强化学习不需要带标签的输入输出对，同时也无需对非最优解的精确地纠正。强化学习主要由智能体（Agent）、环境（Environment）、状态（State）、动作（Action）、奖励（Reward）组成。智能体执行了某个动作后，环境将会转换到一个新的状态，对于该新的状态环境会给出奖励信号（正奖励或者负奖励）。随后，智能体根据新的状态和环境反馈的奖励，按照一定的策略执行新的动作。上述过程为智能体和环境通过状态、动作、奖励进行交互的方式。在每个时刻 $t$，智能体观察到所在的环境状态记为 $s_t$，，并再次基础上选择一个动作 $a_t$。作为动作的结果，智能体接收到一个数值化的奖励 $r_{t+1}$，并转移到一个新的状态 $s_{t+1}$ 。如此反复迭代交互，可以得到一个序列或轨迹（trajectory）。强化学习的朴素目标：训练智能体尽可能多的收集奖励。1.1. 状态空间1.1.1. 状态「状态」$s$ 是对环境当前所处环境的完整描述，对于状态来说环境的所有信息都是可知的。在数学上，状态空间是一系列状态组成的集合 $\\mathcal{S}$，其中 $s \\in \\mathcal{S}$。在深度强化学习中，我们通常会使用实值向量vector、矩阵 matrix 或者高维张量 tensor 来表示状态。比如，视觉的状态可以表示为像素值构成的 RGB 矩阵，机器人的状态则可以表示为其关节角度和速度。1.1.2. 观测「观测」$o$ 则是一个状态的部分描述，可能会忽略一些信息，其同样可用实值向量vector、矩阵 matrix 或者高维张量 tensor 来表示。当智能体能够观测到环境的全部状态时，这样的环境是可完全观测的 fully observed；当智能体只能观测到部分状态时，这样的环境称为可部分观测 partially observed。  「注」：在强化学习的公式中我们经常会看到表示状态的符号 $s$，但是实际上更准确的用法应该是使用表示观测的符号 $o$。比如，当我们探讨智能体如果进行动作决策时，公式中通常会说动作是基于状态的，但是「实际上动作是基于观测的」，因为智能体是无法直接感知到状态的。为了遵循惯例，之后的公式仍然会使用符号 $s$。1.2. 动作空间「给定的环境中有效的动作集合称为动作空间」。动作是对状态而言的，不同的状态可能有不同的动作空间，因此动作空间是一个与状态有关的集合。动作可以表示为 $\\mathcal{A}(s),\\; \\forall s\\in \\mathcal{S}$。「动作空间是离散的还是连续的」在强化学习问题中非常重要，有些方法只适合用于其中一个场景，所以这点需要特别关注。有些环境中（比如 Atari 和 Go），「动作空间是离散的」discrete，也就是说智能体的动作数量是有限的；而有些环境中（比如机器人控制），「动作空间是连续的」continuous，这些空间中动作通常用实值向量表示。1.3. 策略强化学习是从环境状态到动作的映射学习，称该映射关系为策略。通俗的理解，即智能体如何选择动作的思考过程称为策略。最简单的策略可以是固定策略，如不管什么情况都执行特定动作。也可以采用规则策略，即满足什么条件下执行什么动作。也可以采用随机策略，即按照某个概率采样来选取动作。2. 马尔可夫过程（MP）2.1. 基本概念几个基本概念定义如下：      马尔可夫性（Markov property）：在一个时序过程中，如果 $t＋1$ 时刻的状态仅取决于 $t$ 时刻的状态 $s_t$ 而与 $t$ 时刻之前的任何状态都无关时，则认为 $t$ 时刻的状态 $s_t$ 具有马尔可夫性，数学表述为\\(p(s_{t+1}\\vert s_{t},\\cdots, s_1 ) = p( s_{t+1} \\vert s_t)\\)        马尔科夫过程（Markov Process）：若过程中的每一个状态都具有马尔科夫性，则这个过程具备马尔科夫性。具备了马尔科夫性的随机过程称为马尔科夫过程，        马尔可夫链（Markov chain）：离散状态空间的马尔可夫过程称为马尔科夫链（Markov chain）。  马尔可夫过程中的三个概念：  采样（sample）或抽样：从符合马尔科夫过程给定的状态转移概率矩阵生成一个轨迹或回合的过程  轨迹（trajectory）或序列：采样得到的一条无限长的状态序列,如：$s_1-s_2-s_3-…$  回合（episode）或情节：采样直至一个终止状态，形成一条完整的状态序列。如：$s_1-s_2-s_3-\\cdots-s_T$2.2. 环境环境是智能体交互的对象，是智能体在某状态下采取某动作后转移到新状态的最终参与者。以自动驾驶为例，在某个雨天的行驶状态下，智驾决定在 $120$ km/h 车速下（状态 $s_1$）向左打方向盘（动作）变向超车，期望状态是变到左侧相邻车道，但由于雨天湿滑（环境）导致车子最终滑到路边（新状态 $s_2$）。但是如果换一个干燥的晴天，大概率车子会正常变到左侧相邻车道（新状态 $s_3$）。上述例子比较直观体现了环境在状态转移中的作用，即在状态 $s_1$ 下动作 $a_1$ 的结果并不一定是某个确定的新状态，而是与实际环境有关。一般情况下，环境可以建模为一个状态转移概率矩阵 $P$。在马尔可夫过程中，我们暂时还不用考虑动作的作用，因此可以假设雨天环境大概率滑到路边（$s_2$），状态转移矩阵的元素为：\\[\\begin{aligned}P(s_2\\vert s_1) &amp;= 0.85\\\\P(s_3\\vert s_1) &amp;= 0.15\\end{aligned}\\]用二元组 $&lt;S,P&gt;$ 表述马尔可夫过程。其中，$S$ 为状态，$P$ 为不同状态间的转移概率，如状态 $s$ 到 $s^\\prime$ 的状态转移概率\\[P_{s s^\\prime}=P_{s s^\\prime}=\\mathbb{P}[S_{t+1}=s^\\prime \\vert S_t = s]\\]从上式也可以看到，下一时刻的状态$S_{t+1}$ 仅与当前时刻的状态 $S_t$ 有关，而与 $S_1,\\cdots,S_{t-1}$ 无关。注意：这里的记号非常严谨， $S_{t}, S_{t+1}$ 代表某一时刻的状态，而 $s,s^\\prime$ 代表某一种具体的状态类型。而在实际情况下，人们会将其简写多种不同的形式，需要特别注意\\[P_{s s^\\prime}=P=p(S_{t+1}=s^\\prime \\vert S_{t}=s)=p(s^\\prime \\vert s) = p(s_{t+1} \\vert s_{t})\\]对于离散的状态空间，为了描述整个状态空间中不同类型状态之间的关系，自然用矩阵表示，即：\\[P=\\begin{bmatrix}p(s_1\\vert s_1) &amp; p(s_2\\vert s_1) &amp;\\dots &amp; p(s_n\\vert s_1)\\\\p(s_1\\vert s_2) &amp; p(s_2\\vert s_2) &amp;\\dots &amp; p(s_n\\vert s_2)\\\\\\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\p(s_1\\vert s_n) &amp; p(s_2\\vert s_n)&amp;\\dots &amp; p(s_n\\vert s_n)\\\\\\end{bmatrix}\\]显然状态转移概率矩阵 $P$ 的规模是所有状态类型数 $n$ 的平方。且从一个状态转移到所有可能状态的概率之和为 $1$。以下图为例：不难写出状态转移概率矩阵：\\[\\begin{aligned}&amp;\\quad C1\\;\\;\\;C2\\;\\;\\;C3\\;\\;\\;Pass\\;Pub\\;FB\\;\\;Sleep\\\\P=\\begin{array}{r}    C1\\\\    C2\\\\    C3\\\\    Pass\\\\    Pub \\\\    FB\\\\    Sleep\\end{array}&amp;\\begin{bmatrix}    0&amp; 0.5 &amp;0&amp;0&amp;0&amp;0.5&amp;0\\\\    0&amp;0&amp;0.8&amp;0&amp;0&amp;0&amp;0.2\\\\    0&amp;0&amp;0&amp;0.6&amp;0.4&amp;0&amp;0\\\\    0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\\\    0.2&amp;0.4&amp;0.4&amp;0&amp;0&amp;0&amp;0\\\\    0.1&amp;0&amp;0&amp;0&amp;0&amp;0.9&amp;0\\\\    0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\\\\\end{bmatrix}\\end{aligned}\\]3. 马尔可夫奖励过程（MRP）马尔可夫奖励过程（Markov Reward Process，MRP）就是在马尔可夫过程中增加了奖励（收益） $R$ 项和奖励因子 $\\gamma$。表述一个马尔可夫奖励过程需要四元组 $&lt;S,P,R,\\gamma&gt;$，其中：  $S$ 是一个有限状态集；  $P$ 是集合中状态转移概率矩阵：$P_{s s^\\prime}=\\mathbb{P}[S_{t+1}=s^\\prime \\vert S_t = s]$  $R$ 是奖励（收益）函数：$R_t = \\mathbb{E}[R_{t+1}\\vert S_t=s]$  $\\gamma$ 是折扣因子：$\\gamma \\in [0,1)$如下图所示3.1. 奖励（Reward）3.1.1. 奖励的定义某时刻 $t$ 的即时奖励（immediate reward） $R_t$ 定义为从该时刻所处状态转移到下一时刻状态后从环境获得的标量数值。它是环境直接返回的反馈值，这个值可以是确定的，也可以是随机的（从某个概率分布中采样得到），具体取决于环境的定义。如果环境是随机的，即时奖励可能是一个随机变量，但从单次交互的角度来看，它是一个具体的标量值。\\[r_{t+1} = r(s_t)\\]关于下标为何为 $t+1$ 而不是 $t$，是因为通常约定奖励是离开当前状态后在下一时刻才获得的。  在后续马尔可夫决策过程中，其是与下一时刻状态 $s_{t+1}$ 一同被环境所返回的。3.1.2. 与动作的关系即时奖励与动作有关，因此在后续马尔可夫决策过程中，奖励可以表述为\\[r_{t+1} = r(s_t,a_t)\\]3.1.3. 与下一时刻状态的关系奖励是环境赋予的，其与下一时刻是否有关取决于环境的定义。从正常的思维来讲，奖励当然与下一时刻的状态有关系的（比如状态转移后进入终点导致获得正奖励，或者进入陷阱导致获得负奖励）。这种情况下，奖励应表述为\\[r_{t+1} = r(s_t,a_t,s_{t+1})\\]但我们通常约定，奖励函数只依赖于当前状态和动作，与下一时刻无关。  在后续马尔可夫决策过程中，强调下一时刻的奖励和下一时刻的状态是被环境一起决定的。这导致离开当前状态获得的奖励是概率性的，我们需要求解它的期望\\[r_{t+1} = \\mathbb{E}[r\\vert s_t,a_t] = r\\cdot p(r\\vert s_t,a_t) = r\\cdot \\sum_{s_{t+1}}p(r\\vert s_t,a_t,s_{t+1})p(s_{t+1}\\vert s_t,a_t)\\]  可以发现，即使奖励和下一时刻状态有关，这种相关性也可以通过状态转移概率来体现。此时，强化学习的目标：使得智能体收到的累计奖励最大化。对于无限长度的采样轨迹，奖励的期望是无限大的，所以需要做出一个折扣，以便在远期奖励的期望值有较好的收敛性。这就引入了回报和折扣因子的必要性。3.2. 回报（Return）某时刻 $t$ 的回报（收益）定义为从时刻 $t$ 开始的 采样一条 状态序列得到的所有奖励的折扣和：\\[G_t\\doteq r_{t+1}+\\gamma r_{t+2}+...=\\sum_{k=0}^\\infty \\gamma^k r_{t+k+1}\\]其中 $\\gamma \\in [0,1)$ 被称为折扣因子，通常取值为 $0.9$。设置折扣因子的原因如下：  数学表达的方便，这也是最重要的  保证奖励的收敛性，避免陷入无限循环  远期利益具有一定的不确定性  符合人类更看重眼前利益的性格折扣因子可以作为强化学习的一个超参数来进行调整，折扣因子不同就会得到不同行为的智能体：  折扣因子接近 $0$ 则表明趋向于“近视”性评估；  折扣因子接近 $1$ 则表明偏重考虑远期的利益。前述例子中，假设从 $Class 1$ 状态开始到 $Sleep$ 状态终止，折扣因子 $\\gamma = 0.5$，采样两条序列计算回报如下：episode 1: C1 - C2 - C3 - Pass - SleepG_1 = -2 + 1/2 × (-2) + 1/4 × (-2) + 1/8 × (+10) = -2.25episode 2: C1 - FB - FB - C1 - C2 - SleepG_2 = -2 + 1/2 × (-1) + 1/4 × (-1) + 1/8 × (-2) + 1/16 ×(-2) = -3.125此时，强化学习的目标：使得智能体收到的回报最大化。回报值是针对一次完整的采样序列的结果，存在很大的样本偏差。即 $G(s)$ 是从 $t$ 时刻的状态到终止状态的一条状态转移序列的回报值，但从 $t$ 时刻的状态到终止状态的马尔可夫链不止一条，每一条都有对应的采样概率和回报。对于复杂问题而言，要想精确的计算出 $G(s)$ 是几乎不可能的，因为无法穷举所有序列。为了能够评估状态的好坏，引入新概念：价值函数。3.3. 价值函数价值函数（Value Function）：从某个状态 $s_t$ 开始的回报的期望，也即从某个状态 $s_t$ 开始采样无数条完整状态序列的回报的平均值，即\\[V(s_t) = \\mathbb{E}[G_t \\vert S_t=s_t]\\]对于马尔可夫奖励过程，价值函数即为状态价值函数。以前面的例子，如果仅观测到两个序列，那么在状态 Class 1 处的学生的值函数就是 2 个回报值除以 2 即可。v(Class1) = (G_1 + G_2) / 2 = ( (-2.25) + (-3.125)) / 2 = -2.6875状态值函数的引入，从数学上解决了回报 $G(s)$ 计算时依赖大量采样，难以实际应用的问题。但状态价值函数也不好算，因为在计算某个状态时候需要使用到将来所有状态的 $G(s)$。为了便于计算，对价值函数进行展开\\[\\begin{aligned}V(s_t) &amp;= \\mathbb{E}[G_t \\vert S_t=s_t]\\\\&amp;=\\mathbb{E}[r_{t+1}+\\gamma r_{t+2}+\\gamma^2 r_{t+3}+...\\vert S_t=s_t]\\\\&amp;=\\mathbb{E}[r_{t+1}+\\gamma (r_{t+2}+\\gamma r_{t+3}+...)\\vert S_t=s_t]\\\\&amp;=\\mathbb{E}[r_{t+1}+\\gamma G_{t+1}\\vert S_t=s_t]\\\\&amp;=\\mathbb{E}[r_{t+1}\\vert S_t=s]+\\gamma \\mathbb{E}[G_{t+1}\\vert S_t=s_t]\\\\&amp;=R_{s}+\\gamma \\mathbb{E}[G_{t+1}\\vert S_t=s_t]\\end{aligned}\\]上式中，第一项 $R_s$ 对应即时奖励的期望\\[R_s = \\sum_{a}\\pi(a\\vert s)\\sum_r(p(r\\vert s,a)\\cdot r)\\]第二项则代表了长期的潜在奖励。可以看出，长期潜在奖励的计算需要获取下一时刻状态对应回报的期望。然而，未来时刻的状态及其回报是不确定的，即\\[\\mathbb{E}[G_{t+1}\\vert S_t=s_t]\\]依然是一个很难求解的期望形式。因此直接计算价值函数是不现实的。下面介绍贝尔曼方程来计算价值函数。3.4. 贝尔曼方程[ 推导 1 ]：      定义：如果 $X$ 和 $Y$ 都是离散型随机变量，则条件期望（Conditional Expectation）定义为$\\mathbb{E}[Y\\vert X=x]=\\sum_y yP(Y=y\\vert X=x)$    定义：如果 $X$ 是随机变量，其期望为 $\\mathbb{E}[X]$，$Y$ 为相同概率空间上的任意随机变量，则有全期望（Total Expectation）公式$\\mathbb{E}[X] = \\mathbb{E}[\\mathbb{E}[X\\vert Y]]$  现证明（主要证明第一个等式）\\[\\mathbb{E}[G_{t+1}\\vert S_t=s_t] = \\mathbb{E}[\\mathbb{E}[G_{t+1}\\vert S_{t+1}]\\vert S_t=s_t] = \\mathbb{E}[V(s_{t+1})\\vert S_t=s_t]\\]为了推导简便，另 $s_{t+1} = s^\\prime$，$s_t=s$，有\\[\\begin{aligned}\\mathbb{E}[\\mathbb{E}[G_{t+1}\\vert S_{t+1}]\\vert S_t=s] &amp;= \\mathbb{E}\\left[\\sum_{g^\\prime}g^{\\prime}P(G(s^\\prime)=g^{\\prime}\\vert S_{t+1})\\vert s\\right]\\quad (条件期望)\\\\&amp;=\\sum_{s^\\prime} \\sum_{g^\\prime}g^{\\prime}P(G(s^\\prime)=g^{\\prime}\\vert S_{t+1}=s^\\prime, s)P(S_{t+1}=s^\\prime\\vert s)\\\\&amp;=\\sum_{s^\\prime} \\sum_{g^\\prime}g^{\\prime} \\frac{P(G(s^\\prime)=g^{\\prime}\\vert S_{t+1}=s^\\prime, s)P(S_{t+1}=s^\\prime\\vert s)\\cdot P(s)}{P(s)} \\\\&amp;=\\sum_{s^\\prime} \\sum_{g^\\prime}g^{\\prime} \\frac{P(G(s^\\prime)=g^{\\prime}\\vert S_{t+1}=s^\\prime, s)P(S_{t+1}=s^\\prime, s)}{P(s)} \\\\&amp;=\\sum_{s^\\prime} \\sum_{g^\\prime}g^{\\prime} \\frac{P(G(s^\\prime)=g^{\\prime}, S_{t+1}=s^\\prime, s)}{P(s)} \\\\&amp;=\\sum_{s^\\prime} \\sum_{g^\\prime}g^{\\prime} P(G(s^\\prime)=g^{\\prime}, S_{t+1}=s^\\prime \\vert s) \\\\&amp;=\\sum_{g^\\prime} \\sum_{s^\\prime}g^{\\prime} P(G(s^\\prime)=g^{\\prime}, S_{t+1}=s^\\prime \\vert s) \\\\&amp;=\\sum_{g^\\prime}g^{\\prime} P(G(s^\\prime)=g^{\\prime} \\vert s) \\\\&amp;=\\mathbb{E}[G(s^\\prime)\\vert s]=\\mathbb{E}[G_{t+1}\\vert s_t]\\end{aligned}\\]得证。则当前时刻的状态价值函数\\[\\begin{aligned}V(s_t)&amp;=R_{s}+\\gamma \\mathbb{E}[G_{t+1}\\vert S_t=s_t]\\\\&amp;=R_{s}+\\gamma \\mathbb{E}[V(s_{t+1})\\vert S_t=s_t]\\\\&amp;=R_{s}+\\gamma \\sum_{s_{t+1}\\in S} V(s_{t+1})P(s_{t+1}\\vert s_t)\\end{aligned}\\]上式即为马尔可夫奖励过程的贝尔曼方程。[ 推导 2 ]：对后项进行全概率展开\\[\\begin{aligned}\\gamma \\mathbb{E}[G_{t+1}\\vert S_t=s_t] &amp;= \\gamma \\sum_{s_{t+1}\\in S}\\mathbb{E}[G_{t+1}\\vert S_{t+1}=s_{t+1}]P(s_{t+1}\\vert s_t)\\\\&amp;= \\gamma \\sum_{s_{t+1}\\in S} V(s_{t+1})P(s_{t+1}\\vert s_t)\\end{aligned}\\]上面第二步是因为（根据价值的定义）\\[V(s_{t+1}) = \\mathbb{E}[G_{t+1}  \\vert S_{t+1} = s_{t+1}]\\]最终得到\\[V(s_t) = r_{s}+\\gamma \\sum_{s_{t+1}\\in S} V(s_{t+1})P(s_{t+1}\\vert s_t)\\]即为马尔可夫奖励过程的贝尔曼方程。贝尔曼方程刻画了当前状态 $s_t$ 和下一个状态 $s_{t+1}$ 之间的关系。可以看出，当前状态的价值函数可以通过下一个状态的价值函数来迭代计算。若将马尔可夫奖励过程的状态构成 $n$ 维状态空间，贝尔曼方程可以写成矩阵形式\\[\\begin{aligned}\\begin{bmatrix}    V(s_1)\\\\    V(s_2)\\\\    \\vdots\\\\    V(s_n)\\end{bmatrix} &amp;=\\begin{bmatrix}    R(s_1)\\\\    R(s_2)\\\\    \\vdots\\\\    R(s_n)\\end{bmatrix}+\\gamma\\begin{bmatrix}P(s_1\\vert s_1) &amp; P(s_2\\vert s_1)&amp; \\cdots &amp; P(s_n\\vert s_1)\\\\    P(s_1\\vert s_2) &amp; P(s_2\\vert s_2)&amp; \\cdots &amp; P(s_n\\vert s_2)\\\\    \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\    P(s_1\\vert s_n) &amp; P(s_2\\vert s_n)&amp; \\cdots &amp; P(s_n\\vert s_n)\\\\    \\end{bmatrix}\\begin{bmatrix}    V(s_1)\\\\    V(s_2)\\\\    \\vdots\\\\    V(s_n)\\end{bmatrix}\\\\\\boldsymbol{V} &amp;= \\boldsymbol{R}+\\gamma \\boldsymbol{P} \\boldsymbol{V}\\\\\\end{aligned}\\]上述是个线性方程组，可直接得到闭式解\\[\\boldsymbol{V} = (\\boldsymbol{I}-\\gamma\\boldsymbol{P})^{-1}\\boldsymbol{R}\\]需要注意的是，矩阵求逆的复杂度为 $O(n^3)$，因此直接求解仅适用于状态空间规模小的问题。状态空间规模大的问题的求解通常使用迭代法，在后续介绍马尔可夫决策过程时进行详细介绍。  注意到，只有当 $P$ 已知的情况下，也就是模型已知时，才可以得到解析形式的闭式解。4. 马尔可夫决策过程（MDP）马尔可夫决策过程是在马尔可夫奖励过程的基础上加入了决策，即增加了动作。其定义为：马尔科夫决策过程是一个五元组 $&lt;S,A,P,R,\\gamma&gt;$，其中  $S$ 是有限数量的状态集  $A$ 是有限数量的动作集  $P$ 是状态转移概率，$P_{ss^\\prime}^a=\\mathbb{P}[S_{t+1} = s^\\prime \\vert S_t = s, A_t=a]$  $R$ 是一个奖励函数，\\(R_{s}^a=\\mathbb{E}[R_{t+1} \\vert S_t = s, A_t=a]\\)  $\\gamma$ 是一个折扣因子，$\\gamma \\in [0,1)$从上面定义可以看出，马尔可夫决策过程的状态转移概率和奖励函数不仅取决于智能体当前状体，还取决于智能体选取的动作。而马尔可夫奖励过程仅取决于当前状态。4.1. 动作（Action）以下图为例：图中红色的文字表示学生采取的动作，而不是 MRP 时的状态名。对比之前的学生 MRP 示例可以发现，即时奖励与动作有关了，同一个状态下采取不同的动作得到的即时奖励是不一样的。由于引入了动作，容易与状态名称混淆，因此此图没有给出各状态的名称；此图还把 Pass 和 Sleep 状态合并成一个终止状态；另外当选择”去查阅文献（Pub）”这个动作时，主动进入了一个临时状态（图中用黑色小实点表示），随后被动的被环境按照其动力学分配到另外三个状态，也就是说此时智能体没有选择权决定去哪一个状态。可以看出，状态转移概率 $P_{ss^\\prime}^a$ 和奖励函数 $R_{s}^a$ 均与当前状态 $s$ 下采取的动作 $a$ 有关。由于动作的选取不是固定的，因此引入新概念：策略。4.2. 策略（Policy）策略 $\\pi(a\\vert s)$ 是从状态 $s$ 到每个动作 $a$ 的选择概率之间的映射，即\\[\\pi(a\\vert s) = \\mathbb{P}[A_t=a \\vert S_t=s]\\]一个策略完整地定义了智能体的行为方式，即策略定义了智能体在各种状态下可能采取的动作，以及在各种状态下采取各种动作的概率。MDP的策略仅与当前的状态有关，与历史信息无关；同时某一确定的策略是静态的，与时间无关；但是个体可以随着时间更新策略。给定一个马尔可夫决策过程 $&lt;S,A,P,R,\\gamma&gt;$ 和一个策略 $\\pi$ 后，相应的状态转移概率 $P_{ss^\\prime}^\\pi$ 和奖励函数 $R_{s}^\\pi$ 可更新描述如下\\[\\begin{aligned}    P_{ss^\\prime}^\\pi &amp;= \\sum_{a\\in A}\\pi(a\\vert s)P_{ss^\\prime}^a\\\\    R_{s}^\\pi &amp;= \\sum_{a\\in A}\\pi(a\\vert s)R_{s}^a\\end{aligned}\\]对应的 $&lt;S,P^\\pi,R^\\pi,\\gamma&gt;$ 是一个马尔可夫奖励过程， $&lt;S,P^\\pi&gt;$ 是一个马尔可夫过程。4.3. 动态特性在有限 MDP 中，状态、动作和奖励的集合（$S, A, R$）都只有有限个元素。在这种情况下，随机变量 $R_t$ 和 $S_t$ 具有定义明确的离散概率分布，并且之依赖于前一时刻的状态和动作。也就是说，给定前一时刻的状态和动作的值时，这些随机变量的特定值 $s^\\prime \\in S, r^\\prime \\in R$ 在 $t$ 时刻出现的概率为\\[p(s^\\prime,r \\vert s,a) \\doteq \\mathbb{P}\\{S_t=s^\\prime, R_t=r \\vert S_{t-1}=s, A_{t-1}=a\\}\\]函数 $p$ 定义了 MDP 的动态特性。动态特性函数是一个描述 $t-1$ 和 $t$ 前后两个相邻时刻的随机变量间动态关系的条件概率。在 MDP 中，由 $p$ 给出的概率完全刻画了环境的动态特性，即$S_t,R_t$ 的每个可能的值出现的概率只取决于前一个状态 $S_{t-1}$ 和动作 $A_{t-1}$，且与更早时刻的状态和动作无关（马尔可夫性）。4.3.1. 状态转移概率从四参数动态函数 $p$ 中，可以计算出关于环境的任何其它信息。比如，想表达MDP的状态转移过程，可以将随机变量 $R$ 求积分得到 状态转移概率\\[P_{ss^\\prime}^a = p(s^\\prime \\vert s,a) \\doteq \\mathbb{P}\\{ S_t=s^\\prime \\vert S_{t-1}=s, A_{t-1}=a \\} = \\sum_{r\\in R}p(s^\\prime,r \\vert s,a)\\]所以，整个马尔可夫决策过程的全部信息包含在状态变量集合 $A$，$S$，$R$ 和函数空间 $P$ 中，每个时刻都有一个 $A_t$，$S_t$，$R_t$，每两个相邻时刻之间都有一个 $p_t$。4.3.2. 奖励概率类似地，状态动作 $s,a$ 对的期望奖励可以写作两个参数的函数\\[r(s,a) = \\mathbb{E}_\\pi [R_{t+1} \\vert S_t = s] = \\sum_{r\\in R} r \\sum_{s^\\prime \\in S} p(s^\\prime, r \\vert s,a)\\]想表达 MDP 的即时奖励获取过程，可以将对 $s^\\prime$ 求积分得到 奖励概率\\[P_{ss^\\prime}^r = p(r \\vert s,a) = \\sum_{s^\\prime \\in S}p(s^\\prime, r \\vert s,a)\\]4.4. 价值函数马尔可夫决策过程中，价值函数分为状态价值函数和动作价值函数。4.4.1. 状态价值函数状态价值函数（state-value Function）是从某个状态 $s$ 开始，执行策略 $\\pi$ 所获得的回报的期望；也即在执行当前策略时，衡量智能体处在状态 $s$ 时的价值大小。即\\[v_\\pi(s) \\doteq \\mathbb{E}_\\pi[G_t \\vert S_t=s]\\]注意，终止状态的价值始终为零。我们把函数 $v_{\\pi}(s)$ 称为策略 $\\pi$ 的状态价值函数。状态价值函数衡量了一个状态的好坏，好的状态拥有较大的状态价值函数，表明从这个状态出发，预期能获得更高的回报。4.4.2. 动作价值函数类似地，我们把策略 $\\pi$ 下在状态 $s$ 时采取动作 $a$ 的价值即为 $q_\\pi(s,a)$。即根据策略 $\\pi$，从状态 $s$ 开始，执行动作 $a$ 之后，所有可能的决策序列的期望回报\\[q_\\pi(s,a) \\doteq \\mathbb{E}_\\pi[G_t \\vert S_t=s, A_t=a]\\]状态-动作价值函数衡量了某个状态下不同动作的好坏，好的状态-动作拥有较大的状态-动作价值函数，表明从这个状态出发选择这个动作，预期能获得更高的回报。4.4.3. 二者的意义  如何理解强化学习中的Q值和V值？ https://zhuanlan.zhihu.com/p/109498587  强化学习-1-Q_Table based Method  https://zhuanlan.zhihu.com/p/138291295状态价值函数是对状态的价值的衡量。从某个状态出发，依据特定策略 $\\pi$ 采用不同动作，在环境的影响下进行状态转移。动作价值函数是对某状态下特定动作的价值的衡量。从某个状态出发，采取特定的动作 $a$，在环境的影响下进行状态转移；后续依据特定策略 $\\pi$ 采用不同动作，在环境的影响下进行状态转移。强化学习模型的好坏，主要取决于在当前状态下，是否能选择出收益最大的动作，因此 $q(s,a)$ 的精准预估显得十分重要。4.4.4. 回溯图与回溯操作回溯操作就是将后继状态（或“状态-动作”二元组）的价值信息 回传 给当前时刻的状态（或”状态-动作“二元组），可以用回溯图来表示，这是强化学习的核心内容。典型的回溯图如下严谨地说，$q_\\pi$ 和 $v_\\pi$ 的作用是评估给定策略 $\\pi$ 的价值，也就是一直使用这个策略来选取动作能得到的期望回报。不同之处是，$v_\\pi$ 评估的对象是状态，考虑从状态 $s$ 出发，遵循策略 $\\pi$ 得到的期望回报；$q_\\pi$ 评估的对象是一个状态-动作对，考虑从状态 $s$ 出发，执行动作 $a$ 之后，遵循策略 $\\pi$ 得到的期望回报。因此，$v_\\pi$ 可以写成 $q_\\pi$ 关于策略 $\\pi$（执行不同动作）的期望，$q_\\pi$ 可以写成 $v_\\pi$ 关于状态转移 $P_{ss^\\prime}^a=p(s^\\prime \\vert s,a)$（执行动作 $a$ 后转移到不同状态）的期望。然后它们相互套娃，就得到了下面的两条等式，这两个等式也可以通过回溯图来直观理解。[ 等式1 ]：\\[v_\\pi(s) = \\mathbb{E}_aq_\\pi(s,a) = \\sum_{a\\in A}\\pi(a\\vert s)q_\\pi(s,a)\\]上面回溯图的上半部分对应上述等式，描述了处于特定状态 $s$ 的价值。即在状态 $s$ 时，遵循策略 $\\pi$ 后，状态 $s$ 的价值体表示为在该状态下采取所有可能动作的动作价值（$q$ 值）按该状态下动作发生概率（策略 $\\pi$）的乘积求和。从状态 $s$ 来看，我们有可能采取两种行动（图中黑点），每个动作都有一个 $q$ 值（状态-动作值函数）。对 $q$ 值进行平均，这个均值告诉我们在特定状态下有多好，也即 $v_\\pi(s)$。上述等式可以通过 $v_\\pi(s)$ 的贝尔曼方程推导得到，即\\[\\begin{aligned}v_\\pi(s) &amp;= \\sum_{a, s^\\prime, r}\\pi(a\\vert s)p(s^\\prime,r \\vert s,a)\\cdot [  r+\\gamma v_\\pi(s^\\prime)  ]\\\\&amp;= \\sum_{a}\\pi(a\\vert s)\\cdot \\sum_{s^\\prime, r}p(s^\\prime,r \\vert s,a)\\cdot [  r+\\gamma v_\\pi(s^\\prime)  ]\\\\&amp;=\\sum_{a}\\pi(a\\vert s)\\cdot \\sum_{s^\\prime, r}p(s^\\prime,r \\vert s,a)\\cdot [r+\\gamma r+\\gamma^2 r+...\\vert s,a]\\\\&amp;=\\sum_{a}\\pi(a\\vert s)\\cdot \\mathbb{E}_\\pi[G_t\\vert s,a]\\\\&amp;=\\sum_{a}\\pi(a\\vert s)\\cdot q_\\pi(s,a)\\end{aligned}\\][ 等式2 ]：\\[q_\\pi(s,a) = \\sum_{s^\\prime,r}p(s^\\prime,r \\vert s,a) \\left[r+\\gamma v_\\pi(s^\\prime) \\right]\\]证明如下\\[\\begin{aligned}q_\\pi(s,a) &amp;= \\mathbb{E}_\\pi\\left[ G_t \\vert S_t=s, A_t=a \\right]\\\\&amp;=\\mathbb{E}_\\pi\\left[R_{t+1}+\\gamma G_{t+1}\\vert S_t=s, A_t=a \\right]\\\\&amp;=\\sum_{s^\\prime,r}p(s^\\prime,r \\vert s,a) \\left[r+\\gamma \\sum_{a^\\prime}   \\pi(a^\\prime \\vert s^\\prime) \\mathbb{E}_\\pi [G_{t+1} \\vert S_{t+1}=s^\\prime, A_{t+1}=a^\\prime]  \\right]\\\\&amp;=\\sum_{s^\\prime,r}p(s^\\prime,r \\vert s,a) \\left[r+\\gamma \\sum_{a^\\prime}   \\pi(a^\\prime \\vert s^\\prime) q_\\pi(s^\\prime, a^\\prime)  \\right]\\\\&amp;=\\sum_{s^\\prime,r}p(s^\\prime,r \\vert s,a) \\left[r+\\gamma v_\\pi(s^\\prime) \\right]\\end{aligned}\\]上式也可以从回溯图中推导得出。4.5. 贝尔曼方程4.5.1. 状态价值函数的贝尔曼方程与马尔可夫奖励过程中的价值函数类似，状态价值函数也有如下贝尔曼方程成立\\[\\begin{aligned}v_\\pi(s) &amp;= \\mathbb{E}_\\pi[R_{t+1} + \\gamma G_{t+1} \\vert S_t = s]\\\\&amp;= \\sum_a \\pi(a\\vert s) \\sum_{s^\\prime}\\sum_r p(s^\\prime,r \\vert s,a) [  r+\\gamma v_\\pi(s^\\prime)  ],\\; \\forall s\\in \\mathcal{S}\\end{aligned}\\]方程推导过程如下，首先易知第一项为即时奖励的期望\\[\\begin{aligned}\\mathbb{E}_\\pi[R_{t+1}\\vert S_t=s] &amp;= \\sum_a \\pi(a\\vert s)\\mathbb{E} [R_{t+1}\\vert S_t=s, A_t=a]\\\\&amp;= \\sum_a \\pi(a\\vert s)\\sum_{s^\\prime} p(r \\vert s,a) r\\\\&amp;=\\sum_a\\pi(a\\vert s)\\sum_{s^\\prime}\\sum_r p(s^\\prime, r \\vert s,a) r\\\\\\end{aligned}\\]第二项为未来奖励的折扣期望（推导中暂不关注折扣因子）\\[\\begin{aligned}\\mathbb{E}_\\pi[G_{t+1}\\vert S_{t}=s] &amp;= \\sum_{s^\\prime}\\mathbb{E}_\\pi[G_{t+1}\\vert S_{t}=s, S_{t+1}=s^\\prime]p(s^\\prime\\vert s)\\\\&amp;= \\sum_{s^\\prime}\\mathbb{E}_\\pi[G_{t+1}\\vert S_{t+1}=s^\\prime]p(s^\\prime\\vert s)\\quad (\\text{Markov Property})\\\\&amp;=\\sum_{s^\\prime}v_\\pi(s^\\prime)p(s^\\prime\\vert s)\\\\&amp;= \\sum_{s^\\prime}v_\\pi(s^\\prime) \\sum_a  p(s^\\prime \\vert s,a) \\pi(a\\vert s)\\\\&amp;= \\sum_{s^\\prime} v_\\pi(s^\\prime)\\sum_a\\sum_r p(s^\\prime,r \\vert s,a)  \\pi(a\\vert s) \\\\&amp;= \\sum_a \\pi(a\\vert s) \\sum_{s^\\prime}\\sum_r  p(s^\\prime,r \\vert s,a) v_\\pi(s^\\prime)\\end{aligned}\\]将上述两项推导加和，则有贝尔曼（期望）方程推导如下\\[\\begin{aligned}v_\\pi(s) &amp;= \\mathbb{E}_\\pi[G_t \\vert S_t=s]\\\\&amp;=\\mathbb{E}_\\pi[R_{t+1}+ \\gamma G_{t+1}\\vert S_t=s]\\\\&amp;=\\sum_a \\pi(a\\vert s) \\left[ \\sum_{r} p(r \\vert s,a) r+\\gamma \\sum_{s^\\prime} p(s^\\prime \\vert s,a) v_\\pi(s^\\prime) \\right]\\\\&amp;=\\sum_a \\pi(a\\vert s) \\sum_{s^\\prime}\\sum_r p(s^\\prime,r \\vert s,a) [  r+\\gamma v_\\pi(s^\\prime)  ] \\\\&amp;=\\sum_{a, s^\\prime, r}\\pi(a\\vert s)p(s^\\prime,r \\vert s,a)\\cdot [  r+\\gamma v_\\pi(s^\\prime)  ]\\end{aligned}\\]最后一行，通过将求和符号合并后，我们可以看出，上述状等式描述了一个关于三参数 $a\\in A, s^\\prime \\in S, r\\in R$ 在所有可能性上的求和。对于每一个三元组，我们计算出其概率 $\\pi(a\\vert s)p(s^\\prime,r \\vert s,a)$ 然后乘以方括号内的值作为权值，最后加权求和得到状态价值函数的期望。参考回溯图可以更好理解。4.5.2. 矩阵化表述与迭代求解与马尔可夫奖励过程类似，将状态价值函数的贝尔曼方程矩阵化，首先列写贝尔曼方程如下\\[v_\\pi(s) =\\sum_a \\pi(a\\vert s) \\left[ \\sum_{r} p(r \\vert s,a) r+\\gamma \\sum_{s^\\prime} p(s^\\prime \\vert s,a) v_\\pi(s^\\prime) \\right]\\]令\\[\\begin{aligned}r_\\pi(s) &amp;= \\sum_a \\pi(a\\vert s)\\sum_{r} p(r \\vert s,a) r\\\\p_\\pi(s^\\prime\\vert s) &amp;= \\sum_a \\pi(a\\vert s)\\sum_{r} p(s^\\prime \\vert s, a)\\end{aligned}\\]则对于任意状态 $s_i \\in \\mathcal{S}\\in \\mathbb{R}^n$ 和其后续状态 $s_j \\in \\mathcal{S}\\in \\mathbb{R}^n$，有\\[v_\\pi(s_i) = r_\\pi(s) + \\gamma \\sum_{s_j}p_\\pi(s_j\\vert s_i)v_\\pi(s_j)\\]将所有状态写成矩阵形式，有\\[\\boldsymbol{V}_\\pi = \\boldsymbol{R}_\\pi + \\gamma \\boldsymbol{P}_\\pi \\boldsymbol{V}_\\pi\\]其中\\[\\begin{aligned}\\boldsymbol{V}_\\pi &amp;= [v_\\pi(s_1),\\cdots, v_\\pi(s_n)]^\\top \\in \\mathbb{R}^n\\\\\\boldsymbol{R}_\\pi &amp;= [r_\\pi(s_1),\\cdots, r_\\pi(s_n)]^\\top \\in \\mathbb{R}^n\\\\\\boldsymbol{P}_\\pi &amp;= [p_\\pi(s_1\\vert s_1),\\cdots, p_\\pi(s_1\\vert s_n); \\cdots; p_\\pi(s_n\\vert s_1),\\cdots, p_\\pi(s_n\\vert s_n)] \\in \\mathbb{R}^{n\\times n}\\end{aligned}\\]则闭式解为\\[\\boldsymbol{V}_\\pi^* = (\\boldsymbol{I}-\\gamma \\boldsymbol{P}_\\pi)^{-1}\\boldsymbol{R}_\\pi\\]可通过迭代求解的方法规避矩阵求逆操作，即\\[\\boldsymbol{V}_\\pi^{(k+1)} = \\boldsymbol{R}_\\pi + \\gamma \\boldsymbol{P}_\\pi \\boldsymbol{V}_\\pi^{(k)}\\]可证明，当 $k\\rightarrow \\infty$ 时，$V_\\pi^{(k)}\\rightarrow V_\\pi^*$，证明如下：定义误差\\[\\delta^k = \\boldsymbol{V}_\\pi^{(k)} - \\boldsymbol{V}_\\pi^*\\]我们需要证明\\[\\delta^k \\rightarrow 0\\]有\\[\\begin{aligned}  \\boldsymbol{V}_\\pi^{(k)} &amp;= \\delta^k + \\boldsymbol{V}_\\pi^*\\\\  \\boldsymbol{V}_\\pi^{(k+1)} &amp;= \\delta^{k+1} + \\boldsymbol{V}_\\pi^*\\\\\\end{aligned}\\]代入迭代形式的贝尔曼方程，有\\[\\begin{aligned}\\delta^{k+1} + \\boldsymbol{V}_\\pi^* &amp;= \\boldsymbol{R}_\\pi + \\gamma \\boldsymbol{P}_\\pi (\\delta^k + \\boldsymbol{V}_\\pi^*)\\\\\\delta^{k+1} &amp;= -\\boldsymbol{V}_\\pi^* + \\boldsymbol{R}_\\pi + \\gamma \\boldsymbol{P}_\\pi \\delta^k + \\gamma \\boldsymbol{P}_\\pi \\boldsymbol{V}_\\pi^*\\\\\\end{aligned}\\]注意到 $\\boldsymbol{V}_\\pi^*$ 同样也满足贝尔曼方程，因此\\[\\begin{aligned}\\delta^{k+1} &amp;= -\\boldsymbol{V}_\\pi^* + (\\boldsymbol{R}_\\pi + \\gamma \\boldsymbol{P}_\\pi \\boldsymbol{V}_\\pi^*) + \\gamma \\boldsymbol{P}_\\pi \\delta^k\\\\&amp;= \\gamma \\boldsymbol{P}_\\pi \\delta^k\\end{aligned}\\]因此\\[\\delta^{k+1} = \\gamma \\boldsymbol{P}_\\pi \\delta^k = \\gamma^2 \\boldsymbol{P}_\\pi^2 \\delta^{k-1} = \\cdots = \\gamma^{k+1} \\boldsymbol{P}_\\pi^{k+1} \\delta^0\\]由于 $\\gamma &lt; 1,\\; \\gamma^{k+1}\\rightarrow 0$，且 $0\\leq \\boldsymbol{P}_\\pi^{k} &lt; 1$（其每一行之和等于 $1$），所以当 $k\\rightarrow \\infty$ 时，$\\delta^k \\rightarrow 0$，证毕。4.5.3. 状态-动作价值函数的贝尔曼方程类似地，动作价值函数也有如下贝尔曼方程成立\\[\\begin{aligned}q_\\pi(s,a) &amp;= \\mathbb{E}_\\pi[R_{t+1} + \\gamma G_{t+1} \\vert S_t = s, A_t = a]\\\\&amp;=\\sum_{s^\\prime,r}p(s^\\prime,r \\vert s,a) \\left[r+\\gamma \\sum_{a^\\prime}   \\pi(a^\\prime \\vert s^\\prime) q_\\pi(s^\\prime, a^\\prime)  \\right]\\end{aligned}\\]4.6. 贝尔曼最优方程4.6.1. 最优策略强化学习的最终目标是寻找最优策略，最优策略是使得价值函数最大的策略\\[\\pi^* \\; \\text{is optimal if}\\; v_{\\pi^*}(s)\\geq v_\\pi(s),\\; \\forall s\\in\\mathcal{S},\\forall\\pi\\in\\mathcal{\\Pi}\\]  这个定义引出了许多问题：      最优策略是否存在？因为定义里的最优策略非常理想，它比其他所有策略都要好，并且在所有状态上都能打败其它策略，那么是否存在这样的情况，最优策略在某些状态上能打败其它的策略，但是在某些状态上没法打败。    最优策略是否唯一？（分别使状态价值函数最大，和使状态-动作价值函数最大，这两个策略等价么？如果等价那么唯一么？）    最优策略是随机的还是确定的？    如何获得最优策略？  由于价值函数有两种，因此可分别定义如下两种最优策略：\\[\\begin{aligned}\\pi^* &amp;= \\mathop{\\text{argmax}}\\limits_\\pi \\;v_\\pi(s)\\\\\\pi^o &amp;= \\mathop{\\text{argmax}}\\limits_\\pi \\;q_\\pi(s,a)\\\\\\end{aligned}\\]其中最大状态价值函数可定义为\\[\\begin{aligned}v_*(s) &amp;\\doteq \\mathop{\\text{max}}\\limits_\\pi \\;v_\\pi(s) = v_{\\pi^*}(s)\\geq v_\\pi(s)\\quad\\forall s\\in\\mathcal{S},\\forall\\pi\\in\\mathcal{\\Pi}\\\\q_*(s,a) &amp;\\doteq \\mathop{\\text{max}}\\limits_\\pi \\;q_\\pi(s,a) = q_{\\pi^o}(s,a)\\geq q_\\pi(s,a)\\quad\\forall s\\in\\mathcal{S},\\forall\\pi\\in\\mathcal{\\Pi}\\\\\\end{aligned}\\]首先证明，对于不同的价值函数（即 $v_\\pi(s)$ 和 $q_\\pi(s,a)$），上述两种最优策略是等价的。根据两个价值函数的关系有\\[v_\\pi(s) = \\sum_{a}\\pi(a\\vert s)\\cdot q_\\pi(s,a) = \\mathbb{E}[q_\\pi(s,a)]\\]对上式的策略统一取到令状态价值函数最大的最优策略，有\\[\\begin{aligned}  v_{\\pi^*}(s) &amp;= \\max_a\\sum_{a}\\pi^*(a\\vert s)\\cdot q_\\pi(s,a)\\\\  &amp;=\\max_a[\\pi(a_1\\vert s)q_\\pi(s,a_1)+\\cdots+\\pi(a_n\\vert s)q_\\pi(s,a_n)]\\\\\\end{aligned}\\]等式右边可以看作对所有状态-动作价值函数的加权和求最大值，若其中某个状态-动作价值函数最大，其权重必然为 $1$，才能保证上式取到最大值。此时对应的策略可以写为\\[\\pi^*(a\\vert s) = \\left\\{\\begin{aligned}  1&amp; \\quad \\text{if}\\quad a=\\text{argmax}_a q_{\\pi^*}(s,a)\\\\  0&amp; \\quad \\text{otherwise}\\end{aligned}\\right.\\]我们发现，这个策略就是一个 $0-1$ 策略，对于不同的价值函数而言，最优策略是等价的\\[\\pi^* = \\mathop{\\text{argmax}}\\limits_\\pi \\;q_\\pi(s,a) = \\pi^o\\]4.6.2. 最优价值函数已知状态价值函数是动作价值函数的期望（加权平均）\\[v_\\pi(s) = \\mathbb{E}_aq_\\pi(s,a)\\]那么当取最优策略时，其必然取到最大值，即\\[v_*(s) = \\mathop{\\text{max}}\\limits_a \\; q_*(s,a)\\]将最优状态价值函数代入前述【等式2】，得到最优状态-动作价值函数的表达式\\[q_*(s,a) = \\sum_{s^\\prime,r}p(s^\\prime,r \\vert s,a) \\left[r+\\gamma v_*(s^\\prime) \\right]\\]4.6.3. 贝尔曼最优方程将最优状态价值函数的代入改写贝尔曼方程，得到贝尔曼最优方程为\\[v_*(s) = \\mathop{\\text{max}}\\limits_a \\sum_{s^\\prime}\\sum_r p(s^\\prime,r \\vert s,a) [  r+\\gamma v_*(s^\\prime)  ]\\]矩阵形式为\\[\\boldsymbol{V} = \\max_\\pi(\\boldsymbol{R}_\\pi + \\gamma\\boldsymbol{P}_\\pi\\boldsymbol{V})\\]类似地 ，最优状态-动作价值函数对应的贝尔曼最优方程为\\[q_*(s,a) = \\sum_{s^\\prime,r}p(s^\\prime,r \\vert s,a) \\left[r+\\gamma \\mathop{\\text{max}}\\limits_a \\; q_*(s^\\prime,a^\\prime) \\right]\\]贝尔曼最优方程给出了最优价值函数和最优策略的关系，即二者通过贝尔曼最优方程约束彼此，相互共同达到最优。但关于方程解的存在性和唯一性还有待进一步证明。以状态价值函数的贝尔曼最优方程为例，定义贝尔曼算子：\\[\\mathcal{B}(\\boldsymbol{V}) = \\max_\\pi(\\boldsymbol{R}_\\pi + \\gamma\\boldsymbol{P}_\\pi\\boldsymbol{V})\\]其解（也即最优状态价值函数）是存在且唯一的，可通过不动点定理来证明。      不动点（fix point）：若 $x\\in X$ 满足 $f(x)=x$，其中 $f:X\\rightarrow X$，则 $x$ 为一个不动点    压缩映射（contraction mapping）：若 $f:X\\rightarrow X$ 满足 $\\Vert f(x)-f(y)\\Vert\\leq \\lambda\\Vert y-x\\Vert$，其中 $\\lambda&lt;1$，则 $f$ 为一个压缩映射，其中 $d=\\Vert \\cdot \\Vert$ 可以是任意向量范数    不动点定理：对于完备度量空间 $(X,d)$ 中任何形式的 $x=f(x)$ 方程，如果 $f$ 是压缩映射，那么满足：              存在性：存在一个不动点 $x^$ 使得 $f(x^)=x^*$        唯一性：不动点是唯一存在的        求解方法：考虑一个序列 $x_k$ 满足 $x_{k+1}=f(x_k)$，则 $x_k\\rightarrow x^*, k\\rightarrow \\infty$，且收敛过程是呈指数级的            对于度量空间，我们使用 $L_\\infty$ 范数\\[\\Vert \\boldsymbol{V}\\Vert_{\\infty} = \\max_i \\vert V_i \\vert\\]根据此度量空间范数的定义，两个值函数之间的距离等于两个值函数向量各方向绝对值之差的最大值。同样，对于有限奖励的有限MDP，值函数将始终在实数空间中。因此，此有限空间是完备的。定理：贝尔曼算子 $\\mathcal{B}$ 是有限空间 $(X, L_\\infty)$ 上的压缩映射。证明过程略，可参考《Mathematical Foundation of Reinforcement Learning》第 3.3.4 节。上述定理保证了贝尔曼最优方程解的存在性和唯一性，并且保证可以通过迭代的形式求解得到最优价值函数（也即后文中的价值迭代（value iteration））。4.6.4. 最优策略的求解通过迭代求解得到最优价值函数后，如何确定最优策略？我们根据迭代求解的价值函数的类别分别讨论：  已知 $v_{*}$为了求解最优策略，只需要做一步搜索就行。也就是对于不同的 $a\\in A$，计算\\[\\pi_*(a\\vert s) \\leftarrow \\mathop{\\text{argmax}}\\limits_a \\sum_{s^\\prime,r}p(s^\\prime,r\\vert s,a)[r+\\gamma v_*(s^\\prime)]\\]就是我们的最优策略。为什么只需要一步搜索就行呢？因为 $v_*$ 已经考虑未来可能行为的回报。  已知 $q_{*}$已知 $q_*$ 就更直接了，只要取其中最大值对应的动作就是最优动作（策略）\\[\\pi_*(a\\vert s) \\leftarrow \\mathop{\\text{argmax}}\\limits_a\\; q_*(s,a)\\]可以看到，如果已经得到了所有状态（或状态-动作）的最优价值函数，那么最优策略是很容易得到的。经过前面的分析我们指导，最优的状态（或状态-动作）价值函数可以通过对贝尔曼最优方程迭代来求解。具体来说，我们需要将强化学习分为两步，第一步解决一个预测问题，即给定状态、动作、奖励、状态转移概率，策略，预测出所有状态（或状态-动作）价值函数；第二步解决一个控制问题，即在预测问题的基础上，如何更新策略使得策略逐渐变得更优。当状态转移概率（也即环境 $p$）已知时，预测问题可以通过 策略迭代（policy iteration） 或者 值迭代（value iteration） 的方式来先进行价值预测，再求解最优策略。这就是 动态规划方法（Dynamic Programming，DP）。当状态转移概率（也即环境 $p$）未知时，可以通过 蒙特卡洛方法（Monte Carlo，MC） 进行价值预测。4.7. 贝尔曼期望方程从状态价值函数的定义出发\\[v_\\pi(s) = \\mathbb{E}[R+\\gamma G\\vert S=s] = \\mathbb{E}[R\\vert S=s] + \\gamma \\mathbb{E}[G\\vert S=s], \\;s\\in S\\]其中\\[\\mathbb{E}[G\\vert S=s] = \\sum_a\\pi(a\\vert s)\\sum_{s^\\prime}p(s^\\prime\\vert s,a)v_\\pi(s^\\prime) = \\mathbb{E}[v_\\pi(s^\\prime)\\vert S=s]\\]带回状态价值函数定义式，有\\[v_\\pi(s) = \\mathbb{E}[R+\\gamma v_\\pi(s^\\prime)\\vert S=s], \\;\\forall s\\]类似地，针对状态-动作价值函数，也有\\[q_\\pi(s,a) = \\mathbb{E}[R+\\gamma q_\\pi(s^\\prime,a^\\prime)\\vert S=s,A=a],\\; \\forall s,a\\]上述两个公式合称为贝尔曼期望方程。5. 参考文献[1] 知乎. 强化学习（Reinforcement Learning）.[2] ReEchooo. 强化学习知识要点与编程实践（1）——马尔可夫决策过程[3] ReEchooo. 强化学习笔记（2）——马尔可夫决策过程[4] Ping2021. 第二讲 马尔可夫决策过程[5] 木头人puppet. 强化学习：贝尔曼方程和最优性[6] koch. 强化学习-贝尔曼方程和贝尔曼最优方程的推导[7] Alvin. 知乎：3.6 最优策略和最优值函数"
  },
  
  {
    "title": "Windows环境下使用CMake+MinGW-w64编译模型加载库assimp",
    "url": "/posts/windows-mingw64-assimp/",
    "categories": "Tutorial, Coding",
    "tags": "c/c++, vscode",
    "date": "2022-10-26 16:23:19 +0800",
    





    
    "snippet": "本文介绍了在Windows环境下使用MinGW-w64编译模型加载库assimp的方法和坑。  1. 基本知识          1.1. MinGW-w64      1.2. assimp        2. 部署方式          2.1. CMake      2.2. make        3. 参考文献1. 基本知识1.1. MinGW-w64MinGW 的全称是 Mini...",
    "content": "本文介绍了在Windows环境下使用MinGW-w64编译模型加载库assimp的方法和坑。  1. 基本知识          1.1. MinGW-w64      1.2. assimp        2. 部署方式          2.1. CMake      2.2. make        3. 参考文献1. 基本知识1.1. MinGW-w64MinGW 的全称是 Minimalist GNU on Windows 。是将经典的开源 C 语言编译器 GCC 移植到了 Windows 平台下，并且包含了 Win32API ，因此可以将源代码编译为可在 Windows 中运行的可执行程序。而且还可以使用一些 Windows 不具备的，Linux平台下的开发工具。一句话来概括：MinGW 就是 GCC 的 Windows 版本 。MinGW-w64 与 MinGW 的区别在于 MinGW 只能编译生成32位可执行程序，而 MinGW-w64 则可以编译生成 64位 或 32位 可执行程序。正因为如此，MinGW 现已被 MinGW-w64 所取代，且 MinGW 也早已停止了更新，内置的 GCC 停滞在了 4.8.1 版本，而 MinGW-w64 内置的 GCC 则一直保持更新。可在此处下载最新版本。(https://github.com/niXman/mingw-builds-binaries/releases)。更多介绍可参考：VSCode部署C/C++开发环境。1.2. assimpAssimp 全称为 Open Asset Import Library，这是一个模型加载库，可以导入几十种不同格式的模型文件（同样也可以导出部分模型格式）。只要 Assimp 加载完了模型文件，我们就可以从 Assimp 上获取所有我们需要的模型数据。Assimp 把不同的模型文件都转换为一个统一的数据结构，所有无论我们导入何种格式的模型文件，都可以用同一个方式去访问我们需要的模型数据。官方手册地址：https://assimp-docs.readthedocs.io/en/v5.1.0/官方仓库地址：https://github.com/assimp/assimpAssimp 基本上没有预编译的文件，而且为了适配本机环境，最好还是自己编译，因此我们需要下载 Assimp 的源码。2. 部署方式部署过程在如下版本部署成功：  assimp 5.2.5  OS: Windows 11  CMake 3.25.0-rc2  gcc version 12.2.0 (x86_64-win32-sjlj-rev0, Built by MinGW-W64 project)  MinGW-w64: https://github.com/niXman/mingw-builds-binaries/releases 下载的 2022 Aug 23 版本2.1. CMake首先需要下载 CMake，官网：https://cmake.org/下载完成后运行 CMake(cmake-gui)，设置源代码路径（where is the source code）和二进制文件路径（where to build the binaries）点击 Configure 按钮进行配置。配置生成所需的 Makefiles配置编译器注意： 完成配置后，取消勾选 ASSIMP_WARNINGS_AS_ERRORS，否则会将 Warning 看作 Error 报错。最后点击 Generate 按钮生成文件和 makefile。2.2. make管理员打开 PowerShell 或者命令提示符，cd 到设置的二进制文件路径，运行下面的命令mingw32-make.exe -j8注意：前提是 MinGW-w64 安装路径下的 bin 文件夹已经添加到系统的环境变量（PATH）中。注意：-j8 表示使用 CPU 的八核进行编译，根据自己的硬件情况设置。编译完成后，得到  include/assimp/config.h（将本文件拷贝至工程的 include 文件夹或 assimp 文件夹之类 ）  bin/libassimp-5.dll（Windows下将本文件拷贝至 .exe ）  bin/unit.exe  lib/libassimp.dll.a将 include/assimp 中的所有头文件（除了 config.h）拷贝至前面一样的文件夹（工程的 include 文件夹或 assimp 文件夹之类）3. 参考文献无。"
  },
  
  {
    "title": "天文学基础（坐标系统）",
    "url": "/posts/astronomy-basic-coordinate/",
    "categories": "Academic, Knowledge",
    "tags": "astronomy",
    "date": "2022-03-23 16:23:19 +0800",
    





    
    "snippet": "本文介绍了天文学中基本的座标系统。  1. 背景          1.1. 国际地球自转和参考框架服务      1.2. 国际天文学联合会        2. 坐标系          2.1. 参考系统与参考框架      2.2. 坐标系的分类      2.3. 国际天球参考系统和参考框架（ICRS/ICRF）                  2.3.1. 太阳系质心天球参考系统...",
    "content": "本文介绍了天文学中基本的座标系统。  1. 背景          1.1. 国际地球自转和参考框架服务      1.2. 国际天文学联合会        2. 坐标系          2.1. 参考系统与参考框架      2.2. 坐标系的分类      2.3. 国际天球参考系统和参考框架（ICRS/ICRF）                  2.3.1. 太阳系质心天球参考系统和参考框架（BCRS/BCRF）          2.3.2. 地心天球参考系统和参考框架（GCRS/GCRF）                    2.4. J2000.0平赤道平春分点坐标系      2.5. 国际地球参考系统和参考框架（ITRS/ITRF）      2.6. 地理坐标系      2.7. 当地水平坐标系      2.8. 飞行坐标系      2.9. 本体坐标系        3. 坐标变换          3.1. 岁差、章动和极移      3.2. 地心天球参考系统与国际地球参考系统的变换      3.3. 地心天球参考系到地球固连坐标系的变换        4. 参考文献1. 背景1.1. 国际地球自转和参考框架服务国际地球自转和参考框架服务（International Earth Rotation and Reference System, IERS）（官网：https://www.iers.org/IERS/EN/Home/home_node.html ）的主要目标是通过提供国际陆空参考系统的入口来为天文学、测地学和地球物理学的研究团体服务。该网站提供了有关国际地球自转服务中心的任务、机构设置、成员以及相关产品的详细信息，同时还提供了通向其数据库和公告中的观测数据与研究结果的入口。国际地球自转服务(International Earth Rotation Service-简称IERS)由国际大地测量学和地球物理学联合会及与国际天文学联合会联合创办，用以取代国际时间局(BIH)的地球自转部分和原有的国际极移服务(IPMS)。1.2. 国际天文学联合会国际天文学联合会（International Astronomical Union, IAU）（官网：https://www.iau.org/ ）是世界各国天文学术团体联合组成的非政府性学术组织，其宗旨是组织国际学术交流，推动国际协作，促进天文学的发展。国际天文学联合会于1919年7月在布鲁塞尔成立。天文学联盟有73个成员国，其中包括专业天文学研究达到较高程度的大多数国家。天文学联盟的一个主要从事地面和空间天文学各学科的 10528 多名成员的直接参与。2. 坐标系2.1. 参考系统与参考框架参考系统（reference system）是关于坐标系的“理论定义”，包括原点、坐标轴、坐标平面，以及基本的数学或物理模型。其包含自身部署应用所需的模型和标准，用以规定坐标系三个轴向和坐标原点的建模方法，可以理解为一组处方（prescriptions）和公约（conventions）。参考系统也有被翻译为参考框架或参考架。参考框架（reference frame）是对参考系统的“具体实现”，一般是通过对一组参考坐标（天体参考框架是一组基本恒星，地球参考框架是一组基准站）进行观测来具体实现某一参考系统。建立参考框架必须遵循一定的原则，这些原则包括：如何通过观测建立某些事件的时空坐标，如何实现相应系统（框架）。例如，通过观测以一些天体相对于某参考框架的位置的历书或星表的形式来实现。建立天文参考框架可依据三种原理：星历罗盘、恒星罗盘、惯性罗盘。      星历罗盘是以相互作用的天体平动动力学为基础的。在基本的参考框架中，可给出相应的运动动力学方程，并将这些天体位置的观测结果作为事件的函数来实现相应的框架构建。基于星历罗经建立的参考框架称为动力学参考框架（DRS）。国际地球坐标系（ITRS）的建立主要是基于星历罗经，即人造卫星的观测结果；太阳质心动力学参考框架（BDRS）是通过描述太阳系天体运动的历表来实现的。历表（ephemeris）这个词来源于希腊语（ephemeros表示一天），意思为用于确定太阳系大型天体位置和速度的列表、表格或计算机程序。历表可分为数值历表（DE、EPM）和半解析历表（VSOP2010A和VSOP2010B）。        恒星星表是利用遥远的天体，如类星体的光信息构建的准惯性参考框架，如依巴谷参考框架（HCRS）。        不同于天体的平移运动，如激光陀螺等的惯性系统可定义一个参考框架，它直接构建一个动力学非旋转参考框架。  2.2. 坐标系的分类  i 系：地心惯性坐标系（inertial）是在惯性空间中静止或作匀速运动的参考系，是一个理想坐标系。实践中将该坐标系的原点固定在地球质心， z 轴平行于地球平均自转轴且指向北极点（协议北极）， x 轴指向平春分点， z 轴在赤道面内且与 x 轴和 z 轴垂直构成右手坐标系，三个轴在惯性空间中固定不动。  e 系：地心地固坐标系(Earth Center Earth Fixed Frame, ECEF)是指原点在地心，与地球固连，并随着地球一起转动的坐标系。x 轴指向赤道与本初子午线的交点，z 轴指向地球平均自转轴方向，y 轴与 x、z 轴垂直并满足右手定则，常用符号 e 来表示。  n 系：导航坐标系（Navigation） 一般选当地地理水平坐标系（ Local-Level-Frame, LLF），该坐标系可以提供直观的导航参数。该坐标系的原点为载体中心， x 轴沿参考椭球子午线的切线方向指北， y 轴沿参考椭球法线垂直向下， z 轴在当地水平面内与 x 轴和 y 轴构成右手坐标系，又称为北-东-地（ North-East-Down, NED）坐标系。  b 系：同载体固连的一种正交坐标系，x 轴与载体角运动的横滚轴方向相同且指向载体前方， y 轴与载体角运动的俯仰轴方向相同且指向载体右侧， z 轴与载体角运动的航向轴方向相同且与 x 轴和 y 轴构成右手坐标系，称为前-右-下（ Forward-RightDown， FRD）坐标系。  c 系：相机坐标系，原点为光学透镜中心， ܺx 轴沿相机镜头方向且向右为正，z 轴沿相机镜头方向且向前为正，y 轴与ܺx 轴和ܼ z 轴构成右手坐标系。2.3. 国际天球参考系统和参考框架（ICRS/ICRF）国际天球参考系统（Celestial Reference System，ICRS）是一个准惯性无旋转参考系统，其原点是广义相对论框架下的VLBI测定的太阳系质心，基本平面尽可能接近J2000.0平赤道面，X轴指向J2000.0历元的平春分点方向（被隐含定义在一组星表的23个射电源的平赤经中），Z轴垂直于J2000.0平赤道面，Y轴通过右手定则确定。ICRS是直接由遥远、静止的射电源表来定义的。射电源可被分为三类：定义源、候选源、其它源。定义源应有大量的观测和足够长的数据可以评定位置的稳定性，它们维持着ICRS的轴方向；候选源没有足够的观测数据或观测时间太短，不能用来作为定义源，但它们可能是未来潜在的定义源；其它源包括位置确定较差的源，但在导出各种框架时会用到。国际天球参考框架（Celestial Reference Frame, ICRF）是ICRS的一个具体实现，它是通过超长基线干涉测量（Very Long Baseline Interferometry, VLBI）估计一组银河系外射电源的精确坐标确定的（即它相对于遥远的宇宙物体是固定的）。其采用的J2000.0平赤道和平春分点由IAU在1976年发布的协议定义。目前用来实现ICRS的射电源表包含ICRF1和ICRF2两个版本，ICRF1射电源表包含了608个射电源的位置，其中定义源212个，候选源294个，其他源102个；ICRF2射电源表包含了3414个致密天文射电源的精确坐标，有292个定义源。由于ICRF（包括ICRF1和ICRF2）是在射电波段建立的，而基准射电源在光学波段非常暗，对光学观测很不方便，所以IAU12000决议B1.2推荐使用依巴谷星表（Hipparcos Catalogue）作为ICRS在光学波段的主要实现，并命名为依巴谷参考系统（HCRF），其平均观测历元为J1991.25。依巴谷星表比之前的任何光学天体测量星表都精确，而且没有明显的星等差和区域差。与河外射电源相比，最大区别在于有很明显的自行，因此依巴谷星表的位置精度依赖时间，随着时间偏离其平均观测历元而逐渐降低。2.3.1. 太阳系质心天球参考系统和参考框架（BCRS/BCRF）太阳系质心天球参考系统（Barycentric Celestial Reference System，BCRS）是ICRS下属的一种参考系统。BCRS和ICRS的区别体现在不同的抽象层次上。原则上，BCRS轴可以通过不同的技术来固定。但目前它们是由ICRS确定的。严格而言，BCRS的定义应该不参考ICRS。太阳系质心天球参考框架（Barycentric Celestial Reference Frame，BCRF）是BCRS的一个实现。目前ICRS和BCRS，ICRF和BCRF之间存在混用的情况。2.3.2. 地心天球参考系统和参考框架（GCRS/GCRF）地心天球参考系统（Geocentric Celestial Reference System，GCRS）也是ICRS下属的一种参考系统，其原点在地球质心，是一个局部参考系统。GCRS与BCRS之间的空间坐标转换没有旋转，只有平移。地心天球参考框架（Geocentric Celestial Reference Frame，GCRF）是GCRS的一个实现。2.4. J2000.0平赤道平春分点坐标系J2000.0平赤道平春分点坐标系（The mean equator and equinox J2000.0），常被称为J2000平赤道地心坐标系，原点在地球质心，$xy$平面为J2000.0时刻的地球平赤道面，$x$轴指向J2000.0时刻的平春分点（J2000.0时刻平赤道面与平黄道面的一个交点）。此坐标系常被作为地球卫星的惯性坐标系，卫星运动积分等都在此坐标系计算。J2000平赤道地心坐标系与GCRS之间仅有一个常值偏差矩阵$B$。目前IAU推荐用GCRS坐标系逐渐取代J2000平赤道地心坐标系。2.5. 国际地球参考系统和参考框架（ITRS/ITRF）在研究与地球有关的科技问题时，都需要以地球为参考的坐标系，称为地球坐标系，它是大地测量学和地球动力学研究的一种基本坐标系。如果把地球潮汐和地壳运动忽略不计，地球重力场和地面点的位置在这个坐标系中是固定不变的。也就是说这个坐标系仅随地球自转而转动，固定在地球上不变，因而也被称为地固坐标系（ECEF）。地球坐标系的建立已有一百多年的历史，1980年以前主要采用的是光学观测。随着空间大地测量的开展，观测人造的或自然的天体打破了集团或国家独有的观测传统，迫切要求确立与使用公用的地球坐标系。但宇宙间不可能存在绝对固定不动的东西，所以建立这种坐标系只能通过一种协议结果来体现，因而这种坐标系也被称协议地球参考系统（CTRS）。国际上约定统一采用的协议地球参考系统为国际地球参考系统（International Terrestrial Reference System，ITRS）。IERS主要任务是准确及时提供自转参数，同时建立与保持这个地球参考系统。ITRS是一种地心参考系统，由空间大地测量观测站的坐标和运动速度来定义，是国际地球自转服务的地面参考系统。该系统是国际大地测量学和地球物理学联合会（IUGG）、国际大地测量学协会（IAG）、国际天文学会（IAU）专门决定建立的，有关工作由IERS下属地球参考系统部门负责执行。ITRS的原点在地球质心（包含大气海洋等质量），长度为广义相对论框架下定义的米（SI），坐标轴方向与国际时间局1984.0历元的定义一致，时间演变基准是使用满足无整体旋转NNR（No-Net Rotation）条件的板块运动模型描述地球各块体随时间的变化。国际地球参考框架（International Terrestrial Reference Frame，ITRF）是ITRS的一个实现，也就是人们常说的地球固连坐标系（ECEF）。ITRF由IERS每年将全球各地测量站的观测数据进行综合处理分析，就原点差、尺度差和定向差进行平差而确定，并以IERS年报和IERS技术备忘录的形式发布。ITRF是国际上目前公认的精度最高、稳定性最好的地球参考架。ITRF 从 1988 建立起已有13个版本，它们是 ITRF88, ITRF89, ITRF90, ITRF91, ITRF92, ITRF93, ITRF94, ITRF96, ITRF97, ITRF2000, ITRF2005, ITRF2008，ITRF2014。  WGS84参考系：20世纪30年代以来，美国和前苏联等国家利用卫星观测等资料，开展了建立地心坐标系的工作。美国国防部曾先后建立过世界大地坐标系（World Geodetic System，WGS）WGS 30、WGS 33和WGS72，并于1984年开始，经过多年修正和完善，建立起更为精确的地心坐标系统，称为WGS84。WGS84坐标系是目前GPS测量所采用的坐标系统。  CGCS2000参考系：我国当前最新的国家大地坐标系（China Geodetic Coordinate System 2000），原点为包括海洋和大气的整个地球的质量中心，Z轴由原点指向J2000.0历元时刻的地球参考极的方向，X轴由原点指向格林尼治参考子午线与地球赤道面（J2000.0历元时刻）的交点，Y轴与Z轴、X轴构成右手正交坐标系。采用广义相对论意义下的尺度。GCGS 2000 是定义在 ITRF97 地心坐标系统中的区域性地心坐标框架。CGCS2000为我国北斗导航系统所采用的坐标系统。2.6. 地理坐标系地理坐标系（Length-Breadth-Height, LBH 或 Latitude-Longitude-Height, LLA）和地球固连坐标系在理论上是等价的，只不过地球固连坐标系使用直角坐标描述方位，而地理坐标系使用经线和纬线的球面测量值来描述方位。在球面系统中，水平线（或东西线）是等纬度线或纬线。垂直线（或南北线）是等经度线或经线。这些线包络着地球，构成了一个称为经纬网的格网化网络。当地球作为球体建模时，它们是从地心到地球表面上的点的角度测量值（以度为单位）。当使用旋转椭球体（椭球体）时，可通过将与地球表面垂直的线延伸到赤道平面来测量纬度。地理坐标系的使用需要基于地固坐标系的选取（大概？）。2.7. 当地水平坐标系当地水平坐标系（Local Level System/Frame，LLS或LLF）的Z轴沿着当地垂线竖直向上，X轴指向当地东方，Y轴指向当地北方，X轴与Y轴、Z轴构成右手正交坐标系。2.8. 飞行坐标系飞行坐标系是一种固连在飞行器本体的坐标系统，坐标系原点定义在飞行器质心，X轴指向飞行方向，Z轴指向地球质心，Y轴与X轴、Z轴构成右手正交坐标系，垂直于飞行轨道平面。对于航天器，飞行坐标系又可称为轨道坐标系。2.9. 本体坐标系本体（载体）坐标系是一种固连在载体本体的坐标系统，坐标系原点定义在载体质心，X轴指向载体前向中心线方向，Y轴指向垂直于X轴指向载体右侧，Z轴与X轴、Y轴构成右手正交坐标系。3. 坐标变换3.1. 岁差、章动和极移地球的自转轴在惯性空间中并不固定，而是不断摆动的。此摆动造成地轴绕北黄级顺时针运动，夹角约为23.5度，该运动（进动）在天文学上被称为岁差（Precession）。在岁差运动的同时，地轴还在做微小的抖动，称为章动（Nutation）。岁差章动的原因主要有两个方面。其一是太阳系行星对地球绕日轨道所产生的摄动影响；其二是太阳和月球对地球赤道隆起部分的摄动影响。早期岁差章动计算依据IAU 1976岁差模型和IAU 1980章动模型。随着时间的推移，上述模型的精度逐渐无法满足需要。因此，IAU规定从2003年1月1日起，采用新的岁差章动模型，即IAU 2000A模型（精度达到0.2mas）或IAU 2000B模型（精度达到1mas）。地球自转轴相对于地球北极而言也不是固定不动的，地表海洋、大气运动以及地核内部液体运动会造成地球自转轴相对于地球北极CIO点存在小范围运动，被称为极移。3.2. 地心天球参考系统与国际地球参考系统的变换GCRS与ITRS之间有两种坐标变换模型：基于春分点的岁差章动转换和基于CIO的无旋转原点转换。IERS 2003 和 2010 规范针对这两种转换模型分别推荐了相应的转换参数。两种转换模型相应的转换过程如下图所示。3.3. 地心天球参考系到地球固连坐标系的变换4. 参考文献无。"
  },
  
  {
    "title": "CDDIS网站下GNSS相关数据解析（卫星星历部分）",
    "url": "/posts/astronomy-CDDIS/",
    "categories": "Academic, Knowledge",
    "tags": "astronomy",
    "date": "2021-11-18 17:05:49 +0800",
    





    
    "snippet": "本文介绍了CDDIS网站下 GNSS 相关的数据产品下载、命名方式解读、文件格式说明和文件下载地址。  1. 数据（data目录）  2. 广播星历（Broadcast ephemeris data）          2.1. Daily GPS Broadcast Ephemeris Files      2.2. Hourly GPS Broadcast Ephemeris Files...",
    "content": "本文介绍了CDDIS网站下 GNSS 相关的数据产品下载、命名方式解读、文件格式说明和文件下载地址。  1. 数据（data目录）  2. 广播星历（Broadcast ephemeris data）          2.1. Daily GPS Broadcast Ephemeris Files      2.2. Hourly GPS Broadcast Ephemeris Files      2.3. Daily GLONASS Broadcast Ephemeris Files        3. 产品（product目录）  4. 精密星历          4.1. GPS 周        5. 精密星历文件核心参考文献：GNSS. CDDIS网站下 GNSS 相关的数据产品下载+命名方式解读+文件格式说明文件下载地址1. 数据（data目录）CDDIS存档包含来自永久GNSS接收器全球网络的GNSS数据，这些网络支持以30秒的采样率运行的IGS，并包含24小时的数据（UTC时间00：00-23：59）。 IGS分析中心每天都会检索这些数据以生产IGS产品。 这些产品，例如每日和每周的卫星星历，站的位置和速度，卫星和站的时钟信息以及地球自转参数，都将提交给CDDIS。数据目录一览： **********************************************************************                   Welcome to the CDDIS GPS ArchiveThe main directories are:archive/gnss/data/ /campaign                   GPS data from selected campaigns /daily/YYYY/DDD/YYd         Observation files for year YYYY and day DDD                             (Hatanaka format)                 /YYm        Met files for year YYYY and day DDD                 /YYn        Navigation files for year YYYY and day DDD                 /YYo        Observation files for year YYYY and day DDD                 /YYs        Summary files for year YYYY and day DDD                             (teqc output) /hourly/YYYY/DDD/HH         Hourly RINEX GPS files for year YYYY, day DDD,                             and hour HH; observation (Hatanaka format),                             navigation and met data /high-rate/YYYY/DDD/YYd/HH  Observation files for day YYDDD and hour HH                             (Hatanaka format)                    /YYm/HH  Met files for day YYDDD and hour HH                    /YYn/HH  Navigation files for day YYDDD and hour HH /satellite/SATNAME/YYYY/DDD GPS data from on-board GPS receivers for                             satellite SATNAME for year YYYY and day DDD  /gnss/products/ionex/YYYY/DDD    Daily IONEX products for year YYYY and                                  day DDD               /trop/WWWW         Weekly GPS troposphere products for GPS                                  week WWWW                    /YYYY         Yearly GPS troposphere products for year                                  YYYY                     /nrt/WWWW     Near real-time GPS troposphere products                                  for GPS week WWWW               /trop_cmp/YYYY/DDD Troposphere comparison results for year                                  YYYY and day DDD               /trop_new/YYYY/DDD New IGS troposphere product for year                                  YYYY and day DDD               /WWWW              Weekly GPS precise orbits, etc. for GPS                                  week WWWW  All files are archived in UNIX compressed format. Contact Carey Noll (Carey.E.Noll@nasa.gov) for further information. ********************************************************************** The local date and time is: %T数据分为两种格式：  RINEX V2 format： YYYY/DDD/YYt/mmmmDDD#.YYt.Z  RINEX V3 format： YYYY/DDD/YYt/XXXXMRCCC_K_YYYYDDDHHMM_01D_30S_tt.FFF.gRINEX V2 格式的每日 GNSS 数据使用 mmmmDDD＃.YYt.Z 文件名约定，并且为UNIX压缩格式。 从2016年的数据开始，所有使用RINEX V3文件命名约定和gzip压缩格式的RINEX V3格式的每日GNSS数据均以RINEX V2格式的数据归档在/gnss/data/daily 区域的子目录中。RINEX V2 格式文件名中字母的含义说明：YYYY/DDD/YYt/mmmmDDD#.YYt.Z            code      meaning                  YYYY      4位，代表年              DDD      3位，年积日              YYt      YY为年份的后两位数字，t表示不同数据类型，具体含义如下                     b = 组合广播星历数据                     n = GPS广播星历数据                     f = 北斗广播星历数据                     g = GLONASS广播星历数据                     l = Galileo广播星历数据                     i = IRNSS广播星历数据                     h = SBAS广播星历数据                     q = QZSS广播星历数据，同d                     m = 气象数据                     d = 高压缩的观测数据，后续用 crx2rnx.exe 转换为o文件                     o = 观测数据，同d                     s = 观测摘要文件（TEQC的输出）                     x = 混合广播星历数据              mmmm      4位，IGS测站的名字              #      1位，当一天中有多个文件的情况下，表示一天当中的第几个文件。通常为0表示一天当中的所有数据（一个文件）              .Z      UNIX压缩文件      RINEX V3 格式文件名中字母的含义说明：YYYY/DDD/YYt/XXXXMRCCC_K_YYYYDDDHHMM_01D_30S_tt.FFF.g            code      meaning                  YYYY      4位，代表年              DDD      3位，年积日              YYt      YY为年份的后两位数字，t表示不同数据类型，具体含义如下                     b = 组合广播星历数据                     d = 高压缩的观测数据，后续用crx2rnx.exe转换为o文件                     f = 北斗广播星历数据                     g = GLONASS广播星历数据                     h = SBAS广播星历数据                     i = IRNSS广播星历数据                     l = Galileo广播星历数据                     m = 气象数据                     n = GPS广播星历数据                     o = 观测数据，同d                     q = QZSS广播星历数据                     s = 观测摘要文件（TEQC的输出）                     x = 混合广播星历数据              XXXX      4位，IGS测站的名字              M      标记编号(0-9)              R      接收机编号(0 - 9)              CCC      ISO国家代码              K      数据来源，其中：                     R =从使用供应商或其他软件的接收数据                     S =从数据流(RTCM或其他)                     U =未知              HH      2位，小时              MM      2位，分钟              tt      数据类型，其中：                     GO = GPS观测数据                     RO = GLONASS观测数据                     EO = Galileo观测数据                     JO = QZSS观测数据                     CO = BDS观测数据                     IO = IRNSS观测数据                     SO = SBAS观测数据                     MO = 混合观测数据                     GN = GPS导航数据                     RN = GLONASS导航数据                     EN = Galileo导航数据                     JN = QZSS导航数据                     CN = BDS导航数据                     IN = IRNSS导航数据                     SN = SBAS导航数据                     MN = 导航数据(所有GNSS星座)                     MM = 气象观测数据              FFF      rnx = RINEX                     crx = 高压缩的 RINEX              01D_30S      一般来说，这个字段有三类：                     01D_30S Daily 全天 采样30s                     01H_30S hourly 整个小时 采样30s                     15M_01S minutely 15分 采样1s      2. 广播星历（Broadcast ephemeris data）广播星历是接收机直接从天线接收到的卫星所发射的信号中分离出来的。除了观测数据外，很大一部分的GNSS站点还提供广播导航数据。CDDIS从这些站点发送的这些特定于站点的文件中创建每日广播星历文件；这些文件（一个用于GPS，另一个用于GLONASS）包含每天的唯一GPS或GLONASS卫星星历消息。在UTC一天开始时会创建一个类似的文件，并从每小时广播的导航文件中每小时更新一次。因此，用户可以每天或每小时下载一个文件，其中包含后处理所需的所有广播星历消息。2.1. Daily GPS Broadcast Ephemeris Files每日GPS广播星历文件是将单个站点的导航文件合并成一个可供用户使用的非冗余文件，而不是多个单独的导航文件。每天在BKG创建的文件包含来自欧洲站点的独特导航消息。日常文件的起始目录为：https://cddis.nasa.gov/archive/gnss/data/daily/将以下目录和文件名附加到起始目录:YYYY/DDD/YYn/brdcDDD0.YYn.Z (合并GPS广播星历文件)ORYYYY/brdc/brdcDDD0.YYn.Z (合并GPS广播星历文件)YYYY/DDD/YYn/ifagDDD0.YYn.Z (以往在BKG创建的每日文件)2.2. Hourly GPS Broadcast Ephemeris Files组合的广播星历文件是每小时从CDDIS上存档的所有每小时导航文件中生成的。 每小时导航文件包含具有当天TOE的所有广播消息，该消息在小时的顶部创建时可用。 每小时使用新的导航消息更新文件。在UTC一天结束时，当生成文件的最终版本时，该文件将复制到每日目录中，并成为“每日”广播星历表文件。每小时文件的起始目录是https://cddis.nasa.gov/archive/gnss/data/hourly/将以下目录和文件名附加到起始目录:YYYY/DDD/hourDDDm.YYn.Z2.3. Daily GLONASS Broadcast Ephemeris Files类似地，可以在GLONASS导航文件子目录中找到每日仅使用GLONASS的广播星历文件。每日仅使用glonass文件的起始目录为https://cddis.nasa.gov/archive/gnss/data/daily/将以下目录和文件名附加到起始目录:YYYY/DDD/YYg/brdcDDD0.YYg.ZORYYYY/brdc/brdcDDD0.YYg.Z3. 产品（product目录）产品目录一览：https://cddis.nasa.gov/archive/gnss/products/文件为：WWWW/AAAWWWWD_TYP.YYt.Z，其中：            code      meaning                  AAA      International GNSS Service(IGS) 分析中心名称              WWWW      GPS 周              D      星期（0-6，7表示每周）              TYP      解的类型，具体如下：                     eph Satellite orbit solution 卫星轨道解                     erp Earth orientation parameter solution 地球定向参数解                     sp3 Satellite orbit solution 卫星轨道解                     sum Orbit solution analysis summary 轨道解分析总结              .Z      UNIX 压缩文件      分析中心名称缩写对应如下：|code|meaning|| — | — || cod | CODE（3 day long arc solution） || cof | CODE（1 day solution） || cox | CODE GLONASS only || emr | NRCan || emx | NRCan GLONASS only || jpl | JPL || mit | MIT || ncl | University of Newcastle || sio | SIO |等等不再详述。4. 精密星历精密星历由自建跟踪站提供（一般为当地、符合气象、大气层的实际）；可以较准确地提供轨道信息；事后计算；有偿服务；地面通讯获取。精密星历的获取需要根据GPS周来确定。4.1. GPS 周GPS周的计算方法参考：流浪猪头拯救地球. GPS周计算。GPS周（GPS Week）是GPS系统内部所采用的时间系统。 时间零点定义的为：1980年1月5日夜晚与1980年1月6日凌晨之间0点。最大时间单位是周（一周：604800秒）。由于在储存周数的时候，用了10个比特，2的10次方是1024，所以每1024周（即7168天）为一循环周期。我们国家的北斗考虑到每1024周翻转一次过于频繁，所以就开了13个比特来存放周数，2的13次方为8192，大概是150多年翻转一次，我们这辈子恐怕没机会见到了，哈哈哈。第一个GPS周循环点为1999年8月22日0时0分0秒。即从这一刻起，周数重新从0开始算起。星期记数规则是：Sunday为0，Monday为1，以此类推，依次记作0~6，GPS周记数为“GPS周 星期记数”。GPS周与儒略日转换代码（https://github.com/fernandoferreiratbe/gpsweek-converter）：# _*_ encoding: utf-8 _*_class Converter:    # noinspection PyMethodMayBeStatic    def convert_julian_date_to_gps_week(self, julian_date: float):        gps_week = ((julian_date - 2444245) // 7)        return int(gps_week)    # noinspection PyMethodMayBeStatic    def convert_gps_week_to_julian_date(self, gps_week: int, day_of_week: int = 0):        if gps_week is None:            raise ValueError('GPS Week can not be None.')        if day_of_week not in range(0, 7):            raise ValueError('Day of week out of range 0-6.')        julian_day = (7.0 * gps_week + 2444245.0 + day_of_week)        return julian_day或者采用在线计算的方式（https://www.labsat.co.uk/index.php/en/gps-time-calculator）。比如想找2020年元旦的精密星历数据，经过计算知道那一天是GPS周第2086周，所以进入2086目录下去下载相应数据。5. 精密星历文件目前IGS精密星历主要分为三种：最终精密星历（IGS Final，标识为 IGS）、快速精密星历（IGS Rapid，标识为 IGR）、以及超快速精密星历（IGS Ultra-Rapid，标识为 IGU）。对应的精密钟差也有这三种。其中超快速精密星历又分为观测的部分和预测的部分。IGS 会综合所有分析中心的产品（比如SIO，MIT等）加权平均得到最终的产品（标识为IGS、IGR、IGU）。他们的延时、精度等指标如下表所示。在实际工作中，我们可以根据项目对时间及精度的要求，选取不同类型的文件来使用。            名称      延时      更新率      更新时间      采样率      精度                  最终精密星历 IGS      12-18天      每周      每周四      15min      ~2.5cm              快速精密星历 IGR      17-41小时      每天      17:00 UTC      15min      ~2.5cm              超快速精密星历（观测） IGU      3-9小时      6小时      03, 09, 15, 21 UTC      15min      ~3cm              超快速精密星历（预测） IGU      实时      6小时      03, 09, 15, 21 UTC      15min      ~5cm      IGS 精密星历采用sp3格式，sp3文件的存储方式为 ASCII 文本文件，内容包括表头信息以及文件体，文件体中每隔15分钟给出卫星的位置，有时还给出卫星的速度。如果需要其他时刻的卫星位置，可以由给出的卫星位置进行插值得到。关于sp3文件的详细说明可以参考官方文档。与广播星历不一样，精密星历并不是用开普勒参数给出的，而是直接给出卫星在 ITRF框架中的坐标值 ITRF（International Terrestrial Reference Frame 国际地球参考框架）框架是由 IERS（国际地球自转服务）发布的，ITRF 的构成是基于VLBI、LLR、SLR、GPS 和 DORIS 等空间大地测量技术的观测数据，由 IERS中心局分析得到的全球站坐标和速度场。自1988 年起，IERS 已经发布 ITRF88、ITRF89、ITRF90、ITRF9 1、ITRF92、ITRF93、ITRF94、ITRF96、ITRF2000、ITRF2005、ITRF2008、ITRF2014 等全球参考框架。下面是从igs20863.sp3文件中截取的开头部分：#cP2020  1  1  0  0  0.00000000      96 ORBIT IGS14 HLM  IGS## 2086 259200.00000000   900.00000000 58849 0.0000000000000+   32   G01G02G03G04G05G06G07G08G09G10G11G12G13G14G15G16G17+        G18G19G20G21G22G23G24G25G26G27G28G29G30G31G32  0  0+          0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0+          0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0+          0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0++         2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2++         2  2  2  2  2  2  2  2  3  2  2  2  2  2  2  0  0++         0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0++         0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0++         0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0%c G  cc GPS ccc cccc cccc cccc cccc ccccc ccccc ccccc ccccc%c cc cc ccc ccc cccc cccc cccc cccc ccccc ccccc ccccc ccccc%f  1.2500000  1.025000000  0.00000000000  0.000000000000000%f  0.0000000  0.000000000  0.00000000000  0.000000000000000%i    0    0    0    0      0      0      0      0         0%i    0    0    0    0      0      0      0      0         0/* FINAL ORBIT COMBINATION FROM WEIGHTED AVERAGE OF:        /* cod emr esa gfz grg jpl mit ngs sio                      /* REFERENCED TO IGS TIME (IGST) AND TO WEIGHTED MEAN POLE:/* PCV:IGS14_2086 OL/AL:FES2004  NONE     Y  ORB:CMB CLK:CMB*  2020  1  1  0  0  0.00000000PG01   9888.347661 -19617.637150 -14892.695413   -247.874423 12 10  5  71       PG02 -21823.783543  13971.156772  -4920.780210   -377.229970 10  9  7  81       PG03  -1601.529966 -16464.253025 -20857.441401    -63.370799  8  7 11 105       PG04   1221.994671 -26086.976634  -4781.101677    -27.923755 12  4  5 109       PG05 -19154.192243   5721.537965  17444.937173     -5.436142  7  8  6  88       PG06 -21150.813850   2402.751626 -15853.420427   -169.653500  9  7  8 106       PG07  -7307.639840 -13757.950583  21767.441209   -182.185020  6  6  5  99       PG08   7039.047666 -21245.446842  14152.046835    -18.646350  8  5  7  94       PG09  -6875.945629 -25134.252934   5050.629544   -121.818618  9  8  4 109       PG10  24015.414289  11544.134960   1555.732288   -193.008701  8  8  8 103       PG11   7282.297820 -25005.780611  -6416.591136   -403.117157  9  8  7  95       PG12  -3612.078652  14754.643360 -22024.819114    167.238453  6  6  5 121       PG13 -12822.251931  14077.120706  18359.989020    -22.958664  7  7  7  85       PG14  15097.782136    719.539797 -21518.284406    -41.480187  8  9  3  98       PG15  -5026.428258  22304.034935  12884.805910   -261.734981  8  6  5  83       PG16  20065.806133  -2268.606859  17288.279253   -108.806027  7  8  6  98       PG17 -13302.574437 -12501.633252 -18888.874080    190.733864  6  5  7  99       PG18  15683.730129 -20086.062189  -7815.214505 999999.999999PG19 -14744.295897  -4057.283573 -22007.637771   -218.643006  9  7  9 107       PG20  18932.638979  14547.678555  11749.766535    527.763846 11 10 11  93       PG21  10191.957706  12064.511376  22150.584734    -62.423168 10  8 11  69       PG22   7023.579706 -14225.418680 -21077.053685   -780.142685  9  7  9  70       PG23  -1206.975660 -26081.394867  -3218.011480   -145.988210 10  4  6 100       PG24 -10589.076575  20789.036009 -12534.802874     -6.933769  9  7  4 109       PG25  11115.892105  17563.783060 -16907.847503    -16.767205  8  8  6 106       PG26  24809.687134   2652.030547   9387.846884    117.742691  8 10  8 116       PG27  12654.914692 -10785.577586  20515.681941   -167.508526  8  5  8  92       PG28 -22961.626731 -13197.537237    783.057544    747.765166  6  8  6  95       PG29   4498.761624  25678.893062   4992.306129      4.083857 10 10  6  67       PG30 -17217.300944  -5541.835900  19540.416589   -118.767102  6  7  7  87       PG31  22625.699147  -4025.359523 -13738.508642    -13.516273  7  9  7  90       PG32  14835.028318  11206.018688 -18957.170663    172.050190  9 10  5 104       *  2020  1  1  0 15  0.00000000PG01  11218.886280 -20435.428221 -12620.054414   -247.885427 11 10  5  55       PG02 -21416.153632  13234.932709  -7652.201926   -377.236434  9  9  6  89       PG03    658.942604 -15624.793321 -21537.118493    -63.377346  7  7 10  93       PG04   1551.226922 -25415.284695  -7518.401629    -27.928395 11  5  6  93       PG05 -20891.993883   4906.521003  15635.291423     -5.436689  7  8  5  80       PG06 -19726.065274   1101.751537 -17715.564454   -169.663056  9  6  7 113... ... ...简单介绍一下  第一行，时间，2020年1月1日，IGS14 表示座标系   采用ITRF2014框架。  第二行，2086表示GPS周，259200表示累计秒数（3天*86400）  第三/四行，包含32颗GPS卫星的轨道位置  第23行表示从第24行开始的这一组卫星轨道位置对应的时间  第56行表示从第57行开始的这一组卫星轨道位置对应的时间，与前一数据块相差15分钟  第24行为第一个卫星的位置和钟差信息，位置单位为km，精度到mm，包含xyz三个方向。时钟单位为ms，精度为ps。最后四个数为xyz位置和钟差的标准差。  标准差的值要结合第15行的浮点基准值来计算，比如第一颗卫星x方向标准差为12，结合第15行第一个浮点基准值1.25，标准差计算为 $1.25^{12} = 14.5519 mm$。钟差计算方法类似，不过用的第二个基准值1.025。官网有抓取爬虫的代码和教程。示例代码如下：import requestsurl='https://cddis.nasa.gov/archive/gnss/products/'dest = 'C:/GPS/'### determine GPS week rangeGPSweek_start = 2086GPSweek_end = 2087for i in range(GPSweek_end-GPSweek_start):    gpsw = str(GPSweek_start+i)    for d in range(7):        filename = '/igs'+gpsw+str(d)+'.sp3.Z' # e.g., igs20860.sp3.Z        path = url + gpsw + filename        r=requests.get(path)        destf = dest + filename        with open(destf, \"wb\") as f:            for chunk in r.iter_content(chunk_size=1000):                f.write(chunk)        f.close()注意需要将 .netrc 文件放在指定位置后，将该位置加入到系统环境变量中，变量名为 HOME。然后采用 python 即可抓取数据。同样也可以采用cURL 工具，请参考这里。"
  },
  
  {
    "title": "深度学习文章阅读（Image Segmentation）",
    "url": "/posts/CV-FuzzySeg/",
    "categories": "Academic, Paper",
    "tags": "deep learning, computer vision",
    "date": "2021-09-23 09:53:49 +0800",
    





    
    "snippet": "本文介绍了模糊惩罚稀疏编码在扩散张量磁共振图像分割中的应用。Fuzziness Penalized Sparse Coding for Diffusion Tensor Magnetic Resonance Image Segmentation  1. 参数定义  2. 模糊惩罚稀疏编码  3. 优化          3.1. 参数更新                  3.1.1. s ...",
    "content": "本文介绍了模糊惩罚稀疏编码在扩散张量磁共振图像分割中的应用。Fuzziness Penalized Sparse Coding for Diffusion Tensor Magnetic Resonance Image Segmentation  1. 参数定义  2. 模糊惩罚稀疏编码  3. 优化          3.1. 参数更新                  3.1.1. s 更新          3.1.2. t 更新          3.1.3. u 更新          3.1.4. D 更新                    1. 参数定义  扩散张量 $\\boldsymbol{T}$：\\[\\boldsymbol{T}=[\\boldsymbol v_1,\\boldsymbol v_2,\\boldsymbol v_3]\\begin{bmatrix}e_1 &amp; 0 &amp;0 \\\\0 &amp; e_2 &amp;0 \\\\0 &amp; 0 &amp; e_3\\end{bmatrix}[\\boldsymbol v_1,\\boldsymbol v_2,\\boldsymbol v_3]^T\\]其中  $e_1\\geq e_2 \\geq e_3$ 是特征值；  $\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\boldsymbol{v}_3$ 是特征向量；  $\\boldsymbol{v}1=[v{11}, v_{12}, v_{13}]$ 是主要扩散方向，即最大特征值 $e_1$ 对应的特征向量；描述符：  几何描述符：\\[\\boldsymbol{x}_i^G=[e_1, e_2,e_3,FA, MD, RA, VR, RD, PA, SA, LA]\\in \\mathbb R^{11}\\]  方向描述符：\\[\\boldsymbol{x}_i^O=\\frac{1}{\\vert\\vert\\boldsymbol{v}_1\\vert\\vert} (v_{11}^2-v_{12}^2, 2v_{11}v_{12}, 2v_{11}v_{13}, 2v_{12}v_{13},\\frac{1}{\\sqrt{3}}(2v_{13}^2-v_{11}^2-v_{12}^2)) \\in \\mathbb R^{5}\\]  原始数据域下，核磁共振体素的特征向量：\\[\\boldsymbol{x}_i = [t_1, \\boldsymbol x_i^G,\\boldsymbol x_i^O]\\in \\mathbb R^{k\\times 1}, \\; k=17\\]  稀疏编码域下，体素特征向量的稀疏表示\\[\\boldsymbol s_i\\in \\mathbb R^{l\\times 1}\\]  超完备词典\\[\\boldsymbol D = [\\boldsymbol d_1, \\boldsymbol d_2, \\cdots, \\boldsymbol d_l]\\in \\mathbb R^{k\\times l}\\]2. 模糊惩罚稀疏编码输入训练样本 $\\boldsymbol X = [\\boldsymbol x_1, \\cdots, \\boldsymbol x_n]\\in \\mathbb R^{k\\times n}$，对于每个样本可以训练字典得到稀疏编码\\[F(\\boldsymbol s, \\boldsymbol D)=\\min_{\\boldsymbol s, \\boldsymbol D} \\sum_{i=1}^n(\\frac{1}{2}\\vert\\vert\\boldsymbol x_i - \\boldsymbol D \\boldsymbol s_i\\vert\\vert_2^2+\\lambda\\vert\\vert \\boldsymbol s_i\\vert\\vert_1),\\\\s.t.\\vert\\vert\\boldsymbol d_j\\vert\\vert_2^2 &lt; 1 \\; \\forall j\\in[1,\\cdots,l]\\]假设一共有 $C$ 类。专家提供的硬标签为 $\\boldsymbol l_i \\in \\mathbb R^C$（one-hot 形式）。软模糊隶属度 $\\boldsymbol u_i=[u_1,\\cdots, u_C] \\in \\mathbb R^C$（分量和为 1），表明样本 $\\boldsymbol x_i$ 与多个其他类别的关系。其中，$C$ 为类别数。模糊隶属度采用模糊k近邻算法（FKNN）计算。首先计算样本特征向量间的欧式距离矩阵，然后对该距离矩阵进行排序，选取其中 $k$ 个最近邻的训练样本。对于属于第 $m$ 类别的样本 $\\boldsymbol x_i$，其模糊隶属度计算方式为\\[\\begin{array}{l}\\hat u_{ij} = \\left\\{\\begin{aligned}\\gamma + (1-\\gamma)(n_{jm}/k) &amp; &amp; j=m \\\\(1-\\gamma)(n_{jm}/k)  &amp; &amp; j\\not=m \\\\\\end{aligned}\\right. \\end{array}\\]其中 $\\gamma= \\frac{N-C}{2^hN}$，$h,\\lambda\\in(0,1)$ 是控制模糊隶属度取值的常数，$n_{jm}$ 是属于第 $j$ 个类别的邻居样本个数。N，C是啥？？$n_{jm}$ 是属于第 $j$ 类别的邻居个数。$h \\in (0,1),\\gamma \\in (0,1)$ 是用于控制模糊隶属度的常数。为了简化计算，进一步将模糊的分进行归一化，使得 $\\sum_j \\hat{u}_{ij} = 1$。  进一步解读：对于每个样本，选取其 $k$ 个最近样本。计算该选择的样本对所有类别的模糊隶属度，该样本对应该类别的隶属度为第一个式子，该样本对于所有其它类别的隶属度为第二个式子；其中，每个隶属度右与对应类别的近邻样本个数有关。最后做一个归一化。模糊度对应原始特征域的标注数据，采用模糊惩罚稀疏编码（FPSC）来在稀疏编码空间保留上述模糊度。\\[G(\\boldsymbol{s},\\boldsymbol{u},\\boldsymbol{D})= \\min_{\\boldsymbol{s},\\boldsymbol{u},\\boldsymbol{D}} [F(\\boldsymbol{s},\\boldsymbol{D}) + {\\eta_1}\\sum\\limits_{i,j} {u}_{ij}\\vert\\vert\\boldsymbol{s}_i - {\\boldsymbol{c}_j}\\vert\\vert_2^2+\\eta_2\\sum\\limits_{i} I(i\\in\\Omega) \\vert\\vert \\boldsymbol u_i-\\hat{\\boldsymbol u}_i\\vert\\vert_2^2],\\\\s.t.\\;\\boldsymbol{u}_{i}\\boldsymbol{1} = 1\\;\\forall i\\in[1,\\cdots,n]\\]  第一项：前面定义的稀疏编码模型；  第二项：稀疏编码表征 $\\boldsymbol s_i$ 聚类到某些中心 $\\boldsymbol c_j$；  第三项：模糊得分 $\\boldsymbol u$ 被惩罚到与专家打分 $\\hat{ \\boldsymbol u}$ 一致。其中，$\\Omega$ 表示监督数据集，$I(i\\in\\Omega)$ 是一个指示函数，如果 $i\\in\\Omega$ 则取值为 1，否则为 0。  $i=1,2,\\cdots,n$ 遍历每个样本；  $j=1,2,\\cdots,C$ 遍历每个类别；3. 优化难点在于稀疏编码表征 $\\boldsymbol s_i$ 的更新规则，因为他即在稀疏编码模型中出现，又在模糊聚类部分出现。参考稀疏优化的已有研究，引入辅助变量 $\\boldsymbol t_i$ ，将优化转为如下形式\\[\\min_{\\boldsymbol{s},\\boldsymbol{u},\\boldsymbol{D}}\\;  G(\\boldsymbol{s},\\boldsymbol{u},\\boldsymbol{D}), \\; s.t. ~~\\boldsymbol{s}_i=\\boldsymbol{t}_i ~\\forall i.\\]上式是一个典型的约束优化问题，采用交替方向乘子法（ADM）可以将约束松弛到目标函数中\\[\\begin{aligned}L(\\boldsymbol{s},\\boldsymbol{t},\\boldsymbol{u},\\boldsymbol{D}) &amp;= \\sum\\limits_i {\\lambda \\vert\\vert{\\boldsymbol{t}_i}|{|_1} + \\frac{1}{2}\\vert\\vert{\\boldsymbol{x}_i} - } \\boldsymbol{D}{\\boldsymbol{s}_i}\\vert\\vert_2^2 \\\\&amp; + {\\eta _1}\\sum\\limits_{i,j} {u}_{ij}\\vert\\vert{\\boldsymbol{s}_i} - {\\boldsymbol{c}_j}\\vert\\vert_2^2 \\\\&amp; + {\\eta _2}\\sum\\limits_{i}I(i \\in \\Omega )\\vert\\vert{\\hat{\\boldsymbol{u}}_i} - {\\boldsymbol{u}_i}\\vert\\vert_2^2 \\\\&amp; + &lt; {\\theta _{i}},\\boldsymbol{u}_i\\boldsymbol{1} - 1 &gt;+&lt; {\\boldsymbol \\mu_i},{\\boldsymbol{t}_i} - {\\boldsymbol{s}_i} &gt;  \\\\&amp; + \\frac{\\rho}{2}(\\vert\\vert{\\boldsymbol{t}_i} - {\\boldsymbol{s}_i}\\vert\\vert_2^2+\\vert\\vert\\boldsymbol{u}_i\\boldsymbol{1} - 1\\vert\\vert_2^2)\\end{aligned}\\]其中，$\\boldsymbol \\mu_i\\in \\mathbb R^{l\\times 1}, \\theta_i\\in \\mathbb R^1, \\; \\forall i$ 是拉格朗日乘子，$\\rho\\in\\mathbb R^1$ 是增广拉格朗日参数。上述形式是典型的ADM形式，可以采用两步法求解，第一步参数更新，第二部双升？3.1. 参数更新3.1.1. s 更新注：后文中公式的括号内编号为 《The Matrix Cookbook》 书内对应参考公式编号。首先更新 $\\boldsymbol s_i$，剔除与 $\\boldsymbol s_i$ 无关的项，则有优化目标为\\[\\begin{aligned}\\min_{\\boldsymbol s_i} \\; &amp;  \\frac{1}{2}\\vert\\vert{\\boldsymbol{x}_i} -  \\boldsymbol{D}^{(k)}{\\boldsymbol{s}_i}\\vert\\vert_2^2\\\\&amp; + {\\eta _1}\\sum\\limits_{j} u^{(k)}_{ij}\\vert\\vert{\\boldsymbol{s}_i} - {\\boldsymbol{c}_j}\\vert\\vert_2^2 \\\\&amp; +  &lt; {\\mu_{i}},{\\boldsymbol{t}^{(k)}_i} - {\\boldsymbol{s}_i} &gt; \\\\&amp; + \\frac{\\rho}{2}\\vert\\vert{\\boldsymbol{t}^{(k)}_i} - {\\boldsymbol{s}_i}\\vert\\vert_2^2\\\\\\end{aligned}\\]其中 $(k)$ 表示当前第 $k$ 步更新时的参数，涉及的参数为待更新的 $\\boldsymbol s_i, \\boldsymbol t_i, \\boldsymbol D$。对上式求偏导，第一项求偏导为\\[\\begin{aligned}&amp;\\frac{\\partial}{\\partial \\boldsymbol s_i} \\frac{1}{2}\\vert\\vert{\\boldsymbol{x}_i} -  \\boldsymbol{D}^{(k)}{\\boldsymbol{s}_i}\\vert\\vert_2^2 \\\\=&amp;\\vert\\vert{\\boldsymbol{x}_i} -  \\boldsymbol{D}^{(k)}{\\boldsymbol{s}_i}\\vert\\vert_2 \\cdot \\frac{\\boldsymbol{x}_i -  \\boldsymbol{D}^{(k)}\\boldsymbol{s}_i}{\\vert\\vert{\\boldsymbol{x}_i} -  \\boldsymbol{D}^{(k)}{\\boldsymbol{s}_i}\\vert\\vert_2 }\\cdot \\frac{\\partial}{\\partial \\boldsymbol s_i}[{\\boldsymbol{x}_i} - \\boldsymbol{D}^{(k)}{\\boldsymbol{s}_i}] \\quad (129)\\\\=&amp;({\\boldsymbol{x}_i} - \\boldsymbol{D}^{(k)}\\boldsymbol{s}_i) \\cdot (-{\\boldsymbol D^{(k)}}^T) \\quad (69)\\\\=&amp;{\\boldsymbol D^{(k)}}^T\\boldsymbol D^{(k)}\\boldsymbol{s}_i-{\\boldsymbol D^{(k)}}^T\\boldsymbol x_i\\quad \\in \\mathbb R^{l\\times 1}\\end{aligned}\\]第二项求偏导为\\[\\begin{aligned}\\frac{\\partial}{\\partial \\boldsymbol s_i} {\\eta _1}\\sum\\limits_{j} u^{(k)}_{ij}\\vert\\vert{\\boldsymbol{s}_i} - {\\boldsymbol{c}_j}\\vert\\vert_2^2 =&amp;2\\eta_1\\sum\\limits_{j} u^{(k)}_{ij}(\\boldsymbol{s}_i - \\boldsymbol{c}_j)\\quad (129)\\\\=&amp;2\\eta_1 \\bar u \\boldsymbol s_i - 2\\eta_1\\bar{\\boldsymbol c}\\\\where \\quad &amp;\\bar u=\\sum\\limits_j u^{(k)}_{ij},\\quad \\bar{ \\boldsymbol{c}}= \\sum \\limits_{j} u^{(k)}_{ij} \\boldsymbol{c}_j\\end{aligned}\\]第三项为矩阵内积，根据内积的定义有\\[&lt; \\boldsymbol \\mu_i,\\boldsymbol{t}^{(k)}_i - \\boldsymbol{s}_i &gt; = tr(\\boldsymbol \\mu_i^T\\cdot(\\boldsymbol{t}^{(k)}_i - \\boldsymbol{s}_i))\\]则求偏导为\\[\\begin{aligned}\\frac{\\partial}{\\partial \\boldsymbol s_i}&lt; \\boldsymbol \\mu_i,\\boldsymbol{t}^{(k)}_i - \\boldsymbol{s}_i &gt;=&amp; \\frac{\\partial}{\\partial \\boldsymbol s_i}  tr(\\boldsymbol \\mu_i^T\\cdot(\\boldsymbol{t}^{(k)}_i - \\boldsymbol{s}_i))\\\\=&amp;-\\boldsymbol \\mu_i\\quad (101)\\end{aligned}\\]或者根据向量内积定义（$\\boldsymbol \\mu_i \\in\\mathbb R^{l\\times 1}$ 和 $\\boldsymbol t_i-\\boldsymbol s_i \\in\\mathbb R^{l\\times 1}$ 都是向量），去掉 $tr$ 符号，则求偏导为\\[\\begin{aligned}\\frac{\\partial}{\\partial \\boldsymbol s_i}&lt; \\boldsymbol \\mu_i,\\boldsymbol{t}^{(k)}_i - \\boldsymbol{s}_i &gt;=&amp; \\frac{\\partial}{\\partial \\boldsymbol s_i}  (\\boldsymbol \\mu_i^T\\cdot(\\boldsymbol{t}^{(k)}_i - \\boldsymbol{s}_i))\\\\=&amp;-\\boldsymbol \\mu_i \\quad (70)\\end{aligned}\\]第四项求偏导为\\[\\begin{aligned}\\frac{\\partial}{\\partial \\boldsymbol s_i} \\frac{\\rho}{2}\\vert\\vert \\boldsymbol{t}^{(k)}_i - {\\boldsymbol{s}_i}\\vert\\vert_2^2=&amp;\\rho\\vert\\vert \\boldsymbol{t}^{(k)}_i - {\\boldsymbol{s}_i}\\vert\\vert_2 \\frac{\\boldsymbol{t}^{(k)}_i - \\boldsymbol{s}_i}{\\vert\\vert \\boldsymbol{t}^{(k)}_i - {\\boldsymbol{s}_i}\\vert\\vert_2}\\cdot (-\\boldsymbol I)\\quad (129)\\\\=&amp;\\rho(\\boldsymbol{s}_i - \\boldsymbol{t}^{(k)}_i)\\end{aligned}\\]则求偏导后完整的表达式为\\[\\begin{aligned}&amp;\\frac{\\partial}{\\partial \\boldsymbol s_i} L(\\boldsymbol{s}_i,\\boldsymbol{t},\\boldsymbol{u},\\boldsymbol{D})\\\\= &amp;{\\boldsymbol D^{(k)}}^T\\boldsymbol D^{(k)}\\boldsymbol{s}_i-{\\boldsymbol D^{(k)}}^T\\boldsymbol x_i + 2\\eta_1 \\bar u \\boldsymbol s_i - 2\\eta_1\\bar{\\boldsymbol c} - \\boldsymbol \\mu_i + \\rho(\\boldsymbol{s}_i - \\boldsymbol{t}^{(k)}_i)\\\\=&amp; ({\\boldsymbol D^{(k)}}^T\\boldsymbol D^{(k)} + 2\\eta_1 \\bar u + \\rho)\\boldsymbol s_i - ({\\boldsymbol D^{(k)}}^T\\boldsymbol x_i+2\\eta_1\\bar{\\boldsymbol c}+\\rho\\boldsymbol{t}^{(k)}_i+\\boldsymbol \\mu_i)\\end{aligned}\\]令偏导数等于 0，则有\\[\\boldsymbol s_i = ({\\boldsymbol D^{(k)}}^T\\boldsymbol D^{(k)} + 2\\eta_1 \\bar u + \\rho)^{-1}({\\boldsymbol D^{(k)}}^T\\boldsymbol x_i+2\\eta_1\\bar{\\boldsymbol c}+\\rho\\boldsymbol{t}^{(k)}_i+\\boldsymbol \\mu_i)\\]3.1.2. t 更新剔除与 $\\boldsymbol t_i$ 无关的项，则有优化目标为\\[\\begin{aligned}\\min_{\\boldsymbol s_i} \\; &amp;   \\sum\\limits_i \\lambda \\vert\\vert{\\boldsymbol{t}_i}|{|_1}\\\\&amp; + &lt; {\\boldsymbol \\mu_i},{\\boldsymbol{t}_i} - {\\boldsymbol{s}_i} &gt;  \\\\&amp; + \\frac{\\rho}{2}\\vert\\vert{\\boldsymbol{t}_i} - {\\boldsymbol{s}_i}\\vert\\vert_2^2\\end{aligned}\\]注意到，$\\boldsymbol \\mu_i \\in\\mathbb R^{l\\times 1}$ 和 $\\boldsymbol t_i-\\boldsymbol s_i \\in\\mathbb R^{l\\times 1}$ 都是向量，则内积项为\\[&lt; {\\boldsymbol \\mu_i},{\\boldsymbol{t}_i} - {\\boldsymbol{s}_i} &gt; = {\\boldsymbol \\mu_i}^T({\\boldsymbol{t}_i} - {\\boldsymbol{s}_i})\\]二范数项为\\[\\frac{\\rho}{2}\\vert\\vert\\boldsymbol{t}_i - \\boldsymbol{s}_i\\vert\\vert_2^2 = \\frac{\\rho}{2}(\\boldsymbol t_i - \\boldsymbol s_i)^T(\\boldsymbol t_i - \\boldsymbol s_i)\\]对于 $\\boldsymbol t_i$ 而言，损失函数中的 $\\boldsymbol \\mu_i$ 没有影响，因此不妨将损失函数后两项的和配方成如下形式\\[\\begin{aligned}&amp;&lt; {\\boldsymbol \\mu_i},{\\boldsymbol{t}_i} - {\\boldsymbol{s}_i} &gt; + \\frac{\\rho}{2}\\vert\\vert\\boldsymbol{t}_i - \\boldsymbol{s}_i\\vert\\vert_2^2 \\\\=&amp; {\\boldsymbol \\mu_i}^T({\\boldsymbol{t}_i} - {\\boldsymbol{s}_i}) + \\frac{\\rho}{2}(\\boldsymbol t_i - \\boldsymbol s_i)^T(\\boldsymbol t_i - \\boldsymbol s_i)\\\\=&amp; \\frac{1}{\\rho^2}{\\boldsymbol \\mu_i}^T{\\boldsymbol \\mu_i} + \\frac{\\rho}{2}\\frac{2}{\\rho}{\\boldsymbol \\mu_i}^T({\\boldsymbol{t}_i} - {\\boldsymbol{s}_i}) + \\frac{\\rho}{2}(\\boldsymbol t_i - \\boldsymbol s_i)^T(\\boldsymbol t_i - \\boldsymbol s_i)\\\\=&amp; \\frac{\\rho}{2}[(\\frac{1}{\\rho}\\boldsymbol \\mu_i)^T(\\frac{1}{\\rho}\\boldsymbol \\mu_i) + \\frac{1}{\\rho}\\boldsymbol \\mu_i^T(\\boldsymbol t_i - \\boldsymbol s_i) + \\frac{1}{\\rho}\\boldsymbol \\mu_i(\\boldsymbol t_i - \\boldsymbol s_i)^T + (\\boldsymbol t_i - \\boldsymbol s_i)^T(\\boldsymbol t_i - \\boldsymbol s_i)]\\\\=&amp; \\frac{\\rho}{2}( \\frac{1}{\\rho}\\boldsymbol \\mu_i + (\\boldsymbol t_i - \\boldsymbol s_i) )^T( \\frac{1}{\\rho}\\boldsymbol \\mu_i + (\\boldsymbol t_i - \\boldsymbol s_i) )\\\\=&amp; \\frac{\\rho}{2}\\vert\\vert \\frac{1}{\\rho}\\boldsymbol \\mu_i + (\\boldsymbol t_i - \\boldsymbol s_i) \\vert\\vert_2^2\\end{aligned}\\]则原始损失函数变为\\[\\min_{\\boldsymbol t_i} \\;    \\sum\\limits_i \\lambda \\vert\\vert{\\boldsymbol{t}_i}|{|_1} +\\frac{\\rho}{2}\\vert\\vert \\frac{1}{\\rho}\\boldsymbol \\mu_i + (\\boldsymbol t_i - \\boldsymbol s_i) \\vert\\vert_2^2\\]上式是一个标准的 1 范数带二次项的形式，采用迭代收缩算法（具体解法参考下述链接）  L1-L2范数最小化问题-迭代收缩算法. https://www.cnblogs.com/yuningqiu/p/9936184.html其标准闭环形式的更新公式为\\[\\boldsymbol t_i ^{(k+1)}= h_{\\lambda\\rho^{-1}}(\\boldsymbol s_i^{(k)}-\\rho^{-1}\\boldsymbol \\mu^{(k)})\\]其中，$h_{\\lambda\\rho^{-1}}$ 为压缩算子。3.1.3. u 更新提出与 $\\boldsymbol u_i$ 无关项，则有优化目标为\\[\\begin{aligned}\\min_{\\boldsymbol u_i} L(\\boldsymbol{u}) &amp;=  {\\eta _1}\\sum\\limits_{i,j} {u}_{ij}\\vert\\vert{\\boldsymbol{s}_i} - {\\boldsymbol{c}_j}\\vert\\vert_2^2 \\\\&amp; + {\\eta _2}\\sum\\limits_{i}I(i \\in \\Omega )\\vert\\vert{\\hat{\\boldsymbol{u}}_i} - {\\boldsymbol{u}_i}\\vert\\vert_2^2 \\\\&amp; + &lt; {\\theta _{i}},\\boldsymbol{u}_i\\boldsymbol{1} - 1 &gt; \\\\&amp; + \\frac{\\rho}{2}\\vert\\vert\\boldsymbol{u}_i\\boldsymbol{1} - 1\\vert\\vert_2^2\\end{aligned}\\]对于第一项\\[\\begin{aligned}{\\eta _1}\\sum\\limits_{i,j} {u}_{ij}\\vert\\vert{\\boldsymbol{s}_i} - {\\boldsymbol{c}_j}\\vert\\vert_2^2 &amp;= \\sum\\limits_{i}\\eta _1\\sum\\limits_{j} {u}_{ij}\\vert\\vert{\\boldsymbol{s}_i^{(k)}} - {\\boldsymbol{c}_j}\\vert\\vert_2^2\\end{aligned}\\]令 $\\boldsymbol T^{(k)} \\in \\mathbb R^C$，其每个分量为\\[\\boldsymbol T_j^{(k)} = \\vert\\vert{\\boldsymbol{s}_i} - {\\boldsymbol{c}_j}\\vert\\vert_2^2, \\quad j=1,2,\\cdots, C\\]可将第一个分量写成矩阵形式\\[\\sum\\limits_{j} {u}_{ij}\\vert\\vert{\\boldsymbol{s}_i^{(k)}} - {\\boldsymbol{c}_j}\\vert\\vert_2^2 = tr(\\boldsymbol u^T_i \\cdot \\boldsymbol T^{(k)})\\]整个优化目标改写为\\[\\begin{aligned}\\min_{\\boldsymbol u_i} L(\\boldsymbol{u}) = &amp; \\sum\\limits_{i}\\eta _1\\cdot  tr(\\boldsymbol u^T_i \\cdot \\boldsymbol T^{(k)})\\\\&amp; + {\\eta _2}\\sum\\limits_{i}I(i \\in \\Omega )\\vert\\vert{\\hat{\\boldsymbol{u}}_i} - {\\boldsymbol{u}_i}\\vert\\vert_2^2 \\\\&amp; + &lt; {\\theta _{i}},\\boldsymbol{u}_i\\boldsymbol{1} - 1 &gt; \\\\&amp; + \\frac{\\rho}{2}\\vert\\vert\\boldsymbol{u}_i\\boldsymbol{1} - 1\\vert\\vert_2^2\\\\= &amp; \\eta _1\\cdot  tr(\\boldsymbol u^T_i \\cdot \\boldsymbol T^{(k)})\\\\&amp; + {\\eta _2}I(i \\in \\Omega )\\vert\\vert{\\hat{\\boldsymbol{u}}_i} - {\\boldsymbol{u}_i}\\vert\\vert_2^2 \\\\&amp; +  {\\theta _{i}}(\\boldsymbol{u}_i\\boldsymbol{1} - 1 ) \\\\&amp; + \\frac{\\rho}{2}\\vert\\vert\\boldsymbol{u}_i\\boldsymbol{1} - 1\\vert\\vert_2^2\\end{aligned}\\]其对 $\\boldsymbol u_i$ 的偏导数为\\[\\begin{aligned}&amp;\\eta_1\\cdot \\boldsymbol T^{(k)}\\quad (103)\\\\+&amp;2{\\eta _2}I(i \\in \\Omega )(\\boldsymbol{u}_i - \\hat{\\boldsymbol{u}}_i)\\\\+&amp; {\\theta _{i}}\\boldsymbol{1}^T\\quad (70)\\\\+&amp; \\rho (\\boldsymbol{u}_i\\boldsymbol{1} - 1) \\boldsymbol 1^T\\quad (70)\\end{aligned}\\]令偏导等于 0，得到参数 $\\boldsymbol u_i$ 的更新式为\\[\\boldsymbol u_i^{(k+1)} = (2{\\eta _2}I(i \\in \\Omega )+\\rho\\boldsymbol{1}\\boldsymbol{1}^T)^{-1}(2{\\eta _2}I\\hat{\\boldsymbol{u}}_i-\\eta_1\\cdot \\boldsymbol T^{(k)}+(\\rho_{i}^{(k)}-\\theta_{i}^{(k)})\\boldsymbol 1^T)\\]3.1.4. D 更新优化目标为\\[\\min \\sum\\limits_i  \\vert\\vert \\boldsymbol{x}_i - \\boldsymbol{D}{\\boldsymbol{s}_i^{(k)}}\\vert\\vert_2^2\\]这是个典型的最小二乘回归问题，对其二范数展开为\\[\\sum\\limits_i(\\boldsymbol{x}_i - \\boldsymbol{D}\\boldsymbol{s}_i^{(k)})^T(\\boldsymbol{x}_i - \\boldsymbol{D}\\boldsymbol{s}_i^{(k)}) =\\\\\\sum\\limits_i[\\boldsymbol{x}_i^T\\boldsymbol{x}_i - \\boldsymbol x_i^T\\boldsymbol{D}\\boldsymbol{s}_i^{(k)} - \\boldsymbol x_i(\\boldsymbol{D}\\boldsymbol{s}_i^{(k)})^T + (\\boldsymbol{D}\\boldsymbol{s}_i^{(k)})^T\\boldsymbol{D}\\boldsymbol{s}_i^{(k)}]\\]其对 $\\boldsymbol D$ 的偏导为（参考Matrix Cookbook 式（70）、式（71）和式（77）)\\[\\sum\\limits_i[-\\boldsymbol x_i(\\boldsymbol{s}_i^{(k)})^T-\\boldsymbol{s}_i(\\boldsymbol x_i^{(k)})^T+(\\boldsymbol{s}_i^{(k)})^T\\boldsymbol{D}\\boldsymbol{s}_i^{(k)}+\\boldsymbol{D}\\boldsymbol{s}_i^{(k)}(\\boldsymbol{s}_i^{(k)})^T]\\\\=\\sum\\limits_i[-2\\boldsymbol x_i(\\boldsymbol{s}_i^{(k)})^T+2\\boldsymbol{D}\\boldsymbol{s}_i^{(k)}(\\boldsymbol{s}_i^{(k)})^T]\\]  对于向量乘法可交换顺序，即$a^T\\cdot b = a\\cdot b^T$令偏导等于 0，则更新式为\\[\\boldsymbol D^{(k+1)} = (\\sum\\limits_i\\boldsymbol{s}_i^{(k)}(\\boldsymbol{s}_i^{(k)})^T)^{-1}(\\sum\\limits_i\\boldsymbol{x}_i^{(k)}(\\boldsymbol{s}_i^{(k)})^T)\\]"
  },
  
  {
    "title": "计算机视觉（YOLO V5）",
    "url": "/posts/CV-yolov5/",
    "categories": "Academic, Knowledge",
    "tags": "deep learning, computer vision",
    "date": "2021-06-08 09:08:49 +0800",
    





    
    "snippet": "本文介绍了计算机视觉中单阶段目标检测问题的一个最新实现，即 YOLO V5。  1. 网络结构          1.1. parameters      1.2. backnone                  1.2.1. Focus          1.2.2. Conv          1.2.3. BottleneckCSP                    1.3. ...",
    "content": "本文介绍了计算机视觉中单阶段目标检测问题的一个最新实现，即 YOLO V5。  1. 网络结构          1.1. parameters      1.2. backnone                  1.2.1. Focus          1.2.2. Conv          1.2.3. BottleneckCSP                    1.3. head        2. 训练          2.1. 准备标签      2.2. 数据存放位置      2.3. 准备模型      2.4. 进行训练        3. 测试  4. 检测          4.1. 快速检测      4.2. 快速推理      4.3. 自定义检测      4.4. 检测参数        5. 其它          5.1. Citation      1. 网络结构  https://www.cnblogs.com/xiaoheizi-12345/p/14287592.html其中橙色的数字表示层号，0-9层构成backbone，10-23层构成head，17、20、23 层的输出是Detect()函数的输入。  C3后的参数表示(c_in, c_out)*该模块堆叠的次数  Conv和Focus参数(c_in, c_out, kernel_size, stride)  SPP后的参数(c_in, c_out, [kernel_size1,kernel_size2,kernel_size3])  Concat是axes=1时的合并（增加通道）  upsample的scale_factor为2，输出图像为输入的2倍。  https://www.bilibili.com/video/BV18K411n7rcyolov5 是使用 xxxx.yaml 配置文件，通过./models/yolo.py解析文件加了一个输入构成的网络模块。以 yolov5s.yaml 为例：# parametersnc: 80  # number of classesdepth_multiple: 0.33  # model depth multiplewidth_multiple: 0.50  # layer channel multiple# anchorsanchors:  - [10,13, 16,30, 33,23]  # P3/8  - [30,61, 62,45, 59,119]  # P4/16  - [116,90, 156,198, 373,326]  # P5/32# YOLOv5 backbonebackbone:  # [from, number, module, args]  [[-1, 1, Focus, [64, 3]],  # 0-P1/2   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4   [-1, 3, C3, [128]],   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8   [-1, 9, C3, [256]],   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16   [-1, 9, C3, [512]],   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32   [-1, 1, SPP, [1024, [5, 9, 13]]],   [-1, 3, C3, [1024, False]],  # 9  ]# YOLOv5 headhead:  [[-1, 1, Conv, [512, 1, 1]],   [-1, 1, nn.Upsample, [None, 2, 'nearest']],   [[-1, 6], 1, Concat, [1]],  # cat backbone P4   [-1, 3, C3, [512, False]],  # 13   [-1, 1, Conv, [256, 1, 1]],   [-1, 1, nn.Upsample, [None, 2, 'nearest']],   [[-1, 4], 1, Concat, [1]],  # cat backbone P3   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)   [-1, 1, Conv, [256, 3, 2]],   [[-1, 14], 1, Concat, [1]],  # cat head P4   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)   [-1, 1, Conv, [512, 3, 2]],   [[-1, 10], 1, Concat, [1]],  # cat head P5   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)  ]  from 列参数：-1 代表是从上一层获得的输入，-2 表示从上两层获得的输入。  number 列参数：1 表示只有一个，3 表示有三个相同的模块。  module 表示模块：包括 SPP、Conv、Bottleneck、BottleneckCSP，代码可以在./models/common.py中获取到。  Focus 的 [64, 3] 表示输入图片通道数为3（RGB），卷积核个数为 64即输出通道数为64；  [128, 3, 2] 解析得到 [64, 128, 3, 2] ，64 是输入，128 表示输出 128 个卷积核个数，也是是输出通道数，3 表示 3×3 的卷积核，2 表示步长为 2。yaml 中输入都省去了，因为输入都是上层的输出。为了修改过于麻烦，这里输入的获取是从./models/yolo.py的def parse_model(md, ch)函数中解析得到的。1.1. parameters  https://www.cnblogs.com/E-Dreamer-Blogs/p/13297580.html      nc：类别数。        depth_multiple：控制模型的深度。    在 backbone 中的 number ≠ 1 的情况下生效，也即对数量大于 1 的层生效。          yolov5s中：depth_multiple = 0.33，即3个模块缩减为1个，9个模块缩减为3个；      yolov5m中: depth_multiple = 0.66，即3个模块缩减为2个，9个模块缩减为6个；      yolov5l中: depth_multiple = 1      yolov5x中: depth_multiple = 1.33，即3个模块扩充为4个，9个模块缩扩充12个；        假设 yolov5l 中有三个 BottleneckCSP，那 yolov5s 中就只有一个 BottleneckCSP，那        width_multiple：控制卷积核的个数。    用于设置 arguments，例如 yolov5s 设置为 0.5，则 Focus 就变成 [32, 3]，Conv 就变成 [64, 3, 2]。以此类推，卷积核的个数都变成了设置的一半。  yolov5提供了 s、m、l、x 四种尺寸的网络，所有的.yaml文件都一样，只需要修改这两个参数就可以调整模型的网络结构。1.2. backnonehttps://blog.csdn.net/jiafeier_555/article/details/109052569骨干网络特征图从大到小，深度加深。1.2.1. Focus一种下采样方法，从高分辨率图像中，周期性的抽出像素点重构到低分辨率图像中，即将图像相邻的四个位置进行堆叠，聚焦 wh 维度信息到 c 通道空间，提高每个点感受野，并减少原始信息的丢失。一种 space to depth 方法。class Focus(nn.Module):    # Focus wh information into c-space    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups        super(Focus, self).__init__()        self.conv = Conv(c1 * 4, c2, k, s, p, g, act)    def forward(self, x):  # x(b,c,w,h) -&gt; y(b,4c,w/2,h/2)        return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))具体操作是在一张图片中每隔一个像素拿到一个值，类似于邻近下采样，这样就拿到了四张图片，四张图片互补，长的差不多，但是没有信息丢失，这样一来，将 W、H 信息就集中到了 C 维度，输入通道扩充了4倍，即拼接起来的图片相对于原先的RGB三通道模式变成了12个通道，最后将得到的新图片再经过卷积操作，最终得到了没有信息丢失情况下的二倍下采样特征图。以yolov5s为例，原始的 640 × 640 × 3 的图像输入Focus结构，采用切片操作，先变成 320 × 320 × 12 的特征图，再经过一次卷积操作，最终变成 320 × 320 × 32 的特征图。切片操作如下：该模块的设计主要是减少计算量加快速度。作者原话：Focus() module is designed for FLOPS reduction and speed increase, not mAP increase.【然而】……计算量（FLOPs）：即浮点运算数，可以用来衡量算法/模型的复杂度，这关系到算法速度，大模型的单位通常为G，小模型单位通常为M；通常只考虑乘加操作的数量，而且只考虑Conv和FC等参数层的计算量，忽略BN和PReLU等，一般情况下，Conv和FC层也会忽略仅纯加操作的计算量，如bias偏置加和shoutcut残差加等，目前技术有BN和CNN可以不加bias。计算公式（卷积层）：FLOPs =（Cin x Kh x Kw - 1）× H × W × Cout不考虑bias时有-1，有bias时没有-1。输入 640 × 640 × 3 的图片，普通下采样：3 × 3 x 32s2p1 卷积，得到 320 × 320 × 32 的特征图，计算量为：FLOPs（conv） = 3 × 3 × 3 × 320 × 320 × 32 = 88473600Focus：切片操作，先变成 320 × 320 × 12 的特征图，再经过 3 × 3 x 32s1p1 卷积操作，得到 320 × 320 × 32 的特征图，计算量为：FLOPs（Focus） = 3 × 3 × 12 × 32 × 320 × 320 = 353894400可以看出，Focus的计算量是普通卷积的4倍，但是下采样时没有信息的丢失。1.2.2. Convclass Conv(nn.Module):    # Standard convolution    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups        super(Conv, self).__init__()        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)        self.bn = nn.BatchNorm2d(c2)        self.act = nn.Hardswish() if act else nn.Identity()    def forward(self, x):        return self.act(self.bn(self.conv(x)))    def fuseforward(self, x):        return self.act(self.conv(x))    def autopad(k, p=None):  # kernel, padding    # Pad to 'same'    if p is None:        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad    return pCONV层使用的激活函数是 Hardswish;atuopad 是自动填 padding 的值，在k=1的时候，padding=0，在k=3的时候padding=1，保证了卷积模式为 same。1.2.3. BottleneckCSP首先介绍 bottleneck。bottleneck 主要目的是为了减少参数的数量，从而减少计算量，且在降维之后可以更加有效、直观地进行数据的训练和特征提取。class Bottleneck(nn.Module):    # Standard bottleneck    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion        super(Bottleneck, self).__init__()        c_ = int(c2 * e)  # hidden channels        self.cv1 = Conv(c1, c_, 1, 1)        self.cv2 = Conv(c_, c2, 3, 1, g=g)        self.add = shortcut and c1 == c2    def forward(self, x):        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))参数说明：  c1：bottleneck 结构的输入通道维度；  c2：bottleneck 结构的输出通道维度；  shortcut：是否给bottleneck 结构添加shortcut连接，添加后即为ResNet模块；  g：groups，通道分组的参数，输入通道数、输出通道数必须同时满足被groups整除；  e：expansion: bottleneck 结构中的瓶颈部分的通道膨胀率，使用0.5即为变为输入的1/2；瓶颈层的瓶颈主要体现在通道数上面。一般 1 x 1 卷积具有很强的灵活性，这里用于降低通道数，如膨胀率为  0.5，若输入通道为 640，那么经过1 x 1 的卷积层之后变为 320；经过 3x3 之后变为输出的通道数，这样参数量会大量减少。然后介绍 CSP Bottleneck。  CSP Bottleneck: https://github.com/WongKinYiu/CrossStagePartialNetworksclass BottleneckCSP(nn.Module):    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion        super(BottleneckCSP, self).__init__()        c_ = int(c2 * e)  # hidden channels        self.cv1 = Conv(c1, c_, 1, 1)        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)        self.cv4 = Conv(2 * c_, c2, 1, 1)        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)        self.act = nn.LeakyReLU(0.1, inplace=True)        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])    def forward(self, x):        y1 = self.cv3(self.m(self.cv1(x)))        y2 = self.cv2(x)        return self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=1))))参数说明：  c1：BottleneckCSP 结构的输入通道维度；  c2：BottleneckCSP 结构的输出通道维度；  n：bottleneck 结构 结构的个数；  shortcut：是否给bottleneck 结构添加shortcut连接，添加后即为ResNet模块；  g：groups，通道分组的参数，输入通道数、输出通道数必须同时满足被groups整除；  e：expansion: bottleneck 结构中的瓶颈部分的通道膨胀率，使用0.5即为变为输入的12；  torch.cat((y1, y2), dim=1)：这里是指定在第1个维度上进行合并，即在channel维度上合并;  c_：BottleneckCSP 结构的中间层的通道数，由膨胀率e决定。Cross Stage Partial Network (CSPNet) 就是从网络结构设计的角度来解决以往工作在推理过程中需要很大计算量的问题。CSP bottleneck 结构在 Bottleneck 部分存在一个可修改的参数 n，标识使用的Bottleneck结构个数。这一条也是我们的主分支，是对残差进行学习的主要结构，右侧分支nn.Conv2d是shortcut分支。倘若该层后面有BN层的话，一般选择bias=False（因为BN包含偏置），而后面没有的时候bias=True。上面的 Conv 层和 CSPNet 也是这个规律1.3. headYOLO V5 使用的 head 是 PANet。  PANet: https://arxiv.org/pdf/1803.01534.pdf2. 训练2.1. 准备标签yolo格式的标签为txt格式的文件，文件名跟对应的图片名一样，除了后缀改为了.txt。 具体格式如下：  每个目标一行，整个图片没有目标的话不需要有txt文件  每行的格式为class_num x_center y_center width height  其中class_num取值为0至total_class - 1，框的四个值x_center y_center width height是相对于图片分辨率大小正则化的0-1之间的数，左上角为(0,0)，右下角为(1,1)  2.2. 数据存放位置yolov5的代码会根据图片找标签，具体形式的把图片路径/images/*.jpg替换为/labels/*.txt，所以要新建两个文件夹，一个名为images存放图片，一个名为labels存放标签txt文件，如分训练集、验证集和测试集的话，还要再新建各自的文件夹，如：coco|--images   |--train2017   |--val2017|--labels   |--train2017   |--val20172.3. 准备模型自定义训练需要修改.yaml文件，一个是模型文件(可选)，一个是数据文件。  模型文件(可选):可以根据你选择训练的模型，直接修改./models里的yolov5s.yaml / yolov5m.yaml / yolov5l.yaml / yolov5x.yaml文件，只需要将nc: 80中的80修改为你数据集的类别数。其他为模型结构不需要改。 注意 :当需要随机初始化时才会使用本文件，官方推荐使用预训练权重初始化。  数据文件:根据./data文件夹里的coco数据文件，制作自己的数据文件，在数据文件中定义训练集、验证集、测试集路径；定义总类别数；定义类别名称# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]train: /coco128/images/train2017/val: /coco128/images/val2017/test:/coco128/images/test2017/# number of classesnc: 80# class namesnames: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',         'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',         'teddy bear', 'hair drier', 'toothbrush']2.4. 进行训练训练直接运行train.py即可，后面根据需要加上指令参数，–weights指定权重，–data指定数据文件，–batch-size指定batch大小，–epochs指定epoch。一个简单的训练语句：# 使用yolov5s模型训练coco128数据集5个epochs，batch size设为16python train.py --batch 16 --epochs 5 --data ./data/coco128.yaml --weights ./weights/yolov5s.pt训练指令说明:有参：  --weights (⭐)指定权重，如果不加此参数会默认使用COCO预训的yolov5s.pt，--weights ''则会随机初始化权重  --cfg 指定模型文件  --data (⭐)指定数据文件  --hyp指定超参数文件  --epochs (⭐)指定epoch数，默认300  --batch-size (⭐)指定batch大小，默认16，官方推荐越大越好，用你GPU能承受最大的batch size，可简写为–batch  --img-size 指定训练图片大小，默认640，可简写为–img  --name 指定结果文件名，默认result.txt  --device 指定训练设备，如–device 0,1,2,3  --local_rank 分布式训练参数，不要自己修改！  --log-imgs W&amp;B的图片数量，默认16，最大100  --workers 指定dataloader的workers数量，默认8  --project 训练结果存放目录，默认./runs/train/      --name 训练结果存放名，默认exp无参：    --rect矩形训练  --resume 继续训练，默认从最后一次训练继续  --nosave 训练中途不存储模型，只存最后一个checkpoint  --notest 训练中途不在验证集上测试，训练完毕再测试  --noautoanchor 关闭自动锚点检测  --evolve超参数演变  --bucket使用gsutil bucket  --cache-images 使用缓存图片训练  --image-weights 训练中对图片加权重  --multi-scale 训练图片大小+/-50%变换  --single-cls 单类训练  --adam 使用torch.optim.Adam()优化器  --sync-bn 使用SyncBatchNorm，只在分布式训练可用  --log-artifacts 输出artifacts,即模型效果  --exist-ok 如训练结果存放路径重名，不覆盖已存在的文件夹  --quad 使用四分dataloader3. 测试首先明确，推理是直接检测图片，而测试是需要图片有相应的真实标签的，相当于检测图片后再把推理标签和真实标签做mAP计算。使用./weights/yolov5x.pt权重检测./data/coco.yaml里定义的测试集，图片分辨率设为672。python test.py --weights ./weights/yolov5x.pt --data ./data/coco.yaml --img 672有参：  --weights(⭐) 测试所用权重，默认yolov5sCOCO预训练权重模型  --data(⭐) 测试所用的.yaml文件，默认使用./data/coco128.yaml  --batch-size 测试用的batch大小，默认32，这个大小对结果无影响  --img-size 测试集分辨率大小，默认640，测试建议使用更高分辨率  --conf-thres目标置信度阈值，默认0.001  --iou-thresNMS的IOU阈值，默认0.65  --task 指定任务模式，train, val, 或者test,测试的话用–task test  --device 指定设备，如–device 0 –device 0,1,2,3 –device cpu  --project 指定结果存放路径，默认./runs/test/  --name 指定结果存放名,默认exp无参：  --single-cls 视为只有一类  --augment 增强识别  --verbose 输出各个类别的mAP  --save-txt 输出标签结果(yolo格式)  --save-hybrid 输出标签+预测混合结果到txt  --save-conf 保存置信度至输出文件中  --save-json 保存结果为json  --exist-ok 若重名不覆盖4. 检测4.1. 快速检测直接执行detect.py，指定一下要推理的目录即可，如果没有指定权重，会自动下载默认COCO预训练权重模型。推理结果默认会保存到./runs/detect中。注意：每次推理会清空output文件夹，注意留存推理结果。4.2. 快速推理采用 --source 指定检测源，以下任意一种类型都支持。python detect.py --source 0  # 本机默认摄像头python detect.py --source file.jpg  # 图片 python detect.py --source file.mp4  # 视频python detect.py --source path/  # 文件夹下所有媒体python detect.py --source path/*.jpg  # 文件夹下某类型媒体 4.3. 自定义检测使用权重./weights/yolov5s.pt去推理./data/images文件夹下的所有媒体，并且推理置信度阈值设为0.5:python detect.py --source ./data/images/ --weights ./weights/yolov5s.pt --conf 0.54.4. 检测参数自己根据需要加各种指令。有参：  --source(⭐) 指定检测来源  --weights 指定权重，不指定的话会使用yolov5s.pt预训练权重  --img-size 指定推理图片分辨率，默认640，也可使用–img  --conf-thres 指定置信度阈值，默认0.4，也可使用–conf  --iou-thres 指定NMS(非极大值抑制)的IOU阈值，默认0.5  --device 指定设备，如--device 0 --device 0,1,2,3 --device cpu  --classes 只检测特定的类，如--classes 0 2 4 6 8  --project 指定结果存放路径，默认./runs/detect/  --name 指定结果存放名,默认exp无参：  --view-img 图片形式显示结果  --save-txt 输出标签结果(yolo格式)  --save-conf 在输出标签结果txt中同样写入每个目标的置信度  --agnostic-nms 使用agnostic NMS(前背景)  --augment 增强识别，速度会慢不少。详情  --update 更新所有模型  --exist-ok 若重名不覆盖5. 其它BFLOPS 的概念：https://blog.csdn.net/weixin_38145317/article/details/1062814625.1. Citation"
  },
  
  {
    "title": "计算机视觉（One-Stage 目标检测）",
    "url": "/posts/CV-object-detection-1stage/",
    "categories": "Academic, Knowledge",
    "tags": "deep learning, computer vision",
    "date": "2021-06-08 09:08:49 +0800",
    





    
    "snippet": "本文介绍了计算机视觉中单阶段目标检测问题的解决方法，即 Yolo 系列。  1. 前言  2. YOLO V1          2.1. 网络结构      2.2. 输入      2.3. 输出      2.4. 构造训练样本      2.5. 损失函数      2.6. 训练      2.7. 测试预测      2.8. 结论        3. YOLO V2      ...",
    "content": "本文介绍了计算机视觉中单阶段目标检测问题的解决方法，即 Yolo 系列。  1. 前言  2. YOLO V1          2.1. 网络结构      2.2. 输入      2.3. 输出      2.4. 构造训练样本      2.5. 损失函数      2.6. 训练      2.7. 测试预测      2.8. 结论        3. YOLO V2          3.1. 网络结构      3.2. 批归一化      3.3. 高分辨率分类器      3.4. 先验框（anchor）      3.5. 约束预测框位置      3.6. pass through      3.7. 训练      3.8. 测试预测        4. YOLO V3          4.1. 网络结构      4.2. 多尺度特征      4.3. 损失函数        5. 参考文献1. 前言Yolo，SSD 这类 one-stage 算法，仅仅使用一个卷积神经网络 CNN 直接预测不同目标的类别与位置。一阶段方法的速度快，但是准确性要低一些。2. YOLO V1YOLO意思是You Only Look Once，创造性的将候选区和对象识别这两个阶段合二为一，看一眼图片（不用看两眼哦）就能知道有哪些对象以及它们的位置。实际上，YOLO并没有真正去掉候选区，而是采用了预定义的候选区（准确点说应该是预测区，因为并不是Faster RCNN所采用的Anchor）。也就是将图片划分为 $7\\times 7=49$ 个网格（grid），每个网格允许预测出 2 个边框（bounding box，包含某个对象的矩形框），总共 $49\\times 2=98$ 个 bounding box。可以理解为 98 个候选区，它们很粗略的覆盖了图片的整个区域。2.1. 网络结构网络结构借鉴了 GoogLeNet 。24个卷积层，2个全链接层。（用1×1 reduction layers 紧跟 3×3 convolutional layers 取代Goolenet的 inception modules ）2.2. 输入输入就是原始图像，唯一的要求是缩放到 $448\\times 448$ 的大小。主要是因为YOLO的网络中，卷积层最后接了两个全连接层，全连接层是要求固定大小的向量作为输入，所以倒推回去也就要求原始图像有固定的尺寸。2.3. 输出输出是一个 $7\\times 7\\times 30$ 的张量。$7\\times 7$ 对应原始图像的网格，30维向量 = 20个对象的概率 + 2个bounding box * 4个坐标 + 2个bounding box的置信度。前 20 维，one hot 编码。因为YOLO支持识别20种不同的对象（人、鸟、猫、汽车、椅子等），所以这里有20个值表示该网格位置存在任一种对象的概率。中 2 维，2 个 bounding box 的置信度。 = 该 bounding box 内有对象的概率 * 该 bounding box 与该对象实际 bounding box 的 IOU。后 8 维，2 个 bounding box 的位置。每个 bounding box 需要 4 个数值来表示其位置，(Center_x, Center_y, width, height)，2 个 bounding box 共需要 8 个数值来表示其位置。$7\\times 7$ 网格，每个网格 2 个 bounding box，对 $448\\times 448$ 输入图像来说覆盖粒度有点粗。我们也可以设置更多的网格以及更多的bounding box。设网格数量为 $S\\times S$，每个网格产生 B 个边框（4 位置 + 1 置信度），网络支持识别 C 个不同的对象。这时，输出的向量长度为： $C + B\\times (4+1)$ 整个输出的tensor就是： $S\\times S\\times (C + B\\times (4+1))$。2.4. 构造训练样本  20 个对象分类的概率对于输入图像中的每个对象，先找到其中心点。中心点落在某个网格内，该网格对应 30 维向量中的 1 维置 1，其它维度置 0（也即一个网格只能预测 1 个对象，网络一共能从一张图片中检测49个对象）。这就是所谓的”中心点所在的网格对预测该对象负责”。  2 个 bounding box 的位置训练样本的 bounding box 位置应该填写对象实际的 bounding box，但一个对象对应了 2 个 bounding box，该填哪一个呢？上面讨论过，需要根据网络输出的 bounding box 与对象实际 bounding box 的 IOU 来选择，所以要在训练过程中动态决定到底填哪一个 bounding box。参考下面第 3 点。  2 个 bounding box 的置信度上面讨论过置信度公式\\[Confidence = Pr(Object) * IOU^{truth}_{pre}\\]2 个 bounding box 的 $IOU$，哪个比较大就由哪个 bounding box 负责预测该对象是否存在，相应的 $P(Object)=1$，$Confidence = IOU$，该网格其它 bounding box 的 $Confidence = 0$。注意，在训练过程中等网络输出以后，比较两个 bounding box 与自行车实际位置的 IOU，自行车的位置（实际 bounding box）放置在 IOU 比较大的那个 bounding box（图中假设是 bounding box1），且该 bounding box 的置信度设为 1。2.5. 损失函数损失函数就是网络实际输出与标签之间的误差，YOLO V1 简单粗暴采用 sum-squared error loss。\\[\\begin{aligned}loss =&amp;\\lambda_{coord}\\sum_{i=0}^{S^2}\\sum_{j=0}^{B}[(x_i-\\hat{x}_i)^2+(y_i-\\hat{y}_i)^2]\\\\&amp;+\\lambda_{coord}\\sum_{i=0}^{S^2}\\sum_{j=0}^{B}\\mathbb{I}_{ij}^{obj}[(\\sqrt w_i-\\sqrt{\\hat{w}_i})^2+(\\sqrt h_i-\\sqrt{\\hat{h}_i})^2]\\\\&amp;+\\sum_{i=0}^{S^2}\\sum_{j=0}^{B}\\mathbb{I}_{ij}^{obj}(C_i-\\hat C_i)^2\\\\&amp;+\\lambda_{noobj}\\sum_{i=0}^{S^2}\\sum_{j=0}^{B}\\mathbb{I}_{ij}^{noobj}(C_i-\\hat C_i)^2\\\\&amp;+\\sum_{i=0}^{S^2}\\mathbb{I}_{i}^{obj}\\sum_{c\\in classes}(p_i(c) - \\hat p_i(c))^2\\end{aligned}\\]其中，三个布尔系数：  $\\mathbb{I}_{ij}^{obj}=1$ 表示第 $i$ 个网格的第 $j$ 个 bounding box 中存在对象；  $\\mathbb{I}_{ij}^{noobj}=1$ 表示第 $i$ 个网格的第 $j$ 个 bounding box 中不存在对象；  $\\mathbb{I}_{i}^{obj}=1$ 表示第 $i$ 个网格中存在对象。加入这些项的意义在于，只对符合布尔条件的 网格 / bounding box 才参与误差计算。第一行，中心点的误差。第二行，边框宽度高度的误差。注意取了平方根，这是为了平衡小框和大框的不同权重，因为绝对偏差在小框上更加敏感。取平方根可以降低这种敏感度的差异，使得较大的对象和较小的对象在尺寸误差上有相似的权重系数 $\\lambda_{coord}=5$ 用来调高位置误差（相对于分类误差和置信度误差）的权重。第三行，存在对象的 bounding box 的置信度误差。第四行，不存在对象的 bounding box 的置信度误差。因为不存在对象的 bounding box 应该老老实实的说 “我这里没有对象”，也就是输出尽量低的置信度。如果它不恰当的输出较高的置信度，会与真正有对象预测的那个 bounding box 产生混淆。即正确的对象概率最好是 1，所有其它对象的概率最好是 0。系数 $\\lambda_{noobj}=0.5$ 用来调低位置误差（相对于分类误差和置信度误差）的权重。第五行，对于有对象的网格（$\\mathbb{I}_{i}^{obj}=1$），分类的误差。这里将分类的向量与标签的 one-hot 向量进行作差然后求平方，即把分类问题当作回归问题。2.6. 训练最后一层采用线性激活函数，其它层都是 Leaky ReLU。训练过程采用了 drop out 和数据增强来防止过拟合。2.7. 测试预测测试时，每个网格预测的 class 的概率（比如前 20 维向量中最大的那个值），和 bounding box 预测的 confidence 值相乘，就得到每个 bounding box 的 class-specific confidence score：\\[Pr(C_i) = Pr(C_i\\vert Object) *Pr(Object) * IOU_{pred}^{truth}\\]然后设置阈值，滤掉得分低的 boxes，对保留的 boxes 进行 NMS 处理，就得到最终的检测结果。具体而言：每个网格有 20 个对象的概率 * 2个 bounding box 的置信度，共40个得分（候选对象）。49个网格共1960个得分。Andrew Ng建议每种对象分别进行NMS，那么每种对象有 1960/20=98 个得分。NMS步骤如下：1）设置一个Score的阈值，低于该阈值的候选对象排除掉（将该Score设为0）2）遍历每一个对象类别 2.1）遍历该对象的98个得分  2.1.1）找到Score最大的那个对象及其bounding box，添加到输出列表  2.1.2）对每个Score不为0的候选对象，计算其与上面2.1.1输出对象的bounding box的IOU  2.1.3）根据预先设置的IOU阈值，所有高于该阈值（重叠度较高）的候选对象排除掉（将Score设为0）  2.1.4）如果所有bounding box要么在输出列表中，要么Score=0，则该对象类别的NMS完成，返回步骤2处理下一种对象3）输出列表即为预测的对象2.8. 结论YOLO以速度见长，处理速度可以达到45fps，其快速版本（网络较小）甚至可以达到155fps。这得益于其识别和定位合二为一的网络设计，而且这种统一的设计也使得训练和预测可以端到端的进行，非常简便。不足之处是小对象检测效果不太好（尤其是一些聚集在一起的小对象），对边框的预测准确度不是很高，总体预测精度略低于Fast RCNN。主要是因为网格设置比较稀疏，而且每个网格只预测两个边框，另外Pooling层会丢失一些细节信息，对定位存在影响。3. YOLO V2相比 YOLO V1，改进如下表所示。3.1. 网络结构主干网络换成 Darknet-19，19 个卷积层和 5 个最大池化层，比 VGG-16 小一些，精度不弱于它，但浮点运算减少到约 1/5，运算速度更快。  移除全连接层很长一段时间以来，全连接网络一直是 CNN 分类网络的标配结构。一般在全连接后会有激活函数来做分类，假设这个激活函数是一个多分类 softmax，那么全连接网络的作用就是将最后一层卷积得到的 feature map stretch 成向量，对这个向量做乘法，最终降低其维度，然后输入到 softmax 层中得到对应的每个类别的得分。全连接层如此的重要，以至于全连接层过多的参数重要到会造成过拟合，所以也会有一些方法专门用来解决过拟合，比如dropout。YOLO V2 移除了全连接层，而是采用 全局平均池化层来进行分类。global average pooling 与 average pooling 的差别就在 “global” 这一个字眼上。global 与 local 在字面上都是用来形容 pooling 窗口区域的。 local 是取 feature map 的一个子区域求平均值，然后滑动这个子区域； global 显然就是对整个 feature map 求平均值了。  摆脱了固定尺寸的 FC 对输入图像尺寸的约束，可以适应各种尺寸的输入图像。  剔除了 FC 的黑箱特性，直接赋予每个 channel 实际意义。  PLoB. 关于global average pooling理解和介绍  移除一个池化层去掉了一个池化层，使网络卷积层输出具有更高的分辨率。3.2. 批归一化该主干网络中的每个卷积层中还引入了 Batch Normalization 稳定训练，加快收敛，防止过拟合。同时放弃了 dropout。批归一化有助于解决反向传播过程中的梯度消失和梯度爆炸问题，降低对一些超参数（比如学习率、网络参数的大小范围、激活函数的选择）的敏感性，并且每个 batch 分别进行归一化的时候，起到了一定的正则化效果（YOLO V2 不再使用 dropout），从而能够获得更好的收敛速度和收敛效果。通常，一次训练会输入一批样本（batch）进入神经网络。批规一化在神经网络的每一层，在网络（线性变换）输出后和激活函数（非线性变换）之前增加一个批归一化层（BN），BN层进行如下变换：  对该批样本的各特征量（对于中间层来说，就是每一个神经元）分别进行归一化处理，分别使每个特征的数据分布变换为均值 0，方差 1。从而使得每一批训练样本在每一层都有类似的分布。这一变换不需要引入额外的参数。  对上一步的输出再做一次线性变换，假设上一步的输出为Z，则 $Z_1=\\gamma Z + \\beta$。这里γ、β是可以训练的参数。增加这一变换是因为上一步骤中强制改变了特征数据的分布，可能影响了原有数据的信息表达能力。增加的线性变换使其有机会恢复其原本的信息。批归一化使 mAP 有 2.4% 的提升。  天雨粟. Batch Normalization原理与实战. 知乎3.3. 高分辨率分类器图像分类的训练样本很多，而标注了边框的用于训练对象检测的样本相比而言就比较少了，因为标注边框的人工成本比较高。所以对象检测模型通常都先用图像分类样本训练卷积层，提取图像特征。但这引出的另一个问题是，图像分类样本的分辨率不是很高。所以YOLO v1使用ImageNet的图像分类样本采用 224 x 224 作为输入，来训练CNN卷积层。然后在训练对象检测时，检测用的图像样本采用更高分辨率的 448 x 448 的图像作为输入。但这样切换对模型性能有一定影响。所以YOLO2在采用 224 x 224 图像进行分类模型预训练后，再采用 448 x 448 的高分辨率样本对分类模型进行微调（10个epoch），使网络特征逐渐适应 448 x 448 的分辨率。然后再使用 448 x 448 的检测样本进行训练，缓解了分辨率突然切换造成的影响。mAP 提升了 3.7%。3.4. 先验框（anchor）借鉴 Faster R-CNN 的做法，YOLO V2 也尝试采用先验框（anchor）。在每个网格预先设定一组不同大小和宽高比的边框，来覆盖整个图像的不同位置和多种尺度，这些先验框作为预定义的候选区在神经网络中将检测其中是否存在对象，以及微调边框的位置。之前 YOLO V1 并没有采用先验框，并且每个网格只预测两个 bounding box，整个图像 98 个。YOLO V2 如果每个网格采用 9 个先验框，总共有 $13\\times 13\\times 9=1521$ 个先验框。召回率大幅提升到88%，同时mAP轻微下降了0.2%。不过 YOLO V2 接着进一步对先验框进行了改良。之前先验框都是手工设定的，YOLO2尝试统计出更符合样本中对象尺寸的先验框，这样就可以减少网络微调先验框到实际位置的难度。YOLO V2 对训练集中标注的边框进行聚类分析，以寻找尽可能匹配样本的边框尺寸。聚类算法最重要的是选择如何计算两个边框之间的“距离”，对于常用的欧式距离，大边框会产生更大的误差，但我们关心的是边框的IOU。所以，YOLO V2 在聚类时采用以下公式来计算两个边框之间的 “距离”。\\[d(box,centroid) = 1- IOU(box, centroid)\\]$centroid$ 是聚类时被选作中心的边框，$box$ 就是其它边框，$d$ 就是两者间的 “距离”。IOU 越大，“距离” 越近。聚类分析结果如下图所示：上图左边是选择不同的聚类 k 值情况下，得到的 k 个 centroid 边框，计算样本中标注的边框与各 centroid 的 Avg IOU。显然，边框数 k 越多，Avg IOU 越大。YOLO V2 选择 k=5 作为边框数量与 IOU 的折中。对比手工选择的先验框，使用 5 个聚类框即可达到 61 Avg IOU，相当于 9 个手工设置的先验框 60.9 Avg IOU。上图右边显示了 5 种聚类得到的先验框，VOC 和 COCO 数据集略有差异，不过都有较多的瘦高形边框。3.5. 约束预测框位置借鉴于 Faster RCNN 的先验框方法，其位置预测公式为：\\[x = (t_x \\cdot w_a) + x_a\\\\y = (t_y \\cdot h_a) + y_a\\]其中，$x_a, y_a$ 时先验框中心，$w_a, h_a$ 是先验框宽高，$x,y$ 是预测框中心，$t_x, t_y$ 是待学习参数。由于 $t_x, t_y$ 没有任何约束，因此预测框的中心可能出现在任何位置。训练早期阶段不容易稳定。因此 YOLO V2 调整了预测公式，将预测框中心约束在特定的网格内。\\[x = \\sigma (t_x) + c_x\\\\y = \\sigma (t_y) + c_y\\\\w = w_a e^{t_w}\\\\h = h_a e^{t_h}\\\\Pr(obj)\\cdot IOU(b, obj) = \\sigma (t_o)\\]式中，$t_x, t_y, t_w, t_h, t_o$ 是待学习参数。$c_x, x_y$ 是当前网格左上角到图像左上角的距离，要先将网格大小归一化，即令一个网格的宽=1，高=1。$\\sigma$ 即 sigmoid 函数，可以将 $[-\\infty,+\\infty]$ 的 $t_x, t_y$ 映射到 $[0,1]$，从而约束在了当前网格内（蓝色区域）。对于预测框的宽高，采用指数函数，将 $[-\\infty,+\\infty]$ 的 $t_w, t_h$ 映射到 $[0,+\\infty]$，此时 $t=0$ 对应 $e^t=1$ ，则预测框宽高就等于原始宽高，相当于让参数围绕 0 附近波动，更好学习。引入先验框和约束预测框位置，使得 mAP 有 4.8% 的提升。对于置信度，YOLO V1 直接预测置信度的值，而 YOLO V2 预测 $t_o$，要经过 sigmoid 变换作为置信度的值。3.6. pass through为了更好的检测出一些比较小的对象，最后输出的特征图需要保留一些更细节的信息。YOLO V2 引入一种称为 passthrough 层的方法在特征图中保留一些细节信息。具体来说，就是在最后一个 pooling 之前，特征图的大小是 26 x 26 x 512，将其 1 拆 4，直接传递（passthrough）到 pooling 后（并且又经过一组卷积）的特征图，两者叠加到一起作为输出的特征图。由于之后的 YOLO V3 等不再运用，此处就不介绍了。3.7. 训练YOLO V2 的训练主要包括两个阶段。第一阶段就是先在 ImageNet 分类数据集上预训练 Darknet-19，此时模型输入为 224 x 224 ，共训练 160 个 epochs。然后第二阶段将网络的输入调整为 448 x 448 ，继续在 ImageNet 数据集上 finetune 分类模型，训练 10 个 epochs，此时分类模型的 top-1 准确度为 76.5%，而 top-5 准确度为 93.3%。3.8. 测试预测修改 Darknet-19 分类模型为检测模型，移除最后一个卷积层、global avgpooling 层以及 softmax 层，并且新增了三个 3 x 3 x 1024 卷积层，同时增加了一个passthrough层，最后使用 1 x 1 卷积层输出预测结果，输出的 channels 数为：num_anchors x (5+num_classes)，和训练采用的数据集有关系。由于 anchors 数为 5，对于 VOC 数据集（20 种分类对象）输出的 channels 数就是 125，最终的预测矩阵 T 的 shape 为 (batch_size, 13, 13, 125)，可以先将其 reshape 为 (batch_size, 13, 13, 5, 25) ，其中 T[:, :, :, :, 0:4] 为边界框的位置和大小 $[t_x, t_y, t_w, t_h]$ ，T[:, :, :, :, 4] 为边界框的置信度，而 T[:, :, :, :, 5:] 为类别预测值。4. YOLO V34.1. 网络结构其中主干网络（Backbone）为 Backbone。从 YOLO V3 开始引入 Neck 。在目标检测领域，为了更好的提取融合特征，通常在 Backbone 和输出层之间会插入一些层，这个部分称为 Neck。相当于目标检测网络的颈部，也是非常关键的。DarkNet-53 的基本单元为 Convolutional，包括 {conv2d + BN + Leaky ReLU}。上图的 Darknet-53 网络采用 256 x 256 x 3 作为输入，首先经过一个 3 x 3 x 32 Convolutional，然后经过一个 3 x 3 x 64s2 Convolutional 下采样一倍。后面还可以看到， DarkNet 摒弃了所有最大池化层，转而用 stride=2 的 Convolutional 来做下采样。比如第二层的 Convolutional：\\[\\begin{aligned}output &amp;= (input + 2*padding - kernel)/stride+1\\\\&amp;= (256+2*0-3)/2 + 1\\\\&amp;= ceil(136.5) + 1\\\\&amp;= 128\\\\\\end{aligned}\\]紧接是若干重复模块。最左侧那一列的 1、2、8 等数字表示多少个重复的残差组件。每个残差组件有两个 Convolutional 和一个快捷链路。以第一个残差模块为例：            [1 x 1] x 32 kernel          [3 x 3] x 64 kernel128 x 128 x 64 ----------&gt;  128 x 128 x 32 ----------&gt;  128 x 128 x 64       |                                                       ^       |_______________________________________________________| (+)后接一个 3 x 3 x 256s2 的下采样 Convolutional。进入第二个残差模块，这里由 8 个残差模块堆叠而成。后面以此类推。4.2. 多尺度特征YOLO V2 曾采用 passthrough 结构来检测细粒度特征，在 YOLO V3 更进一步采用了 3 个不同尺度的特征图来进行对象检测，构成特征金字塔（Feature Pyramid Networks, FPN）。分别从主干网络的中间层引出两个特征图，分别为：  b: 52 x 52 x 256  c: 26 x 26 x 512下面详细讨论特征金字塔：  Predict one主干网络输出的最抽象的特征，具有大尺度的感受野（特征图上很小的区域就对应原图很大的一块区域），用来检测大目标。首先，主干网络最末端输出 13 x 13 x 1024 ，经过 Convolutional Set，包含五个 Convolutional 组（图右侧），其中每个 Convolutional 的卷积核具体为：[1 x 1] x 512 --&gt; [3 x 3] x 1024 --&gt; [1 x 1] x 512 --&gt; [3 x 3] x 1024 --&gt; [1 x 1] x 512得到 13 x 13 x 512 特征，记作 A。再经过一个单独的 {[3 x 3] x 1024 + BN + Leaky ReLU} Convolutional 和一个 1 x 1 x 255 纯卷积 conv2d，得到 13 x 13 x 255 的特征图 Y1，可识别 13 x 13 = 169 个大物体。  Predict Two具有中等尺度的感受野，用来检测中目标。将前面的 A 拿过来，经过一个单独的 {[1 x 1] x 256 + BN + Leaky ReLU} Convolutional 和一个上采样，得到 26 x 26 x 256 的特征图。将上采样的结果与 b 拼接后得到 26 x 26 x 768。            26 x 26 x 512 ------------------------------------------                                                                     | (concat)A：13 x 13 x 512 --&gt; 13 x 13 x 256 --------&gt; 26 x 26 x 512 --&gt; 26 x 26 x 768                                  (upsample)再经过 Convolutional Set，其中每个 Convolutional 的卷积核具体为：[1 x 1] x 256 --&gt; [3 x 3] x 512 --&gt; [1 x 1] x 256 --&gt; [3 x 3] x 512 --&gt; [1 x 1] x 256得到 26 x 26 x 256，记作 B。再经过一个单独的 {[3 x 3] x 512 + BN + Leaky ReLU} Convolutional 和一个 1 x 1 x 255 纯卷积 conv2d，得到 26 x 26 x 255 的特征图 Y2，可识别 26 x 26 = 676 个中物体。  Predict Three具有小尺度的感受野，用来检测中目标。将前面的 B 拿过来，经过一个单独的 {[1 x 1] x 128 + BN + Leaky ReLU} Convolutional 和一个上采样，得到 52 x 52 x 128 的特征图。            52 x 52 x 256 ------------------------------------------                                                                     | (concat)B：26 x 26 x 256 --&gt; 26 x 26 x 128 --------&gt; 52 x 52 x 128 --&gt; 52 x 52 x 384                                  (upsample)将上采样的结果与 c 拼接后得到 26 x 26 x 384。再经过 Convolutional Set，其中每个 Convolutional 的卷积核具体为：[1 x 1] x 128 --&gt; [3 x 3] x 256 --&gt; [1 x 1] x 128 --&gt; [3 x 3] x 256 --&gt; [1 x 1] x 128再经过一个单独的 {[3 x 3] x 256 + BN + Leaky ReLU} Convolutional 和一个 1 x 1 x 255 纯卷积 conv2d，得到 52 x 52 x 255 的特征图 Y3，可识别 52 x 52 = 2704 个小物体。两个注意点：  上采样（up sampling）方法包括：双线性插值（简单，不需要学习参数）和反卷积，不知道 YOLO V3 采用哪种。  输出特征维度中 255 = [ 80 class + 4 (x,y,w,h) + 1 confidence ] x 3 bbox4.3. 损失函数5. 参考文献[1] X猪. YOLO v1深入理解. 简书"
  },
  
  {
    "title": "计算机视觉（Two-Stage 目标检测）",
    "url": "/posts/CV-object-detection-2stage/",
    "categories": "Academic, Knowledge",
    "tags": "deep learning, computer vision",
    "date": "2021-06-08 09:08:49 +0800",
    





    
    "snippet": "本文介绍了计算机视觉中目标检测问题的基础研究和历史。  1. 前言          1.1. AlexNet      1.2. VGG16        2. R-CNN  3. Fast R-CNN  4. Faster R-CNN  5. 参考文献1. 前言图片分类任务我们已经熟悉了，就是算法对其中的对象进行分类。而今天我们要了解构建神经网络的另一个问题，即目标检测问题。这意味着，我...",
    "content": "本文介绍了计算机视觉中目标检测问题的基础研究和历史。  1. 前言          1.1. AlexNet      1.2. VGG16        2. R-CNN  3. Fast R-CNN  4. Faster R-CNN  5. 参考文献1. 前言图片分类任务我们已经熟悉了，就是算法对其中的对象进行分类。而今天我们要了解构建神经网络的另一个问题，即目标检测问题。这意味着，我们不仅要用算法判断图片中是不是一辆汽车， 还要在图片中标记出它的位置， 用边框或红色方框把汽车圈起来， 这就是目标检测问题。 其中“定位”的意思是判断汽车在图片中的具体位置。近几年来，目标检测算法取得了很大的突破。比较流行的算法可以分为两类，一类是基于 Region Proposal 的 R-CNN 系算法（R-CNN，Fast R-CNN, Faster R-CNN等），它们是two-stage的，需要先算法产生目标候选框，也就是目标位置，然后再对候选框做分类与回归。而另一类是 Yolo，SSD 这类 one-stage 算法，其仅仅使用一个卷积神经网络 CNN 直接预测不同目标的类别与位置。第一类方法是准确度高一些，但是速度慢，但是第二类算法是速度快，但是准确性要低一些。1.1. AlexNetAlexNet 的网络结构如下：      Conv 11$\\times$11s4,96 / ReLU    输入为 $224 \\times 224 \\times 3$ 的图像，每个通道包含 96 个 $11\\times 11,\\ stride=4$ 的卷积核，一共参数量为\\[3\\ channel \\times 11\\times 11\\times 96\\ kernels + 96\\ bias = 34944 \\approx35K\\ params\\]    卷积后得到    wide = (224 + 2 * padding - kernel_size) / stride + 1 = 54height = (224 + 2 * padding - kernel_size) / stride + 1 = 54dimention = 96            Local Response Norm    局部响应归一化层完成一种 “临近抑制” 操作，对局部输入区域进行归一化。借鉴了神经生物学中侧抑制（lateral inhibitio ）的概念，指的是被激活的神经元会抑制它周围的神经元，从而实现局部抑制。但是，在 2015 年 Very Deep Convolutional Networks for Large-Scale Image Recognition 提到 LRN 基本没什么用。因而在后面的 Googlenet，以及之后的一些 CNN 架构模型，LRN 已经不再使用，因为出现了更加有说服能力的批量归一化（Batch Normalization, BN）。        Max Pool最大池化，代替之前网络的平均池化。采用 3$\\times$3卷积核，stride = 2，因此会出现重叠池化的现象。可以减小过拟合。池化后得到：    wide = (54 + 2 * padding - kernel_size) / stride + 1 = 54height = (54 + 2 * padding - kernel_size) / stride + 1 = 54dimention = 96        1.2. VGG16        ICLR. Very Deep Convolutional Networks for Large-Scale Image RecognitionVisual Geometry Group  相比 AlexNet 的一个改进是采用连续的几个 3x3 的卷积核代替 AlexNet 中的较大卷积核（11x11，7x7，5x5）。  使用了 3 个 3x3 卷积核来代替 7x7 卷积核  使用了 2 个 3x3 卷积核来代替 5*5 卷积核对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。VGG网络的结构 非常一致  所有的卷积层都是 3x3x3,stride=1,padding=1（图像尺寸保持不变）；  所有的池化层都是 2x2,padding=0,stride=2 的最大池化（图像尺寸缩小一半）。VGG16 特指 D 列包含 16 个权重层的网络结构，而 VGG19 特指 E 列包含 19 个权重层的网络结构。输入 $224\\times 224 \\times 3\\ channel$ 的图像。首先经过 2 次 64 个滤波器的卷积。套公式计算发现卷积后输出尺寸不变\\[H/W = (224+2\\times padding - kernel)/stride + 1 = 224\\]然后经过 2x2 最大池化后大小缩小为原来的一半。按照网络结构继续进行，最终经过五次池化得到 7x7x512 的 feature map。传入 4096 维的全连接层（FC 层），参数个数为 $7\\times 7\\times 512\\times 4096+4096\\ bias=102764544$，经过 ReLU，后再接一个 4096 维的 FC 层，参数个数为 $4096\\times 4096=16777216$，经过 ReLU，最后送入 1000 维 FC 层，后接 softmax 进行分类。2. R-CNN      Ross Girshick，JeffDonahue,TrevorDarrell,Jitendra Malik. Rich feature hierarchies for accurate oject detection and semantic segmentation  目标检测有两个主要任务：物体分类和定位，为了完成这两个任务，R-CNN借鉴了滑动窗口思想， 采用对区域进行识别的方案。RCNN是一个 two-stage （两阶段，上图中 1+2 是第一阶段，3+4 是第二阶段）目标检测算法，具体实现步骤如下：      提取候选区域。输入一张图片，通过指定算法从图片中提取 2000 个类别独立的候选区域（可能目标区域）。R-CNN 目标检测首先需要获取2000个目标候选区域，能够生成候选区域的方法很多，比如：          objectness      selective search      category-independen object proposals      constrained parametric min-cuts (CPMC)      multi-scale combinatorial grouping      Ciresan        R-CNN 采用的是 Selective Search 算法。简单来说就是通过一些传统图像处理方法将图像分成很多小尺寸区域，然后根据小尺寸区域的特征合并小尺寸得到大尺寸区域，以实现候选区域的选取。 提取候选区域非常耗时，可能比实际对象检测还要耗时。    候选区域有 2000 个，所以很多会进行重叠。针对每个类，通过计算 IoU 指标（交并比），采取非极大性抑制，以最高分的区域为基础，剔除掉那些重叠位置的区域。    提取特征向量。对于上述获取的候选区域，使用 AlexNet (2012) 提取 4096 维特征向量。（AlexNet 的输入图像大小是 227x227，而通过 Selective Search 产生的候选区域大小不一，为了与 AlexNet 兼容，R-CNN 采用了非常暴力的手段，那就是无视候选区域的大小和形状，统一变换到 227x227 的尺寸。有一个细节，在对 Region 进行变换的时候，首先对这些区域进行膨胀处理，在其 box 周围附加了 p 个像素，也就是人为添加了边框，在这里 p=16。）网络训练过程如下：          首先进行有监督预训练：使用 ImageNet 训练网络参数，这里只训练和分类有关的参数，因为 ImageNet 数据只有分类，没有位置标注。输入图片尺寸调整为 227x227，最后一层输出：4096 维向量 -&gt; 1000 维向量的映射（因为 ImageNet 挑战使用了一个“修剪”的1000 个非重叠类的列表）。      然后在特定样本下的微调（迁移学习） ：采用训练好的 AlexNet 模型进行 PASCAL VOC 2007 样本集下的微调，学习率 = 0.001，最后一层输出：4096 维向量 -&gt; 21 维向量的映射（PASCAL VOC 2007 样本集包含 20 个类 + 背景类共 21 类，既有图像中物体类别标签，也有图像中物体位置标签）。将候选区域与 GroundTrue 中的 box 标签相比较，如果 IoU &gt; 0.5，说明两个对象重叠的位置比较多，于是就可以认为这个候选区域是正，否则就是负。mini-batch 为 128（32 个正样本和 96 个负样本）。        SVM 分类。对于每个区域相应的特征向量，利用 SVM 进行分类，并通过一个 bounding box regression 调整目标包围框的大小。          将 2000×4096 维特征（2000 个候选框，每个候选框获得 4096 的特征向量）与 20 个 SVM 组成的权值矩阵 4096×20 相乘（每一个特征向量分别判断 20 次类别，因为 SVM 是二分类器，每个种类训练一个 SVM 则有 20 个 SVM），获得 2000×20 维矩阵表示每个候选框是某个物体类别的得分。      【IOU&lt;0.3被作为负例，ground-truth是正例，其余的全部丢弃】      然后分别对上述 2000×20 维矩阵中每列（即每一类）进行非极大值抑制，剔除重叠候选框，得到该列（即该类）中得分最高的一些候选框。                  非极大值抑制：同一个目标可能有好几个框（每一个框都带有一个分类器得分），目标是一类只保留一个最优的框。                      将所有框的得分排序，选中最高分及其对应的框;            遍历其余的框，挑出其中第二大得分框，如果和当前最高分框的重叠面积（IoU）大于一定阈值，将其删除，即认为他与最高分框重复了，都指向同一个目标。否则，我们认为这个区域有两个该目标。            从未处理的框中继续选一个得分最高的，重复上述过程。                                bounding box 回归。受 DPM 的启发，作者训练了一个线性的回归模型，这个模型能够针对候选区域的 pool5 数据预测一个新的 box 位置。具体细节，作者放在补充材料当中。缺点：  训练分多步。R-CNN 的训练先要fine tuning 一个预训练的网络（AlexNet），然后针对每个类别都训练一个 SVM 分类器，最后还要对 bounding-box 进行回归，另外 region proposal 也要单独用 selective search 的方式获得，步骤比较繁琐；  时间和内存消耗比较大。在训练 SVM 和回归的时候需要用网络训练的特征（2000×4096=819万参数）作为输入，特征保存在磁盘上再读入的时间消耗还是比较大的；  测试的时候也比较慢，每张图片的每个 region proposal 都要做卷积，重复操作太多。3. Fast R-CNN  提取特征图（feature maps）。输入原始图像，主干网络采用 VGG16 来提取特征图，3 大改进：          实现大部分 end-to-end 训练（提proposal阶段除外）。所有的特征都暂存在显存中，就不需要额外的磁盘空间。      joint training （SVM分类，bbox回归 联合起来在 CNN 阶段训练）把最后一层的Softmax换成两个，一个是对区域的分类Softmax（包括背景），另一个是对bounding box的微调。这个网络有两个输入，一个是整张图片，另一个是候选proposals算法产生的可能proposals的坐标。（对于SVM和Softmax，论文在SVM和Softmax的对比实验中说明，SVM的优势并不明显，故直接用Softmax将整个网络整合训练更好。对于联合训练： 同时利用了分类的监督信息和回归的监督信息，使得网络训练的更加鲁棒，效果更好。这两种信息是可以有效联合的。）      提出了一个RoI层，算是SPP的变种，SPP是pooling成多个固定尺度，RoI只pooling到单个固定的尺度 （论文通过实验得到的结论是多尺度学习能提高一点点mAP，不过计算量成倍的增加，故单尺度训练的效果更好。）        提取候选框（region proposals）。输入原始图像，通过 selective search 提取感兴趣区域。每个区域的坐标用四元数组 $[r,c,h,w]$ （左上角的行列坐标+高和宽）定义，该四元数组相对于原始图像，都有对应的 ground truth BBox 和 ground truth class label。  将候选框坐标映射到 feature map 上。采用 VGG16 时，最后一个 max pooling 层后接 ROI pooling 层，区域坐标经过 5 次池化，输出的 feature maps 是原图像的 1/32（16x16x512），则将原图像对应的四元数组转换到 feature maps 上就是每个值都除以 32 并量化到最接近的整数，得到映射的坐标，即为 ROI feture map。在上图的例子中，一个 ROI 的原始大小为 145x200 ，左上角设置为 (192x296) 。除以 32（比例因子）并取整，左上角变为 (9,6)，高宽变为 4x6，得到的 ROI feature maps 为 $[9,6,4,6]$。注意，映射过程存在一次量化损失。损失的信息如上图蓝色区域所示（之后会有改进的 ROI Align 方法去除损失）。      ROI pooling。输入 conv5 层输出的 feature maps 以及 ROI 在该层上的映射（即 ROI feature maps），将其转换为固定大小 feature maps 输出，以便送入后续固定长度的 FC 层。假设经过 ROI 池化后的固定大小为是一个超参数 $H\\times W$ ，因为输入的 ROI feature map 大小不一样，假设为 $h\\times w$，需要对这个 feature map 进行池化来减小尺寸，那么可以计算出池化窗口的尺寸为：$(h/H)\\times (w/W)$，即用这个计算出的窗口对 RoI feature map 做 max pooling，Pooling 对每一个 feature map 通道都是独立的。假设我们需要将上面得到的 4x6x512 池化为固定大小的 3x3x512 feature maps，需要进行 (4/3)x(6/3)x512 = 1x2x512 的卷积核进行最大池化，会丢失 ROI 的最后一行。如此遍历每个 ROI feature map 最终得到 Nx3x3x512 的矩阵。注意，ROI Pooling 过程存在第二次量化损失（上面的例子中为最后一行）。    回归与分类。将所有得到的固定大小的 ROI feature map 送入两个 4096 维的 FC 层，然后分别送入并列的两个 21 和 84 维的FC 层。前者是分类的输出，代表每个 ROI 属于每个类别（20类+背景）的得分，后者是回归的输出，代表每个 ROI 所属类别的四个坐标。在训练时：最后是损失函数，包括两部分，分类的是 softmaxWithLoss，输入是label和分类层输出的得分；回归的是SmoothL1Loss，输入是回归层的输出和 target 坐标及 weight。在测试时：最后两个 loss 层要改成一个 softmax 层，输入是分类的 score，输出概率。最后对每个类别采用非极大抑制（non-maximun suppression）。Fast R-CNN 的主要缺点在于 region proposal 的提取使用 selective search，目标检测时间大多消耗在这上面（提 region proposal 需要 2~3 s，而提特征分类只需 0.32 s），这也是后续 Faster R-CNN 的改进方向之一。4. Faster R-CNN  将输入图像缩放至固定大小 M x N，然后送入主干网络（比如VGG16）的 13 个卷积层、13 个 ReLU 激活函数、4 个池化层，得到 M/16 x N/16 x 256 的 feature maps。  feature map 分别送入两个模块：Region Proposal Network （RPN）和 ROI Pooling。          RPN 模块中（左下角），首先经过 3x3x256 卷积和激活函数，相当于每个点又融合了周围 3 x 3 的空间信息（猜测这样做也许更鲁棒？进一步集中特征信息？），同时 256 深度不变。然后分为两条线。      上一条线做分类，对 256 通道图像做 1 x 1 x 256 卷积，即将输入图像于每个通道乘以卷积系数后加在一起，即相当于把原图像中本来各个独立的通道 “联通” 在了一起，得到一张单通道的 feature map。      单通道 feature map ，anchor，softmax      生成一堆 anchors，对其进行裁剪过滤后，通过 softmax 判断 anchors 属于前景（物体）还是背景，二分类。                  anchors 是一个矩阵，代表了一组矩形框，矩阵的每一行表示矩形左上和右下点的座标，比如，rpn/generate_anchors.py 生成 9 个矩形共有三种形状，三种尺寸分别是小（蓝 128）中（红 256）大（绿 512），三种比例分别为 1:1, 1:2, 2:1 。                    5. 参考文献[1] 维基百科. Kernel regression"
  },
  
  {
    "title": "深度学习基础（CNN 卷积神经网络）",
    "url": "/posts/deep-learning-CNN/",
    "categories": "Academic, Knowledge",
    "tags": "deep learning",
    "date": "2021-06-08 09:08:49 +0800",
    





    
    "snippet": "本文介绍了深度学习中卷积神经网络的（CNN）的基础知识。  1. 基础知识          1.1. 图像      1.2. 卷积                  1.2.1. 单通道卷积          1.2.2. 多通道卷积          1.2.3. 权重          1.2.4. 偏置          1.2.5. 激活          1.2.6. 共享权值...",
    "content": "本文介绍了深度学习中卷积神经网络的（CNN）的基础知识。  1. 基础知识          1.1. 图像      1.2. 卷积                  1.2.1. 单通道卷积          1.2.2. 多通道卷积          1.2.3. 权重          1.2.4. 偏置          1.2.5. 激活          1.2.6. 共享权值          1.2.7. 初始化          1.2.8. 卷积模式          1.2.9. 反向传播                    1.3. 池化                  1.3.1. 最大池化          1.3.2. 平均池化          1.3.3. 池化的好处          1.3.4. 反向传播                      2. 参考文献1. 基础知识1.1. 图像图像在计算机中表示为一个 $height\\times width$ 的 2 维的矩阵，矩阵的各个元素取值为颜色的值，可以表示为 $[0,1]$ 区间或 $[0,255]$ 区间的一个数。灰度图像是单通道的，彩色图像是三通道的（R，G，B）。1.2. 卷积卷积是原始图像与卷积核之间的滑动局部加乘计算过程。狭义的卷积核（kernel）是一个矩阵，可在图像上滑动并与输入相乘，从而以某种我们期望的方式增强输出。1.2.1. 单通道卷积假设输入图片为 $6\\times 6 \\times 1\\ channel$，卷积核为 $3\\times 3$，stride=1（表示 kernel 的滑动步长为1），padding=1（表示对原始输入图像周围额外增加一层，配合stride=1，可以保证卷积后图片大小不变），则卷积过程如下图所示：上面的kernel可用于锐化图像。比如，考虑下图所示的两个输入图像。  第一个图像，中心值为3 * 5 + 2 * -1 + 2 * -1 + 2 * -1 + 2 * -1 =7，值3增加到7。  第二个图像，输出是1 * 5 + 2 * -1 + 2 * -1 + 2 * -1 + 2 * -1 = -3，值1减少到-3。显然，3和1之间的对比度增加到了7和-3，图像将更清晰锐利。卷积后尺寸计算公式：\\[输出图像尺寸 = (输出图像尺寸-卷积核尺寸 + 2*填充值)/步长+1\\]1.2.2. 多通道卷积假设一个图像为 $5\\times 5 \\times 3\\ channel$，此时，对于每一个通道均可以用一个卷积核进行卷积。此时，三个通道的卷积核串联起来，形成一个滤波器（filter）。在前面的单通道卷积中，卷积核就是一个单通道的 filter。举例，采用 1 个 $3\\ channel$ 的滤波器，每个通道的卷积核大小仍为 3x3，padding=0，stride=1。卷积过程如下，每一个通道的像素值与对应通道的卷积核的数值进行卷积，因此每一个通道会对应一个输出卷积结果，三个卷积结果对应位置累加 求和，得到最终的卷积结果。上述过程中，每一个 滤波器 的通道数必须与输入图片的通道数 一致。可以看出，一个 滤波器 最终到一个通道的特征图，则采用多个 滤波器 就可得到多个特征图，也即最终输出的特征图的通道数等于 滤波器 的个数。为什么要采用多个 滤波器 呢？因为一个 滤波器 提取特征是不充分的，需要添加多个 滤波器 去学习多种特征。另外，滤波器 中不同通道上的卷积核的参数并不相同。1.2.3. 权重卷积核的值就是待学习的权重参数。网络训练时，输出的结果会和数据集标签做损失计算，然后把计算得到的损失反向梯度下降去更新卷积核里的每一个参数。所以卷积核里面的参数最终是训练得到的。通过深层 CNN，我们无需再用手工设计的 kernel 来提取特征，而是可以直接学习这些可提取潜在特征的 kernel 值。1.2.4. 偏置每一个 滤波器 都包括一个偏置参数（bias）。这个偏置参数是该 滤波器 中所有 卷积核 共享的。最终的卷积结果需要在加上该偏置值。1.2.5. 激活卷积与偏置加和后的值，还需要再经过激活函数（比如 ReLU）才得到最终特征图上的值。1.2.6. 共享权值共享权值包括 共享权重 和 共享偏置。简而言之，卷积核的权重与偏置在卷积过程中保持不变。如下图所示，相同颜色的权值保持不变1.2.7. 初始化卷积核的权值是通过学习更新的，但是最开始是需要给这些参数提供初始值才能使网络运行。初始化方法可以简略分三种：  取偏差很小的高斯分布随机取值  Xavier 初始化方法  He kai ming 初始化方法1.2.8. 卷积模式橙色部分为 image, 蓝色部分为 filter。  full modefull 模式的意思是，从 filter 和 image 刚相交开始做卷积，白色部分为填 0。filter 的运动范围如图所示。  same mode当filter的中心 K 与 image 的边角重合时，开始做卷积运算。当卷积步长 stride = 1 时，卷积之后输出的 feature map 尺寸相对于输入图片保持不变（same）。  valid mode当filter全部在image里面的时候，进行卷积运算。1.2.9. 反向传播为了说明反向传播，需要先分析前向传播。假设卷积的前向传播采用 valid 模式。我们发现，当误差反向传播到卷积层时，我们的操作方法依然是一个卷积，只不过要把卷积核翻转（旋转180°），然后在周围补 0。注意到，前向传播采用 valid mode 卷积，反向传播时是 full mode 卷积，如图所示：显然，如果前向传播是 full mode 卷积，那么反向传播就是 valid mode 卷积，不过依旧要将卷积核翻过来。而对于 same mode 卷积，它的反向传播也是一个 same mode 卷积，同样也需要翻转卷积核。最后，对于 strided 卷积（跨超过 1 步的卷积），反向传播是 fractional strided 卷积，反之依然。卷积核同样也要翻转。1.3. 池化池化层也称下采样层，会压缩输入的特征图，一方面减少了特征，导致了参数减少，进而简化了卷积网络计算时的复杂度；另一方面保持了特征的某种不变性（旋转、平移、伸缩等）。池化的思想来自于视觉机制，是对信息进行抽象的过程。池化操作主要有两种，一种是平均池化(Average Pooling)，即对邻域内的特征点求平均；另一种是最大池化(Max Pooling)，即对邻域内的特征点取最大。注意，池化也可以看作一种步长与卷积核相等的卷积，且卷积核参数固定不变。注意，池化过程没有需要学习的参数。因此池化可以在不增加参数的情况下，大幅降低 feature map 的维度，节约开销。1.3.1. 最大池化采用 $2\\times 2$ 卷积核对 $4\\times 4$ 图像的最大池化过程：通常认为如果选取区域均值(mean pooling)，往往能保留整体数据的特征，较好的突出背景信息。1.3.2. 平均池化采用 $2\\times 2$ 卷积核对 $4\\times 4$ 图像的平均池化过程：如果选取区域最大值(max pooling)，则能更好保留纹理特征。1.3.3. 池化的好处  言有三. 池化是什么意思？池化的好处：  增大感受野。所谓感受野，即一个像素对应回原图的区域大小，假如没有pooling，一个33，步长为1的卷积，那么输出的一个像素的感受野就是33的区域，再加一个stride=1的33卷积，则感受野为55。假如我们在每一个卷积中间加上3*3的pooling呢？很明显感受野迅速增大，这就是pooling的一大用处。感受野的增加对于模型的能力的提升是必要的，正所谓“一叶障目则不见泰山也”。  平移不变性。我们希望目标的些许位置的移动，能得到相同的结果。因为pooling不断地抽象了区域的特征而不关心位置，所以pooling一定程度上增加了平移不变性。  降低优化难度和参数。我们可以用步长大于1的卷积来替代池化，但是池化每个特征通道单独做降采样，与基于卷积的降采样相比，不需要参数，更容易优化。全局池化更是可以大大降低模型的参数量和优化工作量。1.3.4. 反向传播池化的反向传播比较简单。反向传播是要从缩小后的误差 $\\delta^{l+1}$ 还原池化前较大 feature map 对应的误差 $\\delta^l$。假设采用步长为 1 的$2\\times 2$ 池化，将 $4\\times 4$ 的 feature map 池化为 $2\\times 2$，如果 $\\delta^{l+1}$ 的第 $k$ 个子矩阵为\\[\\delta^{l+1}_k = \\begin{bmatrix}  2 &amp; 8\\\\  4 &amp; 6\\end{bmatrix}\\]对于最大池化，需要在前向传播时，记住每个池化块中最大值的位置，然后将误差放回去即可。假设四个位置分别为左上，右下，右上，左下，则有\\[\\delta^{l}_k = \\begin{bmatrix}  2 &amp;0&amp;0&amp; 0\\\\  0&amp;0&amp;0&amp;8\\\\  0&amp;4&amp;0&amp;0\\\\  0&amp;0&amp;6&amp;0\\end{bmatrix}\\]对于平均池化，我们只需要将池化单元的误差平均值放回原来的子矩阵即可：\\(\\delta^{l}_k = \\begin{bmatrix}  0.5&amp;0.5&amp;2&amp;2\\\\  0.5&amp;0.5&amp;2&amp;2\\\\  1&amp;1&amp;1.5&amp;1.5\\\\  1&amp;1&amp;1.5&amp;1.5\\end{bmatrix}\\)2. 参考文献[1] 木盏. 卷积的三种模式. CSDN.[2] 永远在你身后. 卷积算法的另一种高效实现，as_strided详解. 知乎."
  },
  
  {
    "title": "统计学基础（核回归）",
    "url": "/posts/statistics-kernel-regression/",
    "categories": "Academic, Knowledge",
    "tags": "statistics",
    "date": "2021-04-01 10:50:49 +0800",
    





    
    "snippet": "本文介绍了统计学中的核回归方法，并铺垫了非参数化统计方法等一些基础知识。  1. 基本知识          1.1. 回归      1.2. 近邻回归      1.3. 核回归        2. 参考文献1. 基本知识1.1. 回归回归分析（Regression Analysis）是一种统计学上分析数据的方法，目的在于了解两个或多个变量间是否相关、相关方向与强度，并建立数学模型以便观...",
    "content": "本文介绍了统计学中的核回归方法，并铺垫了非参数化统计方法等一些基础知识。  1. 基本知识          1.1. 回归      1.2. 近邻回归      1.3. 核回归        2. 参考文献1. 基本知识1.1. 回归回归分析（Regression Analysis）是一种统计学上分析数据的方法，目的在于了解两个或多个变量间是否相关、相关方向与强度，并建立数学模型以便观察特定变量来预测研究者感兴趣的变量。更具体的来说，回归分析可以帮助人们了解在只有一个自变量变化时因变量的变化量。一般来说，通过回归分析我们可以由给出的自变量估计因变量的条件期望。回归分析是建立因变量 $Y$（或称依变量，反因变量）与自变量 $X$（或称独变量，解释变量）之间关系的模型。简单线性回归使用一个自变量 $X$，复回归使用超过一个自变量（$X_{1},X_{2}…X_{i}$）。      参数回归    优点：          模型形式简单明确，仅由一些参数表达      在某些问题中，模型参数具有明确的含义（如经济问题中）      当模型参数假设成立时，统计推断的精度较高，能经受实际检验      模型能够进行外推运算      模型可以用于小样本的统计推断        缺点：          回归函数怒的形式需要预先假定      模型限制条件较多，一般要求样本满足某种分布，随机误差满足正态假设，解释变量间独立，解释变量与随机误差不相关等      模型泛化能力弱、缺乏稳健性            非参数回归    非参数回归是指并不需要知道总的分布的情况下进行的一种非参数统计方法。          非参数统计（nonparametric statistics），或称非参数统计学，统计学的分支，适用于母群体分布情况未明、小样本、母群体分布不为正态也不易变换为正态。特点在于尽量减少或不修改其建立之模型，较具稳健特性；在样本数不大时，计算过程较简单。      非参数统计推断时所使用的统计量的抽样分配通常与总体分配无关，不必推论其中位数、拟合优度、独立性、随机性，更广义的说，非参数统计又称为“不受分布限制统计法”（distribution free）。        优点：          回归函数形式自由、受约束少，对数据分布一般不做任何要求      适应能力强，稳健性高，回归模型完全由数据驱动      对于非线性、非齐次问题效果很好        缺点          不能进行外推运算      估计的收敛速度慢      一般只有在大样本下才能取得很好的效果，小样本效果较差      高维诅咒？      1.2. 近邻回归1NN（1-Nearest Neighbor）回归：找寻与输入 $x_q$ 最接近的 $x_i$ 对应的 $y_i$ 作为预测输出。缺点时对大块区域没有数据或数据不足时敏感，拟合的不好。KNN（K-Nearest Neighbor）回归：找寻 $k$ 个最近邻的点 $x_1,x_2,\\cdots,x_k$，然后对他们对应的 $y_1,y_2,\\cdots,y_k$ 求平均。加权 kNN （Weighted K-Nearest Neighbor）回归：找寻 $k$ 个最近邻的点 $X_1,X_2,\\cdots,X_k$，然后对他们对应的 $y_1,y_2,\\cdots,y_k$ 求加权平均。权重取法为，离得更近的点具备更大的权重，反之更小。简单的算法为计算距离的倒数，即\\[\\begin{aligned}y_{q} &amp;= \\frac{c_{1}y_{1}+\\cdots+c_{k}y_{k}}{\\sum_{j=1}^k c_{qj}}\\\\c_{qj} &amp;= \\frac{1}{dis(x_j,x_q)}\\end{aligned}\\]影响近邻回归性能的因素：      k如果 K 值选择的比较小，这时候我们就相当于使用较小的领域中的训练样本对实例进行预测。这时候，算法的近似误差会减小，因为只有与输入实例相近的训练样本才能才会对预测结果起作用。但是它也会有明显的缺点：算法的估计误差会偏大，预测的结果会对近邻点十分敏感，也就是说如果近邻点是噪声点的话，那么预测就会出错。也就是说，k 值太小会使得 KNN 算法容易过拟合。    同理，如果 K 值选的比较大的话，这时候距离较远的训练样本都能够对实例的预测结果产生影响。这时候，而模型相对比较鲁棒，不会因个别噪声点对最终的预测产生影响。但是缺点也是十分明显的：算法的近似误差会偏大，距离较远的点（与预测实例不相似）也会同样对预测结果产生作用，使得预测产生较大偏差。此时相当于模型发生欠拟合。    因此，在实际的工程实践过程中，我们一般采用交叉验证的方式选取 K 值。从上面的分析也可以知道，一般 k 值取得比较小。我们会选取 k 值在较小的范围，同时在测试集上准确率最高的那一个确定为最终的算法超参数 k。        距离度量方法    距离计算一般采用:          闵可夫斯基距离（欧氏距离、曼哈顿距离、切比雪夫距离）      余弦距离（余弦相似度）        闵可夫斯基距离不是一种距离，而是一类距离的定义。对于两个具有 $n$ 维特征的样本点 $\\boldsymbol x_i,\\boldsymbol x_q$，二者间的闵可夫斯基距离为\\[dis(\\boldsymbol x_i,\\boldsymbol x_q)=\\left( \\sum_{k=1}^n \\vert x_i^k - x_q^k \\vert^n \\right)^{\\frac{1}{n}}\\]    $p=1$ 时被称为曼哈顿距离；$p=2$ 时被称为欧氏距离（L2范数）；$p\\rightarrow \\infty$ 时被称为切比雪夫距离。    对于两个具有 $n$ 维特征的样本点 $\\boldsymbol x_i,\\boldsymbol x_q$，二者间的余弦相似度为\\[sim_c(\\boldsymbol x_i,\\boldsymbol x_q) = cos(\\boldsymbol x_i,\\boldsymbol x_q)=\\frac{\\boldsymbol x_i\\cdot \\boldsymbol x_q}{\\vert\\vert\\boldsymbol x_i\\vert\\vert\\cdot\\vert\\vert\\boldsymbol x_q\\vert\\vert} = \\frac{\\sum_{k=1}^n x_{ik}x_{qk}}{\\sqrt{\\sum_{k=1}^n x_{ik}^2} \\sqrt{\\sum_{k=1}^n x_{qk}^2}}\\]    则余弦距离为\\[dis_c(\\boldsymbol x_i,\\boldsymbol x_q) = 1 - sim_c(\\boldsymbol x_i,\\boldsymbol x_q)\\]    注意，余弦距离不是一个严格意义上的距离度量公式，但在形容两个特征向量之间的关系上用处很大。    当向量的模长经过归一化时，欧氏距离与余弦距离有着单调的关系\\[dis_2 = \\sqrt{2\\cdot dis_c}\\]    此时如果选择距离最小（相似度最大）的近邻，那么使用余弦相似度和欧氏距离的结果是相同的。    二者之间的使用差异如下：欧氏距离体现数值上的绝对差异，而余弦距离体现方向上的相对差异。    1) 例如，统计两部剧的用户观看行为，用户A的观看向量为(0,1)，用户B为(1,0)；此时二者的余弦距很大，而欧氏距离很小；我们分析两个用户对于不同视频的偏好，更关注相对差异，显然应当使用余弦距离。    2) 而当我们分析用户活跃度，以登陆次数(单位：次)和平均观看时长(单：分钟)作为特征时，余弦距离会认为(1,10)、(10,100)两个用户距离很近；但显然这两个用户活跃度是有着极大差异的，此时我们更关注数值绝对差异，应当使用欧氏距离。  1.3. 核回归继续细化权重，提出核权重的概念。\\[c_{qj} = k(\\boldsymbol x_i,\\boldsymbol x_q)\\]$k$ 是一个函数，一个二元函数，一个 $R^n\\times R^n \\rightarrow R^+$ 的二元函数，用来描述点与点之间的关系或者说距离的一种东西。范数就是我们之前强调的距离，或者说广义的距离。向量空间中两向量的内积可度量其距离，即内积就是这个距离的定义的方式，也即由内积可以诱导出范数。可以用内积来刻画 kernel\\[k(\\boldsymbol x_i,\\boldsymbol x_q)=&lt;\\boldsymbol x_i,\\boldsymbol x_q&gt;\\]根据不同的内积定义，可以构造出不同的核函数。k 可以用原特征空间上点内积的方式经过运算转化成高维空间点内积的函数，可以用来避免在高维空间里进行繁琐的内积计算。常用的高斯核如下\\[k_\\lambda(x_i,x_q)=exp(-\\frac{\\vert\\vert \\boldsymbol x_i-\\boldsymbol x_q\\vert\\vert^2}{\\lambda})\\]其它常用的核函数包括均匀分布核、三角核等等，如下图所示。核回归就是升级版的加权 KNN，区别在于不是加权 k 个最近的邻居，而是加权所有样本点。然后权重是由特定的核函数来确定的。\\[y_q = \\frac{\\sum_{i=1}^N c_{qi}y_i}{\\sum_{i=1}^Nc_{qi}} = \\frac{\\sum_{i=1}^N k_{\\lambda}(\\boldsymbol x_i,\\boldsymbol x_q)y_i}{\\sum_{i=1}^N k_{\\lambda}(\\boldsymbol x_i,\\boldsymbol x_q)}\\]要确定两个东西：  核  $\\lambda$$\\lambda$ 的选择根据验证集验证时的验证损失来确定。较小的 $\\lambda$ 即使得预测量近受到附近距离很近的点的影响，过小的 $\\lambda$ 会导致过拟合；过大的 $\\lambda$ 则会导致过平滑，即欠拟合。核的选择比 $\\lambda$ 的选择更重要。很多时候我们根本不知道核函数将数据映射成了什么样子，映射后的可分离性可能更好，也可能更差。这个时候我们会尝试不同的核函数和参数。对于非参数回归问题，点 $x_q$ 对应的预测值 $y_q$ 的条件期望可以写成某个未知函数 $m(\\cdot)$ 与噪声 $\\sigma$ 之和\\[y_q = \\mathbb E(y\\vert x=x_q)=m(x)+\\sigma\\]1964年，Nadaraya 和 Watson 提出了一种局部加权平均估计 $m(\\cdot)$ 方法，称为 Nadaraya-Watson 核估计（或 Nadaraya-Watson 回归）。\\[y_q = \\frac{\\sum_{i=1}^N k_{\\lambda}(\\boldsymbol x_q-\\boldsymbol x_i)y_i}{\\sum_{i=1}^N k_{\\lambda}(\\boldsymbol x_q-\\boldsymbol x_i)}\\]另外两个核估计方法为 Priestley-Chao 核估计和 Gasser——Müller 核估计。2. 参考文献[1] 维基百科. Kernel regression"
  },
  
  {
    "title": "最优控制基础（微分方程的解法）",
    "url": "/posts/optimal-control-numerical/",
    "categories": "Academic, Knowledge",
    "tags": "optimal control",
    "date": "2021-01-25 09:07:49 +0800",
    





    
    "snippet": "本文介绍了最优控制的数值解法的基础知识，包括微分方程的数值解法。  1. 多项式局部近似  2. 多项式插值          2.1. 拉格朗日插值      2.2. 重心拉格朗日插值      2.3. 切比雪夫节点        3. ODE-IPV的数值解法          3.1. 时间推进法                  3.1.1. 多步法          3.1.2...",
    "content": "本文介绍了最优控制的数值解法的基础知识，包括微分方程的数值解法。  1. 多项式局部近似  2. 多项式插值          2.1. 拉格朗日插值      2.2. 重心拉格朗日插值      2.3. 切比雪夫节点        3. ODE-IPV的数值解法          3.1. 时间推进法                  3.1.1. 多步法          3.1.2. 多段法                    3.2. 配点法                  3.2.1. 正交配点法                      4. ODE-BPV的数值解法  5. 轨迹规划与最优控制          5.1. 形式化描述      5.2. 间接法      5.3. 直接法                  5.3.1. 直接打靶法          5.3.2. 直接配点法                    5.4. 高斯伪谱法        6. 参考文献1. 多项式局部近似人们希望通过简单的函数来近似表示复杂的函数。多项式就是一类简单函数，只包含加法和乘法两种基本运算。给定函数 $f(x)$ ，要在指定点 $x$ 附近找一个与 $f(x)$ 近似的多项式\\[P(x) = a_0 + a_1x + a_2x^2 + \\cdots + a_nx^n\\]假设指定点为 $x_0$，$f(x)$ 在 $x_0$ 处可导，于是按照定义有\\[f(x) = f(x_0) + f^\\prime(x_0)(x-x_0) + O(x-x_0)\\]这表明在 $x_0$ 附近可以用一次多项式来近似表达 $f(x)$ ，而误差是高于一阶的无穷小量。从几何角度看，这就是用曲线过点 $x_0$ 的切线来近似曲线。从微分学的角度看，这种近似的特点是在点 $x_0$ 处多项式的函数值和一阶导数值与原始函数 $f(x)$ 相等。但是，许多情况下这个逼近程度不够，需要提高多项式的近似精度。为了进一步提高逼近精度，需要在该点附近构造更高阶次的多项式，即构造一个 $(x-x_0)$ 的 $n$ 次多项式\\[P_n(x) = a_0 + a_1(x-x_0) + a_2(x-x_0)^2 + \\cdots + a_n(x-x_0)^n\\]我们希望该多项式在 $x_0$ 处的函数值及其直到 $n$ 阶导数值都与 $f(x)$ 的相应值分别相等，即\\[\\begin{aligned}P_n(x_0) &amp;= a_1 = f(x_0)\\\\P^\\prime_n(x_0) &amp;= a_1 = f^\\prime(x_0)\\\\P^{\\prime\\prime}_n(x_0) &amp;= 2a_2 = f^{\\prime\\prime}(x_0)\\\\\\cdots\\\\P^{(n)}_n(x_0) &amp;= n!a_n = f^{(n)}(x_0)\\\\\\end{aligned}\\]于是有\\[\\begin{aligned}P_n(x) = &amp;f(x_0) \\\\&amp; + f^\\prime(x_0)(x-x_0)\\\\&amp; + \\frac{1}{2}f^{\\prime\\prime}(x_0)(x-x_0)^2\\\\&amp; + \\cdots\\\\&amp; + \\frac{1}{n!}f^{(n)}(x_0)(x-x_0)^n\\end{aligned}\\]称 $P_n(x)$ 为 $f(x)$ 在点 $x_0$ 处的 $n$ 阶泰勒多项式。  匿名用户. 如何通俗地解释泰勒公式？总结  泰勒公式的作用是描述如何在 $x_0$ 点附近, 用一个多项式函数 $P_n(x)$ 去近似一个复杂函数 $f(x)$；  之所以能实现这种近似, 背后的逻辑是：          多项式函数在 $x=x_0$ 处的值, 一阶导, 二阶导 …$n$ 阶导的值 = 原始函数在 $x=x_0$ 处的值, 一阶导, 二阶导 …$n$ 阶导；      多项式和函数在某一点的值一样, 变化率一样, 变化率的变化率一样, 变化率的变化率的变化率也一样…      就这样层层深入, 无论深入到哪一个维度, 关于这一点的变化率, 二者都相等, 那就可以推断：                  在这一点上, 函数和多项式应该是一样的；          在这一点附近, 函数和多项式应该很相似；          离这一点越远, 函数和多项式的相似程度就越难以保证。                    2. 多项式插值在实际问题中，往往通过实验或观测得出表示某种规律的数量关系 $y=F(x)$，通常只给出了 $F(x)$ 在某些点 $x_i$ 上的函数值 $y_i=F(x_i), i=1,2,\\cdots,n+1$。即使有时给出了函数 $F(x)$ 的解析表达式，倘若较为复杂，也不便于计算。因此，需要根据给定点 $x_i$ 上的函数值 $F(x_i)$,求出一个既能反映 $F(x)$ 的特性，又便于计算的简单函数 $ƒ(x)$ 来近似地代替 $F(x)$,此时 $ƒ(x)$ 称为 $F(x)$ 的插值函数；$x_1,x_2,\\cdots,x_{n+1}$ 称为插值节点。求插值函数的方法，称为插值法。多项式是一类简单的初等函数，而且任给两组数：$b_1,b_2,\\cdots,b_{n+1}$ 和各不相同的 $с_1,с_2,\\cdots,с_{n+1}$，总有唯一的次数不超过 $n$ 的多项式 $ƒ(x)$ 满足 $ƒ(с_i)=b_i, i=1,2,\\cdots,n+1$。因此在实际应用中常常取多项式作为插值函数。作为插值函数的多项式，称为插值多项式。2.1. 拉格朗日插值拉格朗日插值法，给定某个函数 $y(x)$，选择 $k+1$ 个插值点 $(x_0,y_0),\\cdots,(x_k,y_k)$，其中 $x_j$ 对应坐标点，$y_j$ 为对应这个坐标点的值，那么拉格朗日插值多项式为：\\[L(x) := \\sum_{j=0}^k y_jl_j(x)\\]其中，每个 $l_j(x)$ 为拉格朗日基本多项式（或称插值基函数），其表达式为：\\[l_j(x) := \\prod_{i=0,i\\neq j}^k \\frac{x-x_i}{x_j-x_i}= \\frac{x-x_0}{x_j-x_0}\\cdots\\frac{x-x_{j-1}}{x_j-x_{j-1}}\\frac{x-x_{j+1}}{x_j-x_{j+1}}\\cdots\\frac{x-x_k}{x_j-x_k}\\]拉格朗日基本多项式 $l_j(x)$ 的性质：  在 $x_{j}$ 上取值为 $1$；  在其它的点 $x_{i},\\,i\\neq j$ 上取值为 $0$。这个性质保证了，在给定的所有离散点 $(x_j,y_j)$ 上：  $y_jl_j(x)$ 在 $x_j$ 处取值为 $y_j$；  $y_jl_j(x)$ 在其余点处取值为 0。对于给定的若 $n+1$ 个点，对应于它们的次数不超过 $n$ 的拉格朗日多项式只有一个。证明略。以三个点的拉格朗日插值为例 [2]，如图所示，我们想找一根穿过它的曲线，我们可以合理的假设，这根曲线是一个二次多项式\\[y=a_0+a_1x + a_2x^2\\]牛逼的拉格朗日认为，需要找到三个二次曲线作为基，就可以达到目标。拉格朗日插值法的公式结构整齐紧凑，在理论分析中十分方便，然而在计算中，当插值点增加或减少一个时，所对应的基本多项式就需要全部重新计算，于是整个公式都会变化，非常繁琐。这时可以用重心拉格朗日插值法或牛顿插值法来代替。此外，当插值点比较多的时候，拉格朗日插值多项式的次数可能会很高，因此具有数值不稳定的特点，也就是说尽管在已知的几个点取到给定的数值，但在附近却会和 “实际上” 的值之间有很大的偏差（如下图）。这类现象也被称为龙格现象，解决的办法是分段用较低次数的插值多项式。上图展示了拉格朗日插值法的数值稳定性：如图，用于模拟一个十分平稳的函数时，插值多项式的取值可能会突然出现一个大的偏差（图中的14至15中间）2.2. 重心拉格朗日插值重心拉格朗日插值（第一型）是拉格朗日插值法的一种改进。在拉格朗日插值法中，运用多项式\\[l(x) = (x-x_0)(x-x_1)\\cdots(x-x_k)\\]可以将拉格朗日基本多项式重新写为：\\[l_j(x) = \\frac{l(x)}{x-x_j}\\frac{1}{\\prod_{i=0,i\\neq j}^k(x_j-x_i)}\\]定义重心权\\[\\omega_j = \\frac{1}{\\prod_{i=0,i\\neq j}^k(x_j-x_i)}\\]上面的表达式可简化为\\[l_j(x) = l(x)\\frac{\\omega_j}{x-x_j}\\]于是拉格朗日插值多项式变为：\\[L(x) = l(x)\\sum_{j=0}^k \\frac{\\omega_j}{x-x_j}y_j\\]它的优点是当插值点的个数增加一个时，将每个 $\\omega_{j}$ 都除以 $(x_{j}-x_{k+1})$，就可以得到新的重心权 $\\omega_{k+1}$，计算复杂度为 ${\\mathcal  O}(n)$，比重新计算每个基本多项式所需要的复杂度 ${\\mathcal  O}(n^{2})$ 降了一个量级。将以上的拉格朗日插值多项式用来对函数 $g(x)\\equiv 1$ 插值，可以得到：\\[\\forall x, g(x) = l(x) \\sum_{j=0}^k \\frac{\\omega_j}{x-x_j}\\]因为 $g(x) \\equiv 1$ 是一个多项式，因此将 $L(x)$ 除以 $g(x)$ 得到\\[L(x) = \\frac{\\sum_{j=0}^k\\frac{\\omega_j}{x-x_j}y_j}{\\sum_{j=0}^k\\frac{\\omega_j}{x-x_j}}\\]上述公式被称为重心拉格朗日插值公式（第二型）。它继承了第一型式容易计算的特点，并且在代入 $x$ 值计算 $L(x)$ 的时候不必计算多项式 $l(x)$。它的另一个优点是，结合切比雪夫节点进行插值的话，可以很好地模拟给定的函数，使得插值点个数趋于无穷时，最大偏差趋于零。同时，重心拉格朗日插值结合切比雪夫节点进行插值可以达到极佳的数值稳定性。第一型拉格朗日插值是向后稳定的，而第二型拉格朗日插值是向前稳定的，并且勒贝格常数很小。2.3. 切比雪夫节点第一类切比雪夫多项式 $T_n$ 由以下递推关系确定：\\[\\begin{aligned}  T_0(x) &amp;= 1\\\\  T_1(x) &amp;= x\\\\  T_{n+1}(x) &amp;= 2xT_n(x) - T_{n-1}(x),\\ n=1,2,\\cdots\\\\\\end{aligned}\\]前 4 阶第一类切比雪夫多项式为\\[\\begin{aligned}  T_0(x) &amp;= 1\\\\  T_1(x) &amp;= x\\\\  T_2(x) &amp;= 2x^2 - 1\\\\  T_3(x) &amp;= 4x^3 - 3x\\\\  T_4(x) &amp;= 8x^4 - 8x^2+1\\\\\\end{aligned}\\]第一类切比雪夫多项式的根又被称为切比雪夫节点，在 $[0,1]$ 区间内为\\[x_k=cos(\\frac{2k-1}{2n}\\pi),\\ k=1,\\cdots,n\\]  多项式的根为使得多项式取值为 0 的值，即多项式曲线与横坐标轴的交点。形象的看，切比雪夫节点等价于 $n$ 等分单位半球的点的 $x$ 坐标（下图中 $n=10$）。对于任意区间 $[a,b]$，切比雪夫节点为\\[x_k=\\frac{1}{2}(a+b) + \\frac{1}{2}(b-a)cos(\\frac{2k-1}{2n}\\pi),\\ k=1,\\cdots,n\\]切比雪夫节点广泛用于多项式插值，因为他们具备一个很好的性质，即具有最小的龙格现象。3. ODE-IPV的数值解法微分方程的初值问题（ODE-IVP）如下\\[\\left\\{\\begin{array}{l}  \\dot{x}=f(x(t),t),\\quad t\\in[t_n,t_{n+1}]\\\\  x(t_0)=x_0\\end{array}\\right.\\]其中，$f$ 为 $x,t$ 的已知函数，$x_0$ 为给定的初值。在以下讨论中，假设函数 $f(x,t)$ 在区域 $t_0\\leq t\\leq T, \\vert x\\vert&lt;\\infty$ 内连续，并且关于 $x$ 满足 Lipschitz 条件，使得\\[\\vert f(x, t) - f(\\overline x, t) \\vert \\leq L\\vert x - \\overline x \\vert\\]由常微分方程理论，在以上假设下，初值问题必定且唯一存在数值解 $x(t)$。由于常微分方程的解析解求解困难，到目前为止我们只能对少数几个特殊类型的方程求得解析解，很多实际问题中常常得不到初等函数表示的解，需要求数值解。假设 $t_n$ 时刻的状态量取值为 $x(t_n) = x_n$，则下一时刻 $t_{n+1}$ 的状态量取值 $x(t_{n+1}) = x_{n+1}$ 可以通过对原始微分式进行积分求得\\[x_{n+1} = x_n + \\int_{t_n}^{t_{n+1}}f(x(s),s)ds\\]常微分方程初值问题的数值解法，就是给定初值 $x(t_0)=x_0$ 的基础上，寻求微分方程在一系列离散节点 $t_1,t_2,\\cdots,t_n$ 上的近似值 $x_1,x_2,\\cdots,x_n$。由于微分方程的解的图形时一条曲线，叫做微分方程的积分曲线，初值问题的几何意义，就是求微分方程通过初值点 $(t_0,x_0)$ 的那条积分曲线。解决上述问题有两种方法：时间推进法和配点法。3.1. 时间推进法Time-Marching，时间推进法，微分方程在每个时刻的解根据前面一个或多个时刻的解求得。时间步进法再次被分为两类：多步法（multiple-step）和多阶段法（multiple-stage）。3.1.1. 多步法又称为 linear multiple-step method，即 $t_{n+1}$ 时刻微分方程的解由 $t_{n-j},\\cdots,t_n$ 时刻的解求得，$j$ 为步长。  单步法（欧拉法）最简单的多步法就是单步法，即 $j=1$，最常用的单步法为欧拉法（Euler Method），具备如下的形式。\\[x_{n+1} = x_n + h_n[b f_n + (1-b)f_{n+1}]\\]其中 $f_n=f[x(t_n),t_n]$，$b\\in[0,1]$，$h_n$ 是步长。当 $b=1$ 时，为对应前向欧拉法；$b=0$ 时，为对应后向欧拉法。以后向欧拉法为例\\[x_{t+1} = x_t + h\\cdot f(x_t,t)\\]当 $b=1/2$ 时，为对应改进的欧拉法。欧拉法也可以从一阶泰勒多项式变化得到。改进的欧拉法可以采用 预测-校正 模型来实施。\\[\\begin{aligned}\\overline x_{t+1} &amp;= x_t + h\\cdot f(x_t,t)\\\\x_{t+1} &amp;= x_t + \\frac{1}{2}h\\cdot [f(x_t,t)+f(\\overline x_{t+1},t+1)]\\\\\\end{aligned}\\]  多步法当 $j&gt;1$ 时，就是更加复杂的线性多步法。形如\\[\\begin{aligned}&amp;a_0x_n + \\cdots + a_{j-1}x_{n+j-1} + a_jx_{n+j} =\\\\&amp;h(b_0f(x_n,t_n) + \\cdots + b_{j-1}f(x_{n+j-1},t_{n+j-1})+b_jf(x_{n+j},t_{n+j}))\\end{aligned}\\]其中 $a_j=1$。系数 $a_0,\\cdots,a_{j-1}$ 和 $b_0,\\cdots,b_j$ 的选取决定了多步法的具体形式，一般在逼近程度和计算简便性上进行权衡。更加普遍的情况下，其中绝大部分的系数都置为0。如果 $b_j=0$ 则称为显式法，因为可以直接根据等式计算 $x_{n+j}$。如果$b_j\\neq 0$ 则称为隐式法，因为 $x_{n+j}$ 依赖于 $f(x_{n+j},t_{n+j})$，需要通过迭代的方法来求解，比如采用牛顿迭代法。有时候，采用显式多步法来 『预测』 $x_{n+j}$，然后用隐式来 『校正』它，这种方式称为 预测-校正法（predictor–corrector method）。下面列举两种常用的线性多步法家族。Adams-Bashforth methods，一种显式法，其中 $a_{j-1}=-1$ 而 $a_{j-2}=\\cdots=a_0=0$，然后设计 $b_j$ 来使得方法具备 $j$ 阶精度（同时也使得算法具备唯一性）。$j=1,2,3$ 步 Adams-Bashforth 方法如下：\\[\\begin{aligned}  x_{n+1} &amp;= x_n + hf(x_n, t_n)\\quad (前向欧拉法)\\\\  x_{n+2} &amp;= x_{n+1} + h[\\frac{3}{2}f(x_{n+1}, t_{n+1})-\\frac{1}{2}f(x_{n}, t_{n})]\\\\  x_{n+3} &amp;= x_{n+2} + h[\\frac{23}{12}f(x_{n+2}, t_{n+2})-\\frac{16}{12}f(x_{n+1}, t_{n+1})+\\frac{5}{12}f(x_{n}, t_{n})]\\\\\\end{aligned}\\]$j=2$ 质为泰勒展开保留至二阶，并用差分代替二阶微分项。\\[\\begin{aligned}x_{n+1} &amp;= x_n + hf(x_n,t_n) + \\frac{h^2}{2}\\dot f(x_n,t_n)+\\cdots\\\\x_{n+2} &amp;= x_{n+1} + hf(x_{n+1},t_{n+1}) + \\frac{h^2}{2}\\dot f(x_{n+1},t_{n+1})\\\\&amp;= x_{n+1} + hf(x_{n+1},t_{n+1}) + \\frac{h^2}{2}[\\frac{f(x_{n+1},t_{n+1})-f(x_{n},t_{n})}{h}]\\\\&amp;= x_{n+1} + h[\\frac{3}{2}f(x_{n+1}, t_{n+1})-\\frac{1}{2}f(x_{n}, t_{n})]\\end{aligned}\\]另一种如何确定参数 $b_j$ 的方法略，可参考维基百科。注意到，多步法需要多个历史数据 $x_n,x_{n+1}$ 来计算下一步 $x_{n+2}$，而常微分方程的初值问题一般只给出初始时刻的初值，因此不能直接从该值启动。常用方法是用 Euler 法或者 Runge-Kutta 法来启动，计算出前几个值。Adams-Moulton methods，一种隐式法，与 Adams-Bashforth 方法很类似，只是设计 $b_j$ 使得精度阶数尽可能高（$j$ 阶 Adams-Moulton 法具备 $j+1$ 阶精度，而$j$ 阶 Adams-Bashforth 法只具备 $j$ 阶精度）。$j=1,2$ 步 Adams-Moulton 方法如下：\\[\\begin{aligned}  x_{n+1} &amp;= x_n + hf(x_{n+1}, t_{n+1})\\quad (后向欧拉法)\\\\  x_{n+1} &amp;= x_n + \\frac{1}{2}h[f(x_{n+1}, t_{n+1})+f(x_n, t_n)]\\quad (梯形法则)\\\\  x_{n+2} &amp;= x_{n+1} + h[\\frac{5}{12}f(x_{n+2}, t_{n+2})+\\frac{3}{2}f(x_{n+1}, t_{n+1})-\\frac{1}{12}f(x_{n}, t_{n})]\\\\\\end{aligned}\\]3.1.2. 多段法又称为 multiple-stage method，是在 $[t_n,t_{n+1}]$ 区间内划分若干临时段，然后进行迭代求解的一种常微分方程数值解法。多段法只需要用到一步的历史信息，但是将这一步区间划分为许多段。多段法其中最常用的是 龙格-库塔（Runge-Kutta） 法。定义步长为 $h$，将区间划分为 $s$ 个子区间，则 $s$ 阶显式 Runge-Kutta 公式为\\[\\begin{aligned}x_{n+1} &amp;= x_n + h\\sum_{i=1}^sb_ik_i\\\\k_1&amp;= f(x_n,t_n)\\\\k_2&amp;= f(x_n+h(a_{21}k_1),t_n+c_2h)\\\\k_3&amp;= f(x_n+h(a_{31}k_1+a_{32}k_2),t_n+c_3h)\\\\\\vdots\\\\k_s&amp;= f(x_n+h(a_{s1}k_1+a_{s2}k_2+\\cdots+a_{s,s-1}k_{s-1}),t_n+c_sh)\\\\\\end{aligned}\\]龙格库塔法的基本思路是，用 $f(x,t)$ 在几个不同点的数值加权平均代替 $f(x_{n+1},t_{n+1})$ 的值，而使截断误差的阶数尽可能高。也就是说，取不同点的斜率加权平均作为平均斜率，从而提高方法的阶数。这样可以保留泰勒展开法所具有的高阶局部截断误差，同时避免了计算函数 $f(x,t)$ 的高阶导数。龙格库塔法包含的系数为 $b_i, a_{ij},c_i$，需要与泰勒展开公式各项系数做对比来确定这些系数。  一阶龙格库塔法泰勒展开到一阶导为\\[x_{n+1} = x_n + hf(x_n,t_n)+\\cdots\\]一阶龙格库塔公式：$s=1$ 时为\\[\\begin{aligned}x_{n+1} &amp;= x_n + hb_1k_1\\\\k_1 &amp;= f(x_n,t_n)\\\\\\Rightarrow x_{n+1} &amp;= x_n + hb_1f(x_n,t_n)\\end{aligned}\\]下面确定系数 $b_1$。与泰勒展开对比，相应项系数保持一致，有\\[b_1=1\\]可以看出，1 阶龙格库塔法就是显式欧拉法。  二阶龙格库塔法泰勒展开到二阶导为\\[\\begin{aligned}x_{n+1} &amp;= x_n + hf(x_n,t_n) + \\frac{h^2}{2}\\dot f(x_n,t_n)+\\cdots\\\\&amp;=x_n + hf(x_n,t_n) + \\frac{h^2}{2}\\left[\\frac{\\partial f(x_n,t_n)}{\\partial x}f(x_n,t_n)+\\frac{\\partial f(x_n,t_n)}{\\partial t}\\right] + \\cdots\\end{aligned}\\]注意，上式隐含了条件 $\\frac{\\partial x}{\\partial t}=\\dot x = f(x_n,t_n)$二阶龙格库塔法：$s=2$ 时为\\[\\begin{aligned}x_{n+1} &amp;= x_n + h(b_1k_1+b_2k_2)\\\\k_1&amp;= f(x_n,t_n)\\\\k_2&amp;= f(x_n+h(a_{21}k_1),t_n+c_2h)\\\\\\Rightarrow x_{n+1} &amp;= x_n + hb_1f(x_n,t_n)+hb_2f(x_n+h(a_{21}k_1),t_n+c_2h)\\end{aligned}\\]相当于在区间 $[t_n,t_n+1]$ 取两个点 $t_n,t_{n}+c_2h$，计算该两个点的斜率值 $k_1,k_2$，然后做加权平均。为了与上述泰勒展开式进行系数对比，需要对斜率 $k_2$ 在 $(x_n,t_n)$ 处做泰勒展开，遵循二元函数的泰勒展开公式，形式如下\\[\\begin{aligned}  f(x_0+h,y_0+k) = f(x_0,t_0) + (h\\frac{\\partial}{\\partial x}+k\\frac{\\partial}{\\partial y})f(x_0,y_0)+\\cdots\\end{aligned}\\]展开后有\\[\\begin{aligned}  k_2 &amp;= f(x_n+h(a_{21}k_1),t_n+c_2h)\\\\  &amp;=f(x_n,t_n) + ha_{21}k_1\\frac{\\partial f(x_n,t_n)}{\\partial x} + c_2h\\frac{\\partial f(x_n,t_n)}{\\partial t}\\\\  &amp;=f(x_n,t_n) + ha_{21}\\frac{\\partial f(x_n,t_n)}{\\partial x}f(x_n,t_n) + c_2h\\frac{\\partial f(x_n,t_n)}{\\partial t}\\\\\\end{aligned}\\]带回到二阶龙格库塔的展开式中，有\\[\\begin{aligned}  x_{n+1} &amp;= x_n + hb_1f(x_n,t_n)+hb_2f(x_n+h(a_{21}k_1),t_n+c_2h)\\\\  &amp;= x_n + hb_1f(x_n,t_n)+hb_2 \\left[ f(x_n,t_n) + ha_{21}\\frac{\\partial f(x_n,t_n)}{\\partial x}f(x_n,t_n) + c_2h\\frac{\\partial f(x_n,t_n)}{\\partial t} [\\right]\\\\  &amp;=x_n + h(b_1+b_2)f(x_n,t_n) + \\frac{h^2}{2}\\left[ 2b_2a_{21}\\frac{\\partial f(x_n,t_n)}{\\partial x}f(x_n,t_n) + 2b_2c_2\\frac{\\partial f(x_n,t_n)}{\\partial t} \\right]\\end{aligned}\\]与泰勒展开式进行系数对比，有\\[b_1+b_2=1,\\quad 2b_2a_{21}=1,\\quad 2b_2c_2 = 1\\]四个未知数，三个方程，因此存在无穷多个系数组合。所有满足的系数统称为二阶龙格库塔格式。注意到， $b_1=b_2=0.5,\\;a_{21}=c_2=1$，对应的二阶龙格库塔公式为\\[\\begin{aligned}x_{n+1} &amp;= x_n + \\frac{h}{2}(k_1+k_2)\\\\k_1&amp;= f(x_n,t_n)\\\\k_2&amp;= f(x_n+hk_1,t_n+h)\\\\\\end{aligned}\\]这就是改进的 Euler 法。  三阶龙格库塔法：略。可参考百度文库. 龙格库塔法推导  四阶龙格库塔法：$s=4$ 时，四阶龙格库塔法如下\\[\\begin{aligned}x_{n+1} &amp;=x_n + \\frac{1}{6}h(k_1+2k_2+2k_3+k_4)\\\\k_1 &amp;= f(x_n,t_n)\\\\k_2 &amp;= f(x_n+h\\frac{k_1}{2},t_n + \\frac{h}{2})\\\\k_3 &amp;= f(x_n+h\\frac{k_2}{2},t_n + \\frac{h}{2})\\\\k_4 &amp;= f(x_n+hk_3,t_n + h)\\\\\\end{aligned}\\]证明过程略。可参考百度文库. 龙格库塔法推导最常用四阶龙格库塔法，因为龙格库塔公式的截断精度并不是随着阶数的增高而提高的，当 $s=5,6$ 时的龙格库塔公式仍然只有四阶精度，只有到 $s=7$ 才具备五阶精度。总结：Runge-Kutta 公式的思路，就是利用区间内一些特殊点的一阶导数值的线性组合来替代某点处的 $n$ 阶导数值，这样就可以仅通过一系列一阶导数值来得到某点幂级数展开的预测效果。这和泰勒公式正好是反过来的，泰勒公式是用某点的 $n$ 阶幂级数展开来近似得到小邻域内的函数值。3.2. 配点法配点法选择的有限维候选解空间（通常是展开到一定阶数的多项式）和域中的多个点（称为配点），并选择在配点处满足给定方程的解 。一种简单的方式是采用如下形式的 $n$ 阶分段多项式来近似状态量取值\\[p(t) = \\sum_{i=0}^n a_i(t-t_0)^i,\\ t\\in[t_0,t_1]\\]假设希望求微分方程初值问题\\[\\left\\{\\begin{array}{l}  \\dot{x}=f(x(t),t)\\\\  x(t_0)=x_0\\end{array}\\right.\\]在区间 $[t_0,t_0+c_kh]$ 的解，其中 $0&lt;c_1&lt;\\cdots&lt;c_n\\leq1$。配点法设计一个 $n$ 阶多项式 $p$，使多项式满足以下两个约束  初始条件 $p(t_{0})=x_{0}$  微分方程 $\\dot p(t_{k})=f(p(t_{k}),t_{k}),\\ k=1,\\cdots,n$后者被称为配点条件，使得多项式在区间的每个配点 $t_1,\\cdots,t_n$ 上的微分均等于微分方程的等式右边。上面两个约束提供了 $n+1$ 个条件，正好对应 $n$ 阶多项式中的 $n+1$ 个待定参数。举例：梯形法/改进的欧拉法（两个配点 $c_1=0, c_2 = 1$，那么 $n=2$）配点条件为\\[\\begin{aligned}  p(t_0) &amp;= x_0\\\\  \\dot p(t_0) &amp;= f(p(t_0),t_0)\\\\  \\dot p(t_0+h) &amp;= f(p(t_0+h),t_0+h)\\end{aligned}\\]因为有三个配点条件，因此多项式的阶数为 2。假设多项式为如下形式\\[p(t) = a_2(t-t_0)^2 + a_1(t-t_0) + a_0\\]将多项式及其导数带入上面的配点条件，可以解出三个系数\\[\\begin{aligned}a_0 &amp;= x_0\\\\a_1 &amp;= f(p(t_0),t_0)\\\\a_2 &amp;= \\frac{1}{2h}[f(p(t_0+h),t_0+h)-f(p(t_0),t_0)]\\\\\\end{aligned}\\]则 $t_0+h$ 位置的微分方程的近似解为\\[x_1 = p(t_0+h) = x_0 + \\frac{1}{2}h[f(x_1,t_0+h)+f(x_0,t_0)]\\]配点法包括三个种类：  Gauss 配点法（始末端点 $t_k,t_{k+1}$ 均不是配点）  Radau 配点法（始末端点 $t_k,t_{k+1}$ 任意一个是配点）  Lobatto 配点法（始末端点 $t_k,t_{k+1}$ 均是配点）所有这些配点法本质上都是隐式龙格库塔法，但不是所有龙格库塔法都是配点法。从另外一个角度，龙格库塔法（包括一阶欧拉法）既可以看作是分段法，又可以看作是配点法。其中的区别在于，从配点法的形式来看，所有微分方程是同时被解出的（多项式的所有参数同时确定），而分段法中所有参数是迭代解出的。类似地，配点法被认为是一种隐式解法，因为所有时刻的状态均同时被解出（所有多项式参数同时确定后，将所有时刻带入多项式得到所有时刻的状态量），有别于时间推进方法中状态量序列的一步步显式解出。最后，配点法也不需要采用「预测」-「校正」策略。总结：  坐标点选择随意，比如等距取点；  状态量取值点选择分段多项式近似；3.2.1. 正交配点法orthogonal collocation methods，配点法中的一个非常常用的具体方法族。与一般配点法的不同在于其采用正交多项式。具体而言，在正交配点方法中，配点是某个正交多项式的根，一般为 切比雪夫（Chebyshev）多项式 或者 Legendre 多项式。正交配点法一般配合拉格朗日多项式进行来近似解。即  坐标点选择正交多项式的根，比如切比雪夫节点；  状态量取值点选择拉格朗日多项式近似；使用正交配点法的好处在于，可以获得明显高于所使用的配点数的精度。4. ODE-BPV的数值解法微分方程的边值问题（ODE-BPV） 类似初值问题。边值问题的条件是在区域的边界上，而初值问题的条件都是在独立变量及其导数在某一特定值时的数值（一般是定义域的下限，所以称为初值问题）。例如独立变量是时间，定义域为 $[0,1]$，边值问题的条件会是 $x(t)$ 在 $t=0$ 及 $t=1$ 时的数值，而初值问题的条件会是 $t=0$ 时的 $x(t)$ 及 $x^\\prime(t)$ 之值。解决边值问题一般采用：  打靶法  差分  伽辽金法  配点法5. 轨迹规划与最优控制轨迹用来描述一个物体的运动过程，通常是关于时间的变量。轨迹优化一种用于寻找最佳轨迹选择的方法，通常是通过选择合适的系统输入或控制量，是系统完成期望的运动过程。在控制领域，轨迹优化近似于最优控制，但从更广的概念上来讲，轨迹优化更具一般性。数值解法将最优控制问题转化成一个等效问题，然后用数值优化的方法来求解该等效问题。因此，数值解法主要包括了最优控制问题的转化和解等效问题两部分。其中，最优控制问题的转化方法主要有直接法和间接法两类。5.1. 形式化描述  目标函数\\[\\mathop{\\rm min}\\limits_{t_0,t_f,\\boldsymbol{x}(t),\\boldsymbol{u}(t)} \\underbrace{J(t_0,t_f,\\boldsymbol x(t_0),\\boldsymbol x(t_f))}_{\\rm Mayer\\; Term} + \\underbrace{\\int_{t_0}^{t_f} H(\\tau,\\boldsymbol x(\\tau),\\boldsymbol u(\\tau))d\\tau}_{\\rm Lagrange\\; Term}\\]约束包括：  动力学约束\\[\\dot{\\boldsymbol{x}}(t)=f(\\boldsymbol{x}(t),\\boldsymbol{u}(t),t)\\]  路径约束\\[\\boldsymbol h(\\boldsymbol x(t),\\boldsymbol u(t),t)\\leq \\boldsymbol 0\\]  边界约束\\[\\boldsymbol g(\\boldsymbol x(t_0),\\boldsymbol x(t_f),t_0,t_f)\\leq \\boldsymbol 0\\]  状态量与控制量边界\\[\\begin{aligned}\\boldsymbol x_{lb}\\leq\\boldsymbol x(t)\\leq \\boldsymbol x_{ub}\\\\\\boldsymbol u_{lb}\\leq\\boldsymbol u(t)\\leq \\boldsymbol u_{ub}\\end{aligned}\\]由于最终我们想要求得的是控制量关于时间的具体函数形式，而非一个值或一个参数，因此轨迹优化问题也可以理解为在一定约束或大量约束下的泛函求极值问题。5.2. 间接法变分法5.3. 直接法直接法是通过把原原始优控制问题的控制变量或状态变量离散和参数化，从而实现现将连续系统统合为最优控题题转化为一个非线性规划问题（NLP），之后再采用某种优 法求解使 NLP 问题性能指标最优的参数，并最终获得得原最优控制问题的最优解。该方法最大的优点是不需要推导原始问题的一阶最优性必要条件，同时收敛域相对于间接法更加宽广，对初值估计精度要求不高，不需要猜猜测协态变量量初值，也不需切切换结构先验验知识。5.3.1. 直接打靶法5.3.2. 直接配点法直接配点法（direct collocation methods）的算法核心是：先将整个时间过程划分为 $N$ 段，毎一段的两个端点称为节点。之后将节点上的控制变董作为一部分设计优化变量，并采用分段线性插值或拉格朗日插值多项式来近似节点之间的控制变量值。与直接打靶法不同的是，配点法不是通过积分状态方程来获得状态变量，而是采用 Gmiss-Lobatto 多项式族来表示节点间状态变量隨时间的变化关系，并根据特定的雅可比多项式选择配点。雅可比多项式是 $[-1，1]$ 区间上的正交多项式族。在选择的配点处应使多项式求导得到的状态变量导数与动态系统运动方程右函数求得的状态变量导数在一定精度条件下相匹配，即将动力学微分方程约束转化为一组代数约束。再以节点处的状态变景和控制变量以及配点处的控制变量作为设计优化变量，并采用某神非线性规划算法，搜索满足约束且使目标函数最小的最优解。下面我们用一个例子来进一步说明配点法如何应用于轨迹优化最优控制问题[1]。如图所示，一个滑块放置在光滑地面上，并受到一个水平方向的作用力。我们想要滑块在里的作用下，在 1s 的时间内从开始位置运动到指定位置，并刚好停在该处。这个问题存在着无数种可能的运动轨迹，进一步，我们希望从中确定一条最优的轨迹，如图所示。系统状态方程为\\[\\dot x = v,\\quad \\dot v = u\\]边界约束为\\[\\begin{aligned}x(0) = 0,\\quad x(1) = 1\\\\v(0) = 0,\\quad v(1) = 0\\end{aligned}\\]轨迹优化关心在一定指标下的最优轨迹，假设需要能量最优，则目标函数为\\[\\mathop{\\rm min}\\limits_{u(t)}\\int_0^1 u^2(\\tau)d\\tau\\]直接配点法的核心思想是将连续时间曲线离散为有限时间序列，从而把轨迹规划问题转化大规模非线性规划问题。首先，我们对轨迹进行离散化，将状态变量 $x(t)$ 和 $v(t)$ 表示为一系列离散时刻上的值，也称为配置点：\\[\\begin{aligned}t\\rightarrow t_0,\\cdots,t_N\\\\x\\rightarrow x_0,\\cdots,x_N\\\\v\\rightarrow v_0,\\cdots,v_N\\\\u\\rightarrow u_0,\\cdots,u_N\\\\\\end{aligned}\\]这些配置点实际上就是最终转化的 NLP 问题优化变量，$N$ 表示离散的细化程度，N越大则离散化误差越小，但优化难度越大。其次，要把原始问题在这些配置点处进行近似表示，其核心思想是两个配置点之间的状态变化等于系统动力学的积分：\\[\\begin{aligned}\\dot x &amp;= v\\\\\\int_{t_k}^{t_{k+1}}\\dot xdt &amp;= \\int_{t_k}^{t_{k+1}}vdt\\\\x_{x+1}-x_k&amp;\\approx \\frac{1}{2}(t_{k+1}-t_k)(v_{k+1}+v_k)\\end{aligned}\\]由于位置的微分等于速度，对等式两侧进行积分，从时刻 $t_k$ 积分到时刻 $t_{k+1}$ 。等式左侧自然等于两个状态之间的差值，而对于等式右侧我们用梯形积分公式进行近似。把速度与作用力的动力学关系同样转化成上面的形式，忽略由梯形积分近似的误差，得到以下由配置点表示的约束方程，其中 $h_k = t_{k+1}-t_k$\\[\\begin{aligned}x_{k+1}-x_{k}=\\frac{1}{2}\\left(h_{k}\\right)\\left(\\nu_{k+1}+\\nu_{k}\\right)\\\\u_{k+1}-\\nu_{k}=\\frac{1}{2}\\left(h_{k}\\right)\\left(u_{k+1}+u_{k}\\right)\\end{aligned}\\]这样，通过离散化，我们把原来连续的动力学方程中的每个变量均转化为 $N$ 个等式约束。当然为了满足问题要求，配置点还要满足以下的约束\\[\\begin{aligned}x_0 = 0,\\quad x_N = 1\\\\v_0 = 0,\\quad v_N = 0\\end{aligned}\\]最后，通过采用梯形积分近似的方法，将目标函数也用配置点进行表示\\(\\mathop{\\rm min}\\limits_{u(t)}\\int_0^1 u^2(\\tau)d\\tau = \\mathop{\\rm min}\\limits_{u_0,\\cdots,u_N}\\sum_{k=0}^{N-1}\\frac{1}{2}h_k(u_k^2 + u_{k+1}^2)\\)至此，滑块移动问题被完全转化为一个 $3N$ 个优化变量（配置点），$2N+4$ 个约束的非线性规划问题，采用类似内点法的非线性规划求解器（IPOPT）进行求解，就可以得到问题数值结果。在上面的例子中，我们采用梯形公式来近似积分，将问题中的所用连续问题转化为离散问题，这种方法称为梯形配点法。梯形法是一种低阶多项式，还可以采用更加高阶的多项式，如 三阶 Simpson 法等。这些多项式都属于 Gauss-Lobatto 多项式族。5.4. 高斯伪谱法      谱方法        伪谱法  6. 参考文献[1] 马同学. 如何直观地理解拉格朗日插值法？[2] 素_履. 轨迹优化与直接配点法[3] 百度文库. 龙格库塔法推导"
  },
  
  {
    "title": "深度学习基础（高斯过程）",
    "url": "/posts/deep-learning-gaussian-process/",
    "categories": "Academic, Knowledge",
    "tags": "deep learning",
    "date": "2021-01-18 16:21:49 +0800",
    





    
    "snippet": "本文介绍了高斯过程，包括高斯函数、多元高斯分布、高斯过程。  1. 一元高斯分布  2. 多元高斯分布  3. 高斯过程          3.1. 概念      3.2. 举例      3.3. 高斯过程回归                  3.3.1. 构建高斯过程先验          3.3.2. 求解超参数          3.3.3. 测试样本预测            ...",
    "content": "本文介绍了高斯过程，包括高斯函数、多元高斯分布、高斯过程。  1. 一元高斯分布  2. 多元高斯分布  3. 高斯过程          3.1. 概念      3.2. 举例      3.3. 高斯过程回归                  3.3.1. 构建高斯过程先验          3.3.2. 求解超参数          3.3.3. 测试样本预测                    3.4. 深度核回归                  3.4.1. 初始化          3.4.2. 前向传播          3.4.3. 反向传播          3.4.4. 预测                      4. 参考文献    1. 一元高斯分布  高斯分布又称正态分布。标准高斯函数为\\[f(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}\\]函数图像为这个函数描述了变量 $x$ 的一种分布特性，变量 $x$ 的分布有如下特点：  均值 = 0  方差 = 1  概率密度和 = 1一元高斯函数的一般形式为\\[f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\\]这里指数函数的参数 $-\\frac{1}{2\\sigma^2}(x-\\mu)^2$ 是一个关于 $x$ 的二项式函数。由于系数为负，所以是抛物线开口向下的函数。此外，由于最前面的系数与 $x$ 无关，因此可以把它当作是一个正规化因子（normalization factor），以保证\\[\\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty}{exp(-\\frac{1}{2\\sigma^2}(x-\\mu)^2)}dx=1\\]若令\\[z = \\frac{x-\\mu}{\\sigma}\\]称这个过程为标准化\\[\\begin{aligned}  x &amp;= z\\cdot \\sigma + \\mu\\\\  \\Rightarrow p(x) &amp;= \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2}(z)^2}\\\\  \\Rightarrow 1 &amp;=\\int_{-\\infty}^{\\infty}{p(x)dx}\\\\  &amp;=\\int_{-\\infty}^{\\infty}{\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2}(z)^2}dx}\\\\  &amp;=\\int_{-\\infty}^{\\infty}{\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2}(z)^2}\\sigma\\cdot dz}\\\\  &amp;=\\int_{-\\infty}^{\\infty}{\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}(z)^2} dz}\\\\\\end{aligned}\\]即 $z\\sim N(0,1)$。随机变量 $x$ 标准化的过程, 实际上的消除量纲影响和分布差异的过程. 通过将随机变量的值减去其均值再除以标准差, 使得随机变量与其均值的差距可以用若干个标准差来衡量, 从而实现了不同随机变量与其对应均值的差距, 可以以一种相对的距离来进行比较。2. 多元高斯分布  钱默吟. 多元高斯分布完全解析多元高斯分布是一元高斯分布在向量形式的推广。假设随机向量 $\\boldsymbol Z = [z_1,\\cdots,z_n]$，其中 $z_i\\sim \\mathcal N(0,1)(i=1,\\cdots,n)$ 且彼此独立，则随机向量的联合概率密度函数为\\[\\begin{aligned}  p(z_1, \\cdots, z_n) &amp;= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}(z_i)^2}\\\\  &amp;=\\frac{1}{2\\pi^{n/2}}e^{-1/2\\cdot Z^TZ}\\\\1&amp;=\\int_{-\\infty}^{\\infty}\\cdots\\int_{-\\infty}^{\\infty} p(z_1,\\cdots,z_n)dz_1\\cdots dz_n\\end{aligned}\\]称随机向量 $\\boldsymbol Z\\sim \\mathcal N(\\boldsymbol 0,\\boldsymbol I)$，即服从均值为零向量，协方差矩阵为单位矩阵的高斯分布。对于向量 $X=[x_1,\\cdots,x_n]$，其概率密度函数的形式为\\[\\begin{aligned}p(x_1,x_2,\\cdots,x_n) &amp;=\\prod_{i=1}^n p(x_i)\\\\&amp;=\\frac{1}{(2\\pi)^{n/2}\\sigma_1\\cdots\\sigma_n}exp\\left( -\\frac{1}{2} \\left[ \\frac{(x_1-\\mu_1)^2}{\\sigma^2_1}+\\cdots+\\frac{(x_n-\\mu_n)^2}{\\sigma^2_n} \\right] \\right)\\\\\\end{aligned}\\]其中 $\\mu_i, \\sigma_i$ 为第 $i$ 维的均值和方差。按照矩阵表示\\[\\begin{aligned}  \\boldsymbol x - \\boldsymbol \\mu &amp;= [x_1-\\mu_1,\\cdots,x_n-\\mu_n]^T\\\\  \\Sigma &amp;= \\left[    \\begin{matrix}      \\sigma_1^2&amp;0&amp;\\cdots&amp;0\\\\      0&amp;\\sigma_2^2&amp;\\cdots&amp;0\\\\      \\vdots&amp;\\vdots&amp;\\ddots&amp;0\\\\      0&amp;0&amp;\\cdots&amp;\\sigma_n^2\\\\    \\end{matrix}    \\right]\\end{aligned}\\]那么有\\[\\begin{aligned}\\sigma_1\\cdots\\sigma_n &amp;= \\vert\\Sigma\\vert^\\frac{1}{2}\\\\\\frac{(x_1-\\mu_1)^2}{\\sigma^2_1}+\\cdots+\\frac{(x_n-\\mu_n)^2}{\\sigma^2_n} &amp;= (\\boldsymbol x - \\boldsymbol \\mu)^T\\Sigma^{-1}(\\boldsymbol x - \\boldsymbol \\mu)\\end{aligned}\\]代入得\\[\\begin{aligned}p(x_1,x_2,\\cdots,x_n) &amp;=p(\\boldsymbol x\\vert \\boldsymbol \\mu, \\Sigma)\\\\&amp;= \\frac{1}{(2\\pi)^{n/2}\\vert\\Sigma\\vert^{1/2}}exp(-\\frac{1}{2}(\\boldsymbol x-\\boldsymbol \\mu)^T\\Sigma^{-1}(\\boldsymbol x-\\boldsymbol \\mu))\\\\\\end{aligned}\\]则称 $X$ 为具有均值 $\\boldsymbol \\mu \\in \\mathbb R^n$，协方差矩阵为 $\\Sigma \\in S^n$ 的多元高斯分布。3. 高斯过程3.1. 概念首先简单理解高斯过程，比如你有 $(t_1,t_2,\\cdots,t_N)=\\boldsymbol T$ 个时间点，每个时间点的观测值都是高斯分布的，并且任意 $k$ 个时间点的观测值的组合都是联合高斯分布。这样的一个过程称为高斯过程。高斯过程通常可以用来表示一个函数的分布。高斯过程，从字面上分解，我们就可以看出他包含两部分：  高斯，指的是高斯分布  过程，指的是随机过程  当随机变量是 1 维时，我们称之为一维高斯分布，概率密度函数 $p(x)=N(\\mu,\\sigma^2)$当随机变量是有限的 $p$ 维时，我们称之为高维高斯分布， $p(x) = N(\\mu, \\Sigma_{p \\times p})$当随机变量是连续域上的无限多个高斯随机变量组成的随机过程，称之为无限维的高斯分布，即高斯过程通常如果我们要学习一个函数（或者说学习一个映射），首先定义函数的参数，然后根据训练数据来学习这个函数的参数。例如我们做线性回归，学习这样一个函数就相当于训练回归参数（权重、偏置）。这种方法叫做参数化的方法。但是这种做法就把可学习的函数的范围限制死了，无法学习任意类型的函数。非参数化的方法就没有这个缺点。用高斯过程来建模函数，就是一种非参数方法。3.2. 举例举一个简单的例子，下面的图中，横轴 $T$ 是一个关于时间的连续域，表示人的一生，而纵轴表示的是体能值 $\\xi$。对于一个人而言，在任意不同的时间点体能值都服从正态分布，但是不同时间点分布的均值和方差不同。一个人的一生的体能曲线就是一个函数（体能关于时间的函数），该函数的分布就是高斯过程。对于任意 $t\\in T, \\xi_t \\sim N(\\mu_t,\\sigma_t^2)$ ，也就是对于一个确定的高斯过程而言，对于任意时刻 $t$ ，他的 $\\mu_t$ 和 $\\sigma_t$ 都已经确定了。而像上图中，我们对同一人体能值在关键节点进行采样，然后平滑连接，也就是图中的两条虚线，就形成了这个高斯过程中的两个样本。回顾 $p$ 维度高斯分布，决定他的分布是两个参数，一个是 $p$ 维的均值向量 $\\mu_p$ ，他反映了 $p$ 维高斯分布中每一维随机变量的期望，另一个就是 $p\\times p$ 的协方差矩阵 $\\Sigma_{p\\times p}$ ，他反映了高维分布中，每一维自身的方差，以及不同维度之间的协方差。定义在连续域 $T$ 上的高斯过程其实也是一样，他是无限维的高斯分布，他同样需要描述每一个时间点 $t$ 上的均值，但是这个时候就不能用向量了，因为是在连续域上的，维数是无限的，因此就应该定义成一个关于时刻 $t$ 的函数 $m(t)$。协方差矩阵也是同理，无限维的情况下就定义为一个核函数 $k(t_i,t_j)$ ，其中 $t_i$ 和 $t_j$ 表示任意两个时刻。核函数也称协方差函数，是一个高斯过程的核心，他决定了高斯过程的性质。在研究和实践中，核函数有很多种不同的类型，他们对高斯过程的衡量方法也不尽相同，最为常见的一个核函数是径向基函数，其定义如下：\\[k_\\lambda(t_i,t_j)=\\sigma^2 exp(-\\frac{\\vert\\vert t_i-t_j\\vert\\vert^2}{2l^2})\\]$\\sigma$ 和 $l$ 是径向基函数的超参数，是我们提前可以设置好的。径向基函数输出的是一个标量，他代表的就是两个时间点各自所代表的高斯分布之间的协方差值，很明显径向基函数是一个关于距离 $\\vert\\vert x_i-x_j\\vert\\vert$ 负相关的函数，两个点距离越大，两个分布之间的协方差值越小，即相关性越小，反之越靠近的两个时间点对应的分布其协方差值就越大。由此，高斯过程的两个核心要素：均值函数和核函数的定义我们就描述清楚了，按照高斯过程存在性定理，一旦这两个要素确定了，那么整个高斯过程就确定了：\\[\\xi_t \\sim GP(m(t),k(t_i,t_j))\\]另一个简单的例子，假设我们有两个点 $x_0=0$ 和 $x_1=1$ ，对应这两个点的函数值服从二维高斯分布（高斯过程中“高斯”二字的由来）\\[\\begin{aligned}\\left(  \\begin{matrix}  y_0\\\\  y_1  \\end{matrix}\\right)\\sim \\mathcal N\\left(  \\begin{matrix}  \\left(  \\begin{matrix}  0\\\\  1  \\end{matrix}  \\right),  \\left(  \\begin{matrix}  1&amp;0\\\\  0&amp;1  \\end{matrix}  \\right)  \\end{matrix}\\right)\\end{aligned}\\]从这个二维高斯分布中采样 10 组数据，其中两个点在 $x$ 轴上的两端，采样得到的两个 $y$ 对应在 $y$ 轴取值，可以得到下图所示的结果每条直线可以被认为是从一个线性函数分布中采样出来的线性函数。如果我们有20个 $x$ 点，对应这 20 个 $x$ 的函数值符合均值为 0，协方差矩阵为单位矩阵的联合高斯分布。和上面一样采样 10 组数据，得到下图每一条线都是一个函数，是从某个函数分布中采样得到的。但是这样的函数看上去一点也不平滑，并且显得杂乱无章，距离很近的两个 $x$ 对应的函数值 $y$ 可以相差很大。直观来说，两个 $x$ 离得越近，对应的函数值应该相差越小，也就是说这个函数应该是平滑的，而不是像上图那样是突变的。所以我们应该通过两个 $x$ 之间的某种距离来定义这两个 $x$ 对应的函数值之间的协方差。两个 $x$ 离得越近，对应函数值之间的协方差应该越大，意味着这两个函数值的取值可能越接近。我们引入核函数（以高斯核为例，也可以用其他核，并不是说我们在讲高斯过程所以这里就一定用高斯核）：\\[k_\\lambda(x_i,x_j)=exp(-\\frac{\\vert\\vert \\boldsymbol x_i-\\boldsymbol x_j\\vert\\vert^2}{\\lambda})\\]和函数可以表示两个点 $x_i,x_j$ 之间的距离。此时，若我们有N个数据点( $x_1,\\cdots,x_N$ )，则这个 $N$ 个数据点对应的 $N$ 个函数值服从 $N$ 维高斯分布，这个高斯分布的均值是 0，协方差矩阵是 $K$，$K$ 里的每一个元素对应\\[K_{nm} = k(\\boldsymbol x_n,\\boldsymbol x_m)\\]此时，再以刚才 20 个数据点的情况为例，我们采样 10 组，得到下图，现在看起来函数就平滑多了如果数据点再多点，例如 100 个数据点，则采样 10 组，得到下图：上图每条曲线就是一个高斯过程的采样，每个数据点上的函数值都是高斯分布。且任意k个数据点对应的函数值的组合都是联合高斯分布。3.3. 高斯过程回归高斯过程回归可以看作是一个根据先验与观测值推出后验的过程。一版遵循以下三步  构建高斯过程先验  求解超参数  对测试样本进行预测3.3.1. 构建高斯过程先验假设一组 $n$ 个观测值，每个观测值为 $D$ 维向量 $\\boldsymbol X={\\boldsymbol x_1, \\cdots, \\boldsymbol x_n}$，对应的值为 $n$ 个 1 维目标向量 $\\boldsymbol Y={y_1,\\cdots, y_n}$。假设回归残差 $\\boldsymbol \\varepsilon=[\\varepsilon_1,\\cdots,\\varepsilon_n]$ 服从 $iid$ 正态分布 $p(\\varepsilon)=\\mathcal N(0,\\sigma^2_{noise})$，则回归问题就是希望我们通过 $\\boldsymbol X,\\boldsymbol Y$ 学习一个由 $\\boldsymbol X$ 到 $\\boldsymbol Y$ 的映射函数 $f$\\[\\boldsymbol Y=f(\\boldsymbol X)+\\boldsymbol \\varepsilon,\\quad where\\quad \\varepsilon_i\\sim \\mathcal N(0,\\sigma^2_{noise}), i=1,\\cdots,n\\]未知映射 $f$ 遵循高斯过程，通过 $\\boldsymbol \\mu = [\\mu(x_1),\\cdots,\\mu(x_n)]$ 与 $k(\\boldsymbol x_i,\\boldsymbol x_j)$ 定义一个高斯过程，但是因为此时没有任何观测值，所以这是一个先验。\\[f(\\boldsymbol X) \\sim \\mathcal{GP}[\\boldsymbol \\mu,\\boldsymbol K(\\boldsymbol X, \\boldsymbol X)]\\]  注意：经典高斯过程输入可以是多维，但输出只有 1 维（即单输出）。如果需要多维输出，当输出分量之间不相关时，可以分别设计多个高斯过程模型进行回归。当输出分量之间相关时，可以参考一些paper和工具包来实现，比如：https://github.com/SheffieldML/multigphttps://github.com/SheffieldML/GPy/blob/devel/GPy/models/gp_multiout_regression.py高斯过程由其数学期望 $\\boldsymbol \\mu$ 和协方差函数 $\\boldsymbol K$ 完全决定。常见的选择是平稳高斯过程，即数学期望为一常数，协方差函数取平稳高斯过程可用的核函数。高斯过程的均值函数决定着曲线的走势，常数均值相当于起了一个平移作用，均值函数不再是常数时，曲线将围绕着均值函数这条曲线而波动。$\\mu = 1$ 时$\\mu = 2x$ 时但是一般情况下，我们都会对数据集的输出进行标准化处理来达到去均值的目的，这样做的好处就是我们只需要设置 $\\boldsymbol \\mu=\\boldsymbol 0$ 即可，而无需猜测输出大致的模样，并且在后面的超参数寻优的过程中也可以减少我们需要优化的超参数的个数。使用最多的核函数是 RBF 核。3.3.2. 求解超参数高斯过程回归的求解也被称为超参学习（hyper-parameter learning），是按照贝叶斯方法通过学习样本确定核函数的超参数 $\\boldsymbol \\theta$ 的过程。根据贝叶斯定理，高斯过程回归的超参数的后验表示如下\\[p(\\boldsymbol \\theta \\vert \\boldsymbol X,\\boldsymbol Y) = \\frac{p(\\boldsymbol Y\\vert \\boldsymbol X,\\boldsymbol \\theta)p(\\boldsymbol \\theta)}{p(\\boldsymbol Y\\vert \\boldsymbol X)}\\]其中，$\\boldsymbol \\theta$ 包括核函数的超参数和残差的方差 $\\sigma^2_{noise}$。$p(\\boldsymbol Y\\vert\\boldsymbol X,\\boldsymbol \\theta)$ 是似然，是对高斯过程回归的输出边缘化得到的边缘似然：\\[p(\\boldsymbol Y\\vert\\boldsymbol X,\\boldsymbol \\theta) = \\int p(\\boldsymbol Y\\vert f, \\boldsymbol X,\\boldsymbol \\theta)p(f\\vert\\boldsymbol X,\\boldsymbol \\theta)df\\]高斯分布的边缘分布也是高斯分布，因此边缘似然也服从高斯分布，则概率可写为\\[p(\\boldsymbol Y\\vert\\boldsymbol X,\\boldsymbol \\theta) = \\frac{1}{(2\\pi)^{n/2}\\vert\\Sigma\\vert^{1/2}}exp(-\\frac{1}{2}(\\boldsymbol Y-\\mu(\\boldsymbol X))^T\\Sigma^{-1}(\\boldsymbol Y-\\mu(\\boldsymbol X)))\\]采用最大似然估计来对高斯过程的超参数进行估计，则负对数似然函数为\\[\\begin{aligned} \\Rightarrow L = -{\\rm ln}\\ p(\\boldsymbol Y\\vert\\boldsymbol X,\\boldsymbol \\theta) &amp;= -[-\\frac{1}{2}{\\rm ln}{\\vert\\Sigma\\vert}-\\frac{n}{2}{\\rm ln}(2\\pi)-\\frac{1}{2}(\\boldsymbol Y-\\mu(\\boldsymbol X))^T\\Sigma^{-1}(\\boldsymbol Y-\\mu(\\boldsymbol X))]\\\\&amp;= \\frac{1}{2}{\\rm ln}{\\vert\\Sigma\\vert}+\\frac{n}{2}{\\rm ln}(2\\pi)+\\frac{1}{2}\\boldsymbol Y^T\\Sigma^{-1}\\boldsymbol Y\\quad \\boldsymbol (\\boldsymbol \\mu = 0)\\end{aligned}\\]上式第一项仅与回归模型有关，回归模型的核矩阵越复杂其取值越高，反映了模型的结构风险（structural risk）。第三项包含学习成本，是数据拟合项，表示模型的经验风险（empirical risk）。其中，$\\Sigma=k(\\boldsymbol X,\\boldsymbol X)+\\sigma^2_{noise}\\boldsymbol I$，与超参数 $\\boldsymbol \\theta$ 有关。利用梯度下降的方法更新超参数，上述式子对超参数 $\\boldsymbol \\theta$ 求导\\[\\begin{aligned}\\frac{\\partial L}{\\partial \\boldsymbol \\theta} = \\frac{\\partial {\\rm ln}\\ p(\\boldsymbol Y\\vert\\boldsymbol X,\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta} &amp;= -\\frac{1}{2}tr(\\Sigma^{-1}\\frac{\\partial \\Sigma}{\\partial \\boldsymbol \\theta}) + \\frac{1}{2}(\\boldsymbol Y-\\mu(\\boldsymbol X))^T\\Sigma^{-1}\\frac{\\partial \\Sigma}{\\partial \\boldsymbol \\theta}(\\boldsymbol Y-\\mu(\\boldsymbol X))\\\\&amp;=-\\frac{1}{2}tr(\\Sigma^{-1}\\frac{\\partial \\Sigma}{\\partial \\boldsymbol \\theta}) + \\frac{1}{2}\\boldsymbol Y^T\\Sigma^{-1}\\frac{\\partial \\Sigma}{\\partial \\boldsymbol \\theta}\\boldsymbol Y\\quad \\boldsymbol (\\boldsymbol \\mu = 0)\\end{aligned}\\]注意，高斯过程回归中的目标函数不是凸的，因而带来的问题就是：通过求解这个最优化问题，我们可以得到的只能是一个局部最小值，而非真正的全局最小值。局部最小不能保证是全局最优时，初始值的选择变得非常的重要。因为一个初始值可能会走向一个具体的极小值，而不同的初始值或许可以得到不同最优值。一种解决方案就是，多次产生不同的初始超参数，然后操作一次最优化问题的求解，然后比较这些最优化，挑选得出其中最小的值。3.3.3. 测试样本预测接着，给定其它 $m$ 个测试观测值 $\\boldsymbol X^$，预测 $\\boldsymbol Y^=f(\\boldsymbol X^*)$ 。我们希望对 $\\boldsymbol Y^\\vert \\boldsymbol Y$ 的条件概率 $p(\\boldsymbol Y^\\vert \\boldsymbol X, \\boldsymbol Y,\\boldsymbol X^)$ 进行建模，即给定观察到的所有数据 $\\boldsymbol X, \\boldsymbol Y,\\boldsymbol X^$，确定预测样本的预测值 $\\boldsymbol Y^*$ 的分布。高斯过程并没有直接对这个条件概率分布进行建模，而是从联合概率分布出发，对 $\\boldsymbol Y^$ 的联合概率 $p(\\boldsymbol Y,\\boldsymbol Y^\\vert\\boldsymbol X,\\boldsymbol X^*)$ 进行建模。当这个概率已知时，可以通过下面的式子得到新样本预测值的条件概率\\[p(\\boldsymbol Y^*\\vert\\boldsymbol X,\\boldsymbol Y,\\boldsymbol X^*)= \\frac{p(\\boldsymbol Y,\\boldsymbol Y^*\\vert \\boldsymbol X,\\boldsymbol X^*)}{p(\\boldsymbol Y\\vert \\boldsymbol X,\\boldsymbol X^*)}= \\frac{p(\\boldsymbol Y,\\boldsymbol Y^*\\vert \\boldsymbol X,\\boldsymbol X^*)}{\\int _{Y^*}p(\\boldsymbol Y,\\boldsymbol Y^*\\vert \\boldsymbol X,\\boldsymbol X^*)dY^*}\\]显然，核心是建立 $p(\\boldsymbol Y,\\boldsymbol Y^\\vert \\boldsymbol X,\\boldsymbol X^)$ 的具体形式，然后通过上式求出关于 $\\boldsymbol Y^*$ 的条件概率。根据回归模型核高斯过程的定义，$\\boldsymbol Y$ 和 $\\boldsymbol Y^*$ 的概率分布为\\[\\begin{aligned}\\boldsymbol Y&amp;\\sim \\mathcal N(\\mu(\\boldsymbol X),k(\\boldsymbol X, \\boldsymbol X)+\\sigma^2_{noise}\\boldsymbol I)\\\\\\boldsymbol Y^* &amp;\\sim \\mathcal N(\\mu(\\boldsymbol X^*),k(\\boldsymbol X^*, \\boldsymbol X^*))\\end{aligned}\\]二者的联合分布满足无限维高斯分布\\[\\begin{aligned}  \\left[\\begin{matrix}    \\boldsymbol Y\\\\\\boldsymbol Y^*  \\end{matrix}\\right]  \\sim  N(  \\left[\\begin{matrix}    \\mu(\\boldsymbol X)\\\\\\mu(\\boldsymbol X^*)  \\end{matrix}\\right],  \\left[\\begin{matrix}    k(\\boldsymbol X,\\boldsymbol X)+\\sigma^2_{noise} \\boldsymbol I &amp; k(\\boldsymbol X,\\boldsymbol X^*)\\\\ k(\\boldsymbol X^*,\\boldsymbol X)&amp;k(\\boldsymbol X^*,\\boldsymbol X^*)  \\end{matrix}\\right]  )\\end{aligned}\\]从这个联合分布中派生出来的条件概率 $\\boldsymbol Y^*\\vert \\boldsymbol Y$ 同样也服从无限维高斯分布。套用高维高斯分布的公式\\[\\begin{aligned}  \\boldsymbol Y^*\\vert \\boldsymbol Y &amp;\\sim N(\\mu^*,k^*) \\Rightarrow p(\\boldsymbol Y^*\\vert \\boldsymbol X,\\boldsymbol Y,\\boldsymbol X^*)= N(\\mu^*,k^*)\\\\  \\mu^* &amp;= k(\\boldsymbol X^*,\\boldsymbol X)[k(\\boldsymbol X,\\boldsymbol X)+\\sigma^2_{noise}\\boldsymbol I]^{-1}(\\boldsymbol Y-\\mu(\\boldsymbol X))+\\mu(\\boldsymbol X^*)\\\\  &amp;= k(\\boldsymbol X^*,\\boldsymbol X)k(\\boldsymbol X,\\boldsymbol X)^{-1}\\boldsymbol Y\\\\  k^* &amp;= k(\\boldsymbol X^*,\\boldsymbol X^*)-k(\\boldsymbol X^*,\\boldsymbol X)[k(\\boldsymbol X,\\boldsymbol X)+\\sigma^2_{noise}\\boldsymbol I]^{-1}k(\\boldsymbol X,\\boldsymbol X^*)\\\\  &amp;=k(\\boldsymbol X^*,\\boldsymbol X^*)-k(\\boldsymbol X^*,\\boldsymbol X)k(\\boldsymbol X,\\boldsymbol X)^{-1}k(\\boldsymbol X,\\boldsymbol X^*)\\end{aligned}\\]均值 $\\mu^$ 实际上是观测点 $\\boldsymbol Y^$ 的一个线性函数。协方差项 $k^*$ 的第一部分是我们的先验的协方差，减掉的后面的那一项实际上表示了观测到数据后函数分布不确定性的减少。如果第二项非常接近于 0，说明观测数据后我们的不确定性几乎不变，反之如果第二项非常大，则说明不确定性降低了很多。  PS1：高斯分布有一个很好的特性，即高斯分布的联合概率、边缘概率、条件概率仍然是满足高斯分布的，假设 $n$ 维随机变量满足高斯分布  $\\boldsymbol x \\sim N(\\mu,\\Sigma_{n\\times n})$  把随机变量分成两部分：$p$ 维 $\\boldsymbol x_a$ 和 $q$ 维 $\\boldsymbol x_b$，满足 $n=p+q$，按照分块规则可以写成\\(\\begin{aligned}  x=\\left[\\begin{matrix}    x_a\\\\x_b  \\end{matrix}\\right],  \\mu=\\left[\\begin{matrix}    \\mu_a\\\\\\mu_b  \\end{matrix}\\right],  \\Sigma=\\left[\\begin{matrix}    \\Sigma_{aa} &amp; \\Sigma_{ab}\\\\\\Sigma_{ba}&amp;\\Sigma_{bb}  \\end{matrix}\\right]\\end{aligned}\\)则下列条件分布依然是高维高斯分布\\(\\begin{aligned}x_b\\vert x_a &amp;\\sim N(\\mu_{b\\vert a},\\Sigma_{b\\vert a})\\\\\\mu_{b\\vert a} &amp;= \\Sigma_{ba}\\Sigma_{aa}^{-1}(x_a-\\mu_a)+\\mu_b\\\\\\Sigma_{b\\vert a} &amp;= \\Sigma_{bb}-\\Sigma_{ba}\\Sigma_{aa}^{-1}\\Sigma_{ab}\\end{aligned}\\)由此可推广到高斯过程。下图是高斯过程的可视化，其中蓝线是高斯过程的均值，浅蓝色区域 95% 置信区间（由协方差矩阵的对角线得到），每条虚线代表一个函数采样（这里用了 100 维模拟连续无限维）。左上角第一幅图是高斯过程的先验（这里用了零均值作为先验），后面几幅图展示了当观测到新的数据点的时候，高斯过程如何更新自身的均值函数和协方差函数。3.4. 深度核回归  Andrew Gordon Wilson, et al. Deep Kernel Learning. 2016.数据集如下，输入 $n$ 个 $D$ 维数据 $\\boldsymbol X=[\\boldsymbol x_1,\\cdots,\\boldsymbol x_n]$，输出 $n$ 个 1 维数据 $\\boldsymbol Y = [y(\\boldsymbol x_1),\\cdots,y(\\boldsymbol x_n)]$。网络结构如下：$n&lt;6000$ 时网络为 $[D-1000-500-50-2-gp]$ 结构，$n\\leq 6000$ 时网络为 $[D-1000-1000-500-50-2-gp]$ 结构。其中前面为全连接的 MLP，输入 $D$ 维数据，输出 2 维特征，最后一层为高斯过程回归层，3.4.1. 初始化NNRegressor.fit()|--first_run()    |--layers[i].initialize_ws()  全连接层Dense()，初始化为def initialize_ws(self):  self.W=numpy.random.randn(self.n_inp,self.n_out)*numpy.sqrt(1.0/self.n_inp)  self.b=numpy.zeros((1,self.n_out))  self.dW=numpy.zeros((self.n_inp,self.n_out))  self.db=numpy.zeros((1,self.n_out))即\\[\\begin{aligned}w&amp;\\sim N(0,\\sqrt{\\frac{1}{D}}) \\in \\mathbb R^{D_i\\times D_o}\\\\b &amp;= [0,\\cdots,0] \\in \\mathbb R^{D_o}\\\\dw &amp;= \\left[\\begin{matrix}  0&amp;\\cdots&amp;0\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  0&amp;\\cdots&amp;0\\\\  \\end{matrix}\\right] \\in \\mathbb R^{D_i\\times D_o}\\\\db &amp;= [0,\\cdots,0] \\in \\mathbb R^{D_o}\\end{aligned}\\]  高斯层CovMat()，初始化为def initialize_ws(self):  self.W=numpy.ones((1,2))*numpy.array([[numpy.log(self.s_alpha/(1.0-self.s_alpha)),numpy.sqrt(self.var)]])  self.b=numpy.zeros((1,1))  self.dW=numpy.zeros((1,2))  self.db=numpy.zeros((1,1))即\\[\\begin{aligned}\\boldsymbol w &amp;= [w_1,w_2] = [{\\rm ln}\\frac{\\alpha}{1-\\alpha},\\sqrt{var}],\\quad \\alpha = 0.1,\\; var = 1\\\\b &amp;= [0]\\\\dw &amp;= [0,0]\\\\db &amp;= [0]\\end{aligned}\\]3.4.2. 前向传播NNRegressor.fit()|--Adam.fit()    |--NNRegressor.update()        |--CoreNN.forward()            |--layers[i].forward(X)  全连接层Dense()，前向传播为def forward(self,X):  self.inp=X  self.out=numpy.dot(self.inp,self.W)+self.b  return self.out即\\[\\boldsymbol {o} = \\boldsymbol x_{ND_i} \\cdot \\boldsymbol w_{D_iD_o} + \\boldsymbol b_{D_o}\\; \\in \\mathbb R^{N\\times D_o}\\]其中，$N$ 是样本数量；$D_i$ 是该层输入维度；$D_o$ 是该层输出维度，也是下一层输入维度。经过多层全连接的 MLP，输入数据集从 $N\\times D$ 维变为 $N\\times M$ 维特征。  高斯层CovMat()，前向传播为def forward_rbf(self,X):  self.inp=X    #Calculate distances  ll=[]  for i in range(0,X.shape[1]):    tmp=X[:,i].reshape(1,-1)-X[:,i].reshape(-1,1)    ll.append(tmp.reshape(X.shape[0],X.shape[0],1))  self.z=numpy.concatenate(ll,-1)    #Apply RBF function to distance  self.s0=numpy.exp(-0.5*numpy.sum(self.z**2,-1))    #Multiply with variance  self.var=self.W[0,1]**2  self.s=self.var*self.s0    #Add noise / whitekernel  self.s_alpha=1.0/(numpy.exp(-self.W[0,0])+1.0)  self.out=self.s+(self.s_alpha+1e-8)*numpy.identity(X.shape[0])  return self.out首先计算每个样本对所有样本的距离矩阵：第一步 X[:,i].reshape(1,-1)-X[:,i].reshape(-1,1)，对数据的每一列转置成行，然后扩充成方阵，然后减去直接对列扩充成的方阵。这里相当于对数据的每一列逐一减去各个列元素形成一个矩阵。  $1m$ 维行向量减 $n1$ 维列向量时，python 会把 $1m$ 维行向量自动扩充为 $nm$ 维，每一行都是行向量的复制； 把 $n1$ 维列向量扩充为 $nm$ 维，增加的每一列都是列向量的复制，然后做差得到 $nm$ 维矩阵。第二步，把上述矩阵重新排列为 $N\\times N\\times 1$ 的形式；第三步，逐一遍历所有列，得到 $D$ 个 $N\\times N\\times 1$ 的矩阵组成的列表，重新拼接为 $N\\times N\\times D$ 维矩阵。其实本质上就是做了对数据集中的每个样本对所有其它样本做差的操作，假设输入高斯过程的数据集为经过 MLP 的 $N\\times M$ 维特征 $\\boldsymbol x$\\[\\boldsymbol x = \\left[  \\begin{matrix}    \\boldsymbol x_1\\\\    \\boldsymbol x_2\\\\    \\vdots\\\\    \\boldsymbol x_N  \\end{matrix}\\right]= \\left[  \\begin{matrix}    x_{11}&amp;x_{12}&amp;\\cdots&amp;x_{1M}\\\\    x_{21}&amp;x_{22}&amp;\\cdots&amp;x_{2M}\\\\    \\vdots\\\\    x_{N1}&amp;x_{N2}&amp;\\cdots&amp;x_{NM}\\\\  \\end{matrix}\\right]\\in \\mathbb R^{N\\times M}\\]那么距离为\\[\\boldsymbol z =\\left[\\left[  \\begin{matrix}    \\boldsymbol x_1 - \\boldsymbol x_1\\\\    \\boldsymbol x_2 - \\boldsymbol x_1\\\\    \\vdots\\\\    \\boldsymbol x_N - \\boldsymbol x_1\\\\  \\end{matrix}\\right],\\left[  \\begin{matrix}    \\boldsymbol x_1 - \\boldsymbol x_2\\\\    \\boldsymbol x_2 - \\boldsymbol x_2\\\\    \\vdots\\\\    \\boldsymbol x_N - \\boldsymbol x_2\\\\  \\end{matrix}\\right],\\cdots,\\left[  \\begin{matrix}    \\boldsymbol x_1 - \\boldsymbol x_N\\\\    \\boldsymbol x_2 - \\boldsymbol x_N\\\\    \\vdots\\\\    \\boldsymbol x_N - \\boldsymbol x_N\\\\  \\end{matrix}\\right]\\right]\\in \\mathbb R^{N\\times N\\times M}\\]对 $\\boldsymbol z$ 的最后一维（$M$ 维）分量计算二范数的平方\\[\\vert\\vert\\boldsymbol z\\vert\\vert^2 = \\left[\\begin{matrix}  \\vert\\vert\\boldsymbol x_1 - \\boldsymbol x_1\\vert\\vert^2 &amp; \\cdots &amp; \\vert\\vert\\boldsymbol x_1 - \\boldsymbol x_N\\vert\\vert^2\\\\  \\vert\\vert\\boldsymbol x_2 - \\boldsymbol x_1\\vert\\vert^2 &amp; \\cdots &amp; \\vert\\vert\\boldsymbol x_2 - \\boldsymbol x_N\\vert\\vert^2\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  \\vert\\vert\\boldsymbol x_N - \\boldsymbol x_1\\vert\\vert^2 &amp; \\cdots &amp; \\vert\\vert\\boldsymbol x_N - \\boldsymbol x_N\\vert\\vert^2\\\\\\end{matrix}\\right]\\in \\mathbb R^{N\\times N}\\]其中二范数为\\[\\vert\\vert\\boldsymbol x_i - \\boldsymbol x_j\\vert\\vert = \\sqrt{\\sum_{k=1}^M (x_{ik}-x_{jk})^2}\\]其次计算RBF：\\[\\boldsymbol s_0 = e^{-0.5\\cdot \\vert\\vert\\boldsymbol z\\vert\\vert^2}\\quad\\in \\mathbb R_{N\\times N}\\]乘以方差（之前定义的第 2 个权重系数 $w_2$）\\[\\boldsymbol s = w_2^2 \\cdot \\boldsymbol s_0  = var\\cdot \\boldsymbol s_0\\quad\\in \\mathbb R_{N\\times N}\\]加噪声（之前定义的第 1 个权重系数 $w_1$）\\[\\begin{aligned}s_\\alpha &amp;= 1/{(e^{-w_1}+1}) = 1/({\\frac{1-\\alpha}{\\alpha}}+1) = \\alpha\\\\\\boldsymbol {out} &amp;= \\boldsymbol s + (s_\\alpha+10^{-8})\\cdot \\boldsymbol I_{N\\times N}\\end{aligned}\\]形式上等效于\\[\\boldsymbol K = var\\cdot \\boldsymbol K(X,X) + \\alpha\\cdot \\boldsymbol I\\]核函数参数分别为两个权重 $var, \\alpha$，最后输出 $N\\times N$ 维的核矩阵 $\\boldsymbol {out} = \\boldsymbol K$。3.4.3. 反向传播根据前文，极大似然估计即最小化负对数似然函数：\\[{\\rm argmin}_\\theta \\quad loss = \\frac{1}{2}{\\rm ln}{\\vert\\boldsymbol K\\vert}+\\frac{n}{2}{\\rm ln}(2\\pi)+\\frac{1}{2}\\boldsymbol Y^T\\boldsymbol K^{-1}\\boldsymbol Y\\]  定理1：设 $\\boldsymbol K$ 为一 $n\\times n$ 正定对称矩阵矩阵，对 $\\boldsymbol K$ 进行 Cholesky 分解  \\(\\vert\\boldsymbol K\\vert=\\boldsymbol L \\boldsymbol L^T\\)      因为三角矩阵的行列式 $\\vert\\boldsymbol L\\vert = \\prod_{i=1}^n L_{ii}$，而 $\\vert\\boldsymbol K\\vert = \\vert\\boldsymbol L\\vert\\vert\\boldsymbol L^T\\vert$，则有  \\[\\vert\\boldsymbol K\\vert=\\prod_{i=1}^n L_{ii}^2\\]\\[{\\rm ln}\\vert\\boldsymbol K\\vert=2\\sum_{i=1}^n {\\rm ln}L_{ii}\\]则 $loss$ 可改写为\\[loss = \\sum_{i=1}^n {\\rm ln}L_{ii}+\\frac{n}{2}{\\rm ln}(2\\pi)+\\frac{1}{2}\\boldsymbol Y^T\\boldsymbol K^{-1}\\boldsymbol Y\\]主要计算量在于求解核矩阵的逆 $\\boldsymbol K^{-1}$。下面结合代码进行说明。NNRegressor.fit(self,X,Y,...)|--Adam.fit(self,X,Y):  |--NNRegressor.update(self,X,Y):    |--CoreNN.backward(self,Y):      self.j,err=self.cost(Y,self.layers[-1].out)      for i in reversed(range(0,len(self.layers))):        err=self.layers[i].backward(err)      return err首先计算损失函数。NNRegressor.__init__()  if gp:    self.cost=self.gp_lossNNRegressor.gp_loss(self,y,K):  self.y=y  self.A=self.layers[-2].out  self.K=K  self.L_ = cholesky(K, lower=True)  L_inv = solve_triangular(self.L_.T,numpy.eye(self.L_.shape[0]))  self.K_inv = L_inv.dot(L_inv.T)    self.alpha_ = cho_solve((self.L_, True), y)  self.nlml=0.0  self.nlml_grad=0.0  for i in range(0,y.shape[1]):    gg1=numpy.dot(self.alpha_[:,i].reshape(1,-1),y[:,i].reshape(-1,1))[0,0]    self.nlml+=0.5*gg1+numpy.sum(numpy.log(numpy.diag(self.L_)))+K.shape[0]*0.5*numpy.log(2.0*numpy.pi)    yy=numpy.dot(y[:,i].reshape(-1,1),y[:,i].reshape(1,-1))    self.nlml_grad += -0.5*( numpy.dot(numpy.dot(self.K_inv,yy),self.K_inv)-self.K_inv)*K.shape[0]  return self.nlml,self.nlml_grad设 $\\boldsymbol K \\in \\mathbb R^{N\\times N}$ 是高斯层最终输出的核矩阵，$\\boldsymbol A\\in \\mathbb R^{N\\times M}$ 是全连接层输出的特征。对核矩阵求逆得到  $\\boldsymbol K^{-1}$ 。因为 $\\boldsymbol K$ 为对称正定矩阵，可采用 Cholesky 矩阵分解加速求逆过程（cholesky() 和 solve_triangular()）。  Cholesky 分解是把一个对称正定的矩阵表示成一个下三角矩阵 $\\boldsymbol L$ 和其转置的乘积的分解。\\[\\boldsymbol K = \\boldsymbol L\\boldsymbol L^T\\]  它要求矩阵的所有特征值必须大于零，故分解的下三角的对角元也是大于零的。由于 $L$ 是可逆方阵，因此求逆和转置可以交换次序，则\\[\\boldsymbol K^{-1} = (\\boldsymbol L^T)^{-1}\\boldsymbol L^{-1} = (\\boldsymbol L^T)^{-1}[{(\\boldsymbol L^T)^{-1}}]^T\\]  那么只需要求 $(\\boldsymbol L^T)^{-1}$ 就可以求出 $\\boldsymbol K^{-1}$。设 $\\boldsymbol y\\in \\mathbb R^{N\\times 1}$ 是训练集标签，根据 $\\boldsymbol L\\boldsymbol \\alpha=\\boldsymbol y$ 求出 $\\boldsymbol \\alpha$（cho_solve()）。\\[\\boldsymbol \\alpha = \\boldsymbol L^{-1} \\boldsymbol y  \\in \\mathbb R^{N\\times 1}\\]则\\[gg1 = \\boldsymbol \\alpha^T\\boldsymbol y = \\boldsymbol y^T (\\boldsymbol L^{-1})^T\\boldsymbol y \\\\\\]有 negative log marginal likelihood (nlml)\\[\\begin{aligned}nlml &amp;= \\frac{1}{2}gg1 + \\sum_{i=1}^N {\\rm ln}L_{ii} + \\frac{N}{2}{\\rm ln} 2\\pi\\\\&amp;=\\frac{1}{2}\\boldsymbol y^T (\\boldsymbol L^{-1})^T\\boldsymbol y + \\sum_{i=1}^N {\\rm ln}L_{ii} + \\frac{N}{2}{\\rm ln} 2\\pi\\\\&amp;= -loss\\quad ?\\end{aligned}\\]【WARNING】：关于为啥公式是 $y^TK^{-1}y$ 而代码是 $y^TL^{-1}y$ 没想明白。要使得极大似然估计最大也就是 $loss$ 最大，就要使得 $nlml$ 最小，二者相差一个负号。求极值则对参数求偏导，因为核矩阵可表示为\\[k(\\boldsymbol x_i, \\boldsymbol x_j\\vert\\boldsymbol \\theta) \\rightarrow k(g(\\boldsymbol x_i,\\boldsymbol w), g(\\boldsymbol x_j,\\boldsymbol w)\\vert\\boldsymbol \\theta)\\]其中 $g(\\boldsymbol x,\\boldsymbol w)$ 是深度神经网络的映射，那么\\[\\begin{aligned}L = -loss &amp;= \\frac{1}{2}{\\rm ln}{\\vert \\boldsymbol K\\vert}+\\frac{n}{2}{\\rm ln}(2\\pi)+\\frac{1}{2}\\boldsymbol Y^T\\boldsymbol K^{-1}\\boldsymbol Y\\\\\\frac{\\partial L}{\\partial \\boldsymbol \\theta} &amp;= \\frac{\\partial L}{\\partial \\boldsymbol K}\\frac{\\partial \\boldsymbol K}{\\partial \\boldsymbol \\theta}\\\\\\frac{\\partial L}{\\partial \\boldsymbol w} &amp;= \\frac{\\partial L}{\\partial \\boldsymbol K}\\frac{\\partial \\boldsymbol K}{\\partial g(\\boldsymbol x,\\boldsymbol w)}\\frac{\\partial g(\\boldsymbol x,\\boldsymbol w)}{\\partial \\boldsymbol w}\\\\\\end{aligned}\\]其中共同项可以首先求解\\[\\begin{aligned}\\frac{\\partial L}{\\partial \\boldsymbol K} &amp;= -\\frac{N}{2}[\\boldsymbol K^{-1}\\boldsymbol Y\\boldsymbol Y^T\\boldsymbol K^{-1} - \\boldsymbol K^{-1}]\\\\\\end{aligned}\\]  常用公式 1 （matrix cookbook 124）：\\(\\frac{\\partial }{\\partial \\boldsymbol X}Tr(\\boldsymbol A\\boldsymbol X^{-1}\\boldsymbol B) = -(\\boldsymbol X^{-1})^T\\boldsymbol A^T\\boldsymbol B(\\boldsymbol X^{-1})^T\\)常用公式 1 （网络）：\\(\\frac{\\partial }{\\partial \\boldsymbol A}(\\boldsymbol x^T\\boldsymbol A^{-1}\\boldsymbol x) = -(\\boldsymbol A^{-1})^T\\boldsymbol x\\boldsymbol x^T(\\boldsymbol A^{-1})^T\\)常用公式 2 （matrix cookbook 141）（对应第二项）：\\(\\frac{\\partial {\\rm ln\\ det}(\\boldsymbol X)}{\\partial \\boldsymbol X} = 2\\boldsymbol X^{-1}-(\\boldsymbol X^{-1}\\cdot \\boldsymbol I)\\)常用公式 2 （维基百科）（对应第二项）：\\(\\frac{\\partial {\\rm ln\\ det}(\\boldsymbol X)}{\\partial \\boldsymbol X} = \\boldsymbol X^{-1}\\)【WARNING】：多余的 $N$ 怎么来的？继续对高斯层反向传播\\[a_{err} = \\frac{\\partial L}{\\partial \\boldsymbol K}(s_\\alpha)(1-s_\\alpha)\\]3.4.4. 预测对于 全连接层，在 first_run() 中，直接定义调用 forward() 函数进行预测（predict = forward）。NNRegressor.fit()|--first_run()    for i in range(0,len(self.layers)):      if type(self.layers[i]) != Dropout and type(self.layers[i]) != CovMat:        self.layers[i].predict=self.layers[i].forward对于高斯层，预测代码如下NNRegressor.predict(self,X):  A=X  A2=self.x  for i in range(0,len(self.layers)-1):    A2=self.layers[i].predict(A2)    A=self.layers[i].predict(A)      self.K=self.layers[-1].forward(A2)  self.L_ = cholesky(self.K, lower=True)    L_inv = solve_triangular(self.L_.T,numpy.eye(self.L_.shape[0]))  self.K_inv = L_inv.dot(L_inv.T)    self.alpha_ = cho_solve((self.L_, True), self.y)      K2=numpy.zeros((X.shape[0],X.shape[0]))  K3=numpy.zeros((X.shape[0],self.K.shape[0]))    if self.layers[-1].kernel=='rbf':    d1=0.0    d2=0.0    for i in range(0,A.shape[1]):      d1+=(A[:,i].reshape(-1,1)-A[:,i].reshape(1,-1))**2      d2+=(A[:,i].reshape(-1,1)-A2[:,i].reshape(1,-1))**2    K2=self.layers[-1].var*numpy.exp(-0.5*d1)+numpy.identity(A.shape[0])*(self.layers[-1].s_alpha+1e-8)    K3=self.layers[-1].var*numpy.exp(-0.5*d2)  elif self.layers[-1].kernel=='dot':    K2=numpy.dot(A,A.T)+numpy.identity(A.shape[0])*(self.layers[-1].s_alpha+1e-8) + self.layers[-1].var    K3=numpy.dot(A,A2.T) + self.layers[-1].var      preds=numpy.zeros((X.shape[0],self.y.shape[1]))  for i in range(0,self.alpha_.shape[1]):    preds[:,i]=numpy.dot(K3,self.alpha_[:,i].reshape(-1,1))[:,0]    return preds, numpy.sqrt(numpy.diagonal(K2-numpy.dot(K3,numpy.dot(self.K_inv,K3.T))))设 $\\boldsymbol A=\\boldsymbol X\\in \\mathbb R^{n\\times D}$ 为测试集，$\\boldsymbol A_2=\\boldsymbol x\\in \\mathbb R^{N\\times D}$ 为训练集.首先经过全连接层前向传播后特征维度为 $M$，得到的输出分别依然记作 $\\boldsymbol A\\in \\mathbb R^{n\\times M}, \\boldsymbol A_2\\in \\mathbb R^{N\\times M}$。对于训练集 $\\boldsymbol A_2$，调用高斯层的前向传播函数，计算出训练集的核矩阵\\[\\boldsymbol K = \\boldsymbol s + (s_\\alpha+10^{-8})\\cdot \\boldsymbol I_{N\\times N}\\]然后对核矩阵求逆。因为 $\\boldsymbol K$ 为对称正定矩阵，可采用 Cholesky 矩阵分解加速求逆过程（cholesky() 和 solve_triangular()）。设 $\\boldsymbol y\\in \\mathbb R^{N\\times1}$ 是训练集的标签，则根据 $\\boldsymbol L\\boldsymbol \\alpha=\\boldsymbol y$ 求出 $\\boldsymbol \\alpha$（cho_solve()）。\\[\\boldsymbol \\alpha = \\boldsymbol y \\boldsymbol L^{-1}  \\in \\mathbb R^{N\\times 1}\\]和高斯层的前向传播类似，分别计算测试集的核函数 $\\boldsymbol K_2 \\in \\mathbb R^{n\\times n}$，以及测试集与训练集之间的核函数 $\\boldsymbol K_3 \\in \\mathbb R^{n\\times N}$。\\[\\begin{aligned}\\vert\\vert\\boldsymbol d_1\\vert\\vert^2 &amp;= \\left[\\begin{matrix}  \\vert\\vert\\boldsymbol X_1 - \\boldsymbol X_1\\vert\\vert^2 &amp; \\cdots &amp; \\vert\\vert\\boldsymbol X_1 - \\boldsymbol X_n\\vert\\vert^2\\\\  \\vert\\vert\\boldsymbol X_2 - \\boldsymbol X_1\\vert\\vert^2 &amp; \\cdots &amp; \\vert\\vert\\boldsymbol X_2 - \\boldsymbol X_n\\vert\\vert^2\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  \\vert\\vert\\boldsymbol X_n - \\boldsymbol X_1\\vert\\vert^2 &amp; \\cdots &amp; \\vert\\vert\\boldsymbol X_n - \\boldsymbol X_n\\vert\\vert^2\\\\\\end{matrix}\\right]\\in \\mathbb R^{n\\times n}\\\\\\vert\\vert\\boldsymbol d_2\\vert\\vert^2 &amp;= \\left[\\begin{matrix}  \\vert\\vert\\boldsymbol X_1 - \\boldsymbol x_1\\vert\\vert^2 &amp; \\cdots &amp; \\vert\\vert\\boldsymbol X_1 - \\boldsymbol x_N\\vert\\vert^2\\\\  \\vert\\vert\\boldsymbol X_2 - \\boldsymbol x_1\\vert\\vert^2 &amp; \\cdots &amp; \\vert\\vert\\boldsymbol X_2 - \\boldsymbol x_N\\vert\\vert^2\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  \\vert\\vert\\boldsymbol X_n - \\boldsymbol x_1\\vert\\vert^2 &amp; \\cdots &amp; \\vert\\vert\\boldsymbol X_n - \\boldsymbol x_N\\vert\\vert^2\\\\\\end{matrix}\\right]\\in \\mathbb R^{n\\times N}\\\\\\boldsymbol K_2 &amp;= var\\cdot e^{-0.5\\cdot \\vert\\vert\\boldsymbol d_1\\vert\\vert^2} + (s_\\alpha + 10^{-8})\\boldsymbol I_{n\\times n}\\\\\\boldsymbol K_3 &amp;= var\\cdot e^{-0.5\\cdot \\vert\\vert\\boldsymbol d_2\\vert\\vert^2}\\\\\\end{aligned}\\]预测输出的值为\\[\\begin{aligned}\\boldsymbol Y &amp;= \\boldsymbol K_3 \\cdot \\boldsymbol \\alpha\\\\std &amp;= \\sqrt{diag[\\boldsymbol K_2-\\boldsymbol K_3\\boldsymbol K^{-1}\\boldsymbol K_3^T]}\\end{aligned}\\]4. 参考文献[1] bingjianing. 多元高斯分布（The Multivariate normal distribution）[2] 论智. 图文详解高斯过程（一）——含代码[3] 我能说什么好. 通俗理解高斯过程及其应用[4] 石溪. 如何通俗易懂地介绍 Gaussian Process[5] 钱默吟. 多元高斯分布完全解析[6] li Eta. 如何通俗易懂地介绍 Gaussian Process？[7] 蓦风星吟. Gaussian process 的最后一步——话说超参学习[7] 蓦风星吟. 【答疑解惑III】说说高斯过程中的多维输入和多维输出"
  },
  
  {
    "title": "VSCode部署R开发环境",
    "url": "/posts/vscode-R/",
    "categories": "Tutorial, Coding",
    "tags": "vscode, r",
    "date": "2021-01-13 22:22:49 +0800",
    





    
    "snippet": "本文介绍了基于 VSCode 的 R 开发环境的搭建方法。  1. 简介  2. 下载与安装  3. 配置 R 开发环境          3.1. 安装 R 语言      3.2. 安装 LanguageServer      3.3. 安装扩展      3.4. 测试 R 环境        4. 安装 R 程辑包  5. 参考文献1. 简介VSCode是微软推出的一款跨平台开源编辑...",
    "content": "本文介绍了基于 VSCode 的 R 开发环境的搭建方法。  1. 简介  2. 下载与安装  3. 配置 R 开发环境          3.1. 安装 R 语言      3.2. 安装 LanguageServer      3.3. 安装扩展      3.4. 测试 R 环境        4. 安装 R 程辑包  5. 参考文献1. 简介VSCode是微软推出的一款跨平台开源编辑器，凭借强大的第三方插件支持C/C++、Python、Java等众多语言，体积小巧功能丰富，适合小型工程项目的开发调试。下面简单介绍VSCode开发环境的部署。注意，VSCode仅仅是一个前端文本编辑器，本质上与记事本并无不同，在没有插件和编译器的情况下只能进行文件的读写，并不能进行源程序编译调试。与之相对，微软自家的Visual Studio是一个集成开发环境（IDE），下载安装后可以直接进行源程序的编译调试。一个现代编译器的主要工作流程如下： 源代码 (source code) =&gt; 预处理器 (preprocessor) =&gt; 编译器 (compiler) =&gt; 汇编程序 (assembler) =&gt; 目标代码 (object code) =&gt; 链接器 (Linker) =&gt; 可执行文件 (executables)。VSCode 本身仅仅是一个源代码编辑器。不过，当配合插件和编译器后，VSCode也能够完成绝大部分的源代码编译调试工作。2. 下载与安装前往官网（https://code.visualstudio.com）下载安装，支持Windows、Linux和Mac系统。可以下载安装版，也可以选择解压即用的绿色版。区别在于安装板会向系统路径写入配置信息，绿色版所有的依赖信息和配置信息均存放于一个目录中。安装版可以在线下载更新和安装更新，绿色版只能下载新版本的绿色安装包解压后覆盖来更新。安装完成后，点击左侧的扩展商店，搜索chinese，下载中文简体汉化包（可能需要翻墙）。安装完成后重启VSCode，即可发现所有界面均已汉化。注意：      VSCode基于文件夹进行编译和调试，每个项目必须对应一个文件夹作为工作路径（根目录），根目录内包含一个.vscode文件夹存放配置文件（json格式）；        VSCode默认编码为UTF8，对中文支持并不完美，特别是打开已有的包含中文注释的源代码文件时要特别注意，可能导致中文乱码，且在保存文件时弹出警告。因此，对于包含中文注释的已有文件，一般需要新建一个空白文件，保存为UTF8编码格式，然后重新输入中文注释部分再进行保存。  3. 配置 R 开发环境注意，R 的开发环境还可以选用 RStudio。3.1. 安装 R 语言前往官网（https://www.r-project.org/） 下载R语言的安装包。然后选择任意一个中国镜像（比如第一个清华镜像）然后根据自己的平台选择安装包（比如 Windows）首次安装，请选择 base最后点击下载安装包，下载完毕后安装即可。3.2. 安装 LanguageServerLanguageServer 是 R 语言端配合 VSCode 进行可视化的 Language Server Protocol 插件。  LSP 是Language Server Protocol 的缩写。简单来说，LSP 为不同语言在不同编辑器或IDE 中的自动补全、查找定义、悬停查看函数文档等功能搭建了桥梁，使得开发者可以减少针对不同语言和不同编辑器的重复开发。对用户来说，使用这一功能意味着可以获得更好的自动补全、查看帮助文档等特性。由于LSP 本身也是微软的项目，在VSCode 中的使用体验也会更好一些。R LSP Client 便是R 语言在这方面的实现，通过安装这个插件，可以弥补自动补全等功能的不足。前往 R 安装的路径，进入 bin 文件夹（比如 C:\\Program Files\\R\\R-4.0.3\\bin），双击 R.exe 启动 R 环境。输入install.packages(\"languageserver\")提示选择一个镜像（忽略 R 官方那蹩脚的中文），选择中国镜像后（比如在北京就选择 China,Beijing）开始疯狂下载依赖包。等待下载完毕即可。3.3. 安装扩展可能需要翻墙。在 VSCode 的扩展列表中搜索并安装 R 和 R LSP Client 两个扩展。安装完毕后，分别点击两个扩展的齿轮按钮，进入扩展设置。首先确定安装 R 的 R.exe 所在的路径，比如C:\\Program Files\\R-4.0.3\\bin\\R.exe对于 R 扩展，设置 R › Rpath: Windows 为安装 R 的 R.exe 所在的路径。对于 R 扩展，设置 R › Rterm: Windows 为安装 R 的 R.exe 所在的路径。对于 R LSP Client 扩展，同样设置 R › Rpath: Windows 为安装 R 的 R.exe 所在的路径。安装 R Debugger 扩展，用以支持 VSCode 内直接断点调试。若不安装也可以，只是只能直接通过前面安装的 R 扩展直接运行整个 R 文件（见下面的章节【测试 R 环境】）。安装完成后，从【运行和调试】界面中，选择 R Debugger，然后选择 Debug R-File 即可进行 R 文件调试。另外，该插件依赖 R 插件包 vscDebugger ，在 Windows 下可通通过 Ctrl+Shift+P 打开命令面板（Mac 下为 ⇧ + ⌘ + P ），然后输入R debugger update or install required package选中后安装即可。3.4. 测试 R 环境打开一个 R 文件，随便写个1/3右上角出现一个新图标按钮，如下图所示，点击即可运行 R 文件。4. 安装 R 程辑包和前面安装 LanguageServer 类似，可以从 R 提供的 R 环境来安装，也可以随便打开一个 .r 文件，点击右上角按钮或者快捷键 Ctrl+Shift+S 进入 R 运行环境安装。输入install.packages(\"survminer\")提示--- 在此連線階段时请选用CRAN的鏡子 ---稍等片刻后弹出选择 CRAN 镜像的列表，选择一个中国镜像，比如北京镜像点击确定后就会自动开始进行安装操作。5. 参考文献无。"
  },
  
  {
    "title": "PyTorch基础（随机数种子）",
    "url": "/posts/pytorch-basic-2/",
    "categories": "Tutorial, Coding",
    "tags": "python, deep learning",
    "date": "2021-01-04 15:22:19 +0800",
    





    
    "snippet": "本文主要记录自己学习 PyTorch 过程中涉及的一些基础知识。  1. 随机数          1.1. 随机数产生      1.2. 随机数种子        2. 参考文献1. 随机数1.1. 随机数产生随机数广泛应用在科学研究，但是计算机无法产生真正的随机数，一般成为伪随机数。它的产生过程：给定一个随机种子（一般是一个正整数），根据随机算法和种子产生随机序列。给定相同的随机种子，...",
    "content": "本文主要记录自己学习 PyTorch 过程中涉及的一些基础知识。  1. 随机数          1.1. 随机数产生      1.2. 随机数种子        2. 参考文献1. 随机数1.1. 随机数产生随机数广泛应用在科学研究，但是计算机无法产生真正的随机数，一般成为伪随机数。它的产生过程：给定一个随机种子（一般是一个正整数），根据随机算法和种子产生随机序列。给定相同的随机种子，计算机产生的随机数列是一样的（这也许是伪随机的原因）。比如：import randomprint(random.random()) # 0.6347616556381207print(random.random()) # 0.17717483228053954random.seed(1024)print(random.random()) # 0.7970515714521261print(random.random()) # 0.4834988702079559random.seed(1024)print(random.random()) # 0.7970515714521261print(random.random()) # 0.4834988702079559可以看到，在设置随机数种子后，产生随机数的过程可以完全重复，这种特性非常适合比如神经网络权值初始化的复现。1.2. 随机数种子随机种子是针对随机方法而言的。常见的随机方法有生成随机数，以及其他的像随机排序之类的，后者本质上也是基于生成随机数来实现的。在深度学习中，比较常用的随机方法的应用有：网络的随机初始化，训练集的随机打乱等。当用户未指定随机种子，系统默认随机生成，一般与系统当前时间有关。用户指定随机种子后，使用随机函数产生的随机数可以复现。种子确定后，每次使用随机函数相当于从随机序列去获取随机数，每次获取的随机数是不同的。使用 PyTorch 复现效果时，总是无法做到完全的复现。同一份代码运行两次，有时结果差异很大。这是由于算法中的随机性导致的。要想每次获得的结果一致，必须固定住随机种子。首先，我们需要找到算法在哪里使用了随机性，再相应的固定住随机种子。import numpy as npimport randomimport osimport torchdef seed_torch(seed=1024):    random.seed(seed)    os.environ['PYTHONHASHSEED'] = str(seed)    np.random.seed(seed)    torch.manual_seed(seed) # 设置 cpu 的随机数种子    torch.cuda.manual_seed(seed) # 对于单张显卡，设置 gpu 的随机数种子    torch.cuda.manual_seed_all(seed) # 对于多张显卡，设置所有 gpu 的随机数种子    torch.backends.cudnn.benchmark = False    torch.backends.cudnn.deterministic = Trueseed_torch()其中      torch.backends.cudnn.enabled：cuDNN 使用非确定性算法。如果该参数设置为 True，说明设置为使用使用非确定性算法；        torch.backends.cudnn.benchmark：在 torch.backends.cudnn.enabled = True 的前提下将该参数设置为 True，可以让程序在开始时花费一点额外时间，自动为整个网络的每个卷积层搜索最适合它的卷积实现算法，来达到优化运行效率的目的。但这会导致网络的训练存在一定的随机性，导致训练结果存在一些微小的不确定。一般来讲，应该遵循以下准则：          如果网络的输入数据维度或类型上变化不大，设置 torch.backends.cudnn.benchmark = True 可以增加运行效率；      如果网络的输入数据在每次 iteration 都变化的话，会导致 cnDNN 每次都会去寻找一遍最优配置，这样反而会降低运行效率。        https://blog.csdn.net/byron123456sfsfsfa/article/details/96003317https://www.cnblogs.com/wanghui-garcia/p/11514502.html  torch.backends.cudnn.deterministic：torch.backends.cudnn.benchmark = True会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异。比如训练CNN的时候，发现每次跑出来小数点后几位会有不一样。epoch 越多，误差就越多，虽然结果大致上一样，但是强迫症真的不能忍。如果想要避免这种结果波动，可以设置 torch.backends.cudnn.deterministic = True 这样调用的 CuDNN 的卷积操作就是每次一样的了。  高斯定理. https://www.zhihu.com/question/67209417/answer/4185688792. 参考文献[1] 梦并不遥远。4.3Python数据处理篇之Matplotlib系列(三)—plt.plot().[2] 我的明天不是梦。python使用matplotlib:subplot绘制多个子图."
  },
  
  {
    "title": "深度学习文章阅读（深度流体可视化）",
    "url": "/posts/deep-PDE/",
    "categories": "Academic, Paper",
    "tags": "deep learning, pde",
    "date": "2020-12-25 15:43:19 +0800",
    





    
    "snippet": "本文介绍了 2020 年 Raissi 等发表在 Science 上的一种根据流体可视化结果来学习速度和压力场的方法，称为隐流体力学（hidden fluid mechanics）。  1. 引言          1.1. 网络框架      1.2. 损失函数      1.3. 仿真                  1.3.1. 圆柱体遮挡的外部流动          1.3.2. ...",
    "content": "本文介绍了 2020 年 Raissi 等发表在 Science 上的一种根据流体可视化结果来学习速度和压力场的方法，称为隐流体力学（hidden fluid mechanics）。  1. 引言          1.1. 网络框架      1.2. 损失函数      1.3. 仿真                  1.3.1. 圆柱体遮挡的外部流动          1.3.2. 3D 颅内动脉瘤的定量血流动力学                      2. 优势  3. 前作  4. 参考文献  M. Raissi, A. Yazdani和G. E. Karniadakis, Hidden fluid mechanics: Learning velocity and pressure fields from flow visualizations, Science, 卷 367, 期 6481, 页 1026–1030, 2月 2020, doi: 10.1126/science.aaw4741.github: maziarraissi/HFM: Hidden fluid mechanics (version v1.0)SUPPLEMENTARY MATERIALS: science.sciencemag.org/content/367/6481/1026/suppl/DC1  Materials and Methods  Supplementary Text  Figs. S1 to S21  Tables S1 to S4  References (20–37)  Movies S1 and S21. 引言本文针对物理和生物系统中的流体运动可视化。理论上，Navier-Stokes 方程（NS 方程）可以描述流动模式，直接使用图像来提取速度和压力场很难。  Navier Stokes（纳维叶－斯托克斯）方程是流体力学中描述粘性牛顿流体的方程，是尚未被完全解决的方程，只有大约一百多个特解被解出来，是最复杂的方程之一。NS 方程由一个连续方程和一个动量方程组成（变成标量就是三个）。相关方程包括：      连续方程：单位时间内，流入质量-流出质量等于质量增量（质量守恒方程的流体表达）    动量方程：某一时刻，控制体中所有流体微团的总动量随时间变化率=控制体中所有流体微团受到的合力（牛顿第二定律的流体表达）    传输方程：分子扩散+随流传输，浓度与速度的关系？    状态方程：表征流体压强、 流体密度、 温度等三个热力学参量的函数关系式，$p=p(\\rho T)$ 或 $U=U(\\rho T)$ 来表示，式中 $p$ 为压强；$\\rho$ 为流体密度；$T$ 为热力学温度；$U$ 为单位质量流体的内能。    注意，方程通过网格划分，能解除特定坐标点的浓度，速度，压力信息。作者开发了一种物理先验的深度学习框架（a physics-informed deep-learning framework），能够将 NS 方程编码到神经网络中，而与几何或初始/边界条件无关。在一些物理和生物医学问题中，hidden fluid mechanics（HFM） 可以提取可能无法直接测量的定量信息。 HFM 对于低分辨率和观测数据中的大量噪声具有鲁棒性。作者考虑一个在速度场 $\\boldsymbol u(t,x,y,z)=[u(t,x,y,z),v(t,x,y,z),w(t,x,y,z)]$ 中的某种被动标量 $c(t,x,y,z)$ 的传输过程，该过程满足不可压缩的 NS 方程。被动标量受流动平流并扩散，但对流体运动本身没有动力学影响。  passive scalar，烟雾和染料是被动标量的两个典型示例。唯一的观测量是一组单点云的离散数据组成的且包含噪声的时空坐标 ${t^n,x^n,y^n,z^n,c^n}_{n=1}^N$，他是被动标量的浓度信息（Fig. 2B）。这组时空坐标一共包含 $N$ 个数据点 $(t^n,x^n,y^n,z^n,c^n)$ 以及其对应的标签 $c^n$，即反映了在时空坐标 $(t^n,x^n,y^n,z^n,c^n)$ 处的浓度信息 $c^n$。N 一般为网格节点或者网格中心点。有了这组观测量后，我们关注于推理出感兴趣的隐状态量，即速度量 $u(t,x,y,z),v(t,x,y,z),w(t,x,y,z)$ 和压力量 $p(t,x,y,z)$。1.1. 网络框架作者致力于开发出一个灵活的框架，可以处理各类流动场，比如运载器附近的流动场，或者大脑或主动脉瘤中的血管流动场。网络框架，包含两个部分，共享参数（其实只有第一部分网络有参数）。  网络1：无物理先验的深度神经网络（a physics-uninformed deep neural network），用来近似下述方程\\[(t,x,y,z)\\mapsto (c,u,v,w,p)\\]根据数学方程求解的结果，输入时空坐标，输出对应的浓度，速度，压力。用来学习方程本身的规律。  网络2：物理先验的深度神经网络\\[(t,x,y,z)\\mapsto (e_1,e_2,e_3,e_4,e_5)\\]其中，输出 $e_1,e_2,e_3,e_4,e_5$ 为采用自动微分（automatic differentiation）编码的被动标量和 NS 方程的耦合动力学信息（Fig. 3C and fig. S1），也就是说这部分本质上不是一个神经网络，而是直接写出偏微分方程。通过最小化这五个残差的范数来保证相应方程的满足性。  $e_1$ 是传递方程的残差，用于建模被动标量的动力学特性（对应浓度 $c$？）；  $e_2,e_3,e_4$ 代表 $x,y,z$ 方向的动量方程（对应速度 $u,v,w$？）；  $e_5$ 是连续方程的残差（对应密度，然后通过状态方程得到压力 $p$？）；1.2. 损失函数上述两个深度神经网络共享参数，通过下面的均方差损失函数来训练\\[MSE = \\frac{1}{N}\\sum_{n=1}^N\\vert c(t^n,x^n,y^n,z^n)-c^n \\vert^2 + \\sum_{i=1}^5\\frac{1}{M}\\sum_{m=1}^M\\vert e_i(t^m,x^m,y^m,z^m) \\vert^2\\]  第一项对应训练数据中各个坐标点的浓度。浓度是对方程的数值解算得到的，只在网格中心点或节点有值。  第二项强制执行了 NS 方程和传输方程强加在各个坐标的结构。由于流体方程在任意点均满足，因此给定任意时空坐标点位置，均可以根据方程计算残差。因此第二项中的坐标与训练数据的个数和位置可以不同，即用来惩罚方程的坐标的个数和位置是由人们完全掌控的（M），但是浓度只在测量点（网格中心或者节点）有数据（N）。  the first term corresponds to the training data ${t^n,x^n,y^n,z^n}{n=1}^N$ on the concentration of the passive scalar, the last term enforces the structure imposed by the NS and transport equations at a finite set of residual points ${t^m,x^m,y^m,z^m}{m=1}^M$. The number and locations of these points at which we penalize the equations are in our full control, whereas the data on the concentration of the passive scalar are available at the measurement points.小批量梯度下降算法及其现代变体（例如Adam优化器）使我们能够在几乎 “无限” 多个点处对方程进行惩罚。更进一步，如表 S2 和 S3 所示，除了速度和压力场，其它未知流体参数也能从被动标量的密度数据中直接发掘，如雷诺数（Re）、佩克莱数（Pe）。1.3. 仿真1.3.1. 圆柱体遮挡的外部流动首先考察外部流动，以一个典型的在圆桶中的 2D 流动问题为起点，$Re=100, Pe=100$（图 2）。在圆筒中放一个圆柱体，考察被圆柱障碍挡住的液体的流动。用谱元法（spectral element method）做一个直接数值仿真，得到训练数据（浓度散点），同时提供参考速度和压力场用以分析 HFM 的准确性。被动标量在左侧边界入口被注入（图 2），训练域的边界的形状和范围任意（如下图中的花瓣形状）。但训练域的选择需要注意以下两点：  第一，被动标量的浓度场必须存在于训练域内，以便其信息可用于推断其他流量变量；  第二，为了避免需要给速度指定适当的边界条件，必须有足够的垂直于边界的浓度梯度 （$\\partial c/\\partial n\\neq 0$），为了使该方法能够推断出速度场的单个解。在训练域的区域中，浓度分布本身不能携带足够的信息来保证获得单个速度场或压力场，可以为算法提供额外信息，如额外的速度或压力数据（比如，针对壁边界上的速度的无滑移边界条件）。但是在本文中，除了一个实验（图 S8 和 S9）外，其它实验中我们只基于封装在浓度数据内的信息。该算法的输入本质上是散布在空间和时间上的被动标量数据点云（图2B）。如 图2 所示，在圆柱体下游任意的训练域内，算法的预测与参考数据之间的定量一致性很好。我们针对被动标量浓度分布的训练数据的时空分辨率进行了系统研究（图 2F 和图 S5），结果表明算法对于点云数据的时空分辨率非常鲁棒。具体而言，如果用于训练的算法每个涡街脱落周期的时间快照少于五个，或者在空间域中少于 250 个 点，算法才会崩溃。1.3.2. 3D 颅内动脉瘤的定量血流动力学训练样本（浓度）和参考数据（速度和压力）来源于右颈内动脉的动脉瘤，如下图所示。图B 中画了两个参考平面，用以后续的展示预测信息和参考信息的插值对比。用来预测浓度和速度压力数据的 NS先验的神经网络结构如下图所示。多了一个 z（w） 维速度数据。结果对比如下图所示。左边两列是竖着的垂直于 Z 轴的参考平面，右边两列是横着的垂直于 X 轴（原文错写为垂直于 Y 轴）的参考平面。三行从上到下分别为浓度，速度和压力。流动流线，根据参考速度场和回归速度场计算得出的，根据压力场着色。 所有字段的轮廓级别范围都相同，以便进行更好的比较。2. 优势开发的算法与几何，初始和边界条件无关，因此可以灵活地选择感兴趣的领域进行数据采集以及后续的训练和预测。此外，当前的方法使我们能够为速度和压力场构造计算有效且完全可微的替代项，这些替代项可进一步用于估计其他感兴趣的量，例如剪切应力和涡度场。  The algorithm we developed is agnostic to the geometry, initial, and boundary conditions, hence providing flexibility in choosing the domain of interest for data acquisition as well as subsequent training and predictions. Moreover, the current methodology allows us to construct computationally efficient and fully differentiable surrogates for velocity and pressure fields that can be further used to estimate other quantities of interest, such as shear stresses and vorticity fields.标量场在流体流中的传输已在许多应用中进行了研究，例如空气动力学，生物流体力学和非反应性流混合等。长期以来，在实验流体力学中一直在使用风洞中的烟或水隧道中的染料进行流量可视化和量化。 此外，已经开发了结合粒子图像测速仪的平面激光诱导荧光成像技术，以评估标量场与速度涡度场之间的关系。现在，将标量运输与先进的成像方式结合使用以量化血管网络中的血流是一种常见的做法。例如，在注射不可扩散的碘造影剂后，通常在多探测器CT系统上进行冠状动脉计算机断层扫描（CT）血管造影，这可以使冠状动脉可视化并检测冠状动脉狭窄。另一个例子是对脑血流进行量化，要么通过造影剂和灌注CT对患者进行中风预后评估，或者在基于功能磁共振成像技术的认知神经科学中应用，仅依赖于血氧水平的对比来测量大脑活动。如这项工作所示，当前方法的直接含义是量化脉管系统中的血液动力学。这可能会对与诸如心脏病发作和中风等重要病理相关的血管疾病的临床诊断（尤其是非侵入性方法）产生重大影响。作用在血管壁上的血流切应力在血管疾病的预后中至关重要，其量化在临床上很重要（14，15）。使用本文提出的方法，可以在不增加成本的情况下估算壁切应力。这将简化需要从临床图像中提取血管确切边界的最新方法的复杂性（16）。我们的框架是通用的，可以扩展到其他学科；例如，在电磁学中，当给定电场数据并了解麦克斯韦方程时，我们就可以推断出磁场。我们还验证了 HFM 在观察到的浓度场中对低分辨率和大量噪声的鲁棒性（图2和图S5和S6），这表明 HFM 可能在工程和生物医学中找到应用。个人总结：  算法与几何、初始条件和边界条件无关，可以灵活选择感兴趣的区域进行数据采集、训练和预测；  高效的计算任意位置的速度压力场，且结果完全可微？  可以进一步用来估计其它感兴趣的量；  对一些领域的某些地方产生重大影响，比如血管壁上的血流切应力在血管疾病的预后中至关重要；  框架是通用的，可以扩展到其他学科。比如电磁学中，当给定电场数据并了解麦克斯韦方程时，我们就可以推断出磁场（个人附：要么求解出来，要么测量出来，才有数据训练）；3. 前作  M. Raissi, P. Perdikaris, and G. E. Karniadakis, “Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations,” Journal of Computational Physics, vol. 378, pp. 606–707, 2019.复杂物理学，生物学或者工程系统中，数据获取代价高昂，人们免不了需要在部分信息未知的情况下得出结论或者做出决定。在这种小数据制度下，最新的绝大部分的机器学习技术（比如深度/卷积/循环神经网络）都缺乏鲁棒性，且无法提供收敛性保证。实际上，在物理或生物系统中，有大量先验知识没有被用上。  M. Raissi and G. E. Karniadakis, “Hidden physics models: Machine learning of nonlinear partial differential equations,” Journal of Computational Physics, vol. 357, pp. 125–141, Mar. 2018, doi: 10.1016/j.jcp.2017.11.039.4. 参考文献无。"
  },
  
  {
    "title": "深度学习文章阅读（广义TS模糊系统）",
    "url": "/posts/deep-learning-generalized-TS-fuzzy/",
    "categories": "Academic, Paper",
    "tags": "deep learning, fuzzy",
    "date": "2020-12-08 10:48:19 +0800",
    





    
    "snippet": "本文介绍了 2001 年 Taniguchi 等提出的一种广义 TS 模糊系统的建模方法、规则约减和鲁棒控制方法。  1. 引言  2. 传统 TS 模糊系统  3. 广义 TS 模糊系统          3.1. 建模                  3.1.1. 系统建模          3.1.2. 模糊化表示          3.1.3. 举例                ...",
    "content": "本文介绍了 2001 年 Taniguchi 等提出的一种广义 TS 模糊系统的建模方法、规则约减和鲁棒控制方法。  1. 引言  2. 传统 TS 模糊系统  3. 广义 TS 模糊系统          3.1. 建模                  3.1.1. 系统建模          3.1.2. 模糊化表示          3.1.3. 举例                    3.2. 规则约减                  3.2.1. 约减方式          3.2.2. 模型不确定性          3.2.3. 举例                    3.3. 模糊控制器                  3.3.1. 设计          3.3.2. 举例                      4. 参考文献  T. Taniguchi; K. Tanaka; H. Ohtake; H.O. Wang. Model construction, rule reduction, and robust compensation for generalized form of Takagi-Sugeno fuzzy systems. IEEE Transactions on Fuzzy Systems ( Volume: 9, Issue: 4, Aug 2001).1. 引言在线性矩阵不等式（linear matrix inequality, LMI）设计框架下，基于 TS 模糊模型的非线性控制得以广泛应用。一般分为三个阶段：  第一阶段：对非线性被控对象的模糊建模          利用输入输出数据进行模糊模型辨识（Takagi and Sugeno, 1993 等）      或 基于分区非线性思想的模糊系统构建（模糊 IF-THEN 规则）        第二阶段：模糊控制规则推导，它反映了模糊模型的规则结构，它通过所谓的并行分布式补偿（PDC）实现  第三阶段：模糊控制器设计，即确定反馈增益。  This paper presents a systematic procedure of fuzzy control system design that consists of fuzzy model construction, rule reduction, and robust compensation for nonlinear systems.本文提出了一种模糊控制系统设计的系统程序，该程序由模糊模型构建，规则约简和非线性系统的鲁棒补偿组成。注意，在本篇文章之前，还有两篇关键文章作为前续研究基础：  H. O. Wang, K. Tanaka, and M. Griffin, “Parallel distributed compensation of nonlinear systems by Takagi-Sugeno fuzzy model,” in Proceedings of 1995 IEEE International Conference on Fuzzy Systems. The International Joint Conference of the Fourth IEEE International Conference on Fuzzy Systems and The Second International Fuzzy Engineering Symposium, Yokohama, Japan, 1995, vol. 2, pp. 531–538, doi: 10.1109/FUZZY.1995.409737.首次将TS模糊系统用于非线性系统的近似，给出了模糊系统 Lyapunov 稳定性的充分条件，研究了并行分布式补偿（PDC），给出了状态反馈控制律下的稳定性判别准则。  D. Localmodel, “Stability Analysis of Fuzzy Control Systems,” IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS-PART B: CYBERNETICS, vol. 26, no. 1, p. 4, 1996.提出了模糊状态反馈控制器，貌似放宽了稳定性的条件（还没细看）。2. 传统 TS 模糊系统形式如下\\[\\begin{aligned}  &amp;rule\\ i\\quad (i=1,2,\\cdots,r):\\\\  &amp;{\\rm IF}\\ z_1(t)\\ is\\ M_{1i}\\ and\\ \\cdots\\ and\\ z_p(t)\\ is\\ M_{pi}\\\\  &amp;{\\rm THEN}\\ \\dot \\boldsymbol x(t) = \\boldsymbol A_i \\boldsymbol x(t) + \\boldsymbol B_i \\boldsymbol u(t)\\end{aligned}\\]其中  $r$ 是规则个数  $M_{ji}$ 是第 $j$ 个输入分量的模糊集  $\\boldsymbol x\\in \\mathbb R^n$ 是状态量，$\\boldsymbol u\\in \\mathbb R^m$ 是输入量  $\\boldsymbol A_i\\in \\mathbb R^{n\\times n}, \\boldsymbol B_i\\in \\mathbb R^{n\\times m}$ 是系数矩阵  $z_1(t),\\cdots,z_p(t)$ 是已知的前提变量，可能为可测量的状态量的函数、外部干扰，和/或时间，用 $\\boldsymbol z(t)$ 来表示所有给定一对 $[\\boldsymbol x(t),\\boldsymbol u(t),\\boldsymbol z(t)]$，采用重心法（加权平均法）可以得到模糊系统的最终输出：\\[\\dot \\boldsymbol x(t) = \\sum_{i=1}^r h_i(\\boldsymbol z(t))(\\boldsymbol A_i \\boldsymbol x(t) + \\boldsymbol B_i \\boldsymbol u(t))\\]其中\\[\\begin{aligned}  h_i(\\boldsymbol z(t)) &amp;= \\frac{\\omega_i(\\boldsymbol z(t))}{\\sum_{i=1}^r\\omega_i(\\boldsymbol z(t))}\\\\  \\omega_i(z(t)) &amp;= \\prod_{j=1}^p M_{ji}(z_j(t))\\end{aligned}\\]$h_i(\\boldsymbol z(t))$ 是每条规则的归一化权重，$M_{ji}(z_j(t)$ 是第 $i$ 条规则中第 $j$ 个分量的模糊集 $M_{ji}$ 的隶属度值。参考：单点模糊产生器、乘积推理机和中心平均解模糊器。  Wang H., Tanaka K. and Griifn M., Parallel distributed conpensation of nonlinear systems by Takagi and Sugeno’s fuzzy model, 1995, in Porc. 4 th IEEE Int. Conf. Fuzzy syst., Yokohama, Japan, pp: 531-538.定理：当模糊规则条数适当时，模糊系统可以以任意的精度逼近实际的任意线性或非线性系统。（万能逼近器？）  MamdaniE.H.and Assilian 5., Applications of fuzzy algorithms for control of simple dynamic Plant, IEEE Proc. Part-D, 1974, vol. 121, no. 8, pp: 1585-15883. 广义 TS 模糊系统个人前言：传统的 TS 模糊系统是有规则个数的概念的，但是下文作者提出的广义 TS 模糊系统不再强调规则的概念，而是直接对状态方程进行模糊近似。3.1. 建模3.1.1. 系统建模考虑某一类非线性系统表示如下：\\[\\dot x_i(t) = \\sum_{j=1}^n f_{ij}(\\boldsymbol z(t))x_j(t) + \\sum_{k=1}^m g_{ik}(\\boldsymbol z(t))u_k(t)\\]其中：  $x_1(t)\\cdots x_n(t)$ 是状态量，$u_1(t)\\cdots u_m(t)$ 是输入量  $z_1(t),\\cdots,z_n(t)$ 是已知的变量，可能为状态量的函数、外部变量，和/或时间  $f_{ij}(\\boldsymbol z(t)), g_{ik}(\\boldsymbol z(t))$ 是关于 $\\boldsymbol z(t)$ 矩阵注意，上式中的 $j$ 是遍历所有状态量，$j=1,2,\\cdots,n$，$k$ 是遍历所有输入量，$k=1,2,\\cdots,m$。上式可以看作描述系统的非线性状态方程。该方程刻画了每个状态量的一阶导与所有状态量和控制（输入）量的线性组合关系。非线性可以体现在：$z_i(t)$ 可为 $x_i(t)$ 的非线性函数。假设 $z_i(t) = sin(x_i(t))$ ，$f_{ij}(\\boldsymbol z(t))=\\boldsymbol z(t) = sin(\\boldsymbol x(t))$，则原始状态方程是关于 $\\boldsymbol x(t)$ 的非线性方程组。定义如下的新变量（表示系数 $f_{ij},g_{ik}$ 的最大最小值）\\[\\begin{aligned}  a_{ij1} &amp;\\equiv \\mathop{\\rm max}\\limits_{\\boldsymbol z(t)} f_{ij}(\\boldsymbol z(t))\\\\  a_{ij2} &amp;\\equiv \\mathop{\\rm min}\\limits_{\\boldsymbol z(t)} f_{ij}(\\boldsymbol z(t))\\\\  b_{ik1} &amp;\\equiv \\mathop{\\rm max}\\limits_{\\boldsymbol z(t)} g_{ik}(\\boldsymbol z(t))\\\\  b_{ik2} &amp;\\equiv \\mathop{\\rm min}\\limits_{\\boldsymbol z(t)} g_{ik}(\\boldsymbol z(t))\\\\\\end{aligned}\\]借助上述新定义的变量，可以将 $f_{ij}(\\boldsymbol z(t)), g_{ik}(\\boldsymbol z(t))$ 转化为用其最大最小值表达的形式（transforming into fuzzy model representation）：\\[\\begin{aligned}  f_{ij}(\\boldsymbol z(t)) &amp;= h_{ij1}(\\boldsymbol z(t))a_{ij1} + h_{ij2}(\\boldsymbol z(t))a_{ij2}\\\\  g_{ik}(\\boldsymbol z(t)) &amp;= v_{ik1}(\\boldsymbol z(t))b_{ik1} + v_{ik2}(\\boldsymbol z(t))b_{ik2}\\end{aligned}\\]上式的权重参数满足\\[\\sum_{l=1}^2 h_{ijl}(\\boldsymbol z(t)) = 1\\quad \\sum_{l=1}^2 v_{ikl}(\\boldsymbol z(t)) = 1\\]权重参数实质上就是隶属度函数的形式，可以定义如下\\[\\begin{aligned}h_{ij1}(\\boldsymbol z(t)) &amp;= \\frac{f_{ij}(\\boldsymbol z(t))-a_{ij2}}{a_{ij1}-a_{ij2}}\\\\h_{ij2}(\\boldsymbol z(t)) &amp;= \\frac{a_{ij1} - f_{ij}(\\boldsymbol z(t))}{a_{ij1}-a_{ij2}}\\\\v_{ik1}(\\boldsymbol z(t)) &amp;= \\frac{g_{ik}(\\boldsymbol z(t))-b_{ij2}}{b_{ij1}-b_{ij2}}\\\\v_{ik2}(\\boldsymbol z(t)) &amp;= \\frac{b_{ik1} - g_{ik}(\\boldsymbol z(t))}{b_{ik1}-b_{ik2}}\\\\\\end{aligned}\\]最终可以将原始TS模糊系统表示为：\\[\\begin{aligned}\\dot x_i(t) &amp;= \\sum_{j=1}^n f_{ij}(\\boldsymbol z(t))x_j(t) + \\sum_{k=1}^m g_{ik}(\\boldsymbol z(t))u_k(t)\\\\&amp;=\\sum_{j=1}^n\\sum_{l=1}^2 h_{ijl}(\\boldsymbol z(t))a_{ijl}x_j(t) + \\sum_{k=1}^m\\sum_{l=1}^2 v_{ikl}(\\boldsymbol z(t))b_{ikl}u_k(t)\\\\&amp;=\\sum_{l=1}^2\\left[\\begin{bmatrix}  h_{i1l}a_{i1l}&amp;\\cdots&amp;h_{inl}a_{inl}\\end{bmatrix}\\begin{bmatrix}  x_1(t)\\\\  \\vdots\\\\  x_n(t)\\end{bmatrix}+\\begin{bmatrix}  v_{i1l}b_{i1l}&amp;\\cdots&amp;v_{iml}b_{iml}\\end{bmatrix}\\begin{bmatrix}  u_1(t)\\\\  \\vdots\\\\  u_m(t)\\end{bmatrix}\\right]\\end{aligned}\\]$i$ 是输入向量的维度（表示状态方程的每个状态量），$j$ 也是输入向量的维度（表示每个状态量的一阶导与所有状态量的关系），$l$ 是取大取小值的维度。将上述式子转为矩阵形式，如下\\[\\begin{aligned}\\dot \\boldsymbol x(t) &amp;=\\sum_{i=1}^n\\sum_{j=1}^n\\sum_{l=1}^2 h_{ijl}(\\boldsymbol z(t))a_{ijl} \\boldsymbol U^A_{ij} \\boldsymbol x(t) + \\sum_{i=1}^n\\sum_{k=1}^m\\sum_{l=1}^2 v_{ikl}(\\boldsymbol z(t))b_{ikl}\\boldsymbol U^B_{ik}\\boldsymbol u(t)\\\\&amp;=\\sum_{i=1}^n\\sum_{j=1}^n\\sum_{l=1}^2 h_{ijl}(\\boldsymbol z(t)) \\boldsymbol A_{ijl} \\boldsymbol x(t) + \\sum_{i=1}^n\\sum_{k=1}^m\\sum_{l=1}^2 v_{ikl}(\\boldsymbol z(t))\\boldsymbol B_{ikl}\\boldsymbol u(t)\\\\\\end{aligned}\\]其中\\[\\begin{aligned}&amp;\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad j\\\\\\boldsymbol A_{ijl} &amp;= i\\begin{bmatrix}  0&amp;\\cdots&amp;0&amp;0&amp;0&amp;\\cdots&amp;0\\\\  \\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\  0&amp;\\cdots&amp;0&amp;0&amp;0&amp;\\cdots&amp;0\\\\  0&amp;\\cdots&amp;0&amp;a_{ijl}&amp;0&amp;\\cdots&amp;0\\\\  0&amp;\\cdots&amp;0&amp;0&amp;0&amp;\\cdots&amp;0\\\\  \\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\  0&amp;\\cdots&amp;0&amp;0&amp;0&amp;\\cdots&amp;0\\\\\\end{bmatrix}\\\\&amp;\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad k\\\\\\boldsymbol B_{ikl} &amp;= i\\begin{bmatrix}  0&amp;\\cdots&amp;0&amp;0&amp;0&amp;\\cdots&amp;0\\\\  \\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\  0&amp;\\cdots&amp;0&amp;0&amp;0&amp;\\cdots&amp;0\\\\  0&amp;\\cdots&amp;0&amp;b_{ikl}&amp;0&amp;\\cdots&amp;0\\\\  0&amp;\\cdots&amp;0&amp;0&amp;0&amp;\\cdots&amp;0\\\\  \\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\  0&amp;\\cdots&amp;0&amp;0&amp;0&amp;\\cdots&amp;0\\\\\\end{bmatrix}\\end{aligned}\\]个人理解：上述两个矩阵就是为了前面的矩阵求和式而人工构造的，可以与后面的 $\\boldsymbol x(t), \\boldsymbol u(t)$ 做矩阵乘法，取到对应的元素乘积。也就是说，上述两个矩阵分别有 $n^2,m^2$ 个，且每个都是上面这种只有一个元素不为 0 的稀疏形式。即\\[\\begin{aligned}\\dot \\boldsymbol x(t) &amp;=\\sum_{l=1}^2\\left[a_{11l}\\begin{bmatrix}  h_{11l}&amp;\\boldsymbol 0\\\\  \\boldsymbol 0&amp;\\boldsymbol 0\\\\\\end{bmatrix}\\boldsymbol x(t)+\\cdots+a_{nnl}\\begin{bmatrix}  \\boldsymbol 0&amp;\\boldsymbol 0\\\\  \\boldsymbol 0&amp;h_{nnl}\\\\\\end{bmatrix}\\boldsymbol x(t)+b_{11l}\\begin{bmatrix}  h_{11l}&amp;\\boldsymbol 0\\\\  \\boldsymbol 0&amp;\\boldsymbol 0\\\\\\end{bmatrix}\\boldsymbol u(t)+\\cdots+b_{nnl}\\begin{bmatrix}  \\boldsymbol 0&amp;\\boldsymbol 0\\\\  \\boldsymbol 0&amp;v_{nml}\\\\\\end{bmatrix}\\boldsymbol u(t)\\right]\\\\&amp;=\\sum_{l=1}^2\\left[\\begin{bmatrix}  h_{11l}a_{11l}&amp;\\cdots&amp;h_{1nl}a_{1nl}\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  h_{n1l}a_{n1l}&amp;\\cdots&amp;h_{nnl}a_{nnl}\\\\\\end{bmatrix}\\begin{bmatrix}  x_1(t)\\\\  \\vdots\\\\  x_n(t)\\end{bmatrix}+\\begin{bmatrix}  v_{11l}b_{11l}&amp;\\cdots&amp;v_{1ml}b_{1ml}\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  v_{n1l}b_{n1l}&amp;\\cdots&amp;v_{nml}b_{nml}\\\\\\end{bmatrix}\\begin{bmatrix}  u_1(t)\\\\  \\vdots\\\\  u_m(t)\\end{bmatrix}\\right]\\\\&amp;=\\sum_{l=1}^2\\left[\\boldsymbol h_l*\\boldsymbol A_l\\cdot \\boldsymbol x(t) + \\boldsymbol v_l*\\boldsymbol B_l\\cdot \\boldsymbol u(t)\\right]\\end{aligned}\\]作者表明，$a_{ijl}, b_{ikl}$ 再规则约减中非常重要，上面矩阵和的式子在规则约减中十分方便。3.1.2. 模糊化表示下面分析一般系统状态方程和广义 TS 模型之间的等价性，也即分析一般的系统状态方程怎么转化为广义 TS 模糊模型的形式。首先给出结论\\[\\begin{aligned}  \\dot \\boldsymbol x(t) &amp;=\\sum_{i=1}^n\\sum_{j=1}^n\\sum_{l=1}^2 h_{ijl}(\\boldsymbol z(t))a_{ijl} \\boldsymbol U^A_{ij} \\boldsymbol x(t)+\\sum_{i=1}^n\\sum_{k=1}^m\\sum_{l=1}^2 v_{ikl}(\\boldsymbol z(t))b_{ikl}\\boldsymbol U^B_{ik}\\boldsymbol u(t)\\\\  &amp;=\\sum_{p=1}^{2^{n(n+m)}} \\hat h_p(\\boldsymbol z(t))[\\hat \\boldsymbol A_p\\boldsymbol x(t) + \\hat \\boldsymbol B_p\\boldsymbol u(t)]                                     \\end{aligned}\\]下面进行一步步推导分析（原文中又是一个 where 易得，我人傻了）。利用各项系数和为 1 的性质，进行连乘展开\\[\\begin{aligned}  1 = &amp;\\overbrace{(h_{111}+h_{112})\\cdots (h_{1n1}+h_{1n2})}^{n}&amp;&lt;1&gt;\\\\  &amp;\\cdot(h_{211}+h_{212})\\cdots (h_{2n1}+h_{2n2})&amp;&lt;2&gt;\\\\  &amp;\\cdot\\quad \\cdots&amp;\\cdots\\\\  &amp;\\cdot(h_{n11}+h_{n12})\\cdots (h_{nn1}+h_{nn2})&amp;&lt;n&gt;\\\\  &amp;\\cdot\\overbrace{(v_{111}+v_{n12})\\cdots (v_{1m1}+v_{1m2})}^{m}&amp;&lt;1&gt;\\\\  &amp;\\cdot\\quad \\cdots&amp;\\cdots\\\\  &amp;\\cdot(v_{n11}+v_{n12})\\cdots (v_{nm1}+v_{nm2})&amp;&lt;n&gt;\\\\\\end{aligned}\\]上式中一共有 $n\\cdot n+n\\cdot m$ 个括号，每个括号的和均为 1。下面从每个括号中任意取一个元素（$l=1\\ or\\ 2$）组成连乘项  前 $n$ 行中，第一行展开后共有 $2^n$ 项，则前 $n$ 行一共有 $2^{n\\cdot n}$ 项；  后 $n$ 行中，第一行展开后共有 $2^m$ 项，则后 $n$ 行一共有 $2^{m\\cdot n}$ 项。那么，整个式子一共有 $C_{2^{n\\cdot n}}^1C_{2^{m\\cdot n}}^1=2^{n(n+m)}$ 项。每一项都是所有 $i,j,k$ 对不同 $l$ 的排列组合，即一共有 $2^{n(n+m)}$ 种排列组合。假设选取所有括号里的 $l=1$（取所有括号里左边的元素），设该连乘项为第 $p=1$ 项， 则该项为\\[\\begin{aligned}  t_{p=1} = &amp;(h_{111}\\cdots h_{1n1})\\cdots(h_{n11}\\cdots h_{nn1})\\\\  &amp;\\cdot(v_{111}\\cdots v_{1n1})\\cdots(v_{1m1}\\cdots v_{nm1})\\\\  = &amp;\\prod_{i=1}^n (h_{i11}\\cdots h_{in1}) \\cdot (v_{i11} \\cdots v_{im1})\\\\  = &amp;\\prod_{i=1}^n \\prod_{j=1}^n h_{ij1}\\cdot (v_{i11}\\cdots v_{im1})\\\\  = &amp;\\prod_{i=1}^n\\prod_{j=1}^n\\prod_{k=1}^m h_{ij1}v_{ik1}\\end{aligned}\\]对所有的 $p$ 个连乘项求和，得到原始等式的最终表达形式\\[1 =\\sum_{p=1}^{2^{n(n+m)}} t_p = \\sum_{p=1}^{2^{n(n+m)}} \\prod_{i=1}^n\\prod_{j=1}^n\\prod_{k=1}^m h_{ijl}v_{ikl}\\]其中 $l$ 与具体每项有关。那么\\[\\begin{aligned}  \\dot \\boldsymbol x(t) &amp;=\\sum_{i=1}^n\\sum_{j=1}^n\\sum_{l=1}^2 h_{ijl}a_{ijl}\\boldsymbol U_{ij}^A\\boldsymbol x(t) + \\sum_{i=1}^n\\sum_{k=1}^m\\sum_{l=1}^2 v_{ijl}(\\boldsymbol z(t))b_{ikl}\\boldsymbol U^B_{ik}\\boldsymbol u(t)\\\\  &amp;= \\sum_{i=1}^n\\sum_{j=1}^n\\sum_{l=1}^2h_{ijl}\\boldsymbol A_{ijl}\\boldsymbol x(t) + \\sum_{i=1}^n\\sum_{k=1}^m\\sum_{l=1}^2v_{ikl}\\boldsymbol B_{ikl}\\boldsymbol u(t)\\\\  &amp;=\\sum_{p=1}^{2^{n(n+m)}} \\prod_{i=1}^n\\prod_{j=1}^n\\prod_{k=1}^m h_{ijl}v_{ikl} \\left[ \\sum_{i=1}^n\\sum_{j=1}^n\\sum_{l=1}^2h_{ijl}\\boldsymbol A_{ijl}\\boldsymbol x(t) + \\sum_{i=1}^n\\sum_{k=1}^m\\sum_{l=1}^2v_{ikl}\\boldsymbol B_{ikl}\\boldsymbol u(t)\\right] \\\\\\end{aligned}\\]然后我就推不出来了！3.1.3. 举例考虑如下非线性系统\\[\\begin{aligned}\\left\\{\\begin{array}{l}\\dot x_1(t) = x_2(t)\\\\\\dot x_2(t) = x_1(t){\\rm cos}x_2(t)-x_3(t)\\\\\\dot x_3(t) = x_1(t)x_3(t) + (1+\\varepsilon {\\rm sin}x_3(t))u(t)\\end{array}\\right.\\end{aligned}\\]状态量的取值范围为\\[\\begin{aligned}  \\underline d_1\\leq x_1(t)\\leq \\overline d_1\\\\  \\underline d_2\\leq x_2(t)\\leq \\overline d_2\\\\  \\underline d_3\\leq x_3(t)\\leq \\overline d_3\\\\\\end{aligned}\\]其中\\[\\begin{aligned}\\underline d_1 &amp;= -5\\\\\\overline d_1 &amp;= 5\\\\\\underline d_2 &amp;= -\\pi/2\\\\\\overline d_2 &amp;= \\pi/2\\\\\\underline d_3 &amp;= -\\pi\\\\\\overline d_3 &amp;= \\pi\\\\\\varepsilon &amp;= 0.5\\\\\\end{aligned}\\]根据前面的约定，重新整理状态方程如下\\[\\begin{aligned}\\left\\{\\begin{array}{l}\\dot x_1(t) &amp;= 0\\cdot x_1(t)&amp; + 1\\cdot x_2(t)&amp; + 0\\cdot x_3(t)&amp; + 0\\cdot u(t)&amp;\\\\\\dot x_2(t) &amp;= {\\rm cos}x_2(t)\\cdot x_1(t)&amp; + 0\\cdot x_2(t)&amp; +(-1) \\cdot x_3(t)&amp; + 0\\cdot u(t)&amp;\\\\\\dot x_3(t) &amp;= 0\\cdot x_1(t)&amp; +0\\cdot x_2(t)&amp; + x_1(t)\\cdot x_3(t)&amp; + (1+\\varepsilon {\\rm sin}x_3(t))u(t)&amp;\\end{array}\\right.\\end{aligned}\\]有\\[\\begin{aligned}f_{11}(z(t)) &amp;= 0,\\ &amp;f_{12}(z(t)) = 1,\\ &amp;f_{13}(z(t)) = 0,\\ &amp;g_{11}(z(t)) = 0\\\\f_{21}(z(t)) &amp;= {\\rm cos}x_2(t),\\ &amp;f_{22}(z(t)) = 0,\\ &amp;f_{23}(z(t)) = -1,\\ &amp;g_{11}(z(t)) = 0\\\\f_{31}(z(t)) &amp;= 0,\\ &amp;f_{32}(z(t)) = 0,\\ &amp;f_{33}(z(t)) = x_1(t),\\ &amp;g_{11}(z(t)) = (1+\\varepsilon {\\rm sin}x_3(t))\\\\\\end{aligned}\\]计算系数的最大最小值，有（加 * 号的是原文中列出的，略去了  $a=b=0$ 项）\\[\\begin{aligned}a_{111} &amp;= 0,\\ &amp;a_{112} = 0\\\\*a_{121} &amp;= 1,\\ &amp;a_{122} = 1\\\\a_{131} &amp;= 0,\\ &amp;a_{132} = 0\\\\b_{111} &amp;= 0,\\ &amp;b_{112} = 0\\\\\\\\*a_{211} &amp;= 1,\\ &amp;a_{212} = 0\\\\a_{221} &amp;= 0,\\ &amp;a_{222} = 0\\\\*a_{231} &amp;= -1,\\ &amp;a_{232} = -1\\\\b_{211} &amp;= 0,\\ &amp;b_{212} = 0\\\\\\\\a_{311} &amp;= 0,\\ &amp;a_{312} = 0\\\\a_{321} &amp;= 0,\\ &amp;a_{322} = 0\\\\*a_{331} &amp;= 5,\\ &amp;a_{332} = -5\\\\*b_{311} &amp;= 1.5,\\ &amp;b_{312} = 0.5\\\\\\end{aligned}\\]隶属度函数指定为（加 * 号的是原文中列出的，略去了 $a=b=0$ 对应项）\\[\\begin{aligned}h_{111}(z(t)) &amp;= 0.5,\\ &amp;h_{112}(z(t)) = 0.5\\\\*h_{121}(z(t)) &amp;= 0.5,\\ &amp;h_{122}(z(t)) = 0.5\\\\h_{131}(z(t)) &amp;= 0.5,\\ &amp;h_{132}(z(t)) = 0.5\\\\v_{111}(z(t)) &amp;= 0.5,\\ &amp;v_{112}(z(t)) = 0.5\\\\\\\\*h_{211}(z(t)) &amp;= {\\rm cos}x_2(t),\\ &amp;h_{212}(z(t)) = 1-{\\rm cos}x_2(t)\\\\h_{221}(z(t)) &amp;= 0.5,\\ &amp;h_{222}(z(t)) = 0.5\\\\*h_{231}(z(t)) &amp;= 0.5,\\ &amp;h_{232}(z(t)) = 0.5\\\\v_{211}(z(t)) &amp;= 0.5,\\ &amp;v_{212}(z(t)) = 0.5\\\\\\\\h_{311}(z(t)) &amp;= 0.5,\\ &amp;h_{312}(z(t)) = 0.5\\\\h_{321}(z(t)) &amp;= 0.5,\\ &amp;h_{322}(z(t)) = 0.5\\\\*h_{331}(z(t)) &amp;= \\frac{x_1(t)+5}{10},\\ &amp;h_{332}(z(t)) = \\frac{5-x_1(t)}{10}\\\\*v_{311}(z(t)) &amp;= \\frac{1+{\\rm sin}x_3(t)}{2},\\ &amp;v_{312}(z(t)) = \\frac{1-{\\rm sin}x_3(t)}{2}\\\\\\end{aligned}\\]根据一般形式\\[\\dot \\boldsymbol x(t) =\\sum_{i=1}^n\\sum_{j=1}^n\\sum_{l=1}^2 h_{ijl}(\\boldsymbol z(t))a_{ijl} \\boldsymbol U^A_{ij} \\boldsymbol x(t) + \\sum_{i=1}^n\\sum_{k=1}^m\\sum_{l=1}^2 v_{ikl}(\\boldsymbol z(t))b_{ikl}\\boldsymbol U^B_{ik}\\boldsymbol u(t)\\]则原系统对应的模糊模型可以写为（所有 0 项乘积忽略）\\[\\begin{aligned}\\dot \\boldsymbol x(t) = &amp;h_{121}a_{121}\\boldsymbol U_{12}^A \\boldsymbol x(t)+h_{122}a_{122}\\boldsymbol U_{12}^A \\boldsymbol x(t)+\\\\&amp; h_{211}a_{211}\\boldsymbol U^A_{21} \\boldsymbol x(t)+h_{212}a_{212}\\boldsymbol U^A_{21} \\boldsymbol x(t)+\\\\&amp; h_{231}a_{231}\\boldsymbol U^A_{23} \\boldsymbol x(t)+h_{232}a_{232}\\boldsymbol U^A_{23} \\boldsymbol x(t)+\\\\&amp; h_{331}a_{331}\\boldsymbol U^A_{33} \\boldsymbol x(t)+h_{332}a_{332}\\boldsymbol U^A_{33} \\boldsymbol x(t)+\\\\&amp; v_{311}b_{311}\\boldsymbol U^B_{31} \\boldsymbol u(t)+v_{312}b_{312}\\boldsymbol U^B_{31} \\boldsymbol u(t)\\end{aligned}\\]进行矩阵化，$h, a$ 的前两个下标以及 $U$ 的下标为行列号，$h, a$ 的第三个下标为最大最小值的加权和作为元素值，列写出子矩阵\\[\\begin{aligned}\\boldsymbol A_1 &amp;= h_{121}a_{121}\\boldsymbol U_{12}^A\\\\\\boldsymbol A_2 &amp;= h_{122}a_{122}\\boldsymbol U_{12}^A\\\\\\boldsymbol A_3 &amp;= h_{211}a_{211}\\boldsymbol U_{21}^A\\\\\\boldsymbol A_4 &amp;= h_{212}a_{212}\\boldsymbol U_{21}^A\\\\\\boldsymbol A_5 &amp;= h_{231}a_{231}\\boldsymbol U_{23}^A\\\\\\boldsymbol A_6 &amp;= h_{232}a_{232}\\boldsymbol U_{23}^A\\\\\\boldsymbol A_7 &amp;= h_{331}a_{331}\\boldsymbol U_{33}^A\\\\\\boldsymbol A_8 &amp;= h_{332}a_{332}\\boldsymbol U_{33}^A\\\\\\boldsymbol B_1 &amp;= v_{311}a_{311}\\boldsymbol U_{31}^B\\\\\\boldsymbol B_2 &amp;= v_{312}a_{312}\\boldsymbol U_{31}^B\\\\\\end{aligned}\\]令\\[\\begin{aligned}\\boldsymbol A &amp;= \\boldsymbol A_1+\\boldsymbol A_2+\\cdots+\\boldsymbol A_8\\\\\\boldsymbol B &amp;= \\boldsymbol B_1+\\boldsymbol B_2\\end{aligned}\\]有\\[\\begin{aligned}\\dot \\boldsymbol x(t) &amp;= \\boldsymbol A\\boldsymbol x(t) + \\boldsymbol B\\boldsymbol u(t)\\\\\\end{aligned}\\]但是这并不是广义模糊 TS 系统的形式，下面进行转换。注意到（存在两组最大最小值相等的情况）\\[a_{121}=a_{122}=1,\\ a_{231}=a_{232}=-1\\]则\\[\\begin{aligned}\\boldsymbol A_1 &amp;= \\boldsymbol A_2 = 0.5\\boldsymbol U_{12}^A\\\\\\boldsymbol A_5 &amp;= \\boldsymbol A_6 = -0.5\\boldsymbol U_{23}^A\\\\\\boldsymbol A_{b1} &amp;= \\boldsymbol A_1 + \\boldsymbol A_2 = \\begin{bmatrix}  0&amp;1&amp;0\\\\  0&amp;0&amp;0\\\\  0&amp;0&amp;0\\end{bmatrix}\\\\\\boldsymbol A_{b2} &amp;= \\boldsymbol A_5 + \\boldsymbol A_6 = \\begin{bmatrix}  0&amp;0&amp;0\\\\  0&amp;0&amp;-1\\\\  0&amp;0&amp;0\\end{bmatrix}\\\\\\boldsymbol A_{b} &amp;= \\boldsymbol A_{b1} + \\boldsymbol A_{b2} = \\begin{bmatrix}  0&amp;1&amp;0\\\\  0&amp;0&amp;-1\\\\  0&amp;0&amp;0\\end{bmatrix}\\end{aligned}\\]分析其它子矩阵。将子矩阵进行变换，如下\\[\\begin{aligned}\\boldsymbol A_3 &amp;= h_{211}a_{211}\\boldsymbol U_{21}^A = h_{211}(v_{311}+v_{312})(h_{331}+h_{332})a_{211}\\boldsymbol U_{21}^A\\\\\\boldsymbol A_4 &amp;= h_{212}a_{211}\\boldsymbol U_{21}^A = h_{212}(v_{311}+v_{312})(h_{331}+h_{332})a_{212}\\boldsymbol U_{21}^A\\\\\\boldsymbol A_7 &amp;= h_{331}a_{331}\\boldsymbol U_{33}^A = h_{331}(v_{311}+v_{312})(h_{211}+h_{212}) a_{331}\\boldsymbol U_{33}^A\\\\\\boldsymbol A_8 &amp;= h_{332}a_{332}\\boldsymbol U_{33}^A = h_{332}(v_{311}+v_{312})(h_{211}+h_{212})a_{332}\\boldsymbol U_{33}^A\\\\\\boldsymbol B_1 &amp;= v_{311}b_{311}\\boldsymbol U_{31}^B= v_{311}(h_{211}+h_{212})(h_{331}+h_{332})b_{311}\\boldsymbol U_{31}^B\\\\\\boldsymbol B_2 &amp;= v_{312}b_{312}\\boldsymbol U_{31}^B= v_{312}(h_{211}+h_{212})(h_{331}+h_{332})b_{312}\\boldsymbol U_{31}^B\\\\\\end{aligned}\\]类似的，将前面的两个矩阵的系数进行配合\\[\\begin{aligned}  \\boldsymbol A_{b} &amp;= (h_{211}+h_{212})(v_{311}+v_{312})(h_{331}+h_{332})\\boldsymbol A_{b}\\\\\\end{aligned}\\]将系数展开后得到 八 组系数\\[\\begin{aligned}h_1 &amp;= h_{211}h_{331}v_{311}\\\\h_2 &amp;= h_{212}h_{331}v_{311}\\\\h_3 &amp;= h_{211}h_{332}v_{311}\\\\h_4 &amp;= h_{212}h_{332}v_{311}\\\\h_5 &amp;= h_{211}h_{331}v_{312}\\\\h_6 &amp;= h_{212}h_{331}v_{312}\\\\h_7 &amp;= h_{211}h_{332}v_{312}\\\\h_8 &amp;= h_{212}h_{332}v_{312}\\\\\\end{aligned}\\]则\\[\\begin{aligned}  \\boldsymbol A_{b} &amp;= (h_1+h_2+h_3+h_4+h_5+h_6+h_7+h_8)\\boldsymbol A_{b}\\\\  \\boldsymbol A_3 &amp;=(h_1+h_3+h_5+h_7)a_{211}\\boldsymbol U_{21}^A\\\\  \\boldsymbol A_4 &amp;=(h_2+h_4+h_6+h_8)a_{212}\\boldsymbol U_{21}^A\\\\  \\boldsymbol A_7 &amp;=(h_1+h_2+h_5+h_6)a_{331}\\boldsymbol U_{33}^A\\\\  \\boldsymbol A_8 &amp;=(h_3+h_4+h_7+h_8)a_{332}\\boldsymbol U_{33}^A\\\\  \\boldsymbol B_1 &amp;= (h_1+h_2+h_3+h_4)\\boldsymbol b_{311}U_{31}^B\\\\  \\boldsymbol B_2 &amp;= (h_5+h_6+h_7+h_8)\\boldsymbol b_{312}U_{31}^B\\\\\\end{aligned}\\]按照系数 $h$ 重新整理矩阵，有\\[\\begin{aligned}\\boldsymbol A = &amp;h_1\\boldsymbol A_1+h_2\\boldsymbol A_2+\\cdots+h_8\\boldsymbol A_8 +\\\\&amp;h_1\\boldsymbol B_1 + h_2\\boldsymbol B_2 + \\cdots + h_8\\boldsymbol B_8\\end{aligned}\\]其中\\[\\begin{aligned}  \\boldsymbol A_1 &amp;= \\boldsymbol A_5 = \\boldsymbol A_b + a_{211}\\boldsymbol U_{21}^A + a_{331}\\boldsymbol U_{33}^A =  \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 1&amp;0&amp;-1\\\\  0&amp;0&amp;\\boldsymbol 5  \\end{bmatrix}\\\\  \\boldsymbol A_2 &amp;= \\boldsymbol A_6  = \\boldsymbol A_b + a_{212}\\boldsymbol U_{21}^A + a_{331}\\boldsymbol U_{33}^A =  \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 0&amp;0&amp;-1\\\\  0&amp;0&amp;\\boldsymbol 5  \\end{bmatrix}\\\\  \\boldsymbol A_3 &amp;= \\boldsymbol A_7 = \\boldsymbol A_b + a_{211}\\boldsymbol U_{21}^A + a_{332}\\boldsymbol U_{33}^A =  \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 1&amp;0&amp;-1\\\\  0&amp;0&amp;-\\boldsymbol 5  \\end{bmatrix}\\\\  \\boldsymbol A_4 &amp;= \\boldsymbol A_8 = \\boldsymbol A_b + a_{212}\\boldsymbol U_{21}^A + a_{332}\\boldsymbol U_{33}^A =  \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 0&amp;0&amp;-1\\\\  0&amp;0&amp;-\\boldsymbol 5  \\end{bmatrix}\\\\  \\boldsymbol B_1 &amp;= \\boldsymbol B_2 = \\boldsymbol B_3 = \\boldsymbol B_4 = b_{311}U_{31}^B =  \\begin{bmatrix}  0\\\\  0\\\\  1.5  \\end{bmatrix}\\\\  \\boldsymbol B_5 &amp;= \\boldsymbol B_6 = \\boldsymbol B_7 = \\boldsymbol B_8 = b_{312}U_{31}^B =  \\begin{bmatrix}  0\\\\  0\\\\  0.5  \\end{bmatrix}\\\\  \\end{aligned}\\]至此终于推得文中 「易得」 的系数，汗！按照整理后的系数和矩阵重新写系统状态方程，有\\[\\dot \\boldsymbol x(t) = \\sum_{i=1}^8 h_i(\\boldsymbol z(t))[\\boldsymbol A_i\\boldsymbol x(t) + \\boldsymbol B_i\\boldsymbol u(t)]\\]  Note that this fuzzy model has nonlinear terms in $A(2,1),A(3,3)$, and $B(3,1)$, where denotes the (2, 1) element of $A$ matrix.原文说模糊系统的 $\\boldsymbol A$ 的 $(2,1),(3,3)$ 元素和矩阵 $\\boldsymbol B$ 的 $(3,1)$ 元素是非线性项。个人觉得，单纯从系数矩阵而言 $\\boldsymbol A(3,3)$ 并不是非线性项，但是对于整个系统而言的确是非线性的。3.2. 规则约减3.2.1. 约减方式规则约减与使用 LMI 进行控制器设计的计算工作量密切相关。基本思路：将非线性项 $f_{ij}(\\boldsymbol z(t)), g_{ik}(\\boldsymbol z(t))$ 替换为常数项 $a_{i_0j_0},b_{i_0k_0}$，其中 $a_{i_0j_0}=(a_{ij1}+a_{ij2})/2,\\ b_{i_0k_0} = (b_{ik1}+b_{ik2})/2$。对于任意的 $i_0,j_0$，对 $f_{i_0j_0}(\\boldsymbol z(t))$ 约减后的模型为\\[\\begin{aligned}\\dot \\boldsymbol x(t) = &amp;\\mathop{\\sum_{i=1}^n\\sum_{j=1}^n\\sum_{l=1}^2}\\limits_{(i,j)\\neq (i_0,j_0)} h_{ijl}(\\boldsymbol z(t))a_{ijl} \\boldsymbol U^A_{ij} \\boldsymbol x(t)\\\\&amp;+a_{i_0j_0}\\boldsymbol U^A_{i_0j_0} \\boldsymbol x(t)\\\\&amp;+\\sum_{i=1}^n\\sum_{k=1}^m\\sum_{l=1}^2 v_{ijl}(\\boldsymbol z(t))b_{ikl}\\boldsymbol U^B_{ik}\\boldsymbol u(t)\\end{aligned}\\]类似地，对于任意的 $i_0,k_0$，对 $g_{i_0j_0}(\\boldsymbol z(t))$ 约减后的模型为\\[\\begin{aligned}\\dot \\boldsymbol x(t) = &amp;\\sum_{i=1}^n\\sum_{j=1}^n\\sum_{l=1}^2 h_{ijl}(\\boldsymbol z(t))a_{ijl} \\boldsymbol U^A_{ij} \\boldsymbol x(t)\\\\&amp;+\\mathop{\\sum_{i=1}^n\\sum_{k=1}^m\\sum_{l=1}^2}\\limits_{(i,k)\\neq (i_0,k_0)} v_{ikl}(\\boldsymbol z(t))b_{ikl}\\boldsymbol U^B_{ik}\\boldsymbol u(t)\\\\&amp;+b_{i_0k_0}\\boldsymbol U^B_{i_0k_0} \\boldsymbol u(t)\\end{aligned}\\]个人理解，假设针对第 $(i,j)=(1,1)$ 个 $f_{ij}$ 进行规则约减，有\\[\\begin{aligned}\\dot \\boldsymbol x(t) &amp;=\\sum_{l=1}^2\\left[\\begin{bmatrix}  h_{11l}a_{11l}&amp;\\cdots&amp;h_{1nl}a_{1nl}\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  h_{n1l}a_{n1l}&amp;\\cdots&amp;h_{nnl}a_{nnl}\\\\\\end{bmatrix}\\begin{bmatrix}  x_1(t)\\\\  \\vdots\\\\  x_n(t)\\end{bmatrix}+\\begin{bmatrix}  v_{11l}b_{11l}&amp;\\cdots&amp;v_{1ml}b_{1ml}\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  v_{n1l}b_{n1l}&amp;\\cdots&amp;v_{nml}b_{nml}\\\\\\end{bmatrix}\\begin{bmatrix}  u_1(t)\\\\  \\vdots\\\\  u_m(t)\\end{bmatrix}\\right]\\\\&amp;=\\begin{bmatrix}  h_{111}a_{111}+h_{112}a_{112}&amp;\\cdots&amp;h_{1n1}a_{1n1}+h_{1n2}a_{1n2}\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  h_{n11}a_{n11}+h_{n12}a_{n12}&amp;\\cdots&amp;h_{nn1}a_{nn1}+h_{nn2}a_{nn2}\\\\\\end{bmatrix}\\begin{bmatrix}  x_1(t)\\\\  \\vdots\\\\  x_n(t)\\end{bmatrix}+\\cdots\\\\&amp;=\\begin{bmatrix}  (a_{111}+a_{112})/2&amp;\\cdots&amp;h_{1n1}a_{1n1}+h_{1n2}a_{1n2}\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  h_{n11}a_{n11}+h_{n12}a_{n12}&amp;\\cdots&amp;h_{nn1}a_{nn1}+h_{nn2}a_{nn2}\\\\\\end{bmatrix}\\begin{bmatrix}  x_1(t)\\\\  \\vdots\\\\  x_n(t)\\end{bmatrix}+\\cdots\\end{aligned}\\]同理，对第 $(i,k)=(1,1)$ 个 $g_{ik}$ 进行规则约减，有\\[\\begin{aligned}\\dot \\boldsymbol x(t) &amp;=\\cdots + \\begin{bmatrix}  (b_{111}+b_{112})/2&amp;\\cdots&amp;v_{1m1}b_{1m1}+v_{1m2}v_{1m2}\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  v_{n11}b_{n11}+v_{n12}b_{n12}&amp;\\cdots&amp;v_{nm1}b_{nm1}+v_{nm2}b_{nm2}\\\\\\end{bmatrix}\\begin{bmatrix}  u_1(t)\\\\  \\vdots\\\\  u_m(t)\\end{bmatrix}\\end{aligned}\\]3.2.2. 模型不确定性对原始模型进行规则约减后，会存在约减偏差，作者将其转化为模型不确定性。  任一约减对于某一 $i_0,j_0,k_0$ 项进行规则约减，假设模型不确定性为 $\\delta^A_{i_0j_0}(t),\\delta^B_{i_0k_0}(t)$，已知\\[a_{i_0j_0}=\\frac{a_{ij1}+a_{ij2}}{2},\\ b_{i_0k_0}=\\frac{b_{ik1}+b_{ik2}}{2}\\]那么原模型可写为\\[\\begin{aligned}\\dot \\boldsymbol x(t) = &amp;\\mathop{\\sum_{i=1}^n\\sum_{j=1}^n\\sum_{l=1}^2}\\limits_{(i,j)\\neq (i_0,j_0)} h_{ijl}(\\boldsymbol z(t))a_{ijl} \\boldsymbol U^A_{ij} \\boldsymbol x(t)\\\\&amp;+(a_{i_0j_0} + \\delta^A_{i_0j_0}(t))\\boldsymbol U^A_{i_0j_0} \\boldsymbol x(t)\\\\&amp;+\\mathop{\\sum_{i=1}^n\\sum_{k=1}^m\\sum_{l=1}^2}\\limits_{(i,k)\\neq (i_0,k_0)} v_{ikl}(\\boldsymbol z(t))b_{ikl}\\boldsymbol U^B_{ik}\\boldsymbol u(t)\\\\&amp;+(b_{i_0k_0}+\\delta^B_{i_0k_0}(t))\\boldsymbol U^B_{i_0k_0} \\boldsymbol u(t)\\end{aligned}\\]这种约减导致的偏差，最大不会超过对应非线性项取值范围的一半（比如该项实际取值为最小值，结果我们用其平均值作为替代，此时偏差正好为取值范围的一半）。即\\[\\vert\\vert \\delta^A_{i_0j_0}(t) \\vert\\vert \\leq \\frac{a_{ij1}-a_{ij2}}{2},\\ \\vert\\vert \\delta^B_{i_0k_0}(t) \\vert\\vert\\leq \\frac{b_{ik1}-b_{ik2}}{2}\\]对模糊化后的系统方程进行重新表达，令\\[\\begin{aligned}r&amp;=2^{n(n+m)}\\end{aligned}\\]则系统可以写为\\[\\begin{aligned}\\dot \\boldsymbol x(t)&amp;=\\sum_{p=1}^{2^{n(n+m)}} \\hat h_p(\\boldsymbol z(t))[\\hat \\boldsymbol A_p\\boldsymbol x(t) + \\hat \\boldsymbol B_p\\boldsymbol u(t)]\\\\&amp;= \\sum_{p=1}^{\\frac{1}{4}r}h_p(\\boldsymbol z(t))[\\boldsymbol A_p\\boldsymbol x(t)+\\boldsymbol B_p\\boldsymbol u(t)+\\delta^A_{i_0j_0}(t) \\boldsymbol U_{i_0j_0}\\boldsymbol x(t)+\\delta^B_{i_0k_0}(t) \\boldsymbol U_{i_0k_0}\\boldsymbol u(t)]\\\\&amp;=\\sum_{p=1}^{\\frac{1}{4}r}h_p(\\boldsymbol z(t))[  (\\boldsymbol A_p + \\boldsymbol D_{ap}\\Delta_{ap}(t)\\boldsymbol E_{ap})\\boldsymbol x(t)+(\\boldsymbol B_p+ \\boldsymbol D_{bp}\\Delta_{bp}(t)\\boldsymbol E_{bp})\\boldsymbol u(t)]\\end{aligned}\\]其中，$\\frac{1}{4}r$ 是因为系统中有两项（$f_{ij},g_{ik}$）被约减了。每少一项，需要遍历的参数减半（参考前面系数和的连乘的分析），因此总规则个数需要除以 $2\\cdot 2=4$。$\\boldsymbol A_p,\\boldsymbol B_p$ 为去除 $(i_0,j_0)$ 元素后的系数矩阵。矩阵 $\\boldsymbol D_{ap},\\boldsymbol E_{ap},\\boldsymbol D_{bp},\\boldsymbol E_{bp}$ 为\\[\\begin{aligned}\\boldsymbol D_{ap} &amp;= \\boldsymbol D_{bp} = i_0\\begin{bmatrix}  0\\\\\\vdots\\\\0\\\\1\\\\0\\\\ \\vdots\\\\ 0\\end{bmatrix}\\\\&amp;\\quad \\quad \\quad \\quad \\ \\ \\ j_0\\\\\\boldsymbol E_{ap} &amp;= [0\\ \\cdots\\ 0\\ 1\\ 0\\ \\cdots\\ 0]\\\\&amp;\\quad \\quad \\quad \\quad \\ \\ \\ k_0\\\\\\boldsymbol E_{bp} &amp;= [0\\ \\cdots\\ 0\\ 1\\ 0\\ \\cdots\\ 0]\\\\\\end{aligned}\\]  一般约减对于任意 $i,j,k$ 项进行规则约减，引入模型不确定性 $\\boldsymbol \\Delta^A_{ij}(t),\\boldsymbol \\Delta^B_{ik}(t)$，有\\[\\begin{aligned}\\dot \\boldsymbol x(t)&amp;=\\sum_{i=1}^n\\sum_{j=1}^n (a_{ij}+\\delta^A_{ij}(t))\\boldsymbol U_{ij}^A\\boldsymbol x(t) + \\sum_{i=1}^n\\sum_{k=1}^m (b_{ik}+\\delta^B_{ik}(t))\\boldsymbol U_{ik}^B\\boldsymbol u(t)\\\\\\end{aligned}\\]其中\\[\\vert\\vert \\delta^A_{ij}(t) \\vert\\vert \\leq \\frac{a_{ij1}-a_{ij2}}{2},\\ \\vert\\vert \\delta^B_{ik}(t) \\vert\\vert\\leq \\frac{b_{ik1}-b_{ik2}}{2}\\]写成矩阵的形式\\[\\dot \\boldsymbol x(t)=\\sum_{i=1}^{\\frac{1}{4}r} (\\boldsymbol A_i+\\boldsymbol D_{ai}\\boldsymbol \\Delta_{ai}(t)\\boldsymbol E_{ai})\\boldsymbol x(t)+(\\boldsymbol B_i+ \\boldsymbol D_{bi}\\boldsymbol \\Delta_{bi}(t)\\boldsymbol E_{bi})\\boldsymbol u(t)\\]其中\\[\\vert\\vert \\delta^A_{ij}(t) \\vert\\vert \\leq \\frac{1}{\\rho_{ai}},\\ \\vert\\vert \\delta^B_{ik}(t) \\vert\\vert\\leq \\frac{1}{\\rho_{bi}}\\]$\\frac{1}{\\rho_{ai}},\\frac{1}{\\rho_{bi}}$ 根据前面不确定性不等式的上界决定（原文可能误写作 $\\rho_{ai},\\rho_{bi}$）。  全部约减对于所有 $i,j,k$ 项进行规则约减，那么很显然，规则最终从 $2^{n(n+m)}$ 个变成 1 个。引入模型不确定性 $\\delta^A_{ij}(t),\\delta^B_{ik}(t)$，有\\[\\begin{aligned}\\dot \\boldsymbol x(t)&amp;=\\sum_{i=1}^n\\sum_{j=1}^n (a_{ij}+\\delta^A_{ij}(t))\\boldsymbol U_{ij}^A\\boldsymbol x(t) + \\sum_{i=1}^n\\sum_{k=1}^m (b_{ik}+\\delta^B_{ik}(t))\\boldsymbol U_{ik}^B\\boldsymbol u(t)\\\\\\end{aligned}\\]其中\\[\\vert\\vert \\delta^A_{ij}(t) \\vert\\vert \\leq \\frac{a_{ij1}-a_{ij2}}{2},\\ \\vert\\vert \\delta^B_{ik}(t) \\vert\\vert\\leq \\frac{b_{ik1}-b_{ik2}}{2}\\]写成矩阵的形式\\[\\dot \\boldsymbol x(t)=(\\boldsymbol A_1+\\boldsymbol D_{a1}\\boldsymbol \\Delta_{a1}(t)\\boldsymbol E_{a1})\\boldsymbol x(t)+(\\boldsymbol B_1+ \\boldsymbol D_{b1}\\boldsymbol \\Delta_{b1}(t)\\boldsymbol E_{b1})\\boldsymbol u(t)\\]其中\\[\\begin{aligned}  \\boldsymbol A_1 &amp;= \\begin{bmatrix}    a_{11}&amp;a_{12}&amp;\\cdots&amp;a_{1n}\\\\    a_{21}&amp;a_{22}&amp;\\cdots&amp;a_{2n}\\\\    \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\    a_{n1}&amp;a_{n2}&amp;\\cdots&amp;a_{nn}\\\\  \\end{bmatrix}\\in \\mathbb R^{n\\times n},\\   \\boldsymbol B_1 = \\begin{bmatrix}    b_{11}&amp;b_{12}&amp;\\cdots&amp;a_{1m}\\\\    b_{21}&amp;b_{22}&amp;\\cdots&amp;a_{2m}\\\\    \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\    b_{n1}&amp;b_{n2}&amp;\\cdots&amp;a_{nm}\\\\  \\end{bmatrix}\\in \\mathbb R^{n\\times m}\\\\  \\boldsymbol \\Delta_{a1}(t) &amp;= diag(\\delta_{11}^A(t)\\cdots\\delta_{1n}^A(t)\\cdots\\delta_{nn}^A(t)) = \\begin{bmatrix}    \\delta_{11}^A(t)&amp;&amp;\\boldsymbol 0\\\\    &amp;\\ddots&amp;\\\\    \\boldsymbol 0&amp;&amp;\\delta_{nn}^A(t)  \\end{bmatrix}\\in R^{n^2\\times n^2}\\\\  \\boldsymbol \\Delta_{b1}(t) &amp;= diag(\\delta_{11}^B(t)\\cdots\\delta_{1m}^B(t)\\cdots\\delta_{nm}^B(t)) = \\begin{bmatrix}  \\delta_{11}^B(t)&amp;&amp;\\boldsymbol 0\\\\  &amp;\\ddots&amp;\\\\  \\boldsymbol 0&amp;&amp;\\delta_{nm}^B(t)  \\end{bmatrix}\\in R^{nm\\times nm}\\\\  \\boldsymbol D_{a1} &amp;= \\begin{bmatrix}    \\overbrace{1 1\\cdots 1}^n&amp;&amp;\\boldsymbol 0\\\\    \\vdots&amp;\\ddots&amp;\\vdots\\\\    \\boldsymbol 0&amp;&amp;\\overbrace{1 1\\cdots 1}^n  \\end{bmatrix}\\in \\mathbb R^{n\\times n^2},\\   \\boldsymbol D_{b1} = \\begin{bmatrix}  \\overbrace{1 1\\cdots 1}^m&amp;&amp;\\boldsymbol 0\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  \\boldsymbol 0&amp;&amp;\\overbrace{1 1\\cdots 1}^m  \\end{bmatrix}\\in \\mathbb R^{n\\times nm}\\\\  \\boldsymbol E_{a1} &amp;= \\begin{bmatrix}    \\boldsymbol I_n\\\\    \\vdots\\\\    \\boldsymbol I_n\\\\  \\end{bmatrix} =\\begin{bmatrix}    1&amp;&amp;\\boldsymbol 0\\\\    &amp;\\ddots&amp;\\\\    \\boldsymbol 0&amp;&amp;1\\\\    1&amp;&amp;\\boldsymbol 0\\\\    &amp;\\ddots&amp;\\\\    \\boldsymbol 0&amp;&amp;1\\\\    &amp;\\vdots&amp;\\\\    \\boldsymbol 0&amp;&amp;1\\\\  \\end{bmatrix}\\in \\mathbb R^{n^2\\times n},\\   \\boldsymbol E_{b1} = \\begin{bmatrix}    \\boldsymbol I_m\\\\    \\vdots\\\\    \\boldsymbol I_m\\\\  \\end{bmatrix} \\in \\mathbb R^{nm\\times m},\\end{aligned}\\]偏差矩阵 $\\boldsymbol D_{a1}\\boldsymbol \\Delta_{a1}(t)\\boldsymbol E_{a1}$ 和系数矩阵 $\\boldsymbol A_1$ 的形式一致，虽然我并不明白为什么非要这么写成这么复杂的矩阵形式\\[\\begin{aligned}\\boldsymbol D_{a1}\\boldsymbol \\Delta_{a1}(t)\\boldsymbol E_{a1} &amp;=\\begin{bmatrix}  \\overbrace{1 1\\cdots 1}^n&amp;&amp;\\boldsymbol 0\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  \\boldsymbol 0&amp;&amp;\\overbrace{1 1\\cdots 1}^n\\end{bmatrix}_{n\\times n^2}\\begin{bmatrix}  \\delta_{11}^A(t)&amp;&amp;\\boldsymbol 0\\\\  &amp;\\ddots&amp;\\\\  \\boldsymbol 0&amp;&amp;\\delta_{nn}^A(t)\\end{bmatrix}_{n^2\\times n^2}\\begin{bmatrix}  1&amp;&amp;\\boldsymbol 0\\\\  &amp;\\ddots&amp;\\\\  \\boldsymbol 0&amp;&amp;1\\\\  1&amp;&amp;\\boldsymbol 0\\\\  &amp;\\ddots&amp;\\\\  \\boldsymbol 0&amp;&amp;1\\\\  &amp;\\vdots&amp;\\\\  \\boldsymbol 0&amp;&amp;1\\\\\\end{bmatrix}_{n^2\\times n}\\\\&amp;=\\begin{bmatrix}  \\overbrace{\\delta_{11}^A(t)\\ \\delta_{12}^A(t)\\ \\cdots \\delta_{1n}^A(t)}^n&amp;&amp;\\boldsymbol 0\\\\  \\vdots&amp;\\ddots&amp;\\vdots\\\\  \\boldsymbol 0&amp;&amp;\\overbrace{\\delta_{n1}^A(t)\\ \\delta_{n2}^A(t)\\ \\cdots \\delta_{nn}^A(t)}^n\\end{bmatrix}_{n\\times n^2}\\begin{bmatrix}  1&amp;&amp;\\boldsymbol 0\\\\  &amp;\\ddots&amp;\\\\  \\boldsymbol 0&amp;&amp;1\\\\  1&amp;&amp;\\boldsymbol 0\\\\  &amp;\\ddots&amp;\\\\  \\boldsymbol 0&amp;&amp;1\\\\  &amp;\\vdots&amp;\\\\  \\boldsymbol 0&amp;&amp;1\\\\\\end{bmatrix}_{n^2\\times n}\\\\&amp;=\\begin{bmatrix}  \\delta_{11}^A(t)&amp;\\delta_{12}^A(t)&amp;\\cdots&amp;\\delta_{1n}^A(t)\\\\  \\delta_{21}^A(t)&amp;\\delta_{22}^A(t)&amp;\\cdots&amp;\\delta_{2n}^A(t)\\\\  \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\  \\delta_{n1}^A(t)&amp;\\delta_{n2}^A(t)&amp;\\cdots&amp;\\delta_{nn}^A(t)\\\\\\end{bmatrix}\\end{aligned}\\]偏差矩阵 $\\boldsymbol D_{b1}\\boldsymbol \\Delta_{b1}(t)\\boldsymbol E_{b1}$ 和系数矩阵 $\\boldsymbol B_1$ 类似，这里不再赘述。3.2.3. 举例对前面已经完成建模的系统（3.1.3. 举例）进行规则约减。系统状态方程为\\[\\dot \\boldsymbol x(t) = \\sum_{i=1}^8 h_i(\\boldsymbol z(t))[\\boldsymbol A_i\\boldsymbol x(t) + \\boldsymbol B_i\\boldsymbol u(t)]\\]其中\\[\\begin{aligned}  h_1 &amp;= h_{211}h_{331}v_{311}={\\rm cos}x_2(t)\\cdot\\frac{5+x_1(t)}{10}\\cdot\\frac{1+{\\rm sin}x_3(t)}{2}\\\\  h_2 &amp;= h_{212}h_{331}v_{311}=(1-{\\rm cos}x_2(t))\\cdot\\frac{5+x_1(t)}{10}\\cdot\\frac{1+{\\rm sin}x_3(t)}{2}\\\\  h_3 &amp;= h_{211}h_{332}v_{311}={\\rm cos}x_2(t)\\cdot\\frac{5-x_1(t)}{10}\\cdot\\frac{1+{\\rm sin}x_3(t)}{2}\\\\  h_4 &amp;= h_{212}h_{332}v_{311}=(1-{\\rm cos}x_2(t))\\cdot\\frac{5-x_1(t)}{10}\\cdot\\frac{1+{\\rm sin}x_3(t)}{2}\\\\  h_5 &amp;= h_{211}h_{331}v_{312}={\\rm cos}x_2(t)\\cdot\\frac{5+x_1(t)}{10}\\cdot\\frac{1-{\\rm sin}x_3(t)}{2}\\\\  h_6 &amp;= h_{212}h_{331}v_{312}=(1-{\\rm cos}x_2(t))\\cdot\\frac{5+x_1(t)}{10}\\cdot\\frac{1-{\\rm sin}x_3(t)}{2}\\\\  h_7 &amp;= h_{211}h_{332}v_{312}={\\rm cos}x_2(t)\\cdot\\frac{5-x_1(t)}{10}\\cdot\\frac{1-{\\rm sin}x_3(t)}{2}\\\\  h_8 &amp;= h_{212}h_{332}v_{312}=(1-{\\rm cos}x_2(t))\\cdot\\frac{5-x_1(t)}{10}\\cdot\\frac{1-{\\rm sin}x_3(t)}{2}\\\\  \\boldsymbol A_1 &amp;= \\boldsymbol A_5 =   \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 1&amp;0&amp;-1\\\\  0&amp;0&amp;\\boldsymbol 5  \\end{bmatrix},\\   \\boldsymbol A_2 = \\boldsymbol A_6  =   \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 0&amp;0&amp;-1\\\\  0&amp;0&amp;\\boldsymbol 5  \\end{bmatrix}\\\\  \\boldsymbol A_3 &amp;= \\boldsymbol A_7 =   \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 1&amp;0&amp;-1\\\\  0&amp;0&amp;-\\boldsymbol 5  \\end{bmatrix},\\   \\boldsymbol A_4 = \\boldsymbol A_8 =   \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 0&amp;0&amp;-1\\\\  0&amp;0&amp;-\\boldsymbol 5  \\end{bmatrix}\\\\  \\boldsymbol B_1 &amp;= \\boldsymbol B_2 = \\boldsymbol B_3 = \\boldsymbol B_4 =  \\begin{bmatrix}  0\\\\  0\\\\  1.5  \\end{bmatrix},\\   \\boldsymbol B_5 = \\boldsymbol B_6 = \\boldsymbol B_7 = \\boldsymbol B_8 =   \\begin{bmatrix}  0\\\\  0\\\\  0.5  \\end{bmatrix}  \\end{aligned}\\]  约减形式一如果针对 $A(2,1)$ 进行规则约减，即 $A(2,1)=\\sum_ih_iA_i(2,1)\\equiv\\frac{1+0}{2}=0.5$。此时相当于 $h_{211},h_{212}$ 失去作用，$A_1,A_2$ 合并为新的 $A_1^\\prime$（原文中仍以 $A_1$ 表示），其它矩阵类似。隶属度函数 $h_1,h_2$ 合并为 $h_1^\\prime$（原文中以 $m_1$ 表示），其它隶属度函数类似。则规则数和矩阵数目减半，系统变为\\[\\begin{aligned}  \\dot \\boldsymbol x(t) &amp;= \\sum_{i=1}^4 h_i^\\prime(\\boldsymbol z(t))[\\boldsymbol A_i^\\prime\\boldsymbol x(t) + \\boldsymbol B_i^\\prime\\boldsymbol u(t)]\\\\  h_1^\\prime &amp;= h_{331}v_{311}=\\frac{5+x_1(t)}{10}\\cdot\\frac{1+{\\rm sin}x_3(t)}{2}\\\\  h_2^\\prime &amp;= h_{332}v_{311}=\\frac{5-x_1(t)}{10}\\cdot\\frac{1+{\\rm sin}x_3(t)}{2}\\\\  h_3^\\prime &amp;= h_{331}v_{312}=\\frac{5+x_1(t)}{10}\\cdot\\frac{1-{\\rm sin}x_3(t)}{2}\\\\  h_4^\\prime &amp;= h_{332}v_{312}=\\frac{5-x_1(t)}{10}\\cdot\\frac{1-{\\rm sin}x_3(t)}{2}\\\\  \\boldsymbol A_1^\\prime &amp;=   \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 0.5&amp;0&amp;-1\\\\  0&amp;0&amp;5  \\end{bmatrix},\\   \\boldsymbol A_2^\\prime =   \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 0.5&amp;0&amp;-1\\\\  0&amp;0&amp;-5  \\end{bmatrix}\\\\  \\boldsymbol A_3^\\prime &amp;=  \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 0.5&amp;0&amp;-1\\\\  0&amp;0&amp;5  \\end{bmatrix},\\   \\boldsymbol A_4^\\prime =  \\begin{bmatrix}  0&amp;1&amp;0\\\\  \\boldsymbol 0.5&amp;0&amp;-1\\\\  0&amp;0&amp;-5  \\end{bmatrix}\\\\  \\boldsymbol B_1^\\prime &amp;= \\boldsymbol B_2^\\prime =  \\begin{bmatrix}  0\\\\  0\\\\  1.5  \\end{bmatrix},\\   \\boldsymbol B_3^\\prime = \\boldsymbol B_4^\\prime =  \\begin{bmatrix}  0\\\\  0\\\\  0.5  \\end{bmatrix}  \\end{aligned}\\]相应的模型不确定性为\\[\\vert\\vert\\boldsymbol \\Delta_{ai}(t) \\vert\\vert \\leq 0.5,\\ i=1,2,3,4\\]  约减形式二针对 $A(3,3)$ 进行约减，即 $A(3,3)=\\sum_ih_iA_i(3,3)\\equiv\\frac{5+(-5)}{2}=0$，系统变为\\[\\begin{aligned}  \\dot \\boldsymbol x(t) &amp;= \\sum_{i=1}^4 h_i^\\prime(\\boldsymbol z(t))[\\boldsymbol A_i^\\prime\\boldsymbol x(t) + \\boldsymbol B_i^\\prime\\boldsymbol u(t)]\\\\  h_1^\\prime &amp;= h_{211}v_{311}={\\rm cos}x_2(t)\\cdot\\frac{1+{\\rm sin}x_3(t)}{2}\\\\  h_2^\\prime &amp;= h_{212}v_{311}=(1-{\\rm cos}x_2(t))\\cdot\\frac{1+{\\rm sin}x_3(t)}{2}\\\\  h_3^\\prime &amp;= h_{211}v_{312}={\\rm cos}x_2(t)\\cdot\\frac{1-{\\rm sin}x_3(t)}{2}\\\\  h_4^\\prime &amp;= h_{212}v_{312}=(1-{\\rm cos}x_2(t))\\cdot\\frac{1-{\\rm sin}x_3(t)}{2}\\\\  \\boldsymbol A_1^\\prime &amp;=   \\begin{bmatrix}  0&amp;1&amp;0\\\\  1&amp;0&amp;-1\\\\  0&amp;0&amp;\\boldsymbol 0  \\end{bmatrix},\\   \\boldsymbol A_2^\\prime =   \\begin{bmatrix}  0&amp;1&amp;0\\\\  0&amp;0&amp;-1\\\\  0&amp;0&amp;\\boldsymbol 0  \\end{bmatrix}\\\\  \\boldsymbol A_3^\\prime &amp;=  \\begin{bmatrix}  0&amp;1&amp;0\\\\  1&amp;0&amp;-1\\\\  0&amp;0&amp;\\boldsymbol 0  \\end{bmatrix},\\   \\boldsymbol A_4^\\prime =  \\begin{bmatrix}  0&amp;1&amp;0\\\\  0&amp;0&amp;-1\\\\  0&amp;0&amp;\\boldsymbol 0  \\end{bmatrix}\\\\  \\boldsymbol B_1^\\prime &amp;= \\boldsymbol B_2^\\prime =  \\begin{bmatrix}  0\\\\  0\\\\  1.5  \\end{bmatrix},\\   \\boldsymbol B_3^\\prime = \\boldsymbol B_4^\\prime =  \\begin{bmatrix}  0\\\\  0\\\\  0.5  \\end{bmatrix}  \\end{aligned}\\]相应的模型不确定性为\\[\\vert\\vert\\boldsymbol \\Delta_{ai}(t) \\vert\\vert \\leq 5,\\ i=1,2,3,4\\]  约减形式三针对 $B(3,1)$ 进行约减，即 $B(3,1)=\\sum_ih_iB_i(3,1)\\equiv\\frac{1.5+0.5}{2}=1$，系统变为\\[\\begin{aligned}  \\dot \\boldsymbol x(t) &amp;= \\sum_{i=1}^4 h_i^\\prime(\\boldsymbol z(t))[\\boldsymbol A_i^\\prime\\boldsymbol x(t) + \\boldsymbol B_i^\\prime\\boldsymbol u(t)]\\\\  h_1^\\prime &amp;= h_{211}h_{331}={\\rm cos}x_2(t)\\cdot\\frac{5+x_1(t)}{10}\\\\  h_2^\\prime &amp;= h_{212}h_{331}=(1-{\\rm cos}x_2(t))\\cdot\\frac{5+x_1(t)}{10}\\\\  h_3^\\prime &amp;= h_{211}h_{332}={\\rm cos}x_2(t)\\cdot\\frac{5-x_1(t)}{10}\\\\  h_4^\\prime &amp;= h_{212}h_{332}=(1-{\\rm cos}x_2(t))\\cdot\\frac{5-x_1(t)}{10}\\\\  \\boldsymbol A_1^\\prime &amp;=   \\begin{bmatrix}  0&amp;1&amp;0\\\\  1&amp;0&amp;-1\\\\  0&amp;0&amp;5  \\end{bmatrix},\\   \\boldsymbol A_2^\\prime =   \\begin{bmatrix}  0&amp;1&amp;0\\\\  0&amp;0&amp;-1\\\\  0&amp;0&amp;5  \\end{bmatrix}\\\\  \\boldsymbol A_3^\\prime &amp;=  \\begin{bmatrix}  0&amp;1&amp;0\\\\  1&amp;0&amp;-1\\\\  0&amp;0&amp;-5  \\end{bmatrix},\\   \\boldsymbol A_4^\\prime =  \\begin{bmatrix}  0&amp;1&amp;0\\\\  0&amp;0&amp;-1\\\\  0&amp;0&amp;-5  \\end{bmatrix}\\\\  \\boldsymbol B_1^\\prime &amp;= \\boldsymbol B_2^\\prime =  \\begin{bmatrix}  0\\\\  0\\\\  \\boldsymbol 1  \\end{bmatrix},\\   \\boldsymbol B_3^\\prime = \\boldsymbol B_4^\\prime =  \\begin{bmatrix}  0\\\\  0\\\\  \\boldsymbol 1  \\end{bmatrix}  \\end{aligned}\\]相应的模型不确定性为\\[\\vert\\vert\\boldsymbol \\Delta_{bi}(t) \\vert\\vert \\leq 0.5,\\ i=1,2,3,4\\]3.3. 模糊控制器3.3.1. 设计3.3.2. 举例未完待续！4. 参考文献无。"
  },
  
  {
    "title": "深度学习文章阅读（模糊注意力轨迹预测）",
    "url": "/posts/deep-learning-fuzzy-attention-trajpre/",
    "categories": "Academic, Paper",
    "tags": "fuzzy, deep learning",
    "date": "2020-12-07 16:39:19 +0800",
    





    
    "snippet": "本文介绍了 2020 年 NIPS 上的一篇关于模糊注意力轨迹预测的文章，但是被骗啦（我大意了）。其实和 Fuzzy 并没有什么关系，反而是用的 Attention 机制。  1. 引言          1.1. 归纳偏置        2. 结构          2.1. 预测架构      2.2. 交互模块      2.3. 模糊查询注意力模块      2.4. 分析     ...",
    "content": "本文介绍了 2020 年 NIPS 上的一篇关于模糊注意力轨迹预测的文章，但是被骗啦（我大意了）。其实和 Fuzzy 并没有什么关系，反而是用的 Attention 机制。  1. 引言          1.1. 归纳偏置        2. 结构          2.1. 预测架构      2.2. 交互模块      2.3. 模糊查询注意力模块      2.4. 分析      2.5. 训练        3. 实验  4. 其它  5. 参考文献  Nitin Kamra, et al. Multi-agent Trajectory Prediction with Fuzzy Query Attention. NIPS 2020.1. 引言1.1. 归纳偏置inductive biases，归纳偏置。  LinT. 如何理解Inductive bias？归纳偏置在机器学习中是一种很微妙的概念：在机器学习中，很多学习算法经常会对学习的问题做一些假设，这些假设就称为归纳偏置(Inductive Bias)。归纳偏置这个译名可能不能很好地帮助理解，不妨拆解开来看：归纳(Induction)是自然科学中常用的两大方法之一(归纳与演绎, induction and deduction)，指的是从一些例子中寻找共性、泛化，形成一个比较通用的规则的过程；偏置(Bias)是指我们对模型的偏好。因此，归纳偏置可以理解为，从现实生活中观察到的现象中归纳出一定的规则(heuristics)，然后对模型做一定的约束，从而可以起到“模型选择”的作用，即从假设空间中选择出更符合现实规则的模型。其实，贝叶斯学习中的“先验(Prior)”这个叫法，可能比“归纳偏置”更直观一些。以神经网络为例，各式各样的网络结构/组件/机制往往就来源于归纳偏置。在卷积神经网络中，我们假设特征具有局部性(Locality)的特性，即当我们把相邻的一些特征放在一起，会更容易得到“解”；在循环神经网络中，我们假设每一时刻的计算依赖于历史计算结果；还有注意力机制，也是基于从人的直觉、生活经验归纳得到的规则。  惯性（Inertia）：几乎所有无生命实体都按照匀速前进，除非收到外力作用。这个规则在作为一阶近似估计时，在段时间内同样适用于有生命实体（如行人），因为行人几乎也以匀速行走，除非需要转弯或减速以避免碰撞；  运动的相对性（Motion is relative）：两个目标之间的运动是相对的，在预测未来轨迹时应该使用他们之间的相对位置和速度（相对观测，relative observations），对未来的预测也需要是相对于当前位置的偏差（相对预测，relative predictions）；  意图（Intent）：有生命对象有自己的意图，运动会偏离惯性，需要在预测模型中进行考虑；  交互（Interactions）：有生命对象和无生命对象可能偏离它们预期的运动，比如受到其它附近对象的影响。这种影响需要清晰的建模。2. 结构2.1. 预测架构下图 (a) 为预测架构，输入 $t$ 时刻的所有对象的位置 $p^t_{i=1:N}$。使用 $t\\leq T_{obs}$ 时刻的位置作为观测，对 $t\\geq T_{obs}$ 时刻的位置进行预测。我们对每个对象的下一时刻位置 $\\hat p^{t+1}_i$ 进行预测，预测量是相对于当前时刻 $p_i^t$ 的位置偏差（relative prediction）。  公式 1：将位置偏差拆分为一阶常速度估计 $\\tilde v_i^t$ （惯性）和速度修正项 $\\Delta v_i^t$ （意图和对象间的交互）。  公式 2：一阶常速度估计由当前时刻位置和前一时刻位置直接差分得到。  公式 3：采用 LSTM 来捕捉每个对象的意图，其隐藏状态 $h_i^t$ 能够保存之前的轨迹信息。LSTM 的权重参数所有对象均共享。为了计算速度修正项 $\\Delta v_i^t$，首先用 LSTM 根据每个对象的当前位置初步更新一个临时隐藏状态 $\\tilde h_i^t$。  公式 4：然后将对象当前位置和临时隐层状态 $h_i^t,$ 同时送入一个 「交互模块（Interaction module）」 来推理对象间的交互、合计他们的效果，然后更新每个对象的隐藏状态，同时计算对象的速度修正项。和所有对象的当前位置向量进一步被用于将来的对象间的交互，汇总其效果并更新每个对象的隐藏状态，\\[\\begin{aligned}\\hat p^{t+1}_i &amp;= p_i^t + \\tilde v_i^t + \\Delta v_i^t,&amp;\\quad \\forall i\\in 1:N\\\\(Inertia): \\tilde v_i^t &amp;= p_i^t - p_i^{t-1},&amp;\\quad \\forall i\\in 1:N\\\\(Intents): \\tilde h_i^t &amp;= LSTM(p_i^t, h_i^{t-1}),&amp;\\quad \\forall i\\in 1:N\\\\(Interactions): h_i^t,\\Delta v_i^t&amp;= InteractionModule(p_i^t, \\tilde h_i^t)&amp;\\end{aligned}\\]由于所有的计算都在当前时刻 $t$ 下，因此后文可以略去该上标。2.2. 交互模块下图 (b) 作为交互模块。  公式 1：在每两个对象间产生一条有向边来建立一张图（creates a graph by generating directed edges between all pairs of agents）（忽略自身与自身的边连接），得到边集合 $\\varepsilon$。将边集合、所有对象的位置和临时隐藏状态（意图）估计送入 模糊查询注意力模块（Fuzzy Query Attention, FQA）得到每一个对象的注意力向量 $a_i$，该向量汇聚了其与其它所有对象的交互信息。    有向边的方向如何确定的不明确。    公式 2，3：将注意力向量、位置向量、临时隐藏状态（意图）送入随后的 2 层全连接层（ReLU），得到更新后的隐藏状态 $h_i$（且之后返传给 LSTM 作为上一时刻的隐藏状态），再次经过 2 层全连接层（ReLU）得到每个对象的速度修正项 $\\Delta v_i$。\\[\\begin{aligned}a&amp;=FQA(p,\\hat h, \\varepsilon)&amp;\\\\h_i&amp;= FC_2(ReLU(FC_1(p_i, h_i, a_i))),&amp;\\quad \\forall i\\in 1:N\\\\\\Delta v_i&amp;= FC_4(ReLU(FC_3(p_i))),&amp;\\quad \\forall i\\in 1:N\\end{aligned}\\]2.3. 模糊查询注意力模块FQA 模块将有向边图看作 发送-接收 对象对（sender-receiver pairs of agents）。从高层来看，该模块建模了所有发送对象对一个特定接收对象的汇聚影响。基本想法是建立 key-query-value self attention 网络（Vaswani et al）。  Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. Attention Is All You Need[J]. arXiv preprint arXiv:1706.03762v5 [cs.CL], 2017. [Google Transformer]  Self attention: 输入一系列向量，输出所有向量对每个特定向量的 value 的加权和（注意力 / 重要性）。value 是每个向量乘以一个权重矩阵得到的，矩阵需要被训练。  产生独立特征：复制 $p,\\hat h$ 到每一条边，一条边两个对象，一个 sender 一个 receiver，那么就复制出 $p_s, p_r, h_s, h_r$。  产生相对特征：$p_{sr} = p_s-p_r$ （相对位移），$h_{sr} = h_s-h_r$ （相对状态），$\\hat p_{sr} = p_{sr}/\\vert\\vert p_{sr} \\vert\\vert$（单位化）,$\\hat h_{sr} = h_{sr}/\\vert\\vert h_{sr} \\vert\\vert$（单位化）。这些特征用来捕捉相对观测归纳偏差。  对于每一条边，将上述所有特征拼接 $f_{sr} = { p_s, p_r, p_sr, \\hat p_{sr}, h_s, h_r, h_sr, \\hat h_{sr} }$，然后分别经过一个 单层全连接层，产生 $n$ 个 keys $K_{sr}\\in \\mathbb R^{n\\times d}$ 和  $n$ 个 queries $Q_{sr}\\in \\mathbb R^{n\\times d}$。$n$ 代表 $s-r$ 对的个数（个人理解也就是边的个数，也就是 $f_{sr} 的个数$），$d$ 应该是用户定义的维度。  将 $K_{sr}\\in \\mathbb R^{n\\times d}$ 和 $Q_{sr}\\in \\mathbb R^{n\\times d}$ 通过一个点乘的变体（元素积然后按行求和，row-wise dot-product），产生模糊决策 $D_{sr}\\in \\mathbb R^n$。  \\[\\begin{aligned}K_{sr}&amp;=FC_5(f_{sr}^\\perp)&amp;\\ \\forall (s,r)\\in 1:N,s\\neq r\\\\Q_{sr}&amp;=FC_6(f_{sr}^\\perp)&amp;\\ \\forall (s,r)\\in 1:N,s\\neq r\\\\D_{sr}&amp;= \\sigma(K_{sr}\\star Q_{sr}+B)=\\left( \\sum_{dim=1} K_{sr}\\odot Q_{sr}+B\\right),&amp;\\ \\forall (s,r)\\in 1:N,s\\neq r\\end{aligned}\\]  注：作者说的模糊决策不是模糊逻辑，而是浮点数取值的决策，相对于离散取值的布尔决策。「大意了！」其中 $B$ 是一个待优化的偏差参数矩阵，$\\sigma$ 是 sigmoid 激活函数，$\\perp$ 是分离运算符（detach operator）。[不允许梯度从 $Q,K$ 回传，只能从 $V$ 回传]  The detach operator acts as identity for the forward-pass but prevents any gradients from propagating back through its operand. This allows us to learn feature representations only using responses while the keys and queries make useful decisions from the learnt features.we learn the sender-receiver features by backpropagating only through the responses ($V_sr$) while features are detached to generate the keys and queries. This additionally allows us to inject human knowledge into the model via handcrafted non-learnable decisions, IF such decisions are available最终得到的模糊决策 $D_{sr} \\in [0,1]^n$ 可以解释为一组 $n$个 连续取值的决策，反应了 sender 对象和 receiver 对象之间的交互。这个决策可以用来影响（select）receiver 对象对 sender 对象当前状态的应答。  确定性应答（公式 1，2）：相对特征并行的通过两个 2 层全连接层（第一层包含 ReLU 激活函数）产生 yes-no 应答 $V_{y,sr},V_{n,sr}\\in \\mathbb R^{n\\times d_v}$，与 $D_{sr}=1\\ or\\ D_{sr}=0$ 对应。虽然可以使用全部特征 $f_{sr}$，但实验表明只用一部分特征（$p_{sr},h_s$）的表现就很好了，还能节约参数。  模糊应答（公式 3）：将上述确定性应答模糊化，根据模糊决策 $D_{sr}$ 和其补集 $\\overline D_{sr}= 1 - D_{sr}$ 通过 fuzzy IF-else 产生最终的模糊应答。\\[\\begin{aligned}V_{y,sr}&amp;=FC_8(ReLU(FC_7(p_{sr},h_s))),&amp;\\quad \\forall (s,r)\\in 1:N,s\\neq r\\\\V_{n,sr}&amp;=FC_{10}(ReLU(FC_9(p_{sr},h_s))),&amp;\\quad \\forall (s,r)\\in 1:N,s\\neq r\\\\V_{sr}&amp;=D_{sr}V_{y,sr}+\\overline D_{sr}V_{n,sr}&amp;\\quad \\forall (s,r)\\in 1:N,s\\neq r\\\\\\end{aligned}\\]最后得到 $n$ 个对象对的应答 $V_{sr}\\in \\mathbb R^{n\\times d_v}$。  公式 1：将应答拼接 $\\in \\mathbb R^{nd_v}$，然后过一个全连接层，提高向量维度增加信息量，以弥补后续最大池化带来的信息丢失。  公式 2：对上述步骤的输出进行最大池化，将所有对 receiver 对象的交互的影响累积。  公式 3：最后再通过一个全连接层降维（与之前升维对应）。\\[\\begin{aligned}V_{proc,sr} &amp;= FC_{11}(concat(V_{sr}))\\\\V_{proc,r} &amp;= maxpool_{s:(s-r)\\in\\varepsilon}V_{proc,sr}\\\\a_r&amp;=FC_{12}(V_{proc,r}),\\quad \\forall r\\in 1:N\\end{aligned}\\]2.4. 分析上述架构受到 multi-head self-attention 的启发，但是经过了大量改造。  从 self-attention 改成 pairwise-attention；  包括一个可学习的 $B$ 使得模型能力更高；  从矩阵元素积变为元素积然后按行求和，降低计算量和硬件性能要求，同时保证了性能；  只允许梯度从 $V_{sr}$ 回传。这使得额外增加不可学习的人类知识成为可能（section 4.3）？FQA 能学到：  靠近（Proximity）：假设 $K,Q$ 是 $p_{sr}$ 且对应的 $B$ 是 $-d_{th}^2$ 那么决策 $D = \\sigma(p_{sr}^Tp_{sr}-d_{th}^2)$ 逼近 0 表示两个对象 $s$ 和 $r$ 间的距离小于 $d_{th}$。注意到上述决策依赖 $B$ 的存在，即 $B$ 赋予模型更灵活的能力；  接近（Approach）：由于部分隐藏状态内部能够学习如何对对象的速度进行建模，FQA 可能可以学习到一种 $K_{sr} = v_{sr},Q_{sr} = \\hat p_{sr},B=0$ 形式，这种形式逼近 0 表示两个对象相互直接接近对方。虽然我们并没有直接要求 FQA 学习这些可解释的决策，但是实验表明 FQA 学习到的模糊决策能够高度预测对象间的交互（section 4.3）。2.5. 训练用 MSE，评估下一时刻所有对象的预测位置与真实位置的偏差，用 Adam，batch size = 32， 初始学习率 0.001，每 5 epoch 乘以 0.8 下降。所有待比较的模型都训练至少 50 epoch，然后当连续 10 epoch 的验证 MSE 不下降时激活 early stopping，最多进行 100 epochs 训练。所有样本的 $T_{obs} = \\frac{2T}{5}$，我们遵循动态时间表，允许所有模型查看 $T_{temp}$ 时间步长的真实观测值，然后预测 $T-Ttemp$ 时间步长。在起始阶段，$T_{temp} = T$，然后每次减 1 直到 $T_{temp} = T_{obs}$。发现这样操作可以提高所有模型的预测性能：  观察 $T$ 个步长，预测 $T-T=0$ 个步长；  观察 $T-1$ 个步长，预测 $T-(T-1)=1$ 个步长；  观察 $T-2$ 个步长，预测 $T-(T-2)=2$ 个步长；  ……；  观察 $T_{obs}$ 个步长，预测 $T-(T-T_{obs})=T_{obs}$ 个步长；3. 实验采用以下几个前人研究的数据集（包含不同种类的交互特征）。如果数据集没有划分，那么我们按照 $70:15:15$ 来划分训练集、验证集和测试集。  ETH-UCY：3400 场景，T = 20；  Collisions：9500 场景，T = 25；  NGsim：3500 场景，T = 20；  Charges：3600 场景，T = 25；  NBA：7500 场景，T = 30。baselines：  Vanilla LSTM：  Social LSTM：  GraphSAGE：  Graph Networks：  Neural Relational Inference：  Graph Attention Networks：4. 其它  Robust ${L_1}$ Observer-Based Non-PDC Controller Design for Persistent Bounded Disturbed TS Fuzzy Systems5. 参考文献无。"
  },
  
  {
    "title": "深度学习文章阅读（TS深度模糊网络）",
    "url": "/posts/deep-learning-TSDFN/",
    "categories": "Academic, Paper",
    "tags": "fuzzy, deep learning",
    "date": "2020-12-06 16:39:19 +0800",
    





    
    "snippet": "本文介绍了 TS 深度模糊网络（TS Deep Fuzzy Network, TSDFN），于 2017 年提出，基于 TS 模糊系统组成三层网络，并推导了反向传播的梯度。  1. 网络结构  2. 网络参数辨识          2.1. 前向传播      2.2. 反向传播        3. 实验          3.1. 准备工作      3.2. 算例 1      3.3....",
    "content": "本文介绍了 TS 深度模糊网络（TS Deep Fuzzy Network, TSDFN），于 2017 年提出，基于 TS 模糊系统组成三层网络，并推导了反向传播的梯度。  1. 网络结构  2. 网络参数辨识          2.1. 前向传播      2.2. 反向传播        3. 实验          3.1. 准备工作      3.2. 算例 1      3.3. 算例 2      3.4. 分析        4. 参考文献  Shreedharkumar Rajurkar, Nishchal Kumar Verma. Developing deep fuzzy network with Takagi Sugeno fuzzy inference system[J]. IEEE Transactions on Fuzzy System. 2017.1. 网络结构提出了一种新型的三层 TS Deep Fuzzy Network (TSDFN) 网络架构。TSDFN 的网络架构如下图所示图中，隐层（hidden layer）中的每一个神经元都是一个 TSFIS ，输出层只有一个神经元，也是一个 TSFIS 。当然也可以扩展为多输出，不同的输出间相互独立。  FIS：fuzzy inference system，模糊推理系统，是一个完整的输入-输出模糊系统，比如上面介绍的 TS 模糊系统，就被称为 TSFIS一个 TSFIS 神经元的模糊规则基（Fuzzy Rul Base，FRB）包含多条模糊规则，每条规则都包括前提部分和结论部分。一阶 TSFIS 的结论是输入的线形方程。FRB 的规则形式如下\\[\\begin{aligned}R_i^h:&amp;\\quad {\\rm IF}\\quad x_1\\ is\\ G_{1,i}\\ {\\rm AND}\\ \\cdots\\ {\\rm AND}\\ x_D\\ is\\ G_{D,i}\\quad\\\\&amp;\\quad {\\rm THEN}\\quad y\\ is\\ y_i=p_{i,0}+p_{i,1}x_1+\\cdots+p_{i,D}x_D\\end{aligned}\\]$D$ 是输入个数，$x_d$ 是第 $d$ 个输入分量（$d=1,\\cdots,D$）。$R$ 是规则总个数$G_{d,i}$ 是前提中相应的输入模糊隶属度函数（$i=1,\\cdots,R$）。前提中采用 “AND” 作为模糊连接符。一个 TSFIS 的参数即为输入前提模糊隶属度函数的参数和结论系数，二者的组合可表示特定输入的模糊结构。可采用多种模糊隶属度函数。采用不同的模糊连接符可以定义不同的模糊规则基。整个网络包括如下参数：  模糊规则的前提（premise）中的输入隶属度的参数；  每一层的每一个 TS 模糊神经元的结论部分的输入系数；一个 TS 模糊神经元（TSFN）建模出了一种输入的复杂函数，输入的隶属度函数代表了模糊区域，建模出了输入数据的不确定性。模糊区域可以表示语义标签。TSDFN 中的 TSFN 提取输入数据中的复杂模式，相应的FRB参数以模糊规则的形式表示模式的内部结构。  a TSFN in TSDFN extracts a complex pattern in input data and corresponding FRB parameters represent the nternal structure of the pattern in the form of fuzzy rules.2. 网络参数辨识采用标准的误差反向传播来针对特定数据进行网络参数辨识。2.1. 前向传播下面考虑 一个一般的隐层 TSFN（$S_h$），假设输入向量为 $\\boldsymbol x=[x_1,x_2,\\cdots,x_d,\\cdots,x_D]$。  $θ^h_{d,f}$ denotes parameter of $f^th$ input MF of input $d$ in premise part of a rule in FRB of $S_h$$\\boldsymbol \\theta^h$ 表示某个规则中的输入隶属度函数的参数矩阵，那么\\[\\begin{aligned}\\boldsymbol \\theta^h = \\begin{bmatrix}\\theta^h_{1,1} &amp; \\cdots &amp; \\theta^h_{1,f} &amp; \\cdots &amp; \\theta^h_{1,F}\\\\\\vdots &amp; \\ddots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\theta^h_{d,1} &amp; \\cdots &amp; \\theta^h_{d,f} &amp; \\cdots &amp; \\theta^h_{d,F}\\\\\\vdots &amp; \\ddots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\theta^h_{D,1} &amp; \\cdots &amp; \\theta^h_{D,f} &amp; \\cdots &amp; \\theta^h_{D,F}\\end{bmatrix}\\end{aligned}\\]其中 $F$ 是隶属度函数的参数个数（个人理解）。如果隶属度函数采用 高斯 函数，那么参数为均值和方差（参数的个数为 2 ）。为了进行反向传播，必须要计算梯度，因此隶属度函数必须是连续的。（类似关于激活函数是否要求处处可导的问题，涉及次梯度，不做展开）$\\boldsymbol p^h$ 表示结论部分的系数矩阵，那么\\[\\begin{aligned}\\boldsymbol p^h = \\begin{bmatrix}p^h_{1,0} &amp; \\cdots &amp; p^h_{1,f} &amp; \\cdots &amp; p^h_{1,D}\\\\\\vdots &amp; \\ddots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ p^h_{r,0} &amp; \\cdots &amp; p^h_{r,f} &amp; \\cdots &amp; p^h_{r,D}\\\\\\vdots &amp; \\ddots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ p^h_{R,0} &amp; \\cdots &amp; p^h_{R,f} &amp; \\cdots &amp; p^h_{R,D}\\end{bmatrix}\\end{aligned}\\]其中 $R$ 为规则个数。对于输出层的 TSFN，其参数与隐层的 TSFN 类似，只不过将上标换为 $O$，即 $\\boldsymbol \\theta^o, \\boldsymbol p^o$。给定输入，隶属度函数的输出表示为\\[\\begin{aligned}\\boldsymbol \\mu^h = \\begin{bmatrix}\\mu^h_{1,1} &amp; \\cdots &amp; \\mu^h_{1,f} &amp; \\cdots &amp; \\mu^h_{1,D}\\\\\\vdots &amp; \\ddots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\mu^h_{r,1} &amp; \\cdots &amp; \\mu^h_{r,d} &amp; \\cdots &amp; \\mu^h_{r,D}\\\\\\vdots &amp; \\ddots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\mu^h_{R,1} &amp; \\cdots &amp; \\mu^h_{R,d} &amp; \\cdots &amp; \\mu^h_{R,D}\\end{bmatrix}\\end{aligned}\\]其中 $\\mu^h_{r,d}=\\mu_{G^h_{r,d}(x_d)}$ 是第 $h$ 个TS模糊神经元中第 $r$ 个规则下第 $d$ 个输入的隶属度。第 $r$ 个规则的权重计算如下（原文 t-norm ？）\\[\\omega_r^h = \\land_{d=1}^D\\mu_{r,d}^h\\]第 $r$ 个规则的输出（原文用 $v^h_r$）\\[y_r^h = p^h_{r,0}+p^h_{r,1}x_1 + \\cdots + p^h_{r,d}x_d+\\cdots+p^h_{r,D}x_D\\]最终 $S_h$ 的输出为\\[a^h = \\frac{\\sum_{r=1}^R\\omega^h_ry_r^h}{\\sum_{r=1}^R\\omega^h_r}\\]$a^h$ 作为输出层的 STFN 的（$H$ 维）输入。在输出层，经过上述类似的步骤，可以得到一个输出 $y^o$（原文用 $y^O$），作为整个 TSDFN 的输出，如下\\[\\begin{aligned}\\mu^o_{r,h} &amp;=\\mu_{G^o_{r,h}(a^h)}\\\\\\omega_r^o &amp;= \\land_{h=1}^H\\mu_{r,h}^o\\\\y_r^o &amp;= p^o_{r,0}+p^o_{r,1}a^1 + \\cdots + p^o_{r,h}a^h+\\cdots+p^o_{r,H}a^H\\\\y^o &amp;= \\frac{\\sum_{r=1}^R\\omega^o_ry_r^o}{\\sum_{r=1}^R\\omega^o_r}\\end{aligned}\\]误差 $e = y^o-y_d$ 可用于 MSE 损失函数（原文 $\\frac{1}{2n}$ 可能 有误）\\[J = \\frac{1}{2}\\sum_{n=1}^N(e^{(n)})^2\\]其中 $N$ 是数据样本（输入输出对）总个数，$e^n$ 是第 $n$ 个样本对应的误差。2.2. 反向传播首先求 loss 对输出层参数的梯度。loss 对输出的梯度\\[\\frac{\\partial J}{\\partial y^o} = \\sum_{n=1}^Ne^{(n)}\\]loss 对输出系数 $p^o_{r,h}$ 的梯度\\[\\begin{aligned}\\frac{\\partial J}{\\partial p_{r,h}^o} &amp;=\\frac{\\partial J}{\\partial y^o}\\frac{\\partial y^o}{\\partial y^o_r}\\frac{\\partial y^o_r}{\\partial p^o_{r,h}} \\\\&amp;=\\sum_{n=1}^Ne^{(n)}\\cdot \\frac{\\omega^o_r}{\\sum_{r=1}^R\\omega^o_r}\\cdot a^h\\end{aligned}\\]其中 $a^0=1$ 。loss 对输出层隶属度函数参数 $\\theta^o_{h,f}$ 的梯度\\[\\frac{\\partial J}{\\partial \\theta^o_{h,f}} =\\frac{\\partial J}{\\partial y^o}\\sum_{r=1}^R\\frac{\\partial y^o}{\\partial \\omega^o_r}\\frac{\\partial \\omega^o_r}{\\partial \\mu^o_r}\\frac{\\partial \\mu^o_r}{\\partial \\theta^o_f}\\]但是需要注意一点，不是每个隶属度函数都参与每条规则的计算（也即不是每个输入都参与规则计算）。假设有 $Q\\leq R$ 个规则中包含待求解的隶属度函数的参数，则上式变为  $Q$ denotes the total number of rules in which the corresponding MF appears in premise part.\\[\\frac{\\partial J}{\\partial \\theta^o_{h,f}} =\\frac{\\partial J}{\\partial y^o}\\sum_{q=1}^Q(\\frac{\\partial y^o}{\\partial \\omega^o_q}\\frac{\\partial \\omega^o_q}{\\partial \\mu^o_{q,h}}\\frac{\\partial \\mu^o_{q,h}}{\\partial \\theta^o_{h,f}})\\]下面求 loss 对隐层参数的梯度。首先求 loss 对隐层输出的梯度。注意到从 $y^o$ 到 $a^h$ 实际上是有两个部分的，因此下式包含两项\\[\\frac{\\partial J}{\\partial a^h} = \\frac{\\partial J}{\\partial y^o}\\sum_{r=1}^R(\\frac{\\partial y^o}{\\partial y^o_h}\\frac{\\partial y^o_h}{\\partial a^h}+\\frac{\\partial y^o}{\\partial \\omega^o_r}\\frac{\\partial \\omega^o_r}{\\partial a^h})\\]然后求 loss 对隐层系数 $p^h_{r,d}$ 和隐层隶属度函数参数 $\\theta^h_{r,f}$ 的梯度\\[\\frac{\\partial J}{\\partial p_{r,d}^h} =\\frac{\\partial J}{\\partial a^h} \\cdot\\frac{\\partial a^h}{\\partial y^h_r}\\frac{\\partial y^h_r}{\\partial p^h_{r,d}}\\]\\[\\frac{\\partial J}{\\partial \\theta^h_{d,f}} =\\frac{\\partial J}{\\partial a^h}\\sum_{q=1}^Q(\\frac{\\partial a^h}{\\partial \\omega^h_q}\\frac{\\partial \\omega^h_q}{\\partial \\mu^h_{q,d}}\\frac{\\partial \\mu^h_{q,d}}{\\partial \\theta^h_{d,f}})\\]实际上，隐层和输出层的 $Q$ 应该用不同的符号表示，为了简略此处不加区分（个人理解）。原文到此处就不再推导，这里也不进行展开了。计算出全部梯度后，采用梯度下降更新参数。3. 实验3.1. 准备工作采用高斯隶属度函数，简便起见，隐层的每个模糊神经元的每条规则中，均采用相同个数的隶属度函数。为了从前提参数值评估规则权重，采用 代数乘积（而不是取小） 作为 t-norm 运算符，因为它易于求微分。设计三种工况：  不加任何处理的原始训练数据集；  增加小幅度的不精确的训练数据集。实际上，在进行测量时，总是存在测量值正确性的公差。实际值在测量值的指定公差范围内。为了在数据集中添加不精确度，数据集值的某一随机部分在某些带前缀（prefixed？）的公差带之间变化；  更进一步，添加模糊性使得数据集含糊不清。通常而言，模糊性是指对值的不清楚的理解或不正确和错误的度量。在模糊情况下，多个观测者（或传感器）对某个单个值没有达成共识。如果认为某数值属于模糊集，则更改其参数会导致模糊性（vagueness）增加到数据集中，因为更改模糊集的参数会由于模糊性而引入不确定性（uncertainty），并且模糊集的性质也会变得模糊（vague）。本文考虑使用高斯模糊集将模糊性添加到数据中。          If data values are considered to belong to fuzzy set THEN varying its parameters leads to add vagueness into dataset since varying the parameter of fuzzy set introduces uncertainty due to vagueness and the nature of fuzzy set becomes vague.      后续每个实验中，针对上述每个情况，将数据集划分为 70% 的训练集，15% 的验证集和 15% 的测试集。TSDFN 网络架构的确定包含下面几步：  TSDFN 的网络架构：不同的隐层模糊神经元个数；  TSDFN 的网络结构：不同的隶属度函数个数；  对每个网络结构在训练集上训练，在验证集上测试；  根据最好的测试性能确定隶属度函数个数（即确定网络结构）；  将已经确定隶属度函数个数的不同架构的网络在测试集上测试。（然后就能最终确定采用啥架构的 TSDFN 了？）在上述每个工况下，设计一个 3 层普通神经网络与 TSDFN 进行对比。神经网络激活函数采用 sigmoid 函数，隐层个数与 TSDFN 一致，训练方式采用现有的复杂方式（啥？）。  This ANN is trained with existing sophisticated approaches.采用 MSE 衡量性能。最终如图所示（图中 impression 可能写错了，应该是 imprecision）3.2. 算例 1辨识一个非线性系统\\[f=x^2+y^2+xy+2y+x\\]文中没说数据集咋来的，个人理解就是对上述系统进行离散赋值求解，然后得到一堆输入输出样本集（$f_i\\leftarrow (x_i,y_i),i=1,2,\\cdots,M$）下表列举了 TSDFN 在验证集上的测试结果，加粗的数字表示不同网络架构下的最小 MSE，对应最佳的网络结构（对应最佳的隶属度函数个数）。确定不同工况下的最佳网络结构（隶属度函数个数）后，分别在三个工况下与 ANN 进行比较，结果如下。可以看出 TSDFN 均全面超越 ANN。3.3. 算例 2小车倒车问题（Truck Backer Upper problem），是一个将卡车以合适的方向后退到对接位置的问题。来自以下参考文献，总共包含 14 个表（总共 239 个读数），每个表均包含位置 $x$ 和方向 $\\phi$ 的值以及相应的输出 —— 转向角 $\\theta$。用于生成数据集的模型（待识别的非线性复杂系统）在文献中也有说明。  Wang, Li-Xin, and Jerry M. Mendel, Generating fuzzy rules from numerical data, with applications, Signal and Image Processing Institute, University of Southern California, Department of Electrical EngineeringSystems, 1991.TSDFN 在验证集上的测试结果如下表所示。同样分别在三个工况下与 ANN 进行比较，结果如下。可以看出 TSDFN 均全面超越 ANN。3.4. 分析两个算例的结果表明，对于相同数量的隐层神经元个数，在隶属函数数量方面，性能存在一些不规律。对实验的分析表明，误差在这些算例中不下降了，因为梯度在到达最小前卡住了。适当的调整学习率和增加迭代次数可以解决这个问题。但是总的来说 TSDFN 牛逼！  In both case studies, the results show that there is a slight irregularity in the performance with respect to the number of membership functions for the same number of hidden nodes. The analysis of experiments have shown that this happens because the training error doesn’t decrease in such cases and the gradient gets stuck before reaching minimum. Proper tunning of learning rate and increased number of iterations solve this problem4. 参考文献无。"
  },
  
  {
    "title": "深度学习文章阅读（TS模糊系统）",
    "url": "/posts/deep-learning-TS-fuzzy-system/",
    "categories": "Academic, Paper",
    "tags": "fuzzy, deep learning",
    "date": "2020-12-02 16:39:19 +0800",
    





    
    "snippet": "本文介绍了 TS 型模糊系统，由 Takagi 和 Sugeno 两位学者在 1985 年提出，主要思想是将非线性系统用许多线段相近的表示出来，即将复杂的非线性问题转化为在不同小线段上的问题。  1. TS 模糊系统          1.1. 推理过程      1.2. 特性      1.3. 辨识算法                  1.3.1. 结论参数辨识          1...",
    "content": "本文介绍了 TS 型模糊系统，由 Takagi 和 Sugeno 两位学者在 1985 年提出，主要思想是将非线性系统用许多线段相近的表示出来，即将复杂的非线性问题转化为在不同小线段上的问题。  1. TS 模糊系统          1.1. 推理过程      1.2. 特性      1.3. 辨识算法                  1.3.1. 结论参数辨识          1.3.2. 前提参数辨识          1.3.3. 前提变量的选择                    1.4. 广义 TS 模糊系统        3. 参考文献1. TS 模糊系统  Tomohiro Takagi and Michio Sugeno. Fuzzy Identification of Systems and Its Applications to Modeling and Control[J]. Fuzzy Identification of Systems, 1993.  A mathematical tool to build a fuzzy model of a system where fuzzy implications and reasoning are used is presented in this paper. The premise of an implication is the description of fuzzy subspace of inputs and its consequence is a linear input-output relation. The method of identification of a system using its input-output data is then shown. Two applications of the method to industrial processes are also discussed: a water cleaning process and a converter in a steel-making process.TS 模糊模型是由多个线性系统对同一个非线性系统进行拟合，利用模糊算法进行输入变量的解构，通过模糊演算推理再去模糊化，生成数条代表每组输入与输出关系的方程。假设模糊集为 $A$，隶属度函数为 $A(x)$，$x$ 属于某论域 $X$。“$x$ 属于 $A$ 且 $y$ 属于 $B$” 表达为\\[\\vert x\\ is\\ A\\ and\\ y\\ is\\ B \\vert = A(x) \\land B(y)\\]对于离散系统模型，令 $R_i$ 表示模糊系统的第 $i$ 条规则，其一阶 TS 模糊系统典型的模糊蕴含条件（Implication）句为\\[R_i:\\quad IF\\quad f(x_1\\ is\\ A_1,\\ \\cdots,\\ x_k\\ is\\ A_k)\\quad THEN\\quad y = g(x_1, \\cdots, x_k)\\]在实际应用中，$f$ 为 $and$ 连接符，$g$ 为线性函数，即\\[R:\\quad IF\\quad x_1\\ is\\ A_1\\ and\\ \\cdots\\ and\\ x_k\\ is\\ A_k\\quad THEN\\quad y = p_0+p_1x_1+\\cdots+p_kx_k)\\]1.1. 推理过程假设有 3 个上述格式的蕴含条件 $R_i,\\ i=1,\\cdots,3$，分别为\\[\\begin{aligned}R_1:&amp;\\quad IF\\quad x_1\\ is\\ small_1\\ and\\ x_2\\ is\\ small_2 &amp; \\quad THEN \\quad y=x_1+x_2\\\\R_2:&amp;\\quad IF\\quad x_1\\ is\\ big_1\\ &amp; \\quad THEN \\quad y=2x_1\\\\R_2:&amp;\\quad IF\\quad x_2\\ is\\ big_2\\ &amp; \\quad THEN \\quad y=3x_2\\end{aligned}\\]前提（Premise）中涉及到的隶属度函数定义为假设输入 $x_1=12, x_2=5$，那么三个前提下的结论（Consequence）为\\[\\begin{aligned}y_1 &amp;= x_1+x_2 = 17\\\\y_2 &amp;= 2x_1 = 24\\\\y_3 &amp;= 3x_2 = 15\\end{aligned}\\]相应的三个真值（True Value）为\\[\\begin{aligned}t_1 &amp;= small_1(x_1)\\land small_2(x_2) = 0.25\\land 0.375 = 0.25\\\\t_2 &amp;= big_1(x_1) = 0.2\\\\t_3 &amp;= big_2(x_2) = 0.375\\end{aligned}\\]那么最终 $y$ 的取值为（此处采用加权平均法）\\[y = \\frac{t_1y_1+t_2y_2+t_3y_3}{t_1+t_2+t_3} \\approx 17.8\\]用一张表格可以列写如下1.2. 特性优点：  相比分段线性逼近，数学形式更紧凑，连接处比较平滑；  相比原始的非线性函数，更加简明，方便进一步处理；  模糊划分可以包含有意义的语义条件，方便的讲人类语言规则形式表达的先验知识融入到模型建立过程中（模糊逻辑的功效）；  万能逼近定律表明 TS 模糊系统能以任意精度逼近非线性模型，适用于广泛类型的非线性系统。另一方面，TS 模糊系统存在以下问题  隶属度函数全部由直线组成，不具备自适应性  不能保证参数的最优性  模糊规则数目无法最佳确定，即无法预知模型的复杂程度1.3. 辨识算法需要确定以下三个部分  $x_i, \\cdots, x_k$，前提变量；  $A_1,\\cdots,A_k$，隶属度函数的参数，简记为隶属度参数；  $p_0, p_1,\\cdots,p_k$，结论中的参数。注意，前提中的变量不需要全部出现。前两个部分的确定和变量如何划分到模糊子空间有关，最后一个部分与模糊子空间中如何描述输入输出关系有关。论文作者提出依次逐层考虑如何确定。1.3.1. 结论参数辨识假设一个一般的系统（$n$ 条规则）表示如下\\[\\begin{aligned}R_1:&amp;\\quad IF\\quad x_1\\ is\\ A_1^1,\\ \\cdots,\\ x_k\\ is\\ A_k^1\\\\&amp;\\quad THEN\\quad y=p_0^1 + p_1^1\\cdot x_1+\\cdots+p^1_k\\cdot x_k\\\\&amp;\\quad \\vdots\\\\R_n:&amp;\\quad IF\\quad x_1\\ is\\ A_1^n,\\ \\cdots,\\ x_k\\ is\\ A_k^n\\\\&amp;\\quad THEN\\quad y=p_0^n + p_1^n\\cdot x_1+\\cdots+p^n_k\\cdot x_k\\\\\\end{aligned}\\]那么输出为\\[y = \\frac{\\sum_{i=1}^n (A_1^i(x_1)\\land\\cdots\\land A_k^i(x_k))\\cdot(p_0^i+p_1^ix_1+\\cdots+p_k^ix_k)}{\\sum_{i=1}^n (A_1^i(x_1)\\land\\cdots\\land A_k^i(x_k))}\\]假设\\[\\beta_i = \\frac{A_1^i(x_1)\\land\\cdots\\land A_k^i(x_k)}{\\sum_{i=1}^n (A_1^i(x_1)\\land\\cdots\\land A_k^i(x_k))}\\]那么\\[y = \\sum_{i=1}^n\\beta_i(p_0^i+p_1^ix_1+\\cdots+p_k^ix_k)\\]当给定一组输入输出数据 $x_{1j},\\cdots,x_{kj}\\rightarrow y_j\\ (j=1,\\cdots,m)$ 时，可以通过最小二乘法来确定参数 $p_0^i, p_1^i,\\cdots,p_k^i$。  最小二乘法：在实验中获得了自变量与因变量的若干组对应数据，在使偏差平方和取最小值时，找出一个已知类型的函数（即确定关系式中的参数）的方法。经过 TS 模糊系统的推理后得到输出的估计为\\[\\begin{aligned}\\hat y_1 &amp;= \\sum_{i=1}^n\\beta_{i1}(p_0^i+p_1^ix_{11}+\\cdots+p_k^ix_{k1})\\\\\\hat y_2 &amp;= \\sum_{i=1}^n\\beta_{i2}(p_0^i+p_1^ix_{12}+\\cdots+p_k^ix_{k2})\\\\&amp;\\cdots\\\\\\hat y_m &amp;= \\sum_{i=1}^n\\beta_{im}(p_0^i+p_1^ix_{1m}+\\cdots+p_k^ix_{km})\\\\\\end{aligned}\\]对于其中第 $j$ 个式子，展开如下\\[\\begin{aligned}\\hat y_j &amp;= \\sum_{i=1}^n\\beta_{ij}(p_0^i+p_1^ix_{1j}+\\cdots+p_k^ix_{kj})\\\\&amp;= (\\beta_{1j}p_0^1+\\cdots+\\beta_{nj}p_0^n)+(\\beta_{1j}p_1^1+\\cdots+\\beta_{nj}p_1^n)x_{11}+\\cdots\\\\&amp;= [\\beta_{1j},\\cdots,\\beta_{nj}][p_0^1,\\cdots,p_0^n]^T+[\\beta_{1j}x_{11},\\cdots,\\beta_{nj}x_{11}][p_1^1,\\cdots,p_1^n]^T+\\cdots\\\\&amp;=\\begin{bmatrix}  \\beta_{1j}\\cdots\\beta_{nj},\\quad \\beta_{1j}x_{11}\\cdots\\beta_{nj}x_{11},\\quad \\cdots\\end{bmatrix}\\begin{bmatrix}  p_0^1\\\\  \\vdots\\\\  p_0^n\\\\  \\\\  p_1^1\\\\  \\vdots\\\\  p_1^n\\\\  \\\\  \\vdots\\end{bmatrix}\\end{aligned}\\]其中\\[\\beta_{ij} = \\frac{A_{i1}(x_{1j})\\land\\cdots\\land  A_{ik}(x_{kj})}{\\sum_j A_{i1}(x_{1j})\\land\\cdots\\land A_{ik}(x_{kj})}\\]将上式的 $j$ 在 $[1,m]$ 上展开，可写成矩阵形式。假设 $X\\in \\mathbb R^{m\\times n(k+1)}$，$Y,\\hat Y\\in \\mathbb R^{m}$，$P\\in \\mathbb R^{n(k+1)}$，则\\[\\begin{aligned}X &amp;= \\begin{bmatrix}\\beta_{11}\\cdots\\beta_{n1},\\ \\beta_{11}x_{11}\\cdots\\beta_{n1}x_{11},\\ \\cdots,\\ beta_{11}x_{k1}\\cdots\\beta_{n1}x_{k1}\\\\\\cdots\\\\\\beta_{1m}\\cdots\\beta_{nm},\\ \\beta_{11}x_{1m}\\cdots\\beta_{nm}x_{1m},\\ \\cdots,\\ \\beta_{1m}x_{km}\\cdots\\beta_{nm}x_{km}\\end{bmatrix}\\\\Y &amp;= [y_1,\\cdots,y_m]^T\\\\\\hat Y &amp;= [\\hat y_1,\\cdots,\\hat y_m]^T\\\\P&amp;=[p_0^1\\cdots p_0^n,\\cdots p_1^1\\cdots p_1^n,\\cdots,p_k^1\\cdots p_k^n]^T\\end{aligned}\\]$m$ 表示样本个数（$X,Y$ 的行数），$n$ 表示规则个数，$n(k+1)$ 表示待估计的特征参数 $P$ 的个数。用矩阵形式表达的推理过程变为\\[\\hat Y = XP\\]损失函数定义为\\[J(P) = \\frac{1}{2}(\\hat Y-Y)^T(\\hat Y-Y)= \\frac{1}{2}(XP-Y)^T(XP-Y)\\]根据最小二乘法原理，将损失函数对待估计参数求导取 0，结果为（组内大神推导表示无误）  Eureka机器学习读书笔记. 最小二乘法（least sqaure method）\\[\\begin{aligned}&amp;\\frac{\\partial}{\\partial P}J(P)= X^T(XP-Y)=0\\\\&amp;\\Rightarrow X^TXP=X^TY\\Rightarrow P=(X^TX)^{-1}X^TY\\end{aligned}\\]即得到最小二乘法的标准解析解\\[P=(X^TX)^{-1}X^TY\\]如果能够提供足够数量的无噪声样本数据，最小二乘法可以精确估计出原始问题的真实参数。如果数据有噪声，则采用稳态卡尔曼滤波（原文 stable-state，现在一般用 steady-state）来估计 $P$。稳态卡尔曼滤波可以计算出线性代数方程中的参数，使得均方差最小。假设 $X$ 矩阵的第 $i$ 行为 $x_i$，$Y$ 的第 $i$ 个元素为 $y_i$，那么 $P$ 可以通过下面的式子递归估计（涉及卡尔曼滤波的知识，还没看，假设就能估计出来了）\\[\\begin{aligned}P_{i+1} &amp;= P_i + S_{i+1}\\cdot x_{i+1}\\cdot(y_{i+1}-x_{i+1}\\cdot P_i)\\\\S_{i+1} &amp;= S_i-\\frac{S_i\\cdot x_i+x_{i+1}\\cdot P_i}{1+x_{i+1}\\cdot S\\cdot x_{i+1}^T},\\quad i=0,1,\\cdots,m-1\\\\P &amp;= P_m\\end{aligned}\\]初值为\\[\\begin{aligned}P_0 &amp;= 0\\\\S_0 &amp;= \\alpha\\cdot I\\quad(\\alpha=big\\ number)\\end{aligned}\\]最后给出一个例子。假设系统为在将模型的前提固定为原始系统的前提的情况下，将噪声添加到数据中，可以从输入输出数据中识别出后果，如下所示。下图展示了包含噪声的输入输出数据，原始结论和辨识出的结论。1.3.2. 前提参数辨识在本节中，我们说明如何确定前提中的模糊集，即在前提变量已经选定的情况下，如何将前提变量的空间划分为模糊子空间（包括确定规则个数和确定每个规则中的模糊集/隶属度函数参数），但是规则个数作者只是一笔带过。如上图所示，根据图中的输入输出数据来划分 $x$ 的模糊子空间，比如 x is small 或者 x is big。即可设计如下两个规则\\[\\begin{aligned}IF\\ x\\ is\\ small\\ THEN\\ y=a_1x+b_1\\\\IF\\ x\\ is\\ big\\ THEN\\ y=a_2x+b_2\\\\\\end{aligned}\\]然后需要确定 small 和 big 的隶属度函数，以及结论中的 $a_1,a_2,b_1,b_2$。问题转变为，找寻隶属度函数的最优参数，使得性能指标最优。步骤如下  固定模糊集参数，通过上一节的方法得到最优的结论参数估计；  找寻隶属度函数的最优参数使得性能指标最优的问题可简化为一个非线性规划问题。作者采用著名的  complex method for the minimization（著名到我居然不认识）求解。由于传统的 TS 模糊系统的隶属度函数是线性的，因此用两个参数（分别对应取值为 0 和 1 的隶属度值）就能确定。例子：使用从假定系统中收集的带有噪声的输入输出数据进行的识别，噪声的标准差是输出值的 5% 。注意，如果不存在噪音，我们可以识别与原始系统相同的所有前提参数。指出这个事实非常重要。如果不是这种情况，我们就不能与模糊系统描述语言一起主张识别算法的有效性。假设原始系统描述如下结论和带噪音的输入输出数据如下图所示。所识别的前提参数如下。我们可以看到已经推导出几乎相同的参数。1.3.3. 前提变量的选择上一节假设前提变量已经给定。但是如何确定前提中用到哪些变量？因为给定的输入量 $x$ 可以不全用在前提中。本质上包括两个问题：  选择哪些变量：选择一个变量意味着它的空间要被划分；  划分出多少子空间；两个问题是有组合关系的，所以一般而言没有理论方法解决（The whole problem is a combinatorial one. So in general there seems no theoretical approach available）。作者提出一种启发式搜索方法，包含以下步骤：假设一个包含 $k$ 个输入和 1 个输出的模糊系统。      步骤 1：只划分 $x_1$ 为 big 和 small，其它分量不划分，意味着只有 $x_1$ 出现在前提中，其它分量不出现。那么模型规则如下\\[\\begin{aligned}  IF\\ x_1\\ is\\ big_1\\ THEN\\ \\cdots\\\\  IF\\ x_1\\ is\\ small_1\\ THEN\\ \\cdots\\\\\\end{aligned}\\]    称上述模型为 模型 1-1，类似的，只划分第 $i$ 个分量的情况称为 模型 1-$i$。这样可以得到 $k$ 个模型，每个模型包含两个模糊蕴含条件（规则）。    步骤 2：对上述每一个模型，用前面所述的方法确定最优的前提参数和结论参数。挑出其中性能指标最低的模型，作为稳定状态（stable state）。  步骤 3：从前面的稳定状态出发，比如 模型 1-$i$，对所有分量 $x_i - x_j$ 进行排列组合，每个分量划分为 2 个模糊子空间。特别地，$x_i - x_i$ 组合将 $x_i$ 划分为 4 个模糊子空间，比如 small, medium small, medium big, big。这样又得到 $k$ 个模型，称为 模型 2-j。再次挑出其中性能指标最小的一个模型。  步骤 4：重复步骤 3，往里再次添加一个其它分量。当满足下列任一条件时搜索停止：          性能指标小于预设值；      模糊蕴含条件的个数大于预设值；      整个过程如图所示1.4. 广义 TS 模糊系统将 TS 模糊系统进行规范化描述如下。给定 $m$ 个输入向量 $x_1,\\cdots,x_m$，$n$ 条模糊规则为 $R_1,\\cdots,R_n$，第 $i$ 条模糊规则的模糊子集分别为 $A^i_1,\\cdots,A^i_m$（相应的隶属度函数为 $A^i_j(x_j)$），各个模糊规则的真值为 $G_1, \\cdots, G_n$，各个模糊规则对应的结论为 $y_1,\\cdots,y_n$，最终输出为 $y$，那么采用加权平均法的 TS 模糊系统为\\[\\begin{aligned}y &amp;= \\frac{\\sum_{i=1}^n G_iy_i}{\\sum_{i=1}^n G_i}\\\\G_i &amp;= \\prod_{j=1}^m A^i_j(x_j)\\end{aligned}\\]其中 $\\prod$ 为模糊化算子，通常采取取小 “$\\land$” 或者 代数积 “$\\cdot$” 计算。若隶属度函数采用高斯隶属度函数形式，则可得到具有 $m$ 输入单输出、模糊规则数为 $n$ 的广义 TS 模糊系统（未能找到出处）\\[\\begin{aligned}y &amp;= \\frac{\\sum_{i=1}^n G_iy_i}{\\sum_{i=1}^n G_i}\\\\G_i &amp;= \\prod_{j=1}^m A^i_j(x_j) = \\prod_{j=1}^m exp{(-\\left\\vert\\frac{x_j - b_j^i}{a_j^i}\\right\\vert)}\\end{aligned}\\]广义 TS 模糊系统可以以任意精度逼近被控对象，而模型的参数可以通过参数辨识方法获得。3. 参考文献无。"
  },
  
  {
    "title": "深度学习文章阅读（learn2learn）",
    "url": "/posts/deep-learning-learn-2-learn/",
    "categories": "Academic, Paper",
    "tags": "deep learning",
    "date": "2020-11-30 16:46:19 +0800",
    





    
    "snippet": "本文介绍了用梯度下降的方法学会了梯度下降的学习方法，用 LSTM 代替传统人设计的诸如RMSprop、ADAM 等优化方法去学习出一个针对特定任务的优化器。  1. 简介          1.1. 迁移学习和泛化      1.2. 相关工作        2. 采用 RNN 实现学会学习          2.1. 问题框架      2.2. coordinatewise LSTM 优...",
    "content": "本文介绍了用梯度下降的方法学会了梯度下降的学习方法，用 LSTM 代替传统人设计的诸如RMSprop、ADAM 等优化方法去学习出一个针对特定任务的优化器。  1. 简介          1.1. 迁移学习和泛化      1.2. 相关工作        2. 采用 RNN 实现学会学习          2.1. 问题框架      2.2. coordinatewise LSTM 优化器      2.3. 预处理与后处理        3. 实验          3.1. 10 维函数      3.2. MNIST（MLP）      3.3. CIFAR（CNN）      3.4. Neural Art        4. 参考文献1. 简介  Marcin Andrychowicz1, Misha Denil1, Sergio Gómez Colmenarejo, Nando de Freitas, et al. Learning to learn by gradient descent by gradient descent[J]. NIPS 2016.  Learning to learn is a very exciting topic for a host of reasons, not least of which is the fact that we know that the type of backpropagation currently done in neural networks is implausible as an mechanism that the brain is actually likely to use: there is no Adam optimizer nor automatic differentiation in the brain! Something else has to be doing the optimization of our brain’s neural network, and most likely that something else is itself a neural network!目前深度学习的情况只是输入输出过程是神经网络，但调控神经网络的是人工设计！或者说这个学习机制是人工给定的。本文解决的是优化算法的学习问题。具体来说，假设目标函数为 $f(\\theta)$，机器学习中我们经常可以把优化目标表示成\\[\\theta^*=argmin_{\\theta\\in \\Theta}f(\\theta)\\]对于连续的目标函数，标准的梯度下降序列式如下\\[\\theta_{t+1} - \\theta_t - \\alpha \\nabla f(\\theta_t)\\]优化方面的许多现代工作都基于设计针对特定问题类别的更新规则，不同研究社区之间关注的问题类型不同。比如在深度学习领域，大量研究专门针对高维，非凸优化问题的优化方法，这些促使了momentum [Nesterov, 1983, Tseng, 1998], Rprop [Riedmiller and Braun, 1993], Adagrad [Duchi et al., 2011], RMSprop [Tieleman and Hinton, 2012], 和 ADAM [Kingma and Ba, 2015] 等优化方法的研究。上述研究更多的关注各自问题结构本身，但往往存在潜在的较差泛化性能为代价。根据 No Free Lunch Theorems for Optimization [Wolpert and Macready, 1997] （天下没有免费的午餐）理论，组合优化设置下，没有一个算法可以绝对好过一个随机策略。因此，将研究局限于特定子问题的方式是 唯一 能提高性能的研究手段。本文另辟蹊径，提出了一种【基于学习的更新策略】代替【人工设计的更新策略】（用一个可学习的梯度更新规则，替代手工设计的梯度更新规则），称之为（优化）优化器（optimizer） $g$，由其参数 $\\phi$ 定义。  （优化）优化器 optimizer：$g$，参数为 $\\phi$  （原始）优化器 optimizee：参数为 $\\theta$因此原始优化器（optimizee）的参数优化序列式形式为\\[\\theta_{t+1} - \\theta_t + g_t ( \\nabla f(\\theta_t),\\phi)\\]也即用一个 optimizer 来直接给出 optimizee 的参数更新方式（大小和方向）。$g$ 的取值与目标函数 $f$ 的梯度 $\\nabla f$ 以及自身参数 $\\phi$。文中的 optimizer 采用 RNN 实现，具体而言采用 LSTM 实现。  RNN 存在一个可以保存历史信息的隐状态，LSTM 可以从一个历史的全局去适应这个特定的优化过程，LSTM 的参数对每个时刻节点都保持 “聪明”，是一种 “全局性的聪明”，适应每分每秒。1.1. 迁移学习和泛化【强烈怀疑本节是审稿人要求加的】这项工作的目的是开发一种构建学习算法的程序，该算法在特定类别的优化问题上表现良好。通过将算法设计演化为学习问题，我们可以通过示例问题实例来指定我们感兴趣的问题类别。这与通常的方法不同，后者通常通过分析来表征有趣问题的特性，并利用这些分析见解来手动设计学习算法。【个人理解，通过数据驱动来学习设计优化算法，而不是通过人工分析问题来设计优化算法】在普通的统计学习中，泛化 反映了目标函数在未知点处的行为进行预测的能力。 而在本文中，任务本身就是问题实例，这意味着泛化衡量了在不同问题之间传递知识的能力。问题结构的这种重用通常被称为迁移学习，并且通常被视为独立的主题。但是从元学习的观点出发，我们可以认为迁移学习是一种泛化，后者在机器学习领域中已有广泛的研究。深度学习的成功之处就在于，我们可以依赖深度网络的泛化能力，通过学习感兴趣的子结构去适应新样本。本文旨在利用这种泛化能力，还将其从简单的监督学习提升到更广泛的优化设置。  This is in contrast to the ordinary approach of characterizing properties of interesting problems analytically and using these analytical insights to design learning algorithms by hand.  The meaning of generalization in this framework is      the ability to transfer knowledge between different problems    the way that learning some cmmon structures in different problems    the capability applied to more general optimization problem.  在本文的框架中，泛化的含义是  在不同问题之间传递知识的能力  学习不同问题中某些通用结构的方式  该能力适用于更一般的优化问题1.2. 相关工作略。2. 采用 RNN 实现学会学习2.1. 问题框架假设最终的 optimizee 的参数为 $\\theta^*(f,\\phi)$，即其与 optimizer 参数 $\\phi$ 和位置的目标函数 $f$ 有关。提出以下问题：什么样的 optimizer 算是 “好” 的optimizer呢？当然是让 optimizee 的 loss 值越最小的 optimizer 最好。所以optimizer 的 loss 值应该是基于 optimizee 的 loss 值的。再次回顾我们最终的目标\\[\\theta^*=argmin_{\\theta\\in \\Theta}f(\\theta)\\]给定一个目标函数 $f$ 的分布，那么 optimizer 的损失定义为\\[\\mathcal L(\\phi) = \\mathbb E_f[f(\\theta^*)]\\]这里详细解读一下，对于某个具体的任务  目标函数 $f$ （个人理解就是 loss）  最终优化后的 optimizee 的参数为 $\\theta^$。写成 $\\theta^(f,\\phi)$，与 $f$ 有关因为不同的 $f$ 会导致不同的最优参数；与 $\\phi$ 有关因为最优的参数是依赖 optimizer 给出的，而 optimizer 的参数为 $\\phi$  最终的损失为 $f(\\theta^*)$  因此 optimizer 的损失就是上述最终损失的期望 $\\mathbb E_f[f(\\theta^*)]$，为啥求期望？上式即为优化最终的 optimizee 的损失（optimizing for the best final result with our optimizee.）。注意，最终最优的参数 $\\theta^*$ 我们还并不知道，它是通过一个优化过程得到的。因此虽然这样设计合理，但是给训练造成了很大麻烦（This seems reasonable, but it makes it much harder to train）。假设经过 $T$ 次优化步骤，更加方便的做法是将 optimizer 的损失定义为整个优化过程的损失的加权和\\[\\mathcal L(\\phi) = \\mathbb E_f\\left[ \\sum_{t=1}^T\\omega_tf(\\theta_t) \\right]\\]其中\\[\\theta_{t+1} = \\theta_t+g_t\\]\\[[ g_t,h_{t+1} ] = {\\rm lstm}(\\nabla_t,h_t,\\phi)\\]$\\omega_t \\in \\mathbb R_{\\geq0}$ 是各个优化时刻的任意权重，$\\nabla_t = \\nabla_\\theta f(\\theta_t)$。当 $t=T$ 且只有该时刻的 $\\omega_t = 1$ 时\\[\\mathcal L(\\phi) = \\mathbb E_f[f(\\theta^*(f,\\phi))] = \\mathbb E_f\\left[ \\sum_{t=1}^T\\omega_tf(\\theta_t) \\right]\\]对上面的过程进行详细解读：  Meta-optimizer 优化器：目标函数整个优化周期的 loss 都要很小（加权和）  传统优化器：对于当前的目标函数，只要这一步的 loss 比上一步的 loss 值要小就行可以用 GD 来最小化 $\\mathcal L(\\phi)$，梯度估计 $\\partial \\mathcal L(\\phi)/\\partial\\phi$ 可以通过采样随机的 $f$ 然后对计算图进行反向传播来求解。我们允许梯度沿着实线反传，但是丢弃了沿着虚线的路径。这种考虑相当于假设 $\\partial \\nabla_t/\\partial \\phi = 0$，这样可以避免计算 $f$ 的二阶导。  【个人理解】：从计算图上求$\\partial \\mathcal L(\\phi)/\\partial\\phi$，需要沿着箭头方向反向流动，如果考虑虚线，那么就包括如下图所示的路径，这需要求 $\\partial \\nabla_t/\\partial \\theta \\cdot \\partial \\theta / \\partial \\phi$，其中 $\\theta$ 对 $\\phi$ 包含三部分，一部分是 lstm 内直接相关的 $\\partial \\theta / \\partial \\phi$，另一部分是通过隐层回传的 $\\partial \\theta / \\partial h_t$。第三一部分是随着 $\\nabla_tf$ 往前回传的（$\\partial \\nabla_t/\\partial \\phi = \\partial \\nabla_t / \\partial \\theta \\cdot \\partial \\theta / \\partial \\phi$），这一部分中包含 $f$ 的二阶导（$\\partial \\nabla_t / \\partial \\theta$），为了计算简便，作者假设该项等于 0，也即忽略了下图中梯度回传的虚线（红线）路径。  从上面 LSTM 优化器的设计来看，我们几乎没有加入任何先验的人为经验在里面，只是用了长短期记忆神经网络的架构，优化器本身的参数 $\\phi$ 即 LSTM 的参数，这个优化器的参数代表了我们的更新策略，后面我们会学习这个参数，即学习用什么样的更新策略。2.2. coordinatewise LSTM 优化器  One challenge in applying RNNs in our setting is that we want to be able to optimize at least tens of thousands of parameters. Optimizing at this scale with a fully connected RNN is not feasible as it would require a huge hidden state and an enormous number of parameters. To avoid this difficulty we will use an optimizer m which operates coordinatewise on the parameters of the objective function, similar to other common update rules like RMSprop and ADAM. This coordinatewise network architecture allows us to use a very small network that only looks at a single coordinate to define the optimizer and share optimizer parameters across different parameters of the optimizee.采用 RNN（LSTM） 的一大挑战就是，我们想要优化成千上万的参数。采用全连接 RNN 需要巨大的隐层 $h_t$（假设输入向量 $\\theta$ 维度为 $M$，则 $h_t \\in \\mathbb R^M$）和巨量的参数（假设隐层维度为 $D$，则参数 $W_f, W_i, W_o, W_c\\in \\mathbb R^{D\\times (D+M)}$），这是不现实的。为了克服这一点，我们只设计一个优化器 $m$ 对目标函数的每个参数分量进行操作。具体而言，每次只对 optimizee 的 一个参数分量 $\\theta_i$ 进行优化，这样只需要维持一个很小的 optimizer（lstm）就可以完成工作了。对于每个参数分量 $\\theta_i$ 而言，optimizer（lstm）的参数 $\\phi$ 是共享的，但是隐层状态 $h_i$ 是不共享的。由于每个维度上的 optimizer（lstm）输入的 $h_i$ 和 $\\nabla f(\\theta_i)$ 是不同的，所以即使它们的 $\\phi$ 相同，但是它们的输出却是不一样的。换句话说，这样设计的 lstm 变相实现了优化与维度（顺序）无关。这与传统的 RMSprop 和 ADAM 的优化方式类似，它们也是为每个维度的参数施行同样的梯度更新规则。  Adrien Lucas Ecoffet 的解读[1]：The “coordinatewise” section is phrased in a way that is a bit confusing to me, but I think it is actually quite simple: what it means is simply this: every single “coordinate” has its own state (though the optimizer itself is shared), and information is not shared across coordinates.I wasn’t 100% sure about is what a “coordinate” is supposed to be. My guess, however, is that it is simply a weight or a bias, which I think is confirmed by my experiments. In other words, if we have a network with 100 weights and biases, there will be 100 hidden states involved in optimizing it, which means that effectively there will be 100 instances of our optimizer network running in parallel as we optimize.2.3. 预处理与后处理由于 optimizer（lstm） 的输入是梯度，梯度的幅值变化换位很大，而神经网络一般只对小范围的输入输出鲁棒，因此在实践中需要对 lstm 的输入输出进行处理。直觉上，可以采用 log 来缩放输入。作者采用如下的方式\\[\\begin{aligned}\\nabla^k \\rightarrow\\left\\{  \\begin{matrix}  \\left( \\frac{log(\\vert\\nabla\\vert)}{p},sgn(\\nabla) \\right) &amp;\\quad if \\vert\\nabla\\vert\\geq e^{-p}\\\\  (-1,e^{p}\\nabla) &amp;\\quad otherwise\\\\  \\end{matrix}\\right.\\end{aligned}\\]  $p&gt;0$ is a parameter controlling how small gradients are disregarded其中 $p&gt;0$ 为任意一个参数（作者取 $p=10$），用来裁剪梯度。上式中取绝对值就丢失了符号信息，因此需要额外加一项输入记录符号信息。  Adrien Lucas Ecoffet 的解读[1]：With this formula, if the first parameter is greater than -1, it is a log of gradient, otherwise it is a flag indicating that the neural net should look at the second parameter. Likewise, if the second parameter is -1 or 1, it is the sign of the gradient, but if it is between -1 and 1 it is a scaled version of the gradient itself, exactly what we want!如果第一个参数的取值大于 -1，那么它就代表梯度的 log ，第二个参数则是它的符号。如果第一个参数的取值等于 -1，那么它将作为一个标记告诉神经网络应该去寻找第二个参数，此时第二个参数就是对梯度的缩放。变换后画图如下（图中 $p=1$）3. 实验3.1. 10 维函数设计如下的目标函数\\[f(\\theta)=\\vert\\vert W\\theta-y \\vert\\vert_2^2\\]其中 $W,y\\in \\mathbb R^{10} \\sim i.i.d\\ Gaussian\\ distribution$。目的是随机产生一个 $f$，通过训练找到最优的 $\\theta$ 使得 $f$ 最小。而且这个目标函数是独立同分布采样的，意味着任意初始化一个优化问题模型的参数，我们都希望这个优化器能够找到一个优化问题的稳定的解。  Adrien Lucas Ecoffet 的解读[1]：These are pretty simple: our optimizer is supposed to find a 10-element vector called $\\theta$ that, when multiplied by a $10\\times 10$ matrix called $W$, is as close as possible to a 10-element vector called $y$. Both $y$ and $W$ are generated randomly. The error is simply the squared error.从高斯分布中随机采样，得到一条曲线，然后训练100次 optimizee，期间 每 20 次 收集一批 loss 用来训练 optimizer（lstm），然后更新一次 optimizee 的参数更新方式。  原文：Each function was optimized for 100 steps and the trained optimizers were unrolled for 20 steps.Adrien Lucas Ecoffet 的解读[1]：I assume this means that each epoch is made up of trying to optimize a new random function for 100 steps, but we are doing an update of the optimizer every 20 steps. The number of epochs is thus unspecified, but according to the graphs it seems to be 100 too.在本算例中没有采用任何预处理和后处理。结果如下3.2. MNIST（MLP）  In this experiment we test whether trainable optimizers can learn to optimize a small neural network on MNIST. We train the optimizer to optimize a base network and explore a series of modifications to the network architecture and training procedure at test time.训练一个神经网络完成 MNIST 图片分类。目标函数 $f(\\theta)$ 是交叉熵，optimizee 是一个单隐层 20 个神经元的 MLP，激活函数是 sigmoid。随机选取 128 个图片作为一个 minibatch 来计算 $\\partial f(\\theta)/ \\partial \\theta$。每次任务的唯一不同在于初始参数 $\\theta_0$ 和随机选择的 minibatch。每个任务跑 100 步，每 20 步训练一次 optimizer。采用前面设计的预处理，后处理给 lstm 的输出乘以 0.1。结果如下下面研究对不同架构的泛化。分别将训练好的 optimizer 用于  40 个隐层神经元的 optimizee  2 层/每层 20 个神经元的 optimizee  采用 ReLu 激活函数的 optimizee结果如下还对不同的架构的最终 loss 结果进行了比较。左图两虚线交叉表示基准（optimizer 在 1 层 20 神经元的架构下训练），其它点表示其它改变过后的架构。3.3. CIFAR（CNN）optimizee 采用包含卷积层和全连接层在内的网络，三层卷积层+池化层，最后跟一个 32 神经元的全连接层。激活函数都为 ReLu，采用了 batch normalization。仍然采用前面说的 coordinatewise lstm，但是这个实验中，考虑到卷积和全连接的差异性（同时也尝试过只用一个 lstm 作为 optimizer 但效果不好），作者因此分别针对卷积层和全连接层设计了两个 optimizer，它们之间不共享 $\\phi$。结果如下（原文说的很乱，没法解读结果，好就完事了）  The left-most plot displays the results of using the optimizer to fit a classifier on a held-out test set. The additional two plots on the right display the performance of the trained optimizer on modified datasets which only contain a subset of the labels, i.e. the CIFAR-2 dataset only contains data corresponding to 2 of the 10 labels. Additionally we include an optimizer LSTM-sub which was only trained on the held-out labels.  http://www.cs.toronto.edu/~kriz/cifar.html 163 MB python versionThe CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.3.4. Neural Art略。4. 参考文献[1] Adrien Lucas Ecoffet. Paper repro: “Learning to Learn by Gradient Descent by Gradient Descent” [包含其实现代码][2] Sen Yang. Learning to learn by gradient descent by gradient descent-PyTorch实践 [包含其实现代码]"
  },
  
  {
    "title": "深度学习文章阅读（BERT）",
    "url": "/posts/deep-learning-BERT/",
    "categories": "Academic, Paper",
    "tags": "deep learning",
    "date": "2020-11-25 16:07:19 +0800",
    





    
    "snippet": "本文介绍了谷歌提出的 BERT 框架，基于 Transformer，在 NLP 领域的 11 个方向大幅刷新了精度，是近年来自残差网络最有突破性的一项技术。  1. 简介  2. 预备知识          2.1. 语言模型                  2.1.1. N-gram          2.1.2. NNLM                    2.2. 词向量模型  ...",
    "content": "本文介绍了谷歌提出的 BERT 框架，基于 Transformer，在 NLP 领域的 11 个方向大幅刷新了精度，是近年来自残差网络最有突破性的一项技术。  1. 简介  2. 预备知识          2.1. 语言模型                  2.1.1. N-gram          2.1.2. NNLM                    2.2. 词向量模型                  2.2.1. CBoW          2.2.2. Skip-gram          2.2.3. 两个提速手段          局限性          2.2.4. 后续发展                      3. 总体结构  4. 参考文献1. 简介  Devlin J, Chang M W, Lee K, et al. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding[J]. arXiv preprint arXiv:1810.04805v2, 2018.BERT（Bidirectional Encoder Representations from Transformers）近期提出之后，作为一个 word2vec 的替代者，其在 NLP 领域的 11 个方向大幅刷新了精度，可以说是近年来自残差网络最优突破性的一项技术了。论文的主要特点以下几点：  使用了 Transformer 作为算法的主要框架，Transformer 能更彻底的捕捉语句中的双向关系；  使用了Mask Language Model(MLM) （Wilson L Taylor. 1953. cloze procedure: A new tool for measuring readability. Journalism Bulletin, 30(4):415–433.）和 Next Sentence Prediction(NSP) 的多任务训练目标；  使用更强大的机器训练更大规模的数据，使 BERT 的结果达到了全新的高度，并且 Google 开源了 BERT 模型，用户可以直接使用 BERT 作为 Word2Vec 的转换矩阵并高效的将其应用到自己的任务中。BERT 的本质上是通过在海量的语料的基础上运行自监督学习方法为单词学习一个好的特征表示，即 BERT 是一个词向量模型。所谓自监督学习是指在没有人工标注的数据上运行的监督学习。在以后特定的 NLP 任务中，我们可以直接使用 BERT 的特征表示作为该任务的词嵌入特征。所以 BERT 提供的是一个供其它任务迁移学习的模型，该模型可以根据任务微调或者固定之后作为特征提取器。BERT 的源码和模型2019年10月31号已经在 Github 上开源，简体中文和多语言模型也于11月3号开源。2. 预备知识2.1. 语言模型语言模型是一个基于概率的判别模型，它的输入是一句话（单词的顺序序列），输出是这句话的概率，即这些单词的联合概率（joint probability）。首先回顾一下自然语言处理中的一个基本问题：如何计算一段文本序列在某种语言下出现的概率？之所为称其为一个基本问题，是因为它在很多 NLP 任务中都扮演着重要的角色。例如，在机器翻译的问题中，如果我们知道了目标语言中每句话的概率，就可以从候选集合中挑选出最合理的句子做为翻译结果返回。统计语言模型给出了这一类问题的一个基本解决框架。对于一段文本序列\\[S=\\omega_1,\\omega_2,...,\\omega_T\\]它的概率可以表示为\\[P(S) = P(\\omega_1,\\omega_2,...,\\omega_T) = \\prod_{t=1}^Tp(\\omega_t\\vert \\omega_1,\\omega_2,...,\\omega_{t-1})\\]也即假设，每一个单词 $w_i$ 都要依赖于从第一个单词 $w_1$ 到它之前一个单词 $\\omega_{t-1}$ 的影响。问题变成了如何预测连乘中这些给定 previous words 下的条件概率。上述概率衡量方法有两个缺陷  参数空间巨大，$p(\\omega_t\\vert \\omega_1,\\omega_2,…,\\omega_{t-1})$ 的参数有 $O(n)$ 个；  数据稀疏严重，词同时出现的情况可能没有（条件概率为 0），组合阶数高时尤其明显。2.1.1. N-gram为了解决第一个问题，我们引入马尔科夫假设（Markov Assumption）：一个词的出现仅与它之前的若干个词有关。这就产生了 N-gram 模型\\[p(\\omega_t\\vert \\omega_1,\\omega_2,...,\\omega_{t-1}) = p(\\omega_t\\vert \\omega_{t-N+1},...,\\omega_{t-1})\\]一般取 $N=2$ 或者 $N=3$，分别对应 Bi-gram 和 Tri-gram 模型，前者认为每个词只与前面一个词有关，后者认为与前两个词有关。比如一个句子，I love deep learning 分别分解为：Bi-gram : {I, love}, {love, deep}, {love, deep}, {deep, learning}Tri-gram : {I, love, deep}, {love, deep, learning}2.1.2. NNLM      A neural probabilistic language model西多士NLP. 词向量(one-hot/SVD/NNLM/Word2Vec/GloVe)  在N-gram 的基础上，Bengio 在 2003 年提出 NNLM 即 Neural Network based Language Model，并首次提出了 word embedding 的概念（虽然没有叫这个名字）。它是一个很简单的模型，由四层组成，输入层、嵌入层、隐层和输出层。模型接收的输入是长度为 $n$ 的词序列，输出是下一个词的类别。NNLM模型的基本思想可以概括如下：  假定词表中的每一个 word 都对应着一个连续的特征向量；  假定一个连续平滑的概率模型，输入一段词向量的序列，可以输出这段序列的联合概率；  同时学习词向量的权重和 Ngram 概率模型里的参数。Bengio等人采用了一个简单的前向反馈神经网络 $f(\\omega_{t−n+1},…,w_t)$ 来拟合一个词序列的条件概率 $p(\\omega_t\\vert \\omega_{t-N+1},…,\\omega_{t-1})$。整个模型的网络结构为一个三层神经网络，第一层映射层，第二层隐层，第三层输出层。用端到端的思想来看，我们输入一个词的 one-hot 向量表征，希望得到相应的相应词的条件概率，则神经网络模型要做的就是拟合一个由 one-hot 向量映射为相应概率模型的函数。我们将上图的网络结构拆成两部分来理解：      首先是一个线性的映射层。它将输入的 $N−1$ 个 one-hot 词向量，通过一个共享的 $D\\times V$ 的矩阵 $C$，映射为 $N−1$ 个分布式的词向量（distributed vector）。其中，$V$ 是词典的大小，$D$ 是 embedding 向量的维度（一个先验参数）。    $C$ 矩阵里存储了要学习的词向量，为什么这是我们需要的词向量呢？试想一下，当我们把 $n$ 个 one-hot 表征的词向量词典输入到神经网络中，单层的神经网络进行的运算无非就是 $Y=W^TX$，这个操作等效于查表操作，one-hot 向量将 $n$ 个词向量从 embedding 层中原封不动地提取出来，如下图所示。        这样，我们在训练语言模型的过程中，映射层的权值就等效为我们需要的词向量表征。值得注意的一点是，这里的词向量也是要学习的参数，也就是说词向量是在训练的过程中自动生成的。        其次是一个简单的前向反馈神经网络 $g$。它是前面 embedding 层输出的直接拼接，由一个激活函数为 $tanh$ 的 $(N-1)\\times D$ 维隐藏层和一个 $V$ 维 $softmax$ 输出（分类）层组成，可以将我们得到的一系列输出映射成对应概率。这样，通过将 embedding 层输出的 $N−1$ 个词向量映射为一个长度为 $V$ 的概率分布向量，从而对词典中的 word 在输入 context 下的条件概率做出预估\\[p(\\omega_t\\vert \\omega_1,...,\\omega_{t-1}) \\approx f(\\omega_{t-n+1},...,\\omega_{t-1})=g(C(\\omega_{t-n+1}),...,C(\\omega_{t-1}))\\]  注意到，当词表长度 $V$ 和期望的词向量维度 $D$ 确定的时候，第一层映射层和 softmax 输出层的规模就已经确定了，而隐藏层打大小可以由我们自己指定。我们可以通过最小化一个带正则项的 cross-entropy 损失函数来调整神经网络的模型参数\\[L(\\theta) = \\frac{1}{T}\\sum_t logf(\\omega_{t-n+1},...,\\omega_{t-1})+R(\\theta)\\]上式包含一个巨大的参数空间。不过，在每次用 SGD 学习更新模型的参数时，并不是所有的参数都会进行调整，只有当前 context 包含词的词向量才会被更新（因为映射层的输出只会得到这些词的输出，并参与接下来的运算）。真正的计算瓶颈主要是在 softmax 层的归一化函数上（需要对词典中所有的 word 计算一遍条件概率）。NNLM 解决了语言模型中的以下两个问题  条件概率 $p(\\omega_t \\vert context)$ 的计算；  向量空间模型（Vector Space Model，VSM）里词向量的表达；          一个稠密连续向量也就是所谓的词向量的分布式表征。事实上，这个概念在信息检索（Information Retrieval）领域早就已经被广泛地使用了，当时，这个方法被称为向量空间模型（Vector Space Model，VSM）。VSM 主要基于两个假说：词袋假说（Bag of Words Hypothesis）和分布假说（Distributional Hypothesis）。前者是说，一篇文档的词频（而不是词序）代表了文档的主题；后者是说，上下文环境相似的两个词有着相近的语义。      NNLM模型仍然存在一系列问题：  由于NNLM模型使用的是全连接神经网络，因此只能处理定长的序列；  由于其巨大的参数空间，将NNLM的训练太慢了。即便是在百万量级的数据集上，即便是借助了40个CPU进行训练，NNLM也需要耗时数周才能给出一个稍微靠谱的解来。显然，对于现在动辄上千万甚至上亿的真实语料库，训练一个NNLM模型几乎是一个impossible mission。针对第一个问题，Mikolov 在 2010 年提出了 RNNLM，其结构实际上是用 RNN 代替 NNLM 里的隐层，这样做的好处包括减少模型参数、提高训练速度、接受任意长度输入、利用完整的历史信息。同时，RNN的引入意味着可以使用 RNN 的其他变体，像 LSTM、BiLSTM、GRU 等等，从而在时间序列建模上进行更多更丰富的优化。2.2. 词向量模型针对 NNLM 的第二个问题，因此其经历了将近 10 年的左右才转变为我们所熟知的 word2vec。Mikolov 注意到，原始的NNLM模型的训练其实可以拆分成两个步骤：用一个简单模型训练出连续的词向量；基于词向量的表达，训练一个连续的Ngram神经网络模型。而NNLM模型的计算瓶颈主要是在第二步。如果我们只是想得到word的词向量，是不是可以对第二步里的神经网络模型进行简化呢？就这样，他在 2013 年一口气推出了两篇 paper，并开源了一款计算词向量的工具 —— 至此，word2vec 横空出世，主角闪亮登场。词向量模型要做的事情是：学习一个从高维稀疏离散向量到低维稠密连续向量的映射。该映射的特点是，近义词向量的欧氏距离比较小，词向量之间的加减法有实际物理意义。word2vec 包含两个模型      如果是用一个词语作为输入，来预测它周围的上下文，那这个模型叫做『Skip-gram 模型』        如果是拿一个词语的上下文作为输入，来预测这个词语本身，则是 『CBoW 模型（Continues Bag-of-Words Model）』  2.2.1. CBoW在两个模型中，CBoW 与之前的 NNLM 更为相似，简单概括其思路就是：输入中间词前后共 $C$个词，预测中间词，在这个过程中训练出我们需要的词向量矩阵。其模型结构如下图所示下面讲解一下该模型结构：  图中 $[x_{1k},…,x_{Ck}]$ 表示第 $k$ 个中心词的前后 $C$ 个上下文的 one-hot 向量  将 one-hot 向量输入存放词向量的矩阵 $W_{V\\times N}$进行查表，$V$ 为词表的大小，$N$ 为词向量的维度  将查表得到的上下文向量直接进行求和，再通过一个 $N\\times V$ 的矩阵映射到输出层可以看出，CBoW 与 NNLM 的主要不同为  移除了 NNLM 中的隐层结构（tanh）；  直接将 embedding layer 的查表结果累加求和（NNLM 是拼接）  将下文单词纳入上下文环境，真正考虑了 context（NNLM的输入严格来说为上文文本）2.2.2. Skip-gramCBoW 模型依然是从 context 对 target word 的预测中学习到词向量的表达。反过来，我们能否从 target word 对context 的预测中学习到 word vector 呢？答案显然是可以的：这便是 Skip-gram 模型。其模型结构与 CBoW 模型大同小异，也包括输入层、隐层（其实是多余的，加上该层以便与与 CBoW 模型对比）和输出层经过神经网络隐层的计算，输入词会从一个 $1\\times V$ 的 one-hot 向量变成 $1\\times N$ 的向量，再被输入到输出层。输出层是一个 softmax 回归分类器，它的每个结点将会输出一个 0 ~ 1 之间的值（概率），这些所有输出层神经元结点的概率之和为 1 。Skip-gram 模型的本质是计算输入词的 input vector 与目标词的 output vector 之间的余弦相似度，并进行 softmax 归一化。我们要学习的模型参数正是这两类词向量。2.2.3. 两个提速手段然而，每当计算一个词的概率都要对词典里的 $V$ 个词计算相似度，然后进行归一化，这基本上时不现实的。为此，Mikolov 引入了两个提速手段：  层次 Softmax（Hierarchical Softmax）  负采样（Negative Sampling）普遍认为 Hierarchical Softmax 对低频词效果较好；Negative Sampling对高频词效果较好，向量维度较低时效果更好。Hierarchical Softmax 是 word2vec 中的一项关键技术，简单来说，其通过构造一个 Huffman 树，将复杂的归一化概率问题转化为一系列二分类的条件概率相乘的形式。Huffman 编码又称为最优二叉树，表示一种带权路径长度最短的二叉树。带权路径长度，指的就是叶子结点的权值乘以该结点到根结点的路径长度。而我们需要构造的Huffman树结构，是以词表为根结点，每一个子节点为父节点的不相交子集，词为叶节点的结构。我们将叶节点的权值转化为词频，则带权路径长度指的就是词频乘以路径的大小，带权路径最小的条件使得构造出来的霍夫曼树中，高频词离根结点更近，而低频词离根结点更远。其构造的Huffman树如下所示：在构建Huffman树的同时，会为每一个非叶子节点初始化一个向量，该向量用于与预测向量求条件概率，假设我们的根结点表示原始字典D，则第二层的两个子节点表示D的两个子集D1和D2，则在给定context的条件下，目标词wt属于D1的条件概率可以转换为一个二分类的逻辑回归函数：\\[p(\\omega_t \\in D_i\\vert context) = \\frac{1}{1+e^{-U_{D_{root}} \\cdot V_{\\omega_t}}}\\]当走到一个子节点后，我们又用类似的方法再对其进行二分类，得到下一个二分类的条件概率。假设每当我们将其分为左子节点时记为0，将其分为右子节点时记为1，则可以将最后的路径的用0，1组合的二叉树编码表示，相应的似然函数为\\[p(w_t\\vert context)=p(D_1=1\\vert context)p(D_2=0\\vert D_1=1)...p(w_t\\vert D_k=1)\\]这样，我们可以通过最大化这个似然函数来求解二叉树上的参数——非每一个叶节点上的向量，用来计算游走到某一个子节点的概率。层次Softmax是一个很巧妙的模型。它通过构造一颗二叉树，将目标概率的计算复杂度从最初的 $V$ 降低到了 $log_2V$ 的量级。不过付出的代价是人为增强了词与词之间的耦合性。例如，一个词出现的条件概率的变化，会影响到其路径上所有非叶节点的概率变化，间接地对其他词出现的条件概率带来不同程度的影响。因此，构造一颗有意义的二叉树就显得十分重要。实践证明，在实际的应用中，基于 Huffman 编码的二叉树可以满足大部分应用场景的需求。Negative Sampling 算法改造的是模型的似然函数，与改造模型输出概率的 Hierarchical Softmax 算法不同。其思想来源于一种叫做噪声对比估计（Noise-Contrastive Estimation）的算法。以Skip-gram模型为例，其原始的似然函数对应着一个多项分布。在用最大似然法求解这个似然函数时，我们得到一个 cross-entropy 的损失函数：\\[J(\\theta) = -\\frac{1}{T}\\sum_{t=1}^T\\sum_{-c\\leq j\\leq c,j\\neq 0} log p(\\omega_{t+j}\\vert \\omega_t)\\]$p(\\omega_{t+j}\\vert \\omega_t)$ 是整个字典归一化了的概率。在 NCE 算法中，我们构造了这样一个问题：对于一组训练样本，我们想知道，目标词的预测，是来自于 context 的驱动，还是一个事先假定的背景噪声的驱动？显然，我们可以用一个逻辑回归的函数来回答这个问题\\[p(D=1\\vert \\omega,context)=\\frac{p(\\omega\\vert context)}{p(\\omega\\vert context)+kp_n(\\omega)}=σ(logp(\\omega\\vert context)−logkp_n(\\omega))\\]这个式子给出了一个目标词 $\\omega$ 来自于 context 驱动的概率。其中，$k$ 是一个先验参数，表明噪声的采样频率。$p(\\omega\\vert context)$ 是一个非归一化的概率分布，可以看作是 $softmax$ 归一化函数中的分子部分。$p_n(\\omega)$ 则是背景噪声的词分布，通常采用词的 unigram 分布。而 $\\sigma(\\cdot)$ 是我们熟悉的 $sigmoid$ 函数。在 Mikolov 论文中的负采样算法，是 NCE 的简化版本。简单来说，其正负采样过程具有以下两个步骤：  首先确定正样本，通过计算中心词与上下文中词的其余弦相似度，再用一个 $sigmoid$ 函数来判断\\(p(D=1\\vert \\omega_o,\\omega_i)=\\sigma(U_o\\cdot V_i)\\)  采样词典中不在中心词上下文中的词的词作为负样本，采样频率由该词在语料库中出现的频率有关，作者给出了一个经验公式\\(p(\\omega_i) = \\frac{f(\\omega_i)^{3/4}}{\\sum_{j=0}^nf(\\omega_j)^{3/4}}\\)其中，$f(\\omega_i)$ 是该词在语料库中出现的频率，一共采样 $k$ 个词。经过这样的采样后，得到一个新数据集。其中，label 标记了数据的来源（正例被标记为 1，负例被标记为 0）。在这个新的数据集上，我们仅需要从采样结果中计算归一化概率分布，从而大大简化计算过程。局限性总的来说，word2vec通过嵌入一个线性的投影矩阵（projection matrix），将原始的one-hot向量映射为一个稠密的连续向量，并通过一个语言模型的任务去学习这个向量的权重，而这个过程可以看作是无监督或称为自监督的，其词向量的训练结果与语料库是紧密相关的，因此通常不同的应用场景需要用该场景下的语料库去训练词向量才能在下游任务中获得最好的效果。这一思想后来被广泛应用于包括word2vec在内的各种NLP模型中，从此之后不单单是词向量，我们也有了句向量、文档向量，从Word Embedding走向了World Embedding的新时代。word2vec非常经典，但也有其明显的局限性，其主要在以下几个方面：  在模型训练的过程中仅仅考虑context中的局部语料，没有考虑到全局信息；  对于英文语料，对于什么是词，怎样分词并不是问题（但个词就是独立的个体）。而对于中文而言，我们在训练词向量之前首先要解决分词的问题，而分词的效果在很多情况下将会严重影响词向量的质量（如分词粒度等），因此，从某些方面来说word2vec对中文不是那么的友好；  在 2018 年以前，对于word2vec及其一系列其他的词向量模型都有一个相同的特点：其embedding矩阵在训练完成后便已经是固定了的，这样我们可以轻易从网上获取到大量预训练好的词向量并快速应用到我们自己任务中。但从另一个角度来说，对于同一个词，在任意一个句子，任意一个环境下的词向量都是固定的，这对于一些歧义词来说是存在较大问题的，这也是限制类似word2vec、Glove等词向量工具性能的一个很重要的问题。2.2.4. 后续发展传统意义上来讲，词向量模型是一个工具，可以把真实世界抽象存在的文字转换成可以进行数学公式操作的向量，而对这些向量的操作，才是 NLP 真正要做的任务。因而某种意义上，NLP 任务分成两部分，预训练产生词向量，对词向量操作（下游具体NLP任务）。从 word2vec 到 ELMo 到 BERT，做的其实主要是把下游具体 NLP 任务的活逐渐移到预训练产生词向量上。下面是一个大体概括，具体解释后面会写到。。  word2vec $\\rightarrow$ ELMo：结果：上下文无关的 static 向量变成上下文相关的 dynamic 向量，比如苹果在不同语境 vector 不同。操作：encoder 操作转移到预训练产生词向量过程实现。  ELMo $\\rightarrow$ BERT：结果：训练出的 word-level 向量变成 sentence-level 的向量，下游具体 NLP 任务调用更方便，修正了 ELMo 模型的潜在问题。操作：使用句子级负采样获得句子表示/句对关系，Transformer 模型代替 LSTM 提升表达和时间上的效率，masked LM 解决 “自己看到自己” 的问题。3. 总体结构BERT的网络架构使用的是《Attention is all you need》中提出的多层 Transformer 结构，其最大的特点是抛弃了传统的 RNN 和 CNN，通过 Attention 机制将任意位置的两个单词的距离转换成 1，有效的解决了 NLP 中棘手的长期依赖问题。详细可参考此处。4. 参考文献[1] 大师兄. BERT详解[1] 不会停的蜗牛. 图解什么是 Transformer[2] rumor. 【NLP】Transformer模型原理详解[3] _zhang_bei_. 自然语言处理中的Transformer和BERT[4] Amirhossein Kazemnejad. Transformer Architecture: The Positional Encoding"
  },
  
  {
    "title": "深度学习文章阅读（Transformer）",
    "url": "/posts/deep-learning-Transformer/",
    "categories": "Academic, Paper",
    "tags": "deep learning",
    "date": "2020-11-12 17:04:19 +0800",
    





    
    "snippet": "本文主要介绍 seq2seq learning 中的 Transformer 模型，由谷歌提出。建议前序阅读 Encoder-Decoder。  1. 简介  2. 总体结构  3. Encoder          3.1. input      3.2. positional encoding      3.3. multi-head attention                 ...",
    "content": "本文主要介绍 seq2seq learning 中的 Transformer 模型，由谷歌提出。建议前序阅读 Encoder-Decoder。  1. 简介  2. 总体结构  3. Encoder          3.1. input      3.2. positional encoding      3.3. multi-head attention                  3.3.1. self-attention          3.3.2. scaled dot-product attention          3.3.3. multi-head attention                    3.4. 残差连接        4. Decoder          4.1. encoder-decoder attention      4.2. masked multi-head attention      4.3. output        训练  5. 参考文献1. 简介  Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. Attention Is All You Need[J]. arXiv preprint arXiv:1706.03762v5 [cs.CL], 2017.Transformer 来自 Google 团队 2017 年的文章 《Attenion Is All You Need》（https://arxiv.org/abs/1706.03762 ），该文章的目的：减少计算量并且提高并行效率，同时不减弱最终的实验效果。Transformer 在机器翻译任务上的表现超过了 RNN、CNN，只用 encoder-decoder 和 attention 机制就能达到很好的效果，最大的优点是可以高效地并行化。自 attention 机制提出后，加入 attention 的 seq2seq 模型在各个任务上都有了提升，所以现在的 seq2seq 模型指的都是结合 RNN 和 attention 的模型。之后 google 又提出了解决 seq2seq 问题的 Transformer 模型，用全 attention 的结构代替了 LSTM，在翻译任务上取得了更好的成绩。2. 总体结构模型结构如下图所示和大多数 seq2seq 模型一样，transformer 的结构也是由 encoder 和 decoder 组成。Transformer 的 encoder 由 6 个编码器叠加组成，decoder 也由 6 个解码器组成，在结构上都是相同的，但它们不共享权重。图中左边的部分就是 Encoder，由 6 个相同的 layer 组成，layer 指的就是上图左侧的单元，最左边有个 “Nx”，这里是 $x=6$ 个。类似的，途中右边的部分就是 Decoder，同样由 6 个相同的 layer 组成。从顶层看，Transformer 就是一个 Encoder-Decoder 框架的一种实现。在编码端和解码端，分别堆叠了 6 个编码器 / 解码器。6 这个数字并没由什么特别理由，也可以换成其它数字。编码器和解码器的内部结构大同小异，都包含一个 Self-Attention 模块和一个 Feed Forward 模块，不同的是解码器部分中间还增加了一个 Encoder-Decoder Attention 模块。3. Encoder下面将目光聚焦到 Encoder，它由两个 sub-layer 组成，分别是  multi-head self-attention mechanism  fully connected feed-forward networkEncoder 的数据流通过程如下  Input 经过 embedding 后，要做 positional encoding  然后是 Multi-head attention  再经过 position-wise Feed Forward  每个子层之间有残差连接在这里，我们开始看到 Transformer 的一个关键性质，即每个位置的单词在 encoder 中都有自己的路径，self-attention 层中的这些路径之间存在依赖关系，然而在 feed-forward 层不具有那些依赖关系，这样各种路径在流过 feed-forward 层时可以并行执行。并且，这里每个单词对应的前馈神经网络（feed-forward）都是一样的。3.1. input首先使用嵌入算法将输入的 word（$x$） 转换为 embedding vector（$\\hat x$），这个转换仅在最下方第一个 Encoder 之前发生。在 NLP 任务中，假设每个单词都转化为 $d_{model}=512$ 维的向量，用下图中的 4 个框并排在一起表示。对于其它 Encoder 而言，同样是输入 512 维的向量，只不过第一个 Encoder 输入的是词嵌入向量，而其它 Encoder 输入其下方 Encoder 的输出向量。包含各个词向量的列表长度是一个超参数，一般设为训练数据集中最长句子的长度。3.2. positional encoding在数据预处理的部分，由于 Transformer 抛弃了卷积（convolution）和循环（recurrence），为了使得模型具备利用句子序列顺序的能力，必须要在词向量中插入一些相对或绝对位置信息。在RNN（LSTM，GRU）中，时间步长的概念按顺序编码，因为输入/输出流一次一个。 对于 Transformer，作者将时间编码为正弦波，作为附加的额外输入。 这样的信号被添加到输入和输出以表示时间的流逝。下面的连接详细阐述了 positional encoding 的数学原理。  Amirhossein Kazemnejad. Transformer Architecture: The Positional EncodingPositional Encoding 是一种考虑输入序列中单词顺序的方法。Encoder 为每个输入词向量添加了一个维度与词向量一致（$d_{model}=512$）的位置向量 $PE$，取值范围介于 -1 和 1 之间。这些位置向量符合一种特定模式，可以用来确定每个单词的位置，或者用来提供信息以衡量序列中不同单词之间的距离。作者提出两种 Positional Encoding 的方法  固定方法：用不同频率的 $sine$ 和 $cosine$ 函数直接计算  学习方法：学习出一份 positional embedding经过实验（Convolutional Sequence to Sequence Learning）发现两者的结果一样，所以最后选择了第一种方法。\\[\\begin{aligned}PE_{(pos,2i)} &amp;= sin(pos / 10000^{2i/d_{model}})\\\\PE_{(pos,2i+1)} &amp;= cos(pos / 10000^{2i/d_{model}})\\end{aligned}\\]其中， $pos$ 是词在句子中的位置；$i$ 是位置向量的维度。每个位置向量的分量对应一个正弦或余弦函数。  Amirhossein Kazemnejad. Transformer Architecture: The Positional Encoding  为什么会想到用正弦/余弦函数来刻画位置/顺序？假设你想用二进制表示一个数字，会如下图所示可以发现不同位之间的变化率。最低有效位（LSB）在每个数字上交替，第二低位在每两个数字上旋转，依此类推。  但是使用二进制值来编码浮点数很浪费空间，因此我们可以使用它们的连续浮动对象-正弦函数。实际上，它们等效于交替位的操作。  最终可以得到如下图所示的位置编码  为啥要同时用 $sin$ 和 $cos$ ？Amirhossein 个人认为，仅通过同时使用正弦和余弦，才可以将 $sin(x + k)$ 和 $cos(x + k)$ 表示为$sin(x)$ 和 $cos(x)$ 的线性变换。似乎不能对单个正弦或余弦执行相同的操作。下面详细分析一下位置向量的数学形式。从维度的角度来看，$i=0$ 时第一个维度由波长为 $2\\pi$ 的正余弦函数构成。依次往后，第 $i$ 个维度对应的正余弦函数的波长逐渐变长（$10000^{2i/d_{model}}$）。最终波长从 $2\\pi$ 到 $10000\\cdot 2\\pi$。作者选择正余弦函数的原因，是因为作者认为正余弦函数能够让模型轻松学习相对位置的参与，因为对于任何固定的偏移量 $k$，位置向量 $PE_{pos+k}$ 可以表示为 $PE_{pos}$ 的线性函数\\[\\begin{aligned}sin(PE_{pos+k}) &amp;= sin(PE_{pos})cos(PE_k)+cos(PE_{pos})sin(PE_k)\\\\cos(PE_{pos+k}) &amp;= cos(PE_{pos})cos(PE_k)-sin(PE_{pos})sin(PE_k)\\\\\\end{aligned}\\]这种方法相比学习而言还有一个好处，如果采用学习到的 positional embedding（个人认为，没看论文）会像词向量一样受限于词典大小。也就是只能学习到 “位置2对应的向量是 (1,1,1,2) ” 这样的表示。而用正余弦函数明显不受序列长度的限制，也就是可以应对比训练时所用到序列的更长的序列。当然，正余弦并不是位置编码的唯一方法，只是这个方法能够扩展到看不见的序列长度处，例如当我们要翻译一个句子，这个句子的长度比我们训练集中的任何一个句子都长时。将上述 positional embedding 可视化后的图如下所示（图中假设 $d_{model}=64$，$l_{sequence}=10$）最后将 encoding 后的数据与 embedding 数据求和，加入相对位置信息。数学上，将 $PE+wordvec$ 作为输入。如下图所示，假设 $wordvec$ 的维度为四个格子，那么实际的 positional encoding 过程如下所示  Amirhossein Kazemnejad. Transformer Architecture: The Positional Encoding  为什么用求和，而不是用拼接？即使是 Amirhossein 也没找出背后的理论一句，根据他的推断，因为求和比拼接节约模型参数，因此问题也转化为 “求和有什么弊端么？” Amirhossein 表示没啥弊端。3.3. multi-head attention3.3.1. self-attention例如我们要翻译：”The animal didn’t cross the street because it was too tired” 这句话。这句话中的 “it” 是指什么？它指的是 street 还是 animal？这对人类来说是一个简单的问题，但对算法来说并不简单。而 self-attention 让算法知道这里的 it 指的是 animal 。当模型在处理每个单词时，self-attention 可以帮助模型查看 input 序列中的其他位置，寻找相关的线索，来达到更好的编码效果。它的作用就是将对其他相关单词的“understanding”融入我们当前正在处理的单词中。RNN 可以通过隐层状态将其已处理的先前单词/向量的表示与正在处理的当前单词/向量相结合，而 self-attention 是 Transformer 将其他相关单词的 “理解” 融入我们当前正在处理的单词所使用的方法。下图展示了在第五个 Encoder 中（最顶层的 Encoder） 将大部分注意力放在了 “animal” 且将其表达融入了对 “it” 的编码。上图上方的八个不同颜色的方块表示不同的 attention head，后文会讲解。这里以第二个（橙色）attention head 为例展示了其注意力的分布。  这是一种双向注意（也是唯一一种双向注意力机制，这就是为什么它是BERT中使用的唯一注意力类型），其中每个单词都彼此关联。 它确实捕获了一个句子中的双上下文信息，甚至bi-LSTM也无法捕获（因为bi-LSTM将Forward AR和Backward AR的结果结合在一起，而不是在其核心生成双上下文信息。 这也是从本质上有些人认为ELMo嵌入不是真正的双向的原因）3.3.2. scaled dot-product attention首先用向量来描述如何实现 self-attention。这里采用 scaled dot-product attention 来计算 self-attention。  第一步，根据每一个输入的 word embedding （$X \\in \\mathbb R^{d_{model}}$） 生成三个向量：Query vector（$Q\\in \\mathbb R^{d_k}$）, Key vector（$K\\in \\mathbb R^{d_k}$）, Value vector（$V\\in \\mathbb R^{d_v}$）。这三个向量是由 word embedding 分别乘以三个矩阵得到的。这三个权重矩阵（$W^Q \\in \\mathbb R^{d_{model}\\times d_k},W^K \\in \\mathbb R^{d_{model}\\times d_k},W^V \\in \\mathbb R^{d_{model}\\times d_v}$）是需要在训练过程中进行训练的。注意新生成的三个向量的维度（$d_k=64$）小于 word embedding 的维度（$d_{model}=512$）。然而，它们的维度不必一定要更小，在这里是作者做出的一种架构选择，使得后面计算 multi-head attention 时在绝大多数情况下更稳定。为什么要产生这三个向量呢？因为它们是计算和考虑注意力的一种有用的抽象。继续往下阅读，看到注意力如何计算时，就会发现这些向量的作用。  查询，键和值的概念来自检索系统。例如，当您键入查询以在YouTube上搜索某些视频时，搜索引擎将针对数据库中与候选视频相关的一组键（视频标题，说明等）映射您的查询，然后向您显示最匹配的视频（值）。  第二步，计算一个得分。如果要计算第一个词的 “Thinking” 的 self-attention，我们需要在输入句子的每个单词上对这个单词打分。这个分数决定了当我们在某个位置编码一个单词时，对输入句子其他部分的关注程度（也即句子其它部分对该词的影响）。采用点乘 $Q$ 和 $K$ 的方式产生对应单词的分数，因此分数是个标量。比如如果我们考虑 “Thinking” 对第一个位置（自身）的 self-attention，那么就计算 $q_1\\cdot k_1$，考虑第二个词对 “Thinking” 的 self-attention 则计算 $q_1\\cdot k_2$。  每当需要查找两个向量（查询 $Q$ 和键 $K$）之间的相似性时，我们只需获取它们的点积即可。为了找到第一个单词的相似性输出，我们只考虑第一个单词的表示形式 $Q_i$，并将其与输入中每个单词的表示形式 $K_j$ 取点积。这样，我们就可以知道输入中每个单词相对于第一个单词的关系。      第三步，将分数除以 8 （Key vector 长度 64 的平方根，可以使得梯度计算更稳定，当然也可以用其它数字，但是默认用平方根）。注意，标准的 dot-product attention 没有这一步，作者加了这一步后因此称为 scaled dot-product attention 。        第四步，将算得的分数传入 softmax，将其归一化为和为 1 的正数。归一化后的分数代表句子中的每一个词对当前某个位置的表达量。很明显，当前位置所在的词的归一化分数肯定最高，但有时候注意与当前词相关的另一个词是有用的。    得到相似性后，采用 softmax 归一化，得到每个单词相对第一个单词的（重要性/注意力）权重。      第五步，将 value vector （$V$）与前面计算得到的归一化分数按位相乘（为求和做准备）。这里的直觉是，保留关注词的 value 值，削弱非相关词的 value 值（例如，通过将它们乘以像 0.001 这样的小数字）。    第六步，对所有加权后的 value vectors （$V$）求和，得到当前位置（图例对第一个词）的 self-attention 输出。  将权重（softmax）与相应的表示 $V$ 相乘，然后将它们加起来。因此，我们对第一个单词的最终表示 $Z_i$ 将是所有输入单词的 $V$ 的加权总和，每个输入单词均通过相对于第一个单词的相似性（重要性）加权。从数学公式的角度来看，对于某个具体位置的词，首先比较其 $Q$ 和每个位置 $i$ 的词的 $K$ 的相似度，相似度函数设为 $f$ 那么有\\[f(Q,K_i),\\ i=1,2,...\\]具体的相似度函数包括以下四种  点乘：$f(Q,K_i) = QK_i^T / \\sqrt{d_k}$  权重：$f(Q,K_i) = QWK_i^T / \\sqrt{d_k}$然后通过 $softmax$ 来计算权重\\[\\omega_i = softmax(f(Q,K_i)) = \\frac{e^{f(Q,K_i)}}{\\sum_{i=1}^m e^{f(Q,K_i)}},\\ i=1,2,...\\]在实际的实现中，此计算以矩阵形式进行，以加快处理速度。作者将整个句子的所有词序列打包成一个矩阵 $Q$，keys 和 values 类似打包成矩阵 $K, V$。与上面的向量形式类似，矩阵形式的 attention 计算结果输出为\\[Attention(Q,K,V) = \\omega_iV,\\ i=1,2,...\\]其中然后按行求 softmax，每行和为 1得到 softmax 矩阵之后可以和 $V$ 相乘，得到最终的输出 $Z$上图中 softmax 矩阵的第 1 行表示单词 1 与其他所有单词的 attention 系数，最终单词 1 的输出 $Z_1$ 等于所有单词 $i$ 的值 $V_i$ 根据 attention 系数的比例加在一起得到。最终得到的 $Z \\in \\mathbb R^{l_{seq}\\times d_v}$ 是该句子中所有单词对当前该单词的值 $V$ 的加权和编码，包含了每个单词对其的重要性（注意力）。将其与 RNN 或 LSTM 进行比较：  RNN 或者 LSTM 的隐变量只包含句子前半部分的历史信息，且时间片 $t$ 的计算依赖 $t-1$ 时刻的计算结果，这样限制了模型的并行能力；  LSTM 只能缓解而无法彻底解决长期依赖；  BiLSTM 在捕捉上下文信息时，只是简单的将前向的LSTM和后向的LSTM进行拼接，没有很好的融合上下文的信息；（即使是BiLSTM 双向模型，也只是在 loss 处做一个简单的相加，也就是说它是按顺序做推理的，没办法考虑另一个方向的数据）整个 self-attention 的计算流程图如下图所示除了 scaled dot-product attention 外，作者还提到一种计算 self-attention 的方式，即 additive attention。该方式用一个单隐层的前馈神经网络来计算适应度函数，与 scaled dot-product attention 相比具有相近的计算复杂度，但更慢且稳定性更差（因为 dot-product 可以部署为高度优化的矩阵乘法代码）。3.3.3. multi-head attentionself-attention 是单头的，单头注意力能够将注意力集中在特定的一组单词上。如果我们想拥有多个集合，每个集合对不同的单词集合给予不同的关注呢？虽然在上面的例子中，$Z$ 包含了一点点其他位置的编码，但当前位置的单词还是占主要作用。当我们想知道 “The animal didn’t cross the street because it was too tired” 中 it 的含义时，这时就需要关注到其他位置。这个机制为注意层提供了多个 “表示子空间”。除了使用参数为 $d_{model}$ 行 $d_{k}=d_{v}=d_{model}/h=64$ 列的 $Q,K,V$ 向量外，作者还增加了一个 multi-headed 机制，可以提升注意力层的性能。它使得模型可以关注不同位置。其中 $h=8$ 为多头的头数。经过 multi-headed ，我们会得到和 heads 数目一样多的 Query / Key / Value 权重矩阵组（$W_i^Q,W_i^K,W_i^V$）。论文中用了 8 个，那么每个encoder/decoder 我们都会得到 8 个集合。这些集合都是随机初始化的，经过训练之后，每个集合会将 input embeddings 投影到不同的表示子空间中。\\[\\begin{aligned}MultiHead(Q,K,V) = Concat(head_1,...,head_h)W^O\\\\where\\ head_i = Attention(QW^Q_i,KW^K_i,VW^V_i)\\end{aligned}\\]其中，$W^Q_i,W^K_i \\in \\mathbb R^{d_{model}\\times d_k}$，$W^V_i \\in \\mathbb R^{d_{model}\\times d_v}$，$W^O\\in \\mathbb R^{hd_v\\times d_{model}}$。作者使用 $h=8$ 可以降低每个头的权重矩阵维度，这样在类似于单头注意力计算代价（$d_{model}=512$）的前提下得以使用多头注意力。简单来说，就是随机初始化定义 $h=8$ 组权重矩阵，每个单词会做 8 次上面的 self-attention 的计算，这样每个单词会得到 8 个不同的加权求和 $z_i,\\ i=0,1,…,7$ 。为了和后续前馈层对接（它需要一个矩阵，每个行向量代表一个词，而不是八个矩阵），作者将得到的 8 个矩阵进行拼接，然后乘以一个附加权重矩阵 $W^O$，从而将其压缩到一个 $Z$ 矩阵。可以看到，正如上文所说，multi-head attention 通过最终的向量拼接将输出 $Z$ 重新恢复到了与输入 $X$ 相同的维度，$X,Z \\in \\mathbb R^{l_{seq}\\times d_{model}}$。最终的完整流程如下图所示将所有 8 个 attention heads 的结果放到一张图中展示，如下整个 multi-headed attention 的流程图如下图所示3.4. 残差连接实际上，对于 encoder 中的两个模块（self-attention 和 feed-forward），均包含一个残差连接。残差通过一个 Add-Normalize 层与正常输出进行计算。将 self-attention 模块后面的 add-norm 层展开来看，如下图所示  大师兄. 模型优化之Layer NormalizationBatch Normalization (BN) 并不适用于RNN等动态网络和batchsize较小的时候效果不好。Layer Normalization（LN）的提出有效的解决BN的这两个问题。LN和BN不同点是归一化的维度是互相垂直的，如图1所示。在图1中 $N$ 表示样本轴，$C$ 表示通道轴，$F$ 是每个通道的特征数量。BN 如右侧所示，它是取不同样本的同一个通道的特征做归一化；LN 则是如左侧所示，它取的是同一个样本的不同通道做归一化。  残差连接在 decoder 中同样存在。假设一个 2 层堆叠的 transformer，如下图所示4. Decoderdecoder 相比 encoder 采用的是 masked multi-head attention，多了一个 encoder-decoder attention，最后还要经过一个 linear 和 softmax 输出概率。4.1. encoder-decoder attention输入序列经过 encoder 得到输出 $Z$。同时注意到，最上层的 encoder 的输出还包括 8 组 attention 权重矩阵 $K_{encdec}$ 和 $V_{encdec}$，这些矩阵会用于每个 decoder 的 encoder-decoder attention 层，帮助解码器聚焦在输入序列中合适的位置。注意 $K,V$ 矩阵有 8 组，它们直接全部用于 encoder-decoder attention 中，因为其也是一个 multi-headed。重复这个过程，直到 decoder 完成了输出，每个时间步的输出都在下一个时间步时喂入给最底部的 decoder，同样，在这些 decoder 的输入中也加入了位置编码，来表示每个字的位置。Encoder-Decoder Attention 层的工作方式与 multiheaded self-attention 类似，只是它用下面的层创建其 Queries 矩阵，从编码器栈的输出中获取 Keys 和 Values 矩阵。4.2. masked multi-head attentionmask attention 是 decoder 的 self-attention 层使用的，也是 decoder 和 encoder 的 self-attention 层唯一不同的地方。作者为了保护 decoder 的 auto-regressive 属性，需要通过 mask 的方式来阻止 decoder 中左向的信息流。我们知道 auto-regressive 的基本思想是下一个观测值约等于前 m 个观测值的某种线性加权和。所以后 n 个值（这里对应上面提到的左向信息流）是没有意义的，所以作者通过 mask 的方式，将后 n 个值，也就是 decoder 中self-attention 层的 scaled dot-product 阶段的当前处理词的后面位置的词的 scaled dot-product 结果都设置成负无穷。encoder: You are a great man!decoder:         你 □ □ □ □           你是 □ □ □         你是个 □ □         你是个牛 □         你是个牛人具体而言，在解码器中 self attention 的 softmax 步骤之前，需要将未来的位置设置为 -inf 来屏蔽这些位置，这样做是为了 self attention 层只能关注输出序列中靠前的一些位置，相当于解码时不让其知道当前词之后的词。这样，-inf 经过 softmax 之后就会被置为 0，从而保证仅当前词及前面的词向量的概率和为 1。注意下图中 【Mask(opt.)】环节。4.3. output解码器最后输出的是一个向量，如何把它变成一个单词，这就要靠它后面的线性层和 softmax 层。线性层就是一个很简单的全连接神经网络，将解码器输出的向量映射成一个更长的向量。例如我们有 10,000 个无重复的单词，那么最后输出的向量就有一万维，每个位置上的值代表了相应单词的分数。softmax 层将这个分数转换为了概率，我们选择概率最大的所对应的单词，就是当前时间步的输出。训练我们用一个简单的例子来示范训练，输入是 “je suis étudiant”，期望输出是 “i am a student”。在这个例子下，我们期望模型输出连续的概率分布满足如下条件：  每个概率分布都与词表同维度。  第一个概率分布对 “i” 具有最高的预测概率值。  第二个概率分布对 “am” 具有最高的预测概率值。  一直到第五个输出指向 “EOS” 标记。但是由于模型未训练是随机初始化的，不太可能就是期望的输出。如何对比两个概率分布呢？简单采用 cross-entropy或者 Kullback-Leibler divergence 中的一种。在足够大的训练集上训练足够时间之后，我们期望产生的概率分布如下所示：现在，因为模型每步只产生一组输出，假设模型选择最高概率，扔掉其他的部分，这是种产生预测结果的方法，叫做greedy 解码。另外一种方法是beam search，每一步仅保留最头部高概率的两个输出，根据这俩输出再预测下一步，再保留头部高概率的两个输出，重复直到预测结束。top_beams是超参可试验调整。5. 参考文献[1] Jay Alammar. The Illustrated Transformer[1] 不会停的蜗牛. 图解什么是 Transformer[2] rumor. 【NLP】Transformer模型原理详解[3] _zhang_bei_. 自然语言处理中的Transformer和BERT[4] Amirhossein Kazemnejad. Transformer Architecture: The Positional Encoding"
  },
  
  {
    "title": "科研Tips（数学符号）",
    "url": "/posts/research-tips-math-symbols/",
    "categories": "Tutorial, Writing",
    "tags": "other",
    "date": "2020-11-09 10:01:19 +0800",
    





    
    "snippet": "本文列举了常用数学符号以供平时查询，包括希腊字母、二元关系符、二元运算符。  1. 帽子和鞋子  2. 空格  3. 希腊字母  4. 二元关系符  5. 二元运算符  6. 大尺寸运算符  7. 箭头  8. 其它符号      9. 矩阵  1. 帽子和鞋子            命令      效果                  \\hat{A}      $\\hat{A}$    ...",
    "content": "本文列举了常用数学符号以供平时查询，包括希腊字母、二元关系符、二元运算符。  1. 帽子和鞋子  2. 空格  3. 希腊字母  4. 二元关系符  5. 二元运算符  6. 大尺寸运算符  7. 箭头  8. 其它符号      9. 矩阵  1. 帽子和鞋子            命令      效果                  \\hat{A}      $\\hat{A}$              \\widehat{A}      $\\widehat{A}$              \\tilde{A}      $\\tilde{A}$              \\widetilde{A}      $\\widetilde{A}$              \\overline{A}      $\\overline{A}$              \\underline{A}      $\\underline{A}$              \\overbrace{A-B}^{hat}      $\\overbrace{A-B}^{hat}$              \\underbrace{A-B}_{foot}      $\\underbrace{A-B}_{foot}$              \\sum_{i=1}      $ \\sum_{i=1} $              \\sum\\limits_{i=1}      $ \\sum\\limits_{i=1} $              \\mathop{max}_z      $ \\mathop{max}_z$              \\mathop{max}\\limits_z      $ \\mathop{max}\\limits_z$              \\mathop{\\rm max}\\limits_z      $\\mathop{\\rm max}\\limits_z$      2. 空格            命令      效果      解释                  a \\qquad bmmb      $a \\qquad bmmb$      间隔两个 $m$ 的宽度              a \\quad bmmb      $a \\quad bmb$      间隔一个 $m$ 的宽度              a \\ bmb      $a \\ bmb$      间隔 1/3 个 $m$ 的宽度              a \\; bmb      $a \\; bmb$      间隔 2/7 个 $m$ 的宽度              a \\, bmb      $a \\, bmb$      间隔 1/6 个 $m$ 的宽度              abmb      $abmb$      没有间隔              a\\!bmb      $a!bmb$      缩进 1/6 个 $m$ 的宽度（浏览器可能渲染异常）      3. 希腊字母            大写命令      大写      小写命令      小写                  \\Alpha      $\\Alpha$      \\alpha      $\\alpha$              \\Beta      $\\Beta$      \\beta      $\\beta$              \\Gamma      $\\Gamma$      \\gamma      $\\gamma$              \\Delta      $\\Delta$      \\delta      $\\delta$              \\Epsilon      $\\Epsilon$      \\epsilon,\\varepsilon      $\\epsilon,\\varepsilon$              \\Zeta      $\\Zeta$      \\zeta      $\\zeta$              \\Eta      $\\Eta$      \\eta      $\\eta$              \\Theta      $\\Theta$      \\theta      $\\theta$              \\Iota      $\\Iota$      \\iota      $\\iota$              \\Kappa      $\\Kappa$      \\kappa      $\\kappa$              \\Lambda      $\\Lambda$      \\lambda      $\\lambda$              \\Mu      $\\Mu$      \\mu      $\\mu$              \\Xi      $\\Xi$      \\xi      $\\xi$              \\Rho      $\\Rho$      \\rho,\\varrho      $\\rho,\\varrho$              \\Sigma      $\\Sigma$      \\sigma      $\\sigma$              \\Tau      $\\Tau$      \\tau      $\\tau$              \\Upsilon      $\\Upsilon$      \\upsilon      $\\upsilon$              \\Phi      $\\Phi$      \\phi,\\varphi      $\\phi,\\varphi$              \\Chi      $\\Chi$      \\chi      $\\chi$              \\Psi      $\\Psi$      \\psi      $\\psi$              \\Omega      $\\Omega$      \\omega      $\\omega$      4. 二元关系符            命令      符号             命令      符号             命令      符号                  \\leq, \\le      $\\leq$             \\geq, \\ge      $\\geq$             \\equiv      $\\equiv$              \\ll      $\\ll$             \\gg      $\\gg$             \\doteq      $\\doteq$              \\prec      $\\prec$             \\succ      $\\succ$             \\sim      $\\sim$              \\preceq      $\\preceq$             \\succeq      $\\succeq$             \\simeq      $\\simeq$              \\subset      $\\subset$             \\supset      $\\supset$             \\approx      $\\approx$              \\subseteq      $\\subseteq$             \\supseteq      $\\supseteq$             \\cong      $\\cong$              \\in      $\\in$             \\ni,\\owns      $\\ni$             \\propto      $\\propto$              \\vdash      $\\vdash$             \\dashv      $\\dashv$             \\models      $\\models$              \\mid      $\\mid$             \\parallel      $\\parallel$             \\perp      $\\perp$              \\smile      $\\smile$             \\frown      $\\frown$             \\asymp      $\\asymp$              :      $:$             \\notin      $\\notin$             \\neq,\\ne      $\\neq$      注意，有 3 个比较特殊的关系符，在使用时需要添加 latexsym 宏包：            命令      符号             命令      符号             命令      符号                  \\sqsubseteq      $\\sqsubseteq$             \\sqsupseteq      $\\sqsupseteq$             \\bowtie      $\\bowtie$      5. 二元运算符            命令      符号             命令      符号             命令      符号                  \\pm      $\\pm$             \\mp      $\\mp$             \\triangleleft      $\\triangleleft$              \\cdot      $\\cdot$             \\div      $\\div$             \\triangleright      $\\triangleright$              \\times      $\\times$             \\setminus      $\\setminus$             \\star      $\\star$              \\cup      $\\cup$             \\cap      $\\cap$             \\ast      $\\ast$              \\sqcup      $\\sqcup$             \\sqcap      $\\sqcap$             \\circ      $\\circ$ (上标可作度$^{\\circ}$)              \\vee, \\lor      $\\vee$             \\wedge, \\land      $\\wedge$             \\bullet      $\\bullet$              \\oplus      $\\oplus$             \\ominus      $\\ominus$             \\diamond      $\\diamond$              \\odot      $\\odot$             \\oslash      $\\oslash$             \\uplus      $\\uplus$              \\otimes      $\\otimes$             \\bigcirc      $\\bigcirc$             \\amalg      $\\amalg$              \\bigtriangleup      $\\bigtriangleup$             \\bigtriangledown      $\\bigtriangledown$             \\dagger      $\\dagger$              \\ddagger      $\\ddagger$             \\wr      $\\wr$                           其中，有 4 个特殊符号需要添加 latexsym 宏包：            命令      符号             命令      符号                  \\lhd      $\\lhd$             \\rhd      $\\rhd$              \\unlhd      $\\unlhd$             \\unrhd      $\\unrhd$      6. 大尺寸运算符            命令      符号             命令      符号             命令      符号                  \\sum      $\\sum$             \\bigcup      $\\bigcup$             \\bigvee      $\\bigvee$              \\prod      $\\prod$             \\bigcap      $\\bigcap$             \\bigwedge      $\\bigwedge$              \\coprod      $\\coprod$             \\bigsqcup      $\\bigsqcup$             \\biguplus      $\\biguplus$              \\bigoplus      $\\bigoplus$             \\bigotimes      $\\bigotimes$             \\bigodot      $\\bigodot$              \\int      $\\int$             \\oint      $\\oint$                           7. 箭头            命令      符号             命令      符号             命令      符号                  \\leftarrow, \\gets      $\\leftarrow$             \\longleftarrow      $\\longleftarrow$             \\uparrow      $\\uparrow$              \\rightarrow, \\to      $\\rightarrow$             \\longrightarrow      $\\longrightarrow$             \\downarrow      $\\downarrow$              \\leftrightarrow      $\\leftrightarrow$             \\longleftrightarrow      $\\longleftrightarrow$             \\updownarrow      $\\updownarrow$              \\Leftarrow      $\\Leftarrow$             \\Longleftarrow      $\\Longleftarrow$             \\Uparrow      $\\Uparrow$              \\Rightarrow      $\\Rightarrow$             \\Longrightarrow      $\\Longrightarrow$             \\Downarrow      $\\Downarrow$              \\Leftrightarrow      $\\Leftrightarrow$             \\Longleftrightarrow      $\\Longleftrightarrow$             \\Updownarrow      $\\Updownarrow$              \\mapsto      $\\mapsto$             \\longmapsto      $\\longmapsto$             \\nearrow      $\\nearrow$              \\hookleftarrow      $\\hookleftarrow$             \\hookrightarrow      $\\hookrightarrow$             \\searrow      $\\searrow$              \\leftharpoonup      $\\leftharpoonup$             \\rightharpoonup      $\\rightharpoonup$             \\swarrow      $\\swarrow$              \\leftharpoondown      $\\leftharpoondown$             \\rightharpoondown      $\\rightharpoondown$             \\nwarrow      $\\nwarrow$              \\rightleftharpoons      $\\rightleftharpoons$             \\iff      $\\iff$             \\      $\\backslash$      其中，有 1 个特殊符号需要添加 latexsym 宏包：            命令      符号                  \\leadsto      $\\leadsto$      8. 其它符号            命令      符号             命令      符号             命令      符号                  \\cdots      $\\cdots$             \\vdots      $\\vdots$             \\ddots      $\\ddots$              \\hbar      $\\hbar$             \\ell      $\\ell$             \\Re      $\\Re$              \\aleph      $\\aleph$             \\forall      $\\forall$             \\partial      $\\partial$              \\nabla      $\\nabla$             \\infty      $\\infty$             \\empty      $\\empty$              \\bot      $\\bot$             \\top      $\\top$             \\varnothing      $\\varnothing$              \\flat      $\\flat$             \\natural      $\\natural$             \\sharp      $\\sharp$              \\prime      $\\prime$             \\exists      $\\exists$             \\angle      $\\angle$      9. 矩阵无需 \\begin{aligned} 的写法：a=\\begin{matrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{matrix}a=\\begin{bmatrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{bmatrix}a=\\begin{pmatrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{pmatrix}a=\\begin{Bmatrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{Bmatrix}a=\\begin{vmatrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{vmatrix}a=\\begin{Vmatrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{Vmatrix}\\[a=\\begin{matrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{matrix},\\ a=\\begin{bmatrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{bmatrix},\\ a=\\begin{pmatrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{pmatrix},\\ a=\\begin{Bmatrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{Bmatrix},\\ a=\\begin{vmatrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{vmatrix},\\ a=\\begin{Vmatrix}1 &amp; 2 \\\\3 &amp; 4 \\\\\\end{Vmatrix}\\]方程组对齐的写法（{l}-left,{c}-center,{r}-right）：\\left\\{\\begin{array}{l}\\dot x_1(t) = x_2(t)\\\\\\dot x_2(t) = x_1(t){\\rm cos}x_2(t)-x_3(t)\\\\\\dot x_3(t) = x_1(t)x_3(t) + (1+\\varepsilon {\\rm sin}x_3(t))u(t)\\end{array}\\right.\\(\\left\\{\\begin{array}{l}\\dot x_1(t) = x_2(t)\\\\\\dot x_2(t) = x_1(t){\\rm cos}x_2(t)-x_3(t)\\\\\\dot x_3(t) = x_1(t)x_3(t) + (1+\\varepsilon {\\rm sin}x_3(t))u(t)\\end{array}\\right.\\)方程组对齐的矩阵写法（居中对齐）：\\left\\{\\begin{matrix}\\dot x_1(t) = x_2(t)\\\\\\dot x_2(t) = x_1(t){\\rm cos}x_2(t)-x_3(t)\\\\\\dot x_3(t) = x_1(t)x_3(t) + (1+\\varepsilon {\\rm sin}x_3(t))u(t)\\end{matrix}\\right.\\(\\left\\{\\begin{matrix}\\dot x_1(t) = x_2(t)\\\\\\dot x_2(t) = x_1(t){\\rm cos}x_2(t)-x_3(t)\\\\\\dot x_3(t) = x_1(t)x_3(t) + (1+\\varepsilon {\\rm sin}x_3(t))u(t)\\end{matrix}\\right.\\)"
  },
  
  {
    "title": "科研Tips（颜色码表）",
    "url": "/posts/research-tips-color-table/",
    "categories": "Tutorial, Writing",
    "tags": "other",
    "date": "2020-11-09 10:01:19 +0800",
    





    
    "snippet": "本文列举了常用颜色码表以供平时查询，包括rgb编码，16进制编码。1. 颜色码表颜色名十六进制RGBAliceBlue#F0F8FFrgb(240, 248, 255)AntiqueWhite#FAEBD7rgb(250, 235, 215)Aqua#00FFFFrgb(0, 255, 255)Aquamarine#7FFFD4rgb(127, 255, 212)Azure#F0FFFFrg...",
    "content": "本文列举了常用颜色码表以供平时查询，包括rgb编码，16进制编码。1. 颜色码表颜色名十六进制RGBAliceBlue#F0F8FFrgb(240, 248, 255)AntiqueWhite#FAEBD7rgb(250, 235, 215)Aqua#00FFFFrgb(0, 255, 255)Aquamarine#7FFFD4rgb(127, 255, 212)Azure#F0FFFFrgb(240, 255, 255)Beige#F5F5DCrgb(245, 245, 220)Bisque#FFE4C4rgb(255, 228, 196)Black#000000rgb(0, 0, 0)BlanchedAlmond#FFEBCDrgb(255, 235, 205)Blue#0000FFrgb(0, 0, 255)BlueViolet#8A2BE2rgb(138, 43, 226)Brown#A52A2Argb(165, 42, 42)BurlyWood#DEB887rgb(222, 184, 135)CadetBlue#5F9EA0rgb(95, 158, 160)Chartreuse#7FFF00rgb(127, 255, 0)Chocolate#D2691Ergb(210, 105, 30)Coral#FF7F50rgb(255, 127, 80)CornflowerBlue#6495EDrgb(100, 149, 237)Cornsilk#FFF8DCrgb(255, 248, 220)Crimson#DC143Crgb(220, 20, 60)Cyan#00FFFFrgb(0, 255, 255)DarkBlue#00008Brgb(0, 0, 139)DarkCyan#008B8Brgb(0, 139, 139)DarkGoldenRod#B8860Brgb(184, 134, 11)DarkGray#A9A9A9rgb(169, 169, 169)DarkGreen#006400rgb(0, 100, 0)DarkKhaki#BDB76Brgb(189, 183, 107)DarkMagenta#8B008Brgb(139, 0, 139)DarkOliveGreen#556B2Frgb(85, 107, 47)Darkorange#FF8C00rgb(255, 140, 0)DarkOrchid#9932CCrgb(153, 50, 204)DarkRed#8B0000rgb(139, 0, 0)DarkSalmon#E9967Argb(233, 150, 122)DarkSeaGreen#8FBC8Frgb(143, 188, 143)DarkSlateBlue#483D8Brgb(72, 61, 139)DarkSlateGray#2F4F4Frgb(47, 79, 79)DarkTurquoise#00CED1rgb(0, 206, 209)DarkViolet#9400D3rgb(148, 0, 211)DeepPink#FF1493rgb(255, 20, 147)DeepSkyBlue#00BFFFrgb(0, 191, 255)DimGray#696969rgb(105, 105, 105)DodgerBlue#1E90FFrgb(30, 144, 255)Feldspar#D19275rgb(209, 146, 117)FireBrick#B22222rgb(178, 34, 34)FloralWhite#FFFAF0rgb(255, 250, 240)ForestGreen#228B22rgb(34, 139, 34)Fuchsia#FF00FFrgb(255, 0, 255)Gainsboro#DCDCDCrgb(220, 220, 220)GhostWhite#F8F8FFrgb(248, 248, 255)Gold#FFD700rgb(255, 215, 0)GoldenRod#DAA520rgb(218, 165, 32)Gray#808080rgb(128, 128, 128)Green#008000rgb(0, 128, 0)GreenYellow#ADFF2Frgb(173, 255, 47)HoneyDew#F0FFF0rgb(240, 255, 240)HotPink#FF69B4rgb(255, 105, 180)IndianRed#CD5C5Crgb(205, 92, 92)Indigo#4B0082rgb(75, 0, 130)Ivory#FFFFF0rgb(255, 255, 240)Khaki#F0E68Crgb(240, 230, 140)Lavender#E6E6FArgb(230, 230, 250)LavenderBlush#FFF0F5rgb(255, 240, 245)LawnGreen#7CFC00rgb(124, 252, 0)LemonChiffon#FFFACDrgb(255, 250, 205)LightBlue#ADD8E6rgb(173, 216, 230)LightCoral#F08080rgb(240, 128, 128)LightCyan#E0FFFFrgb(224, 255, 255)LightGoldenRodYellow#FAFAD2rgb(250, 250, 210)LightGrey#D3D3D3rgb(211, 211, 211)LightGreen#90EE90rgb(144, 238, 144)LightPink#FFB6C1rgb(255, 182, 193)LightSalmon#FFA07Argb(255, 160, 122)LightSeaGreen#20B2AArgb(32, 178, 170)LightSkyBlue#87CEFArgb(135, 206, 250)LightSlateBlue#8470FFrgb(132, 112, 255)LightSlateGray#778899rgb(119, 136, 153)LightSteelBlue#B0C4DErgb(176, 196, 222)LightYellow#FFFFE0rgb(255, 255, 224)Lime#00FF00rgb(0, 255, 0)LimeGreen#32CD32rgb(50, 205, 50)Linen#FAF0E6rgb(250, 240, 230)Magenta#FF00FFrgb(255, 0, 255)Maroon#800000rgb(128, 0, 0)MediumAquaMarine#66CDAArgb(102, 205, 170)MediumBlue#0000CDrgb(0, 0, 205)MediumOrchid#BA55D3rgb(186, 85, 211)MediumPurple#9370D8rgb(147, 112, 216)MediumSeaGreen#3CB371rgb(60, 179, 113)MediumSlateBlue#7B68EErgb(123, 104, 238)MediumSpringGreen#00FA9Argb(0, 250, 154)MediumTurquoise#48D1CCrgb(72, 209, 204)MediumVioletRed#C71585rgb(199, 21, 133)MidnightBlue#191970rgb(25, 25, 112)MintCream#F5FFFArgb(245, 255, 250)MistyRose#FFE4E1rgb(255, 228, 225)Moccasin#FFE4B5rgb(255, 228, 181)NavajoWhite#FFDEADrgb(255, 222, 173)Navy#000080rgb(0, 0, 128)OldLace#FDF5E6rgb(253, 245, 230)Olive#808000rgb(128, 128, 0)OliveDrab#6B8E23rgb(107, 142, 35)Orange#FFA500rgb(255, 165, 0)OrangeRed#FF4500rgb(255, 69, 0)Orchid#DA70D6rgb(218, 112, 214)PaleGoldenRod#EEE8AArgb(238, 232, 170)PaleGreen#98FB98rgb(152, 251, 152)PaleTurquoise#AFEEEErgb(175, 238, 238)PaleVioletRed#D87093rgb(216, 112, 147)PapayaWhip#FFEFD5rgb(255, 239, 213)PeachPuff#FFDAB9rgb(255, 218, 185)Peru#CD853Frgb(205, 133, 63)Pink#FFC0CBrgb(255, 192, 203)Plum#DDA0DDrgb(221, 160, 221)PowderBlue#B0E0E6rgb(176, 224, 230)Purple#800080rgb(128, 0, 128)Red#FF0000rgb(255, 0, 0)RosyBrown#BC8F8Frgb(188, 143, 143)RoyalBlue#4169E1rgb(65, 105, 225)SaddleBrown#8B4513rgb(139, 69, 19)Salmon#FA8072rgb(250, 128, 114)SandyBrown#F4A460rgb(244, 164, 96)SeaGreen#2E8B57rgb(46, 139, 87)SeaShell#FFF5EErgb(255, 245, 238)Sienna#A0522Drgb(160, 82, 45)Silver#C0C0C0rgb(192, 192, 192)SkyBlue#87CEEBrgb(135, 206, 235)SlateBlue#6A5ACDrgb(106, 90, 205)SlateGray#708090rgb(112, 128, 144)Snow#FFFAFArgb(255, 250, 250)SpringGreen#00FF7Frgb(0, 255, 127)SteelBlue#4682B4rgb(70, 130, 180)Tan#D2B48Crgb(210, 180, 140)Teal#008080rgb(0, 128, 128)Thistle#D8BFD8rgb(216, 191, 216)Tomato#FF6347rgb(255, 99, 71)Turquoise#40E0D0rgb(64, 224, 208)Violet#EE82EErgb(238, 130, 238)VioletRed#D02090rgb(208, 32, 144)Wheat#F5DEB3rgb(245, 222, 179)White#FFFFFFrgb(255, 255, 255)WhiteSmoke#F5F5F5rgb(245, 245, 245)Yellow#FFFF00rgb(255, 255, 0)YellowGreen#9ACD32rgb(154, 205, 50)"
  },
  
  {
    "title": "深度学习文章阅读（Fuzzy-LSTM）",
    "url": "/posts/deep-learning-FLSTM/",
    "categories": "Academic, Paper",
    "tags": "fuzzy, deep learning",
    "date": "2020-11-04 15:51:19 +0800",
    





    
    "snippet": "本文介绍了 将 Fuzzy 和 LSTM 结合用于二维平面行动轨迹预测的方法，由 Mingxiao Li 于 2020 年提出，提高预测精度，有效学习周期性时空规律。  1. 引言  2. 问题描述  3. 方法          3.1. 模糊轨迹生成                  3.1.1. 模糊空间分割          3.1.2. 模糊轨迹计算                ...",
    "content": "本文介绍了 将 Fuzzy 和 LSTM 结合用于二维平面行动轨迹预测的方法，由 Mingxiao Li 于 2020 年提出，提高预测精度，有效学习周期性时空规律。  1. 引言  2. 问题描述  3. 方法          3.1. 模糊轨迹生成                  3.1.1. 模糊空间分割          3.1.2. 模糊轨迹计算                    3.2. 模糊 LSTM      3.3. TrjPre-LSTM 建模        4. 算例研究  5. 参考文献1. 引言  Mingxiao Li, Feng Lu, Hengcai Zhang &amp; Jie Chen  Predicting future locations of moving objects with deep fuzzy-LSTM networks  TRANSPORTMETRICA A: TRANSPORT SCIENCE. 2020, VOL. 16, NO. 1, 119–136基于运动状态微分、基于频率模式挖掘、基于机器学习，三种运动位置预测方法。基于机器学习的方法已经称为主流。目前的轨迹预测存在两个局限性：  考虑存储容量的制约，大量运动位置信息很难存储，一般将数字地图划分为网格或者类。这样，时序位置轨迹就可以转变为一系列时序网格编号。这样做的弊端在于，严格的边界约束可能会导致原本两个十分相近的轨迹因为归属的网格不同而完全不同。如图所示  城市居民的运行轨迹存在强烈的周期性特征，比如人们在连续工作日早高峰的晨跑轨迹可能每天都很类似。作者发现绝大多数轨迹预测模型只关注最近的运动模式，基本都用最近的历史轨迹来做预测，忽略了周期性运动模式。为了解决上述问题，作者提出了一个新型预测模型，基于深度模糊 LSTM 模型（TrjPre-FLSTM）。贡献点如下  引入模糊空间分割方法，产证模糊轨迹，解决严格边界约束。大幅度提高轨迹预测的精度和可靠性。  提出了一种改进的 LSTM 细胞结构：fuzzy-LSTM，能够很好的适应模糊空间划分，有效学习长时间的历史轨迹中的时空模式。  考虑到人运动的连续性和周期性特点，作者提出的模型在预测轨迹时同时考虑了时间相近和周期运动模式，提高了预测精度。  用真实连续的运动交流信号数据库，与最新方法 NLPMM 和 naive LSTM 进行比较，具备优势。2. 问题描述轨迹被表示为位置的时间序列\\[Traj = (p_1,t_1),(p_2,t_2),...,(p_n,t_n)\\]其中 $t_i$ 时时间，$p_i$ 时经纬度信息 $(x_i, y_i)$。将空间划分为若干单元后，轨迹可被表示为\\[G_{Traj} = (s_1,t_1),(s_2,t_2),...,(s_n,t_n)\\]其中，$s_i$ 是位置 $p_i$ 所在的网格单元的编号。相应的，轨迹预测问题可以转化为序列生成任务，目标是根据已有的知识，计算出下一个最可能的单元。3. 方法采用 TrjPre LSTM 的预测过程如下图所示。3.1. 模糊轨迹生成3.1.1. 模糊空间分割首先介绍模糊轨迹（fuzzy trajectory）。根据模糊集理论和前人研究，作者将传统的网格细胞划分为精确区域（crisp zone）和中间区域（intermediate zone），如下图所示。当位置坐标 $p_i$ 位于精确区域中时，该坐标即属于该区域所在的网格。中间区域相当于一个模糊区域，当位置坐标位于该区域时，它属于最近的四个网格。假设网格方块的边长为 $l$，精确区域半径为 $r$，有 $l &gt; r$。位置坐标 $p_i$ 距离网格中心 $s_j$ 的距离为 $x_{ij}$\\[x_{ij} = \\vert p_i - s_j \\vert \\in [0,\\sqrt 2 l]\\]$x_{ij}=0$ 表示位置坐标位于网格 $j$ 中心，$x_{ij}$ 的取值上界可借助下图阐释。图中，红色的位置坐标属于四个相邻网格内，而绿色的坐标位置已经不属于图中所示的四个相邻网格了。可以看出，位置坐标距离网格中心最远不超过 $\\sqrt 2 \\cdot l$，即图中粉色方形的对角点距离。设计基于距离的隶属度函数如下\\[\\begin{aligned}M_{i,j}^{temp} = \\left\\{\\begin{matrix}&amp;1\\quad &amp;d \\leq r\\\\ &amp;e^{-(x_{ij}-r)} \\quad &amp; d &gt; r\\end{matrix}\\right.\\end{aligned}\\]\\[M_{i,j} = \\frac{M_{i,j}^{temp}}{\\sum_{j}M_{i,j}^{temp}}\\]其中 $M_{i,j}^{temp}$ 是临时隶属度函数，$M_{i,j}$ 是最终的隶属度函数，第二个式子进行了一个归一化操作。需要提醒的是，作者假定如果坐标落在了精确区域，那么其只属于该区域中心且隶属度为 1，而不再进行归一化操作。换句话说，只有落在中间区域的位置坐标才需要进行上述隶属度函数计算。这个在后面的算法伪代码中可以看出来。借助模糊集的概念来定义模糊轨迹位置：$F_Loc_{p_i} =N_Loc_{p_i},M_Loc_{p_i}$。其中 $N_Loc_{p_i}$ 是位置坐标的临近网格集合，$M_Loc_{p_i}$ 是相应的隶属度。那么对于前面图中的位置坐标点 $p_1,p_2$，其模糊轨迹位置为\\[\\begin{aligned}F\\_Loc_{p_1} &amp;= (s_3), (1)\\\\F\\_Loc_{p_2} &amp;= (s_1, s_2, s_3, s_4), (0.2,0.25, 0.25, 0.3)\\end{aligned}\\]进行模糊区域划分和求解模糊轨迹位置的算法伪代码如下所示&lt;font color=#FF0000&gt;很奇怪的是，作者原文的伪代码中，当位置坐标处于中间区域时（也就是代码中的 ELSE 部分），并没有给出如何计算 $N_Loc_{p_i}$ 的。&lt;/font&gt;注意！$r$ 的选取对模糊空间划分影响很大。如果  选择一个较小的 $r$ 很难帮助捕捉落入中间区域的位置点，如果选择很大的 $r$ 会降低靠近网格中心的不同轨迹位置的相似度，还会增加计算代价。$r$ 的取值可以借助轨迹位置坐标的分布来标定。3.1.2. 模糊轨迹计算定义模糊轨迹为\\[F\\_Traj_i = N\\_seq_{Traji},M\\_seq_{Traji}\\]其中，$N_seq_{Traji}$ 是轨迹中每个位置坐标 $N_Loc_{p_i}$ 的笛卡尔乘积（直积），相应的 $M_seq_{Traji}$ 是坐标对应邻近网格的空间隶属度的乘积。那么对于包含 $n$ 个坐标点的轨迹 $S_{seq_m} = N_seq_{Traji}$ 是一个 $4^n$ 项序列（$n$ 个位置坐标，每个位置坐标邻近 4 个网格单元，直积）假设真实轨迹 $Traj_1 = (p_1, p_2)$，那么对应的模糊轨迹 $F_Traj_1 = ( s_3s_2,s_3s_1,s_3s_3,s_3s_4 ),( 0.25,0.3,0.2,0.25 )$。计算模糊轨迹的算法如下  首先根据算法 1 计算出每个轨迹位置的空间隶属度（line 2-5）。  然后计算邻域网格单元序列集，采用直积的形式计算（line 6）。  相应的隶属度序列通过矩阵乘法的形式计算（line 7-12）。&lt;font color=#FF0000&gt;从算法和描述上很难看懂，大概理解了下，如下图所示。&lt;/font&gt;序列 $S_{ij}$ 的第一个下标 $i$ 表示轨迹坐标点的编号，从 1 到 $n$ 。第二个下标 $j$ 表示轨迹坐标点的周围四个邻近网格单元编号，1-左下，2-右下，3-右上，4-左上 的顺序 。前面已经分析过一共有 $4^n$ 中可能的模糊轨迹序列，比如其中一个模糊轨迹序列为\\[S_{11}S_{22}S_{34}S_{43}...S_{n1} = 坐标1左下 - 坐标2右下 - 坐标3左上 - 坐标4右上...坐标n左下\\]注意到，每个坐标对于邻近四个网格单元都可以根据 算法1 计算出相应的隶属度，那么对于一个具体的模糊轨迹序列，其隶属度就是每个坐标与其某个方向邻近网格单元的隶属度的乘积。3.2. 模糊 LSTM作者对 LSTM 单元进行了改进，如下图所示。将隶属度集合 $M_seq_{Traj_i}$ 作为权重矩阵，将模糊轨迹序列作为输入。经过训练，每个位置坐标的邻近网格单元的权重都能得到更新。上面的 LSTM 单元依然包含三个门，遗忘门，输入门，输出门。LSTM 单元的状态存储着历史信息，当新轨迹输入时，遗忘门决定移除哪些信息。可以通过下面的式子表示\\[f_t = \\sigma(M\\_seq_{Traj_t}\\cdot W_f\\cdot [h_{t-1},N\\_seq_{Traj_t}]+ b_f)\\]其中，$\\sigma$ 表示 $sigmoid$ 激活函数。$f_t$ 表示遗忘门层。$N_seq_{Traj_t}$ 是当前邻近网格单元序列输入，$M_seq_{Traj_t}$ 是当前邻近网格单元序列的隶属度，$h_{t -1}$ 是上一时刻的输出，$W_f$ 是遗忘门层的权重矩阵，$b_f$ 是遗忘门层的偏差。  可以参考传统的 LSTM 单元和公式便于比对。这里将公式列写如下：\\[\\boldsymbol f_t = \\sigma(\\boldsymbol W_f\\cdot[\\boldsymbol h_{t-1}, \\boldsymbol x_t]^T + \\boldsymbol b_f)\\]下一步决定新的模糊轨迹如何存进 LSTM 单元。这要分两步进行，输入门决定什么值更新，tanh 函数产生一个新的候选向量，如下式所示\\[\\begin{aligned}i_t &amp;= \\sigma(M\\_seq_{Traj_t}\\cdot W_i\\cdot [h_{t-1},N\\_seq_{Traj_t}]+ b_i)\\\\\\tilde{C}_t &amp;= tanh(M\\_seq_{Traj_t}\\cdot W_c\\cdot [h_{t-1},N\\_seq_{Traj_t}]+ b_c)\\\\\\end{aligned}\\]  相应的传统的 LSTM 单元和公式为\\[\\begin{aligned}\\boldsymbol i_t &amp;= \\sigma(\\boldsymbol W_i\\cdot[\\boldsymbol h_{t-1}, \\boldsymbol x_t]^T + \\boldsymbol b_f)\\\\\\tilde {\\boldsymbol c_t} &amp;=\\sigma(\\boldsymbol W_c\\cdot[\\boldsymbol h_{t-1}, \\boldsymbol x_t]^T + \\boldsymbol b_f)\\end{aligned}\\]与传统 LSTM 相同，更新细胞状态 $C_t$\\[C_t = f_t \\odot c_{t-1} + i_t \\odot \\tilde {\\boldsymbol c_t}\\]最后，更新 LSTM 单元的输出\\[\\begin{aligned}o_t &amp;= \\sigma(M\\_seq_{Traj_t}\\cdot W_o\\cdot [h_{t-1},N\\_seq_{Traj_t}]+ b_o)\\\\h_t &amp;= o_t\\odot tanh(C_t)\\\\\\end{aligned}\\]$\\odot$ 为逐元素相乘（elementwise product）。3.3. TrjPre-LSTM 建模作者将整个轨迹划分为固定长度的子轨迹，然后对每条子轨迹计算隶属度。为了兼顾周期性和最近的运动模式，子轨迹们被划分成两类：一类是靠近预测点的相近轨迹，一类是其它日期相似时刻的轨迹。给定预测点 $p_t$ 和时间片段 $q$ （在文章中取为一天），靠近预测点的相近轨迹为 $seq_t^{close} = {p_{t-m},…,p_{t-2},p_{t-1}}$ 而周期性轨迹为 $seq_t^{period} = {p_{t-mq},…,p_{t-2q},p_{t-1*q}}$。如下图所示上图给出了 TrjPre-LSTM 方法的架构，主要由两部分组成，分别建模近期时间的影响和周期性影响。二者共用一个神经网络结构，二者的输出通过求和融合在一起。最后的结果通过一个 softmax 层转化为固定维度的向量（这种操作在多分类问题中被大量采用）。采用跨类交叉熵作为损失函数。4. 算例研究使用移动电话信号数据库，10 万个用户，15 天共计 150 万条轨迹。将网格划分为 $1km \\times 1 km$，精确区域半径 $r=0.45km$。在 i7-3770 @3.4GHz 和 116 GB 内存 Windows 7 的 PC 上进行实验。TrjPre-FLSTM 采用 Python 实现。给定一条轨迹 $Traj_k = p_1,p_2,…,p_n$ 和一条预测轨迹 $Traj_k’=p_1’,p_2’,…,p_n’$，预测精度定义如下\\[\\begin{aligned}H_{(p_i,p_i')}=\\left\\{\\begin{matrix}1&amp;\\quad if \\vert p_i-p_i' \\vert \\leq \\gamma \\\\ 0&amp;\\quad else\\end{matrix}\\right.\\\\Acc = \\frac{\\sum_{i=1}^m H_{(p_i,p_i')}}{\\vert Traj' \\vert}\\end{aligned}\\]其中，$\\vert p_i-p_i’ \\vert$ 是真实坐标点 $p_i$ 和预测坐标点 $p_i’$ 的欧式距离，$\\gamma$ 是距离门限，$\\vert Traj’ \\vert$ 是预测轨迹的长度。给定多条轨迹的预测结果 $Results = Acc_1, Acc_2,…,Acc_m$，预测精度的标准差定义为\\[Stdev=\\sqrt{\\frac{\\sum_{(i=1)}^m(Acc_i-\\bar{Acc})^2}{m-1}}\\]其中 $\\bar{Acc}$ 是预测精度的平均值。由于网格边长 $1km$，我们定义 $\\gamma = 1km$。5. 参考文献无。"
  },
  
  {
    "title": "日常tips手册（Rime输入法）",
    "url": "/posts/rime-shift-switch-zh-en/",
    "categories": "Diary",
    "tags": "other",
    "date": "2020-10-30 22:06:49 +0800",
    





    
    "snippet": "本文记录个人科研生活中的各种小tips和遇到的问题及其解决方案，留作提醒查阅。  1. 下载安装  2. 方案配置  3. 基础配置  4. 皮肤设置  5. 一些额外的自定义配置          5.1. 更改切换输入方案快捷键      5.2. 更换输入方案      5.3. 中英文shift切换和英文直接上屏      5.4. 希腊/数学/特殊符号快速输入        6. ...",
    "content": "本文记录个人科研生活中的各种小tips和遇到的问题及其解决方案，留作提醒查阅。  1. 下载安装  2. 方案配置  3. 基础配置  4. 皮肤设置  5. 一些额外的自定义配置          5.1. 更改切换输入方案快捷键      5.2. 更换输入方案      5.3. 中英文shift切换和英文直接上屏      5.4. 希腊/数学/特殊符号快速输入        6. 参考文献1. 下载安装Rime Imput Method Engine 中州韵输入法引擎 是一个跨平台的输入法算法框架。前往官网下载安装即可。安装时注意可以指定用户文件夹，建议自行指定一个，不用默认路径，方便之后对输入法进行自定义。具体可参考 此处。2. 方案配置安装完 Rime 后，一般会自动弹出【方案选单设定】界面，提示勾选所需的输入方案。一般默认勾选【朙月拼音】等等。  用户可以取消勾选用不到的，比如繁体、注音等。  用户也可以选择字典词库维护更好的【雾凇拼音】（强烈推荐，且可以保持长期更新字典字库，具体参考 此章节）。3. 基础配置  XNOM. 30分钟搞定 自由输入法RIME简明配置指南Rime 的各种配置，均是由 .yaml 文件所定义。yaml 是一种标记语言。.yaml 文件实际上是文本文档。可使用记事本、或 Emeditor 等进行编辑。对 Rime 进行自定义，是通过对 .custom.yaml 文件修改达成。不同的 .custom.yaml 文件，控制不同的功能实现。.custom.yaml 实际上是相当于对 .yaml 文件打补丁，在重新部署后，会将 .custom.yaml 中的内容写入 .yaml 文件中，完成自定。  例一：weasel.yaml 是常规设置，主要控制托盘图标、候选词横竖排列、界面配色等等功能。那么，我们需要定制界面配色，只需在 weasel.custom.yaml 中修改，重新部署后就可实现。  例二：default.yaml 是默认设置，主要控制快捷键、按键上屏等等。同样，作修改就编辑 default.custom.yaml 文件即可。  例三：以上是全局设置，亦即不论使用何种输入方案，均起作用。double_pinyin_flypy.custom.yaml 这种则是输入法方案设置。主要实现特殊标点符号、词库等功能。是针对特定输入方案的配置。可见，我们绝大部分的自定，都只需修改对应的 .custom.yaml 文件即可。  [!IMPORTANT]  所有自定修改，都必须 重新部署。在开始菜单可以找到【小狼毫】重新部署。4. 皮肤设置  XNOM. 30分钟搞定 自由输入法RIME简明配置指南打开 weasel.custom.yaml 文件，若没有，则新建。所有自定义项均在 patch: 下，注意缩进customization:  distribution_code_name: Weasel  distribution_version: 0.14.3  generator: \"Weasel::UIStyleSettings\"  modified_time: \"Mon Jul 13 11:31:05 2020\"  rime_version: 1.5.3patch:  style/color_scheme: google # 皮肤风格  style/layout/border_width: 0  style/layout/border: 0  style/horizontal: true #横排显示候选词  style/font_face: Microsoft YaHei # 候选词字体  style/font_point: 12 # 候选词字号一个模仿 Windows 10 自带的微软拼音皮肤的设置如下，以供修改尝试参考：customization:  distribution_code_name: Weasel  distribution_version: 0.14.3  generator: \"Weasel::UIStyleSettings\"  modified_time: \"Thu Jun 27 17:32:21 2019\"  rime_version: 1.5.3patch:  style/display_tray_icon: true  style/horizontal: true #横排显示  style/font_face: \"Microsoft YaHei\" #字体  style/font_point: 13 #字体大小  style/inline_preedit: true # 嵌入式候选窗单行显示  style/layout/border_width: 0  style/layout/border: 0  style/layout/margin_x: 12 #候选字左右边距  style/layout/margin_y: 12 #候选字上下边距  style/layout/hilite_padding: 12 #候选字背景色色块高度 若想候选字背景色块无边界填充候选框，仅需其高度和候选字上下边距一致即可  style/layout/hilite_spacing: 3 # 序号和候选字之间的间隔  style/layout/spacing: 10 #作用不明  style/layout/candidate_spacing: 24 # 候选字间隔  style/layout/round_corner: 0 #候选字背景色块圆角幅度  style/color_scheme: Micosoft  preset_color_schemes/Micosoft:    name: \"Micosoft\"    author: \"XNOM\"    back_color: 0xffffff #候选框 背景色    border_color: 0xD77800 #候选框 边框颜色    text_color: 0x000000 #已选择字 文字颜色    hilited_text_color: 0x000000 #已选择字右侧拼音 文字颜色    hilited_back_color: 0xffffff #已选择字右侧拼音 背景色    hilited_candidate_text_color: 0xffffff #候选字颜色    hilited_candidate_back_color: 0xD77800 #候选字背景色    candidate_text_color: 0x000000 #未候选字颜色5. 一些额外的自定义配置5.1. 更改切换输入方案快捷键默认的输入方案切换快捷键为 Ctrl+~ 或者 F4，由于 F4 也是很多常用应用的快捷键（比如 Word 中 F4 用来重复上次操作），因此我们可将该快捷键更改。  右键输入法白色图标，打开 “用户资料文件夹”  打开 default.custom.yaml（如果没有该文件，但有 weasel.custom.yaml，则复制一份，复制后的文件重命名为 default.custom.yaml；如果没有，则自己新建文件命名为 default.custom.yaml）  将文件内容最后的补丁部分修改如下（以Ctrl+F4为例）：    customization:  distribution_code_name: Weasel  distribution_version: x.xx.x  generator: \"Rime::SwitcherSettings\"  modified_time: \"xxxx\"  rime_version: x.xx.xpatch:  switcher/hotkeys:    - Control+F4 # 表示将切换输入方案快捷键更改为 Ctrl+F4        最后右键输入法白色图标，选择 重新部署，即可。5.2. 更换输入方案以更换为【雾凇拼音】为例，雾凇拼音的github地址：https://github.com/iDvel/rime-ice。  前往 雾凇拼音官方 github 仓库，将仓库打包下载，或者整体克隆到本地  右键输入法白色图标，打开 用户文件夹，将压缩包内所有文件复制粘贴到用户文件夹  右键输入法白色图标，选择 重新部署  使用切换输入方案快捷键（默认为 Ctrl+~ 或者 F4），选择【雾凇拼音】即可如果要更改切换输入方案快捷键，请参考 此章节。5.3. 中英文shift切换和英文直接上屏  Xeon-Shao. 小狼毫（Rime）输入法设置Shift直接上屏英文字符并切换为英文状态方法小狼毫默认输入方式下，左Shift键只切换为英文，右Shift键直接上屏中文。这对于用惯了搜狗的人来说在进行中英文混输的时候经常出错，特别影响效率，接下来提供方法解决这个问题。  右键输入法白色图标，打开 “用户资料文件夹”  打开 default.custom.yaml（如果没有该文件，但有 weasel.custom.yaml，则复制一份，复制后的文件重命名为 default.custom.yaml；如果没有，则自己新建文件命名为 default.custom.yaml）      将文件内容最后的补丁部分修改如下：    patch:  ascii_composer/switch_key/Shift_L: commit_code # 使用左右shift键将中文输入下的英文直接上屏并切换至英文输入状态        或（右shift也需要的话）    patch:  ascii_composer:    switch_key: {Shift_L: commit_code, Shift_R: commit_code}        或（多行显示更清晰但占地方）    patch:  ascii_composer:    switch_key:      Shift_L: commit_code      Shift_R: commit_code         最后右键输入法白色图标，选择 重新部署，即可。5.4. 希腊/数学/特殊符号快速输入  百度贴吧. 小狼毫输入法怎么输入希腊字母和数学符号  首先确定使用的拼音方案，右键输入法白色图标，选择输入法设定，在弹出的界面中查看自己勾选的输入方案  打开用户文件夹，打开default.yaml文件，查看其中对应输入方案的英文名称```yamlschema_list:          schema: rime_ice # 雾凇拼音（全拼）      schema: xxx```第一行第一个表明使用的是雾凇拼音，同理其他如 luna_pinyin_simp 表明使用的是明月拼音简化字        新建对应输入方案的自定义配置文件。比如：如果使用 luna_pinyin_simp （明月拼音简化字）方案，那么新建 lunar_pinyin_simp.custom.yaml 配置文件；如果使用 rime_ice （明月拼音简化字）方案，那么新建 rime_ice.custom.yaml 配置文件；  打开新建的配置文件，写入：    patch:  punctuator/import_preset : symbols  recognizer/patterns/punct: \"^/([A-Z|a-z]*|[0-9]|10)$\"        最后右键输入法白色图标，选择 重新部署，即可。配置完成后，可通过 / 键配合缩写实现快速输入。注意使用键盘主区域的 ?/ 键唤起，而不是小键盘的 / 键。  输入 /xl 直接给出希腊字母，如 $\\alpha$ 等。  输入 /sx 直接给出常用数学符号，如 ±, ÷ 等。  输入 /jh 直接给出一些特殊符号，如 ■，□，▣，▥ 等。6. 参考文献无。"
  },
  
  {
    "title": "深度学习基础（概率与统计）",
    "url": "/posts/deep-learning-probability-basic/",
    "categories": "Academic, Knowledge",
    "tags": "statistics",
    "date": "2020-10-30 10:46:19 +0800",
    





    
    "snippet": "本文主要介绍概率与统计的相关知识，包括概率的基本概念，似然函数，全概率，条件概率，贝叶斯公式，信息熵等概念的介绍。  1. 基本概念          1.1. 概率定义      1.2. 随机变量      1.3. 概率分布与概率密度      1.4. 概率和统计      1.5. 概率函数与似然函数      1.6. 极大似然估计        2. 概率          2...",
    "content": "本文主要介绍概率与统计的相关知识，包括概率的基本概念，似然函数，全概率，条件概率，贝叶斯公式，信息熵等概念的介绍。  1. 基本概念          1.1. 概率定义      1.2. 随机变量      1.3. 概率分布与概率密度      1.4. 概率和统计      1.5. 概率函数与似然函数      1.6. 极大似然估计        2. 概率          2.1. 条件概率公式      2.2. 全概率公式      2.3. 概率的两大学派      2.4. 贝叶斯公式        3. 熵          3.1. 自信息      3.2. 信息熵      3.3. 相对熵（KL散度）      3.4. 交叉熵      3.5. softmax 函数        4. 参考文献1. 基本概念1.1. 概率定义条件概率：$P(A\\vert B)$ 在某条件下事件发生的概率。先验概率：指根据以往经验和分析得到的概率，如全概率公式，它往往作为”由因求果”问题中的”因”出现的概率。后验概率：已知原分布，在实际发生某事件时,是原先某情况的可能性。后验概率是信息理论的基本概念之一。后验概率是指在得到“结果”的信息后重新修正的概率，是“执果寻因”问题中的”果”。先验概率与后验概率有不可分割的联系，后验概率的计算要以先验概率为基础。事情还没有发生，要求这件事情发生的可能性的大小，是先验概率。事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小，是后验概率。后验概率是一种条件概率。一种解释认为，条件概率是个数学名称，后验概率是建模的时候赋予了一定的意义。一般的条件概率，条件和事件可以是任意的；对于后验概率，它限定了事件为隐变量取值，而条件为观测结果。联合概率：$P(AB)$，表示两个事件共同发生的概率。边缘概率：是某个事件发生的概率，而与其它事件无关。在联合概率中，把最终结果中不需要的那些事件合并成其事件的全概率而消失（对离散随机变量用求和得全概率，对连续随机变量用积分得全概率）。这称为边缘化（marginalization）。$A$ 的边缘概率表示为 $P(A)$，$B$ 的边缘概率表示为 $P(B)$。需要注意的是，在这些定义中 $A$ 与 $B$ 之间不一定有因果或者时间顺序关系。$A$ 可能会先于 $B$ 发生，也可能相反，也可能二者同时发生。$A$ 可能会导致 $B$ 的发生，也可能相反，也可能二者之间根本就没有因果关系。1.2. 随机变量产品经理马忠信. 应该如何理解概率分布函数和概率密度函数？  微积分是研究变量的数学，概率论与数理统计是研究随机变量的数学。  研究一个随机变量，不只是要看它能取哪些值，更重要的是它取各种值的概率如何。随机变量（random variable）表示随机试验各种结果的实值单值函数。随机事件不论与数量是否直接有关，都可以数量化，即都能用数量化的方式表达。随机事件数量化的好处是可以用数学分析的方法来研究随机现象。例如某一时间内公共汽车站等车乘客人数，电话交换台在一定时间内收到的呼叫次数，灯泡的寿命等等，都是随机变量的实例。按照随机变量可能取得的值，可以把它们分为两种基本类型：  离散型随机变量：随机变量的值可以逐个列举。          离散型随机变量通常依据概率质量函数分类，主要分为：伯努利随机变量、二项随机变量、几何随机变量和泊松随机变量。      离散型随机变量的期望为 $\\mathbb E[X] = \\sum_{x:p(x)&gt;0}xp(x)$。        连续型随机变量：随机变量的取值无法逐个列举。          有几个重要的连续随机变量常常出现在概率论中，如：均匀随机变量、指数随机变量、伽马随机变量和正态随机变量。      连续型随机变量的期望为 $\\mathbb E[X] = \\int_{-\\infty}^{+\\infty}xf(x)dx$（一阶矩）。「见后文推导」      1.3. 概率分布与概率密度  对于离散型随机变量，其概率可以用概率分布列表来描述。如两个离散型随机变量 $x$ 的概率分布列表可以表述为\\(\\begin{bmatrix}x\\\\ P(x)\\end{bmatrix} = \\begin{bmatrix}x_1 &amp; x_2\\\\ 0.99 &amp; 0.01\\end{bmatrix}\\)解读为：$x$ 取值为 $x_1$ 的概率 $P(x=x_1) = 0.99$，取值为 $x_2$ 的概率 $P(x=x_2) = 0.01$。概率分布函数（累积概率函数）是描述随机变量取值分布规律的数学表示。概率分布函数是随机变量特性的表征，它决定了随机变量取值的分布规律，只要已知了概率分布函数，就可以算出随机变量落于某处的概率。对于离散型随机变量，概率分布函数定义为\\[F(x) = P(x\\leq x_i)=\\sum_{x\\leq x_i} P(x_i)\\]对于连续型随机变量，设变量 $x$ 的取值区间为 $(a,b)$，其概率分布函数为\\[F(x) = P(a&lt;x&lt;b) = F(b) - F(a)\\]引入 “概率密度函数 $f(x)$” 的概念，定义为概率分布函数的导数，是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。即\\[f(x) = F'(x) = \\mathop{lim}\\limits_{\\Delta x\\rightarrow 0}\\frac{F(x+\\Delta x) - F(x)}{\\Delta x}\\]概率密度函数的性质有  $f(x) \\geq 0$  $\\int_{-\\infty}^{+\\infty} f(x)dx=1$随机变量的取值落在某个区域之内的概率则为概率密度函数在这个区域上的积分。当概率密度函数存在的时候，概率分布函数是概率密度函数的积分。对于连续型随机变量，其概率分布函数为\\[F(x) = \\int_{-\\infty}^{x_i} f(x)dx\\]那么前面连续型随机变量 $x\\in(a,b)$ 的概率分布函数为\\[F(x) = P(a&lt;x&lt;b) = F(b) - F(a) =\\int_{a}^{b} f(x)dx\\]连续型随机变量 $X$ 的期望 $\\mathbb E(X)$ 为\\[\\mathbb E(X) = \\int_{-\\infty}^{+\\infty}xf(x)dx\\]可以通过将概率密度函数划分为 $n$ 个小区间，对每个小区间求概率分布表，当小区间个数 $n \\rightarrow +\\infty$ 时，$max(\\Delta x_i)\\rightarrow 0$，借助对离散型随机变量的期望求极限，得到上述定义式。即\\[\\mathbb E(X) = \\mathop{lim}\\limits_{n\\rightarrow+\\infty}\\sum_{i=1}^n x_if(x_i)\\Delta x_i =  \\int_{-\\infty}^{+\\infty}xf(x)dx\\]1.4. 概率和统计概率（probabilty）和统计（statistics）看似两个相近的概念，其实研究的问题刚好相反。概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性（例如均值，方差，协方差等等）。 举个例子，我想研究怎么养猪（模型是猪），我选好了想养的品种、喂养方式、猪棚的设计等等（选择参数），我想知道我养出来的猪大概能有多肥，肉质怎么样（预测结果）。统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉（这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等），然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等（推测模型参数）。一句话总结：概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。统计领域有两个基本概念：极大似然估计 和 极大后验概率估计。它们都是用来推测参数的方法。为什么会存在着两种不同方法呢？ 这需要理解概率的两个学派。（很奇怪的一点在于，两个估计是属于统计领域，但是确需要理解概率的两个学派）1.5. 概率函数与似然函数似然（likelihood）这个词其实和概率（probability）是差不多的意思，Colins字典这么解释：The likelihood of something happening is how likely it is to happen. 你把likelihood换成probability，这解释也读得通。但是在统计里面，似然函数和概率函数却是两个不同的概念（其实也很相近就是了）。对于 $P(x\\vert \\theta)$，输入有2个：$x$ 表示某一具体的数据，$\\theta$ 表示模型参数。      如果 $\\theta$ 是已知的，$x$ 是变量，这个函数叫做概率函数，它描述对于不同样本点 $x$，其出现的概率是多少。        如果 $x$ 是已知的，$\\theta$ 是变量，这个函数叫做似然函数，它描述对于不同的模型参数，出现 $x$ 这个样本点的概率是多少。  大概直观的理解一下，假设某组数据 $x$ 服从正态分布，其概率密度函数为\\[f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\]  说到这里，插一个啼笑皆非的事情，在推免研究生面试时，一帮教授大佬们突然恶趣味想出这么一个面试题 “高斯分布和正态分布是什么关系？”，答案是：“它们是一个东西”。结果在面试期间，大佬们真的对好几个学生都问了这个问题。尴尬的是，只有一个学生犹犹豫豫的回复说：“它们好象是一个东西把…”  如果我们已知分布的参数 $\\theta = [\\mu,\\sigma]$ 的具体取值，那么 $P(x\\vert \\theta)$ 就是取到数据 $x$ 的概率。  如果我们不知道分布的参数，而是通过一次采样得到数据 $x$，那么 $P(x\\vert \\theta)$ 描述的就是对于不同的模型参数，出现数据 $x$ 这个样本点的概率。注意到，上面两种不同的解读与概率的两个学派紧密相联。1.6. 极大似然估计  忆臻. 一文搞懂极大似然估计拓季. 交叉熵与最大似然估计贺勇，明杰秀编著．概率论与数理统计．武汉：武汉大学出版社，2012.08：216-217极大似然估计（Maximum likelihood estimation, MLE），是建立在极大似然原理的基础上的一个统计方法。通俗理解来说，就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值。在现实世界的研究中，我们可以首先假定某些被研究对象的概率分布服从某种分布形态，例如二项分布、正态分布、指数分布，但对于相应分布中的具体参数的取值却无从知晓，此时我们可以借助从总体中抽样的方式，对总体的概率分布的参数进行一个点对点的估计。  一种直观的理解：设甲箱中有 99 个白球，1 个黑球；乙箱中有 1 个白球．99 个黑球。现随机取出一箱，再从抽取的一箱中随机取出一球。假设取出的结果是黑球，由于这一黑球从乙箱抽取的概率比从甲箱抽取的概率大得多，这时我们自然更多地相信这个黑球是取自乙箱的。极大似然估计中采样需满足一个重要的假设，就是抽样样本集 $X$ 当中的样本 $x_1,x_2,…,x_n$ 彼此独立同分布。一般说来，事件 $x_i$ 发生的概率与未知的模型参数 $\\theta$ 有关，参数 $\\theta$ 的取值不同，则事件 $x_i$ 发生的概率 $P(x_i\\vert \\theta)$ 也不同。当我们在一次试验中事件 $x_i$ 发生了，则认为此时的 $\\theta$ 值应是的一切可能取值中使 $P(x_i\\vert \\theta)$ 达到最大的那一个，极大似然估计法就是要选取这样的值作为参数 $\\theta$ 的估计值，使所选取的样本在被选的总体中出现的可能性为最大。对于样本集 $X$，由于样本之间彼此独立且服从参数为 $\\theta$ 的分布，那么取得任意一个样本 $x_i$ 的概率可以表示为 $P(x_i \\vert \\theta)$，因而取得当前这个样本集的概率为：\\[P(X) = P(x_1\\vert \\theta)P(x_2\\vert \\theta)...P(x_n\\vert \\theta)\\]由于在抽样后会得到总体的一个观测，因此相应的概率在具体的样本集中都是已知的，上面这个函数则可以看作在不同的参数 $\\theta$ 的取值下，取得当前这个样本集的概率，也即可能性（likelihood），因此将其称为参数 $\\theta$ 相对于样本集 $X$ 的似然函数（likelihood function），记为 $L(\\theta)$，即有\\[\\begin{aligned}L(\\theta) &amp; = L(x_1,x_2,...,x_n\\vert \\theta)\\\\&amp;= P(x_1\\vert \\theta)P(x_2\\vert \\theta)...P(x_n\\vert \\theta)\\\\&amp;= \\prod P(x_i\\vert \\theta), i=1,2,...,n\\end{aligned}\\]对于抽样得到样本集 $X$ 这个既成事实，我们认为这就是最该发生的结果，也即所有可能的结果中概率最大的那一个，这就是最大似然估计的命名由来。此时，我们需要寻找的就是那个使似然函数取得最大值的 $\\theta$ 值\\[{\\rm argmax}\\ L(\\theta) = {\\rm max}_\\theta L(\\theta)\\]${\\rm argmax} f(x)$ 是使得函数 $f(x)$ 取得其最大值的所有自变量 $x$ 的集合。总结起来，利用最大似然函数求解总体参数的估计值的一般步骤为：  获取似然函数  对似然函数取自然对数  将对数似然函数求（偏）导数，令其为 0，得到似然方程  求解似然方程，得到的一个或多个数值，即为总体参数的最大似然估计值由于在计算当中，多个概率的乘法最终会得到一个非常小的值，从而可能造成下溢（underflow），因此一般会对似然函数取一个对数，将连续乘法转化为加法\\[{\\rm argmax}\\ log L(\\theta) = {\\rm argmax}\\  log \\prod P(x_i\\vert \\theta) = {\\rm argmax}\\  \\sum_{i=1}^n logP(x_i\\vert \\theta), i=1,2,...,n\\]再进一步，加一个负号，问题转化为\\[{\\rm argmin}\\  [-log L(\\theta)] = {\\rm argmin}\\  \\sum_{i=1}^n [-logP(x_i\\vert \\theta)], i=1,2,...,n\\]因为当重新缩放代价函数时 argmin 不会改变，我们可以除以 $n$ 得到和训练数据经验分布 $P$ 相关的期望作为准则\\[{\\rm argmin}\\ \\mathbb E_P [-logP(X\\vert \\theta)]\\]令 $Q(X) = P(X\\vert \\theta)$ 上式转化为\\[{\\rm argmin}\\ \\mathbb E_P [-log Q(X)]\\]后面在介绍 KL 散度和交叉熵时会发现，任何一个负对数似然组成的损失都是定义在训练集上的经验分布和定义在模型上的真实分布之间的交叉熵。举一个例子：假定被研究对象的总体服从二项分布，如果知道了基础的 (0，1) 分布中结果指定为 1 时的概率 $p$，也就知道了这个分布形态的全部。  假如有一个罐子，里面有黑白两种颜色的球，数目多少不知，两种颜色的比例也不知。我们想知道罐中白球和黑球的比例，但我们不能把罐中的球全部拿出来数。现在我们可以每次任意从已经摇匀的罐中拿一个球出来，记录球的颜色，然后把拿出来的球再放回罐中。这个过程可以重复，我们可以用记录的球的颜色来估计罐中黑白球的比例。假如在前面的一百次重复记录中，有七十次是白球，请问罐中白球所占的比例最有可能是多少？  很多人马上就有答案了：70%。而其后的理论支撑是什么呢？  我们假设罐中白球的比例是 $p$，那么黑球的比例就是 $1-p$，这里 $p$ 就是模型参数。因为每抽一个球出来，在记录颜色之后，我们把抽出的球放回了罐中并摇匀，所以每次抽出来的球的颜色服从同一独立分布。  这里我们把一次抽出来球的颜色称为一次抽样。题目中在一百次抽样中，七十次是白球的,三十次为黑球事件的概率是：\\(P(样本结果|Model)\\)如果第一次抽象的结果记为 $x_1$，第二次抽样的结果记为 $x_2$…，那么样本结果为 $(x_1,x_2,…,x_{100})$。这样，我们可以得到如下表达式：\\(\\begin{aligned}P(样本结果|Model)&amp;= P(x_1,x_2,…,x_{100}|Model)\\\\&amp;= P(x_1|M)P(x_2|M)\\cdots P(x_{100}|M)\\\\&amp;= p^{70}(1-p)^{30}\\end{aligned}\\)上面就是观察样本结果出现的概率函数了。那么，如何求出模型参数 $p$ 呢？不同的 $p$ 会直接导致上面概率函数的不同。比如:      $p=0.5$（黑50%白50%）时 $p^{70}(1-p)^{30}=7.8\\times 10^{-31}$    $p=0.7$ （黑70%白30%）时 $p^{70}(1-p)^{30}=2.95\\times 10^{-27}$                      那么问题来了，既然有无数种分布可以选择，极大似然估计应该按照什么原则去选取这个分布呢？答案是，让这个样本结果出现的可能性最大，既然事情已经发生了，为什么不让这个出现的结果的可能性最大呢？这也就是最大似然估计的核心。转化为数学问题，就是使得 $P(样本结果        Model)=p^{70}(1-p)^{30}$ 的值最大。              如何求极值呢，那么我们就可以将概率函数看成是 $p$ 的方程，对其求导，导数为 0 的点就是极值点！\\(\\begin{aligned}f'(p) &amp;= {\\rm d}(p^{70}(1-p)^{30})/{\\rm d}p\\\\&amp;= 70\\cdot p^{69}(1-p)^{30}-p^{70}\\cdot 30\\cdot(1-p)^{29}\\\\&amp;= 70\\cdot p^{69}\\cdot(1-p)^{29}[1-p-3/7\\cdot p] = 0\\\\\\end{aligned}\\)即\\(\\begin{aligned}1 - 10/7 \\cdot p = 0\\end{aligned}\\)可求出 $p=0.7$，与我们一开始认为的 70% 是一致的。再举另外一个例子  假设我们要统计全国人民的年均收入，首先假设这个收入服从服从正态分布，但是该分布的均值与方差未知。我们没有人力与物力去统计全国每个人的收入。我们国家有10几亿人口呢？那么岂不是没有办法了？  不不不，有了极大似然估计之后，我们可以采用嘛！我们比如选取一个城市，或者一个乡镇的人口收入，作为我们的观察样本结果。然后通过最大似然估计来获取上述假设中的正态分布的参数。  有了参数的结果后，我们就可以知道该正态分布的期望和方差了。也就是我们通过了一个小样本的采样，反过来知道了全国人民年收入的一系列重要的数学指标量！  那么我们就知道了极大似然估计的核心关键就是对于一些情况，样本太多，无法得出分布的参数值，可以采样小样本后，利用极大似然估计获取假设中分布的参数值。2. 概率2.1. 条件概率公式条件概率是指事件 $A$ 在事件 $B$ 发生的条件下发生的概率。若只有两个事件 $A$，$B$，那么条件概率表示为：$P(A\\vert B)$，读作 “$A$ 在 $B$ 发生的条件下发生的概率”。\\[P(A\\vert B) = \\frac{P(AB)}{P(B)}\\]其中，$P(AB)$ 是两个事件的联合概率，$P(B)$ 是事件 $B$ 的边缘概率。一种不准确的理解方式，$P(AB)$ 是 $A,B$ 同时发生的概率，$P(B)$ 是 $B$ 发生的概率。我们要求已知 $B$ 发生后 $A$ 发生的概率，相当于 B 的发生与否不再是一个不确定的概率，而是确定的条件。由于不同事件同时发生的概率是用乘积的形式来表示，反之某个事件从概率变为已经发生就用除法来表示，那么就应该用 $P(AB)$ 除以 $P(B)$ 来得到这么个条件概率。另一种理解方式，将等式做一个变换\\[P(B)P(A\\vert B) = P(AB)\\]也就是说，$A,B$ 同时发生的概率，等于 $B$ 发生的概率，乘以 $B$ 发生（作为条件）后 $A$ 发生的概率。这给我们一个启示，即交换 $A,B$ 的顺序，等式依然成立\\[P(B)P(A\\vert B) = P(AB) = P(BA) = P(A)P(B\\vert A)\\]2.2. 全概率公式设 $B_1,…,A_n$ 是样本空间 $S$ 的一个完备事件组，即  $B_1,…,B_n$ 两两不相容：$B_i \\cap B_j = \\varnothing\\quad (i\\neq j)$  $B_i \\cup…\\cup B_n = S$每一次试验中，完备事件组中有且仅有一个事件发生。完备事件组构成样本空间的一个划分。全概率公式。定理：设实验 $E$ 的样本空间为 $S$，$B_1, B_2,…,B_n$ 为 $S$ 的一个划分（完备事件组），且 $P(B_i)&gt;0\\quad i=1,2,…n$，$A$ 为 $E$ 的一个事件，则\\[\\begin{aligned}P(A) &amp;= P(B_1)P(A\\vert B_1)+P(B_2)P(A\\vert B_2)+...+P(B_n)P(A\\vert B_n)\\\\&amp;= \\sum_{i=1}^n P(B_i)P(A\\vert B_i)\\end{aligned}\\]其推导过程如下，如图：\\[\\begin{aligned}A &amp;= AS = A(B_1\\cup B_2\\cup ... \\cup B_n)\\\\&amp;= AB_1\\cup AB_2\\cup ... \\cup AB_n \\quad (AB_i两两互斥)\\\\P(A) &amp;= P(AB_1\\cup AB_2\\cup ... \\cup AB_n)\\\\&amp;=P(AB_1) + P(AB_2) + ... + P(AB_n)\\end{aligned}\\]根据条件概率公式\\[P(AB_i) = P(A)P(B_i\\vert A) = P(B_i)P(A\\vert B_i)\\]带入有\\[P(A) = \\sum_{i=1}^n P(B_i)P(A\\vert B_i)\\]即为全概率公式。全概率公式的意义1：将复杂的事件 $A$ 划分为比较简单的事件 $AB_1,…,AB_n$，再结合加法和乘法计算 $A$ 的（边缘）概率。全概率公式的意义2：事件 $A$ 的发生可能有各种原因 $B_i\\quad (i=1,2,…,n)$，如果 $A$ 是由 $B_i$ 引起，则此时 $A$ 发生的（条件）概率为\\[P(AB_i) = P(B_i)P(A\\vert B_i)\\]若每个原因都可能导致 $A$ 的发生，那么 $A$ 发生的概率是全部原因引起其发生的概率的综合，即为全概率公式。因此可以把全概率公式看成是 “由原因推结果”。每一个原因对结果的发生由一定的作用，结果发生的可能性与各种原因的作用大小有关，全概率公式表达了它们之间的关系。2.3. 概率的两大学派对于概率看法不同的两大派别频率学派与贝叶斯派。他们看待世界的视角不同，导致他们对于产生数据的模型参数的理解也不同。      频率学派          他们认为世界是确定的。他们直接为事件本身建模，也就是说事件在多次重复实验中趋于一个稳定的值 $p$，那么这个值就是该事件的概率。      他们认为模型参数是个定值，希望通过类似解方程组的方式从数据中求得该未知数。这就是频率学派使用的参数估计方法：极大似然估计（MLE），这种方法往往在大数据量的情况下可以很好的还原模型的真实情况。      频率派把需要推断的模型参数 $\\theta$ 看做是固定的未知常数，即参数 $\\theta$ 虽然是未知的，但最起码是确定的一个值，同时，样本 $X$ 是随机的，所以频率派重点研究样本空间，大部分的概率计算都是针对样本 $X$ 的分布；            贝叶斯派          他们认为世界是不确定的，因获取的信息不同而异。假设对世界先有一个预先的估计，然后通过获取的信息来不断调整之前的预估计。 他们不试图对事件本身进行建模，而是从旁观者的角度来说。因此对于同一个事件，不同的人掌握的先验不同的话，那么他们所认为的事件状态也会不同。      他们认为模型参数源自某种潜在分布，希望从数据中推知该分布。对于数据的观测方式不同或者假设不同，那么推知的该参数也会因此而存在差异。这就是贝叶斯派视角下用来估计参数的常用方法：最大后验概率估计（MAP），这种方法在先验假设比较靠谱的情况下效果显著，随着数据量的增加，先验假设对于模型参数的主导作用会逐渐削弱，相反真实的数据样例会大大占据有利地位。极端情况下，比如把先验假设去掉，或者假设先验满足均匀分布的话，那她和极大似然估计就如出一辙了。      贝叶斯学派认为，模型参数 $\\theta$ 是随机变量，而样本 $X$ 是固定的，由于样本是固定的，所以他们重点研究的是参数 $\\theta$ 的分布。      贝叶斯学派的创始人，托马斯·贝叶斯（Thomas Bayes），发表了一篇名为《An essay towards solving a problem in the doctrine of chances》，翻译过来则是《机遇理论中一个问题的解》。这篇论文发表后，在当时并未产生多少影响，在20世纪后，这篇论文才逐渐被人们所重视。贝叶斯派既然把 $\\theta$ 看做是一个随机变量，所以要计算 $\\theta$ 的分布，便得事先知道 $\\theta$ 的无条件分布，即在有样本之前（或观察到 $X$ 之前）， $\\theta$ 有着怎样的分布呢？比如往台球桌上扔一个球，这个球落会落在何处？如果是不偏不倚的把球抛出去，那么此球落在台球桌上的任一位置都有着相同的机会，即球落在台球桌上某一位置的概率服从均匀分布。这种在实验之前定下的属于基本前提性质的分布称为先验分布，或的无条件分布。至此，贝叶斯及贝叶斯派提出了一个思考问题的固定模式：\\[先验分布 \\pi(\\theta) + 样本信息x \\Rightarrow 后验分布 \\pi(\\theta \\vert x)\\]2.4. 贝叶斯公式  一种形式设 $B_1,…,B_n$ 是样本空间 $S$ 的一个完备事件组，则对任一事件 $A$，$P(A)&gt;0$，有\\[P(B_i\\vert A) = \\frac{P(B_i)P(A\\vert B_i)}{P(A)}=\\frac{P(B_i)P(A\\vert B_i)}{\\sum_{j=1}^n P(B_j)P(A\\vert B_j)}\\]贝叶斯公式的推导可以通过条件概率公式得到\\[\\begin{aligned}P(A\\vert B_i) &amp;= \\frac{P(AB_i)}{P(B_i)} \\quad &amp;(条件概率公式)\\\\\\Rightarrow  P(AB_i) &amp;= P(B_i)P(A\\vert B_i) \\quad &amp;(移项)\\\\\\Rightarrow  P(A)P(B_i\\vert A) &amp;= P(B_i)P(A\\vert B_i) \\quad &amp;(条件概率公式)\\\\\\Rightarrow  P(B_i\\vert A) &amp;= \\frac{P(B_i)P(A\\vert B_i)}{P(A)} \\quad &amp;(移项)\\end{aligned}\\]一种直观的理解：假设 $B_1,…,B_n$ 是发生时间 $A$ 的各种原因，那么已知事件 $A$ 已经发生了，问是原因 $B_i$ 导致的概率 $P(B_i \\vert A)$ 是多少？  另一种形式使用另一套字母体系：  $H$：hypothesis，假设，规律  $E$：evidence，证据，现象，数据那么贝叶斯的推理过程可以表达为：通过不断收集证据 $E$ 来完善假设 $H$ 。那么贝叶斯公式可以描述为\\[P(H\\vert E) = \\frac{P(H)P(E\\vert H)}{P(E)} = P(H)\\frac{P(E\\vert H)}{P(E)}\\]因此贝叶斯公式实际上阐述的是如下事实\\[新信息E出现后假设H的概率 = H 的概率\\times 新信息带来的调整\\]可以理解为，新观察到的样本信息将修正人们以前对事物的认知。对于一个场景，可能有几种不同的规律来解释，根据对场景的一些现象的观测，如何知道各种可能的规律在背后发生作用的概率？这个问题就是如何求解 $P(规律H\\vert现象E)$。            直接去计算有难度，但是如果我们知道在某个规律 $H$ 下，不同现象 $E$ 发生的概率 $P(现象E      规律H)$，和每个规律发生的概率 $P(规律H)$，和不同现象发生的概率 $P(现象E)$，就可以通过已知数据求解。贝叶斯就是告诉怎么用这些知道的知识去计算现象后面的规律发生的概率。        第三种形式马同学. 如何理解贝叶斯推断和beta分布？假设实验数据 $X\\vert p$ 服从二项分布（比如抛硬币）\\[\\underbrace{f(p\\vert X=k)}_{后验分布}=\\frac{\\overbrace{P(X=k\\vert p)}^{实验数据}\\overbrace{f(p)}^{先验分布}}{\\underbrace{P(X=k)}_{常数}}\\]其中 $k$ 为正面的次数。分母与实验数据无关，可以视作常数。3. 熵《信息论：基础理论与应用》3.1. 自信息在信息传输的一般情况下，收信者获得的信息量等于信息传输前后不确定性的减少量\\[获得的信息量 = 不确定性的减少量 = 收信前某事件发生的不确定性 - 收信后某事件发生的不确定性\\]假设无噪声，信道传输不失真，因此收到消息后某事件发生的不确定性完全消除，即\\[获得的信息量 = 不确定性的减少量 = 收信前某事件发生的不确定性 = 信源输出某消息中含有的信息量\\]事件发生的不确定性与事件发生的概率有关。事件发生的概率越大，该事件发生后能够提供的信息就越少，不确定性就越小。对于发生概率等于 1 的事件（必然事件），提供不了任何信息，就不存在不确定性。因此，某事件发生所含有的信息量就应该是该事件发生先验概率的函数。\\[I(a_i) = f(P(a_i))\\]式中，$P(a_i)$ 是事件 $a_i$ 发生的先验概率，$I(a_i)$ 表示事件 $a_i$ 发生所含有的信息量，我们称之为 $a_i$ 的自信息。下面分析自信息与先验概率之间函数关系 $f$ 的具体形式。  一种形象理解：事件发生概率越大，发生后能够提供的信息就越少（老发生没啥价值，获得不了什么信息），那么不确定性就越小，自信息就小。反之，如果事件发生概率越小，一旦发生了提供的信息量就很大，发生后消除的不确定性就很大，自信息量就大。因此，概率和信息量可能是负相关的。根据客观事实和人们的习惯概念，不确定性函数 $f$ 应该满足如下的条件：  减函数：$f$ 是 $P$ 的单调递减函数，          $P(a_i)=1$ 时 $f(P_i)=0$，      $P(a_i)=0$ 时 $f(P_i)=\\infty$        可加性：两个独立消息所产生的不确定性应等于各自不确定性之和，$f(P_1,P_2)=f(P_1)+f(P_2)$  由于事件 $P_1,P_2$ 是独立不相关的，因此 $P(1,2)=P_1P_2$。同时满足这 3 个条件的函数 $f$ 是负对数函数，即\\[f(P) = {\\rm log}\\frac{1}{P} = -{\\rm log}P\\quad P \\in [0,1]\\]函数图像如下图所示事件发生前，$f$ 表示事件发生的不确定性；事件发生后，$f$ 表示事件所含有（所提供）的信息量。自信息采用的单位取决于对数所选的底。由于概率 $P$（作为自变量） 是小于 1 的正数，又根据实际情况自信息也必然是正数，所以对数的底应选取为大于 1 的任意数。信息论中一般取 2 为底，则所得的信息量单位为 比特（bit，binary unit）。机器学习中一般取 $e$ 为底的自然对数，信息量单位为 奈特（nat, nature unit）。如果取 10为底，信息量单位为 哈特（hart, Hartley 的缩写，纪念他首先提出用对数来度量信息）。取 2 为底时可以略去不写。如果 $P(a_i)=0.5$，则 $f(P)=1$ 比特。所以 1 比特信息量就是两个互不相容的等可能事件之一发生时提供的信息量。注意，这里的比特时抽象的信息量单位，与计算机术语中的比特含义不同，它代表二元数字（binary digits）。这两种概念之间的关系是，每个二元数字所能提供的最大平均信息量为 1 比特。3.2. 信息熵前面定义的自信息是某一信源发出某一消息所含有的信息量。如果发出的消息不同，所含有的信息量也就不同。因此，自信息是一个随机变量，不能用来作为整个信源的信息测度。我们定义自信息的数学期望为信源的平均自信息量。信源一般包括多种信号，如果考虑这个信源所有可能发生情况的平均不确定性，假设信源消息有 $n$ 种取值：$x_1,…,x_i,…,x_n$，对应概率为：$P(x_1),…,P(x_i),…,P(x_n)$，且各种消息的出现彼此独立。这时，信源的平均不确定性应当为单个消息不确定性 $-{\\rm log}P(x_i)$ 的数学期望（$\\mathbb E$），可称为信息熵\\[H(X) = \\mathbb E[-{\\rm log} P(x_i)] = -\\sum_{i=1}^n P(x_i){\\rm log} P(x_i)\\]信息熵：信源的平均不确定性，为单个消息不确定性的数学期望（统计平均值）。1948年，C.E.Shannon（香农）提出了 “信息熵” 的概念，才解决了对信息的量化度量问题。信息熵这个词是香农从热力学中借用过来的。热力学中的热熵是表示分子状态混乱程度的物理量。对于连续分布，信息熵的表示如下（连续型随机变量的数学期望）\\[H(X) = \\mathbb E[-{\\rm log} P(x)] = -\\int_x P(x){\\rm log} P(x) {\\rm d}x\\]香农用信息熵的概念来描述信源的平均不确定度，相当于每个消息所提供的平均信息量。例如，两个信源分别为\\[\\begin{bmatrix}X\\\\ P(x)\\end{bmatrix} = \\begin{bmatrix}a_1 &amp; a_2\\\\ 0.99 &amp; 0.01\\end{bmatrix},\\quad \\begin{bmatrix}Y\\\\ P(y)\\end{bmatrix} = \\begin{bmatrix}b_1 &amp; b_2\\\\ 0.5 &amp; 0.5\\end{bmatrix}\\]两个信源的信息熵分别为\\[\\begin{aligned}  H(X) &amp;= -0.99{\\rm log} 0.99-0.01{\\rm log} 0.01 = 0.08 (bit/info)\\\\  H(Y) &amp;= -0.5{\\rm log} 0.5-0.5{\\rm log} 0.5 = 1 (bit/info)\\end{aligned}\\]可见，信源 $Y$ 的平均不确定性大。我们观察信源 $Y$，它的两个输出消息是等可能性的，所以在没有输出前猜测输出哪个消息的不确定性要大。反之，对于信源 $X$，由于事件 $a_1$ 出现的概率远超事件 $a_2$，虽然具有不确定性，但是大致猜测事件 $a_1$ 会出现。举个例子说明信息熵的作用。  赌马比赛，有4匹马 ${ A, B, C, D}$，获胜概率分别为 ${ 1/2, 1/4, 1/8, 1/8 }$，将哪一匹马获胜视为随机变量X属于 ${ A, B, C, D }$ 。假定我们需要用尽可能少的二元问题来确定随机变量 X 的取值。例如，问题1：A获胜了吗？　问题2：B获胜了吗？　问题3：C获胜了吗？最后我们可以通过最多3个二元问题，来确定取值：      如果X = A，那么需要问1次（问题1：是不是A？），概率为1/2    如果X = B，那么需要问2次（问题1：是不是A？问题2：是不是B？），概率为1/4    如果X = C，那么需要问3次（问题1，问题2，问题3），概率为1/8    如果X = D，那么需要问3次（问题1，问题2，问题3），概率为1/8  在二进制计算机中，一个比特为 0 或 1，其实就代表了一个二元问题的回答。我们可以使用一个 2 比特的数字来完成上面的赌马结果：00 - A获胜，  01 - B获胜，  10 - C获胜，  11 - D获胜然而，我们可以利用非均匀分布这个特点，使用更短的编码来描述更可能的事件，使用更长的编码来描述不太可能的事件。我们希望这样做能够得到一个更短的平均编码长度。我们可以使用下面的编码串（哈夫曼编码）：0 - A获胜,   10 - B获胜,   110 - C获胜,   111 - D获胜此时，传输的编码的平均长度就是：\\[1/2\\times 1bit + 1/4\\times 2bit + 1/8\\times 3bit + 1/8\\times 3bit = \\frac{7}{4}bits = 1.75bits\\]回到信息熵的定义，会发现通过之前的信息熵公式，神奇地得到了\\[H(N) = \\frac{1}{2}\\cdot {\\rm log}(2)+\\frac{1}{4}\\cdot {\\rm log}(4)+\\frac{1}{8}\\cdot {\\rm log}(8)+\\frac{1}{8}\\cdot {\\rm log}(8) =\\frac{1}{2}+\\frac{2}{4}+\\frac{3}{8}+\\frac{3}{8} = \\frac{7}{4} bits\\]也就是说，在计算机中，我们给哪一匹马夺冠这个事件进行编码，所需要的平均码长为 1.75 个比特。所以，信息熵 $H(X)$ 可以看做对信源 $X$ 中的样本进行编码所需要的编码长度的期望值，同时也表明，信息熵是传输一个随机变量状态值所需的比特位下界（最短平均编码长度）。3.3. 相对熵（KL散度）相对熵，relative entropy = Kullback-Leibler divergence，用于衡量两个概率分布之间的差异。设 $P(x)$ 和 $Q(x)$ 是离散随机变量 $X$ 中取值的两个概率分布。其中，$P(x)$ 为我们往往不能测得的真实分布，而 $Q(x)$ 是我们可以测得的预测分布。对于 $P(x)$ 而言，其信息熵为\\[H(P) = -\\int P(x){\\rm log}P(x)\\]对于 $Q(x)$ 而言，由于其样本来自真实分布 $P(x)$，因此其信息熵中的概率依然为 $P(X)$，则其信息熵为\\[H(P,Q) = -\\int P(x){\\rm log}Q(x)\\]为了衡量二者的差异，定义 相对熵 为\\[\\begin{aligned}KL(P\\Vert Q) &amp;= -\\int P(x){\\rm log}Q(x) - [-\\int P(x){\\rm log} P(x)]\\\\&amp;= - \\int P(x){\\rm log}\\frac{Q(x)}{P(x)}\\end{aligned}\\]相对熵又被称为 KL 散度。      由于 $P(x)$ 和 $Q(x)$ 在公式中的地位不是相等的，所以 $KL(P\\Vert Q)\\not\\equiv KL(Q\\Vert P)$。        当，$P(x) = Q(x)$时，$KL(P\\Vert Q) = 0$。若 $P(x)$ 和 $Q(x)$ 有差异，$KL(P\\Vert Q) &gt; 0$。  KL 散度的非负性证明，利用了负指数函数是严格凸函数的性质，证明过程如下：  首先，$-log()$ 函数是上凹函数，如下面的示意图所示根据 Jensen 不等式：$f(\\mathbb E(x))\\leq \\mathbb E(f(x))$根据含隐随机变量的 Jensen 不等式：$f(\\mathbb E[\\xi(z)])\\leq \\mathbb E[f(\\xi(z))]$令 $f(\\cdot) = -log(\\cdot)$，令 $\\xi(z) = \\frac{Q(x)}{P(x)}$，带入上式得\\(\\begin{aligned}\\mathbb E_x[f(\\xi(x))] &amp;\\geq f(\\mathbb E_x[\\xi (x)])\\\\\\mathbb E_x[-log(\\frac{Q(x)}{P(x)})] &amp;\\geq -log(E_x[\\frac{Q(x)}{P(x)}]))\\\\-\\int log(\\frac{Q(x)}{P(x)}) P(x){\\rm d}x &amp;\\geq -log(\\int \\frac{Q(x)}{P(x)}P(x){\\rm d}x)\\\\-\\int log(\\frac{Q(x)}{P(x)}) P(x){\\rm d}x &amp;\\geq -log(\\int Q(x){\\rm d}x)=-log(1)=0\\\\\\end{aligned}\\)3.4. 交叉熵遍地胡说. 详解机器学习中的熵、条件熵、相对熵和交叉熵KL 散度可以用来评估两个分布的差异程度，假设未知真实分布为 $P(x)$，已知估计分布为 $Q(x)$，根据其定义\\[\\begin{aligned}KL(P\\Vert Q) &amp;= -\\int P(x){\\rm log}Q(x) - [-\\int P(x){\\rm log} P(x)]\\\\&amp;= H(P,Q) - H(P)\\end{aligned}\\]注意到，后一项 $H(P)$ 是未知真实分布的信息熵，对于一个确定的未知分布而言是个常数。因此，在实际应用中我们只关心前一项的取值，前一项 $H(P,Q)$ 我们称为 交叉熵。因此，我们可以得到如下的等式\\[相对熵（KL散度） = 交叉熵 - 信息熵\\]根据前面 $KL 散度\\geq 0$ 的性质，我们可以知道，$交叉熵 \\geq 信息熵$。在机器学习中，我们希望在训练数据上模型学到的分布 $Q(x)$ 和真实数据的分布  $P(x)$ 越接近越好，所以我们可以使其相对熵最小。但是我们没有真实数据的分布，所以只能希望模型学到的分布 $Q(x)$ 和训练数据的分布 $P_t(x)$ 尽量相同。假设训练数据是从总体中独立同分布采样的，那么我们可以通过最小化训练数据的经验误差来降低模型的泛化误差。即：  希望学到的模型的分布和真实分布一致，$Q(x) \\simeq P(x)$  但是真实分布不可知，假设训练数据是从真实数据中独立同分布采样的，$P_t(x) \\simeq P(x)$  因此，我们希望学到的模型分布至少和训练数据的分布一致，$Q(x) \\simeq P_t(x)$根据之前的描述，最小化训练数据上的分布 $P_t(x)$ 与最小化模型分布 $Q(x)$ 的差异等价于最小化相对熵，即 ${\\rm minimize}\\ [KL(P_t(x)\\vert \\vert Q(x))]$。此时，$P_t(x)$ 就是 $KL(p\\vert \\vert q)$ 中的 $p$，即真实分布，$Q(x)$ 就是 $q$。又因为训练数据的分布 $p$ 是给定的，所以求 $KL(p\\vert \\vert q)$ 等价于求 $H(p,q)$。得证，交叉熵可以用来计算学习模型分布与训练分布之间的差异。实际上，由于 $P(x)$ 是已知\\[{\\rm minimize}\\ H(p,q) = {\\rm minimize}\\ [-\\int P(x){\\rm log}Q(x)] = {\\rm minimize}\\ \\mathbb E_p[-log Q(x)]\\]任何一个负对数似然组成的损失都是定义在训练集上的经验分布和定义在模型上的真实分布之间的交叉熵。  ccj_zj. 多分类问题中的交叉熵  交叉熵是直接衡量两个分布，或者说两个model之间的差异。而似然函数则是解释以model的输出为参数的某分布模型对样本集的解释程度。因此，可以说这两者是“同貌不同源”，但是“殊途同归”啦。3.5. softmax 函数$n$ 分类问题 的 softmax 函数定义如下\\[\\hat y_i = P(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^n e^{z_j}}\\]假设某个训练样本经过神经网络后到达 softmax 层之前的输出向量为 $z=[ 1, 5, 3 ]$, 那么经过 softmax 函数后的概率分别为 $\\hat y=[0.015,0.866,0.117]$。假设期望输出标签为 $y = [0,1,0]$，那么交叉熵损失函数可以定义为\\[L(\\hat y, y) = -\\sum_{j=1}^3 y_j {\\rm ln} \\hat{y}_j\\]由于在分类问题中，期望输出标签是 one-hot 型变量。不失一般性，假设第 $j$ 个分量为 1 ，则损失函数为\\[L(\\hat y, y) = - {\\rm ln} \\hat{y}_j\\ (y_j = 1)\\]进行梯度下降时，根据链式法则\\[\\frac{\\partial L}{\\partial \\omega} = \\frac{\\partial L}{\\partial \\hat y_j}\\frac{\\partial \\hat y_j}{\\partial z_i}\\frac{\\partial z_i}{\\partial \\omega_k}\\]其中\\[\\frac{\\partial L}{\\partial \\hat y_j} = -\\frac{1}{\\hat y_j}\\]而 $\\frac{\\partial z_i}{\\partial \\omega_k}$ 根据网络具体形式，一般比较好求。因此，重点在于求解中间的偏导项，需要分情况讨论$j=i$ 时，表明反向传播至同样下标的上一层节点：\\[\\begin{aligned}{\\rm if}\\quad j&amp;=i:\\\\\\frac{\\partial \\hat y_j}{\\partial z_i}&amp;=\\frac{\\partial \\hat y_i}{\\partial z_i}\\\\&amp;=\\frac{\\partial }{\\partial z_i}(\\frac{e^{z_i}}{\\sum_{k} e^{z_k}})\\\\&amp;=\\frac{(e^{z_i})'\\cdot \\sum_{k} e^{z_k}-e^{z_i}\\cdot e^{z_i}}{(\\sum_{k} e^{z_k})^2}\\quad(分式函数求导法则)\\\\&amp;=\\frac{e^{z_i}}{\\sum_{k} e^{z_k}} - \\frac{e^{z_i}}{\\sum_{k} e^{z_k}}\\frac{e^{z_i}}{\\sum_{k} e^{z_k}}\\\\&amp;= \\hat y_j(1-\\hat y_j)\\end{aligned}\\]此时\\[\\frac{\\partial L}{\\partial z_j} = -\\frac{1}{\\hat y_j} \\cdot \\hat y_j(1-\\hat y_j) = \\hat y_j - 1\\]可以看出形式非常简单，只要正向求一次得出结果，然后反向传梯度的时候，将结果减 1 即可。$j\\neq i$ 时，表明反向传播至不同下标的上一层节点：\\[\\begin{aligned}{\\rm if}\\quad j&amp;\\neq i:\\\\\\frac{\\partial \\hat y_j}{\\partial z_i}&amp;=\\frac{\\partial }{\\partial z_i}(\\frac{e^{z_j}}{\\sum_{k} e^{z_k}})\\\\&amp;=\\frac{ {\\rm d} e^{z_j}/{\\rm d} e^{z_i}\\cdot \\sum_{k} e^{z_k}-e^{z_j}\\cdot e^{z_i} }{(\\sum_{k} e^{z_k})^2}\\\\&amp;=\\frac{0\\cdot \\sum_{k} e^{z_k}-e^{z_j}\\cdot e^{z_i}}{(\\sum_{k} e^{z_k})^2}\\\\&amp;=-\\frac{e^{z_j}}{\\sum_{k} e^{z_k}}\\frac{e^{z_i}}{\\sum_{k} e^{z_k}}\\\\&amp;= -\\hat y_j\\hat y_i\\end{aligned}\\]此时\\[\\frac{\\partial L}{\\partial z_j} = -\\frac{1}{\\hat y_j} \\cdot (-\\hat y_j\\hat y_i) = \\hat y_i\\]形式同样非常简单，只要正向求一次得出结果，然后反向传梯度的时候，将它结果保存即可。还是上面的例子，假设输出向量为 $z=[ 1, 5, 3 ]$, 那么经过 softmax 函数后的概率分别为 $\\hat y=[0.015,0.866,0.117]$，交叉熵损失函数对 $z$ 的篇导数为 $\\hat y’=[0.015,0.866-1,0.117] = [0.015,-0.134,0.117]$。可以看出，softmax 配合 交叉熵损失函数 可以使得梯度下降非常简单。4. 参考文献[1] 产品经理马忠信. 应该如何理解概率分布函数和概率密度函数？[2] 忆臻. 一文搞懂极大似然估计[3] 马同学. 如何理解贝叶斯推断和beta分布？[4] 遍地胡说. 详解机器学习中的熵、条件熵、相对熵和交叉熵"
  },
  
  {
    "title": "深度学习基础（Encoder-Decoder）",
    "url": "/posts/deep-learning-encoder-decoder/",
    "categories": "Academic, Knowledge",
    "tags": "deep learning",
    "date": "2020-10-28 10:51:19 +0800",
    





    
    "snippet": "本文主要介绍自然语言处理（Natural Language Process，NLP）的基础，然后介绍 Encoder-Decoder（编码-解码）框架和 Attention 机制。  1. NLP 介绍          1.1. 文本表示      1.2. 训练思想        2. Encoder-Decoder          2.1. RNN E-D              ...",
    "content": "本文主要介绍自然语言处理（Natural Language Process，NLP）的基础，然后介绍 Encoder-Decoder（编码-解码）框架和 Attention 机制。  1. NLP 介绍          1.1. 文本表示      1.2. 训练思想        2. Encoder-Decoder          2.1. RNN E-D                  2.1.1. 实现          2.1.2. 结构          2.1.3. 分析                    2.2. attention model                  2.2.1. attention score          2.2.2. attention weights          2.2.3. attention vector          2.2.4. 总结                      3. 参考文献1. NLP 介绍1.1. 文本表示要处理 NLP（Natural Language Processing，自然语言处理）问题，首先要解决文本的表示问题。虽然我们人去看文本，能够清楚明白文本中的符号表达什么含义，但是计算机只能做数学计算，需要将文本表示成计算机可以处理的形式。最开始的方法是采用 one hot。one-hot 编码是一种最普通常见的表示离散数据的表示，首先我们计算出需要表示的离散或类别变量的总个数 $N$，然后对于每个变量，我们就可以用 $N-1$ 个 0 和单个 1 组成的向量来表示每个类别。比如，我们假设英文中常用的单词有 $N=30000$ 个，那么我们就用一个 30000 维的向量表示这个词，所有位置都置0。当我们想表示 apple 这个词时，就在对应位置设置1，如下图所示Dict =    append apple hello look world ... [30000 words]V_apple = [0,    1,    0,    0,   0, ...] 1*30000 dim这样做有两个很明显的缺点：  高维稀疏：对于具有非常多类型的类别变量，变换后的向量维数过于巨大，且过于稀疏。  向量没有任何含义，映射之间完全独立，并不能表示出不同类别之间的关系。。后来出现了词向量（word embedding），用一个低维稠密的向量去表示一个词，如下所示apple = [0.2649816874, 0.14916784874, -1.51968714,...]通常这个向量的维度在几百到上千之间，相比 one hot 几千几万的维度就低了很多。词与词之间可以通过相似度或者距离来表示关系，相关的词向量相似度比较高，或者距离比较近，不相关的词向量相似度低，或者距离比较远，这样词向量本身就有了含义。文本的表示问题就得到了解决。  刘斯坦. 怎么形象理解 embedding 这个概念？  这个概念在深度学习领域最原初的切入点是所谓的 Manifold Hypothesis（流形假设）。流形假设是指“自然的原始数据是低维的流形嵌入于(embedded in)原始数据所在的高维空间”。那么，深度学习的任务就是把高维原始数据（图像，句子）映射到低维流形，使得高维的原始数据被映射到低维流形之后变得可分，而这个映射就叫嵌入（Embedding）。比如 Word Embedding，就是把单词组成的句子映射到一个表征向量。但后来不知咋回事，开始把低维流形的表征向量叫做 embedding，其实是一种误用 0.0  如果按照现在深度学习界通用的理解（其实是偏离了原意的），embedding 就是从原始数据提取出来的 feature，也就是那个通过神经网络映射之后的低维向量。  一句话解释：embedding 的原意是映射过程，现在误用为映射后的低维特征关于 embedding 的更多理解可以参考：Ethan. Embedding 的理解词向量可以通过一些无监督的方法学习得到，比如 CBOW 或者 Skip-Gram 等，可以预先在语料库上训练出词向量，以供后续的使用。顺便提一句，在图像中就不存在表示方法的困扰，因为图像本身就是数值矩阵，计算机可以直接处理。1.2. 训练思想NLP 中有各种各样的任务，比如分类（Classification），问答（QA），实体命名识别（NER）等。对于这些不同的任务，最早的做法是根据每类任务定制不同的模型，输入预训练好的 embedding，然后利用特定任务的数据集对模型进行训练，如下图所示。这里存在的问题就是，不是每个特定任务都有大量的标签数据可供训练，对于那些数据集非常小的任务，恐怕就难以得到一个理想的模型。我们看一下图像领域是如何解决这个问题的。图像分类是计算机视觉中最基本的任务，当我要解决一个小数据集的图像分类任务时，该怎么做？CV领域已经有了一套成熟的解决方案。我会用一个通用的网络模型，比如Vgg，ResNet或者GoogleNet，在ImageNet上做预训练（pre-training）。ImageNet有1400万张有标注的图片，包含1000个类别，这样的数据规模足以训练出一个规模庞大的模型。在训练过程中，模型会不断的学习如何提取特征，底层的CNN网络结构会提取边缘，角，点等通用特征，模型越往上走，提取的特征也越抽象，与特定的任务更加相关。当完成预训练之后，根据我自己的分类任务，调整最上层的网络结构，然后在小数据集里对模型进行训练。在训练时，可以固定住底层的模型参数只训练顶层的参数，也可以对整个模型进行训练，这个过程叫做微调（fine-tuning），最终得到一个可用的模型。总结一下，整个过程包括两步:  拿一个通用模型在ImageNet上做预训练（pre-training）  针对特定任务进行微调（fine-tuning）如此就可以完美解决了特定任务数据不足的问题。还有一个好处是，对于各种各样的任务都不再需要从头开始训练网络，可以直接拿预训练好的结果进行微调，既减少了训练计算量的负担，也减少了人工标注数据的负担。NLP领域也引入了这种做法，用一个通用模型，在非常大的语料库上进行预训练，然后在特定任务上进行微调，BERT 就是这套方案的集大成者。BERT不是第一个，但目前为止，是效果最好的方案。BERT用了一个已有的模型结构，提出了一整套的预训练方法和微调方法，我们在后文中再进行详细的描述。2. Encoder-Decoder在之前贴子关于 RNN / LSTM 的讨论中，我们均考虑的是输入输出序列等长的问题，然而在实际中却大量存在输入输出序列长度不等的情况，如机器翻译、语音识别、问答系统等。这时我们便需要设计一种映射可变长序列至另一个可变长序列的RNN网络结构，Encoder-Decoder框架呼之欲出。vieo. encoder-decoder模型Encoder-Decoder（编码-解码）是深度学习中非常常见的一个模型框架，比如无监督算法的 auto-encoding 就是用编码-解码的结构设计并训练的；比如这两年比较热的 image caption 的应用，就是 CNN-RNN 的编码-解码框架；再比如神经网络机器翻译 NMT 模型，往往就是LSTM-LSTM 的编码-解码框架。因此，准确的说，Encoder-Decoder 并不是一个具体的模型，而是一类框架。Encoder 和 Decoder 部分可以是任意的文字，语音，图像，视频数据，模型可以采用 CNN，RNN，BiRNN、LSTM、GRU 等等。所以基于 Encoder-Decoder，我们可以设计出各种各样的应用算法。Encoder-Decoder框架有一个最显著的特征就是它是一个 End-to-End 学习的算法。  End-to-End （端到端）学习：打一个比方，一个程序为了从输入得到输出，需要包括很多功能函数，一个做法是一个个实现这个函数，然后组成一个程序（非端到端），另一个做法是只写一个函数从输入一步到位给出输出（端到端）。在传统编程领域，后者一般是肯定会受到鄙视。但是在深度学习领域，更宽泛的说可微分编程领域，后者有极大的意义，它把所有模块放在一起，可以当成一个整体来训练，在前向推理的时候，可以一次性得到你想要的结果。这样做有什么意义？误差理论告诉我们误差传播的途径本身会导致误差的累积，多个阶段一定会导致误差累积，e2e训练能减少误差传播的途径，联合优化。相对于深度学习，传统机器学习的流程往往由多个独立的模块组成，比如在一个典型的自然语言处理（Natural Language Processing）问题中，包括分词、词性标注、句法分析、语义分析等多个独立步骤，每个步骤是一个独立的任务，其结果的好坏会影响到下一步骤，从而影响整个训练的结果，这是非端到端的。而深度学习模型在训练过程中，从输入端（输入数据）到输出端会得到一个预测结果，与真实结果相比较会得到一个误差，这个误差会在模型中的每一层传递（反向传播），每一层的表示都会根据这个误差来做调整，直到模型收敛或达到预期的效果才结束，这是端到端的。以文本-文本的例子作为介绍，这样的模型往往用在机器翻译中，比如将法语翻译成英语。这样的模型也被叫做 Sequence to Sequence learning（Sequence2Sequence）。所谓编码，就是将输入序列转化成一个固定长度的向量；解码，就是将之前生成的固定向量再转化成输出序列。这里复习下 Sequence2Sequence 任务到底是什么，所谓的 Sequence2Sequence 任务主要是泛指一些 Sequence 到 Sequence 的映射问题，Sequence 在这里可以理解为一个字符串序列，当我们在给定一个字符串序列后，希望得到与之对应的另一个字符串序列（如翻译后的字符串、或者如语义上对应的字符串）时，这个任务就可以称为 Sequence2Sequence 了。在现在的深度学习领域当中，通常的做法是将输入的源 Sequence 编码到一个中间的 context 当中，这个 context 是一个特定长度的编码（可以理解为一个向量，或者就是前面已经被误用的 embedding），然后再通过这个 context 还原成一个输出的目标 Sequence。Encoder-Decoder 框架可以这么直观地去理解：可以把它看作适合处理由一个句子（或篇章）生成另外一个句子（或篇章）的通用处理模型。对于句子对 ${X,Y}$，我们的目标是给定输入句子 $X$，期待通过 Encoder-Decoder 框架来生成目标句子 $Y$。$X$ 和 $Y$ 可以是同一种语言，也可以是两种不同的语言。而 $X$ 和 $Y$ 分别由各自的单词序列构成：\\[\\begin{aligned}X = \\{x_1,x_2,...,x_m\\}\\\\Y = \\{y_1,y_2,...,y_n\\}\\end{aligned}\\]Encoder 对输入句子 $X$ 进行编码，将输入句子通过非线性变换转化为中间语义表示 $c$\\[c = \\mathcal F(x_1,x_2,...x_m)\\]Decoder 根据句子 $X$ 的中间语义表示 $c$ 和之前已经生成的历史信息 $y_1,y_2,…,y_{i-1}$ 来生成i时刻要生成的单词 $y_i$\\[y_i = \\mathcal G(c,y_1,y_2,...,y_{i-1})\\]每个 $y_i$ 都依次这么产生，那么看起来就是整个系统根据输入句子 $X$ 生成了目标句子 $Y$。整个编码-解码阶段的目标是将输入 $c$ 转换成目标序列 $Y$，即最大化如下的条件概率\\[{\\rm max}_\\theta \\frac{1}{N} \\sum_{n=1}^N logP_\\theta(\\boldsymbol y_n\\vert \\boldsymbol x_n)\\]其中，$\\theta$ 是模型的参数集合，每一个 $(\\boldsymbol x_n,\\boldsymbol y_n)$ 对都是一个训练集。2.1. RNN E-D2.1.1. 实现  参考：学术状态抽奖器. 深度学习（BOT方向） 学习笔记（2） RNN Encoder-Decoder 及 LSTM 学习张俊林博客. 使用Encoder-Decoder模型自动生成对联的思路最经典的 Encoder-Decoder 实现方式，即用 RNN 来实现。在RNN Encoder-Decoder 的工作当中，我们用一个 RNN 去模拟大脑的读入动作，用一个特定长度的特征向量去模拟我们的记忆，然后再用另外一个 RNN 去模拟大脑思考得到答案的动作，将三者组织起来利用就成了一个可以实现 Sequence2Sequence 工作的“模拟大脑”了。关于 RNN 的介绍这里不做展开，详见 另一个帖子。下面以对联为例采用 RNN 来阐述生成过程，那么架构图如下图所示只需要找到大量的对联数据对这个模型进行训练，那么即可利用这个模型，输入上联，机器自动产生下联了。具体实现方式如下  第一步：根据语句顺序，依次将输入 $X$ 的每一个词 $x_t$ 都经过一个 embedding 层进行编码（比如通过 word2vec），得到 word embedding，然后将其输入 RNN，得到第 $t$ 时刻的隐层状态 $h_t$。在 RNN 中，当前时间的隐藏状态是由上一时间的状态和当前时间输入决定的，也就是\\[h_t = f(h_{t-1},x_t)\\]  第二步：输入完 $X$ 获得了各个时间段的隐藏层以后，再将隐藏层的信息汇总，生成最后的语义向量 $c$\\[c = q(h_1, h_2, ..., h_m)\\]一种简单的方法是，直接将最后的隐藏层作为语义向量 $c$，即\\[c = h_m\\]  第三步，将 $c$ 作为 Decoder 的初始隐层，输入 [EOS]（应该为 [SOS] 或者 [BOS]，图中有误） 生成第一个输出词向量，RNN 的隐层也被更新为 $H1$。[SOS] Start Of Sentence / [BOS] Begin of Sentence，是一个起始符号，作为生成句子的起点，这个起始符号经过 embedding 层，输入 RNN 得到编码表示，然后将表示向量通过 softmax，得到生成的词出现的概率，选出比如概率最高的那个词作为输出结果。  第四步，如此反复，将上一次输出的词作为下一次的输入，经过 embedding，softmax，得到本次预测输出的词向量概率，并且用于下一次输入，同时更新 RNN 隐层。使用我们期望生成的句子（训练 pair 中的 $Y$）中的词按照同样的方式处理，每次处理都会产生一个词的概率向量。我们希望的是，产生的词的概率向量接近下一步实际输入的词的 one-hot 表示，所以我们会计算生成的词的概率向量构成的张量与我们期望的词构成的 one-hot 编码张量的损失（交叉熵之类的）。然后利用优化算法减小损失。解码阶段可以看做编码的逆过程。$t$ 时刻，首先更新 Decoder 的隐层状态\\[H_t = f(H_{t-1},y_{t-1})\\]这个阶段，我们要根据给定的语义向量 $c$ 和之前已经生成的输出序列 $y_1,y_2,…,y_{t−1}$ 来预测下一个输出的单词 $y_t$，而解码输出某个词 $y_t$ 的概率\\[P(y_t)=p(y_t \\vert \\{y_1, y_2, ..., y_{t-1}\\},c) = g(y_{t-1},H_{t})\\]从 整个历史角度 来看，$t$ 时刻输出的单词 $y_t$ 是 $1$ 到 $t-1$ 时刻的输出 $y_1,…,y_{t-1}$ 和语义向量 $c$ 一起作为条件的基础上得到的。从 前一时刻角度 来看，$y_t$ 是前一时刻 $t-1$ 的输出 $y_{t-1}$ 和隐层向量 $H_t$ 一起作为条件的基础上得到的（此时 $y_1,…,y_{t-2}$ 被编码进了 $H_{t-1}$， $H_{t-1}$ 和 $y_{t-1}$ 一起得到 $H_t$）。  第五步，理论上 Decoder 可以无限的进行下去，但是一般只需要某一段输出，因此在输出一个结束标号后，进行截断。对于整个输出序列 $y$，我们需要使得实际输出与期望输出尽可能的吻合，问题就转化为\\[{\\rm max}_\\theta P(y) = {\\rm max}_\\theta  \\prod_{t=1}^n P(y_t) = {\\rm max}_\\theta \\sum_{t=1}^n{\\rm ln}P(y_t)\\]这个式子是一个条件概率的连乘，相当于最大似然估计。即找到一组参数 $\\theta$，使得从 $t=1$ 时刻到 $t=T$ 时刻输出的单词的概率是样本期望输出概率的最大似然？2.1.2. 结构下面分析采用多层 LSTM 构建的 Encoder-Decoder 的网络结构。首先给出 Encoder 的网络结构  input：单词的 one-hot 向量，这个向量的维度与字典容量有关，比如字典里有 1000 个常用单词，那么向量维度就是 1000；  embedding：对 input 进行 word2vec 操作，将其转化为稠密的低维向量，得到 embedded_input；  MultiLayer_LSTM：多层 LSTM ；  hidden_state：隐层状态，维度是自定义的，承载着输入词的信息。当前时刻的 hidden_state 将被存储作为历史信息；  output：输出，其实我们不关心；  prev_hidden_state：在下一时刻根据输入向量 embedded_input 更新为 hidden_state，即存储了下一时刻输入词的信息。当输入序列到底时，一般取最后一次更新的 hidden_state 作为语义向量 $c$，传给 Decoder。下面给出 Decoder 的网络结构Decoder 与 Encoder 唯一关联的就是隐层变量 hidden_state。Encoder 得到的语义向量 $c$ 作为 Decoder 的 hidden_state 的初值。  input：单词的 one-hot 向量。在初始时刻为自定义的开始标志 [SOS] 或者 [GO] 等。  embedding：对 input 进行 word2vec 操作，将其转化为稠密的低维向量，得到 embedded_input；  MultiLayer_LSTM：多层 LSTM ；  hidden_state：实际上hidden_state 应该位于 LSTM 与 Dense_Layer 之间；  Dense_Layer：全连接层，将得到的 hidden_state 映射成一个维度与字典相关的向量（比如 1000 维）。因此这个过程也叫维度映射。生成的 hidden_state 已经包含了待生成的词的信息了，但是要生成具体的词，我们还需要知道目标语言中每个词的条件概率 $p(y_i|s_i)$，如果 $s_i$ 的维度就是目标语言的词典大小，那么使用 softmax 就可以算出每个词的概率，但是 $s_i$ 的维度也属于模型的一个参数，通常是不会等于目标语言词典的大小的。因此再增加一个全连接层，将 $s_i$ 映射为维度等于词典大小 $N$ 的向量 $v_i$（output_logits），每个维度代表一个词，使用 softmax 计算出每个词的概率。  output_logits：经过维度映射得到的输出向量 $v_i$；  softmax：对输出向量进行概率层面的归一化，得到 output。在学习训练时，与期望的 one-hot 形式的 output 之间可以计算交叉熵。在推理测试时，根据 softmax 的结果选择概率最高的词作为预测输出和下一时刻的输入。有时为了简便起见也直接用 argmax 得到取值最大的那个维度对应的词作为输出，且作为下一时刻的输入，如下图。2.1.3. 分析举个栗子：我们希望Decoder能够生成这样一句话 “张三有很多儿子”。当 decoder 接收 EOS 作为起始词后，经过 embedding，RNN，softmax 后生成了一个概率向量，这个概率向量表达了词表中每个词作为生成词的概率。因为decoder没有经过训练，所以概率最大词很可能不是“张”，而是其他词，我们希望的状况就是这个概率向量就是“张”的 one-hot 表示，那么实际生成的概率向量和实际的概率向量之间就存在损失（误差）。同样的，我们下一步会把 “张” 输入到 decoder 中，希望经过一系列处理后 decoder 能够生成“三”的 one-hot，而实际生成的概率向量也是存在偏差，就这样我们把整个句子输入到 decoder 中，就可以得到整个句子的偏差，我们下面就通过优化来减小这个偏差。Encoder-Decoder 模型虽然非常经典，但是局限性也非常大。最大的局限性就在于编码和解码之间的唯一联系就是一个固定长度的语义向量 $c$。也就是说，编码器要将整个序列的信息压缩进一个固定长度的向量中去。但是这样做有两个弊端，一是语义向量只是对整个序列的概括，无法完全表示整个序列的信息；二是先输入的内容携带的信息会被后输入的信息稀释掉，或者说，被覆盖了。输入序列越长，这个现象就越严重。这就使得在解码的时候一开始就没有获得输入序列足够的信息， 那么解码的准确度自然也就要打个折扣了。2.2. attention modelAttention Model 即注意力机制，也称为对齐模型(alignment model)，是为了解决固定长度的语义向量存在的弊端的。Attention-based 框架与传统的 Encoder-Decoder 框架的差异在于，语义向量 $c$ 并非固定不变的，而是随着 Decoder 端不同时刻的输出而改变。在翻译任务中，准备生成每个新的词的翻译时，这个机制可以将注意力集中在输入的某个或某几个词上，重点关注这几个词，可以想象成是将他们与待生成的翻译进行对齐，使得翻译更精准。在对联任务中，Encoder-Decoder 框架加上 Attention 应该会显著提升产生下联的质量，原因还是因为它是要求严格对仗的，所以在生成下联某个字的时候，找到对应上联相应字作为生成的重点参考信息无疑是非常重要的。比如看到上联的“三”字，Attention模型使得下联产生对应字 “一” 的时候重点参考上联的 “三” 这个字，应该知道对应的应该是一个数字型汉字。下图是加上 Attention 模型的示意图。增加 attention 机制后，Decoder 过程可以拆分成如下几个部分2.2.1. attention score  Sophia$. Seq2Seq Attention输入输出维度分析-最详细  DownUp. 深度学习方法（九）：自然语言处理中的Attention Model注意力模型  Bahdanau et al.. NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATEattention score 表征原始输入序列 $x_t$ 对即将生成的目标词 $y_i$ 的影响能力。根据此时每个输入词的 score 大小，就可以知道应该使用哪个词与当前的 $y_i$ 进行对齐。参考前面的对联编码-解码示意图，我们知道 $H_2$ 是第三个解码时刻的隐含状态（第一个解码时刻 $H_0 = c$）。从上帝视角来看，与 $H_2$ 最相关的部分应该是 “三” 对应的编码状态 $h_3$。因此，只要网络在第三个解码时刻时，将注意力集中于 $h_3$ 就算达成目的了。更加一般的注意力模型示意图如下图所示。已知输入序列 $X_1, X_2,…,X_T$，在第 $t$ 时刻输出 $y_t$ 时，我们希望相应的语义变量 $c$ 不再是固定的，而是与当前时刻输出挂钩，即 $C_t$。当前时刻的 $C_t$ 一般是输入序列隐层状态的加权和，其中权重为 attention weights，记作 $\\alpha_{tj}$。注意力权重与输入输出的匹配程度有关，这个匹配度就是注意力得分（attention score）。匹配度的数学表示如下\\[e_{ij} = score(s_{i-1},h_j)\\]式中 $e_{ij}$ 衡量了第 $j$ 个输入与第 $i$ 个输出的匹配度。$s_{i-1} = H_{i-1}$ 是输出 $y_i$ 前的隐层，$h_j$ 是第 $j$ 个时刻输入的隐层，也就是说，匹配度基于输入输出的隐层来计算。匹配度的计算有两种方式\\[\\begin{aligned}e_{ij} = score(s_{i-1},h_j) = \\left\\{ \\begin{matrix}s_{i-1}^T W h_j \\quad &amp;[Luong's\\ multiplicative\\ style]\\\\v^T tanh(U s_{t-1}+V h_j)\\quad &amp;[Bahdanau's\\ additive\\ style]\\end{matrix} \\right.\\end{aligned}\\]在论文 [Bahdanau et al., 2015] 中， 匹配度被称为校准模型（alignment model）。其中 $W, v, U, V$ 是权重矩阵，可以与整个模型共同训练。不同论文中的 $e_{ij}$ 计算方法不同。2.2.2. attention weights对匹配度得分进行归一化（采用 softmax）可以得到一个 $[0,1]$ 之间的值，即为注意力权重（attention weights ）\\[\\alpha_{ij} = \\frac{esp(e_{ij})}{\\sum_{j=1}^T esp(e_{ij})}\\]2.2.3. attention vector那么对于每一时刻的输出 $y_i$，对应的语义向量 $C_i$ 可以表示为\\[C_i = \\sum_{j=1}^T \\alpha_{ij}h_j\\]注意，虽然 $s_i$ 仅仅只与 $h_j$ 最为相关，但同样也受其它编码状态的影响（例如到句型复杂的时候）。但是，若是换了应用场景，只进行对应权重乘以对应隐含状态，不进行累加也是可以的。在原始的 Decoder 中，语义向量 $c$ 仅作为初始时刻的解码隐层。而在注意力机制下，我们将语义向量 $C_i$ 与 Decoder 端的隐层 $s_{i-1}$ 进行向量拼接 $[C_i, s_{i-1}]$，得到注意力向量（attention vector），来生成输出词的概率分布。2.2.4. 总结runze Zheng. 在Encoder-Decoder框架中加入Attention机制在 Encoder-Decoder 框架中加入 Attention 机制后的模型可总结为如下公式\\[\\begin{aligned}e_{ij} &amp;= score(s_{i-1},h_j)\\\\\\alpha_{ij} &amp;= \\frac{esp(e_{ij})}{\\sum_{j=1}^T esp(e_{ij})}\\\\C_i &amp;= \\sum_{j=1}^T \\alpha_{ij}h_j\\\\s_i &amp;= f(s_{i-1},y_{i-1},C_i)\\\\P(y_i\\vert y_1,y_2,...,y_{i-1},c) &amp;= softmax(y_{i-1},s_{i})\\end{aligned}\\]3. 参考文献[1] 刘斯坦. 怎么形象理解 embedding 这个概念？[2] Ethan. Embedding 的理解[3] vieo. encoder-decoder模型[4] 学术状态抽奖器. 深度学习（BOT方向） 学习笔记（2） RNN Encoder-Decoder 及 LSTM 学习[5] DownUp. 深度学习方法（九）：自然语言处理中的Attention Model注意力模型[6] _zhang_bei_. 自然语言处理中的Transformer和BERT[7] runze Zheng. 在Encoder-Decoder框架中加入Attention机制"
  },
  
  {
    "title": "PyTorch基础（张量）",
    "url": "/posts/pytorch-basic-1/",
    "categories": "Tutorial, Coding",
    "tags": "python, deep learning",
    "date": "2020-10-26 15:22:19 +0800",
    





    
    "snippet": "本文主要记录自己学习 PyTorch 过程中涉及的一些基础知识。  1. 张量维度          1.1. shape 属性      1.2. size() 成员函数        2. 张量比较          2.1. max        3. 参考文献1. 张量维度1.1. shape 属性输入import torch# dim=2,shape=[2,3],随机生成Tenso...",
    "content": "本文主要记录自己学习 PyTorch 过程中涉及的一些基础知识。  1. 张量维度          1.1. shape 属性      1.2. size() 成员函数        2. 张量比较          2.1. max        3. 参考文献1. 张量维度1.1. shape 属性输入import torch# dim=2,shape=[2,3],随机生成Tensora = torch.FloatTensor(2, 3)print(a.shape)print(a.shape[0])print(a.shape[1])输出为torch.Size([2, 3])231.2. size() 成员函数输入import torch# dim=2,shape=[2,3],随机生成Tensora = torch.FloatTensor(2, 3)print(a.size())print(a.size(0))print(a.size(1))输出为torch.Size([2, 3])232. 张量比较2.1. max不指定维度时，返回一个张量，为输入数据中的最大值&gt;&gt;&gt; a = torch.randn(1, 3)&gt;&gt;&gt; a    tensor([[ 0.6763,  0.7445, -2.2369]])&gt;&gt;&gt; torch.max(a)    tensor(0.7445)指定维度时，返回一个 tuple，包含沿着该维度的最大值和对应的序号。&gt;&gt;&gt; a = torch.randn(4, 4)&gt;&gt;&gt; atensor([[-1.2360, -0.2942, -0.1222,  0.8475],        [ 1.1949, -1.1127, -2.2379, -0.6702],        [ 1.5717, -0.9207,  0.1297, -1.8768],        [-0.6172,  1.0036, -0.6060, -0.2432]])&gt;&gt;&gt; torch.max(a, dim=1)torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1]))对于二维张量，dim=0 沿列求最大（跨行间比较），dim=1 沿行求最大（跨列间比较）。对于三维张量，构成为 (通道，行，列)，那么dim=0 通道间比较求最大，dim=1 跨行间比较求最大，dim=2 跨列间比较求最大。import torch a = torch.randn(2,3,4) #随机生成数组max_0=torch.max(a,dim=0) #针对第1个元素“2”，对应的是通道max_1=torch.max(a,dim=1) #针对第2个元素“3”，对应的是行max_2=torch.max(a,dim=2) #针对第2个元素“4”，对应的是列print(\"a:\\n\", a)print(\"************************************************\")print(\"max(a)_0:\", max_0)  #dim=0,通道间进行比较，所以返回每一张特征图，同一像素位置上的最大值print(\"max(a)_1:\", max_1)  #dim=1，行与行之间进行比较，所以返回每一张特征图，每一列的最大值print(\"max(a)_2:\", max_2)  #dim=2，列与列之间进行比较，所以返回每一张特征图，每一行的最大值 &lt;&lt;a: tensor([[[ 0.5323,  1.5229, -0.6122,  0.6054],         [ 1.2424, -1.6005,  0.0779,  0.9227],         [-0.6340, -0.5770, -0.1672,  0.3598]],         [[-0.3770, -0.4992,  1.8444, -1.1040],         [ 1.2238,  0.7283, -1.6462,  0.0325],         [-0.3555, -0.2599,  1.5741,  1.0683]]])************************************************max(a)_0: (tensor([[ 0.5323,  1.5229,  1.8444,  0.6054],        [ 1.2424,  0.7283,  0.0779,  0.9227],        [-0.3555, -0.2599,  1.5741,  1.0683]]), tensor([[ 0,  0,  1,  0],        [ 0,  1,  0,  0],        [ 1,  1,  1,  1]]))max(a)_1: (tensor([[ 1.2424,  1.5229,  0.0779,  0.9227],        [ 1.2238,  0.7283,  1.8444,  1.0683]]), tensor([[ 1,  0,  1,  1],        [ 1,  1,  0,  2]]))max(a)_2: (tensor([[ 1.2424,  1.5229,  0.0779,  0.9227],        [ 1.2238,  0.7283,  1.8444,  1.0683]]), tensor([[ 1,  0,  1,  1],也就是说，dim 参数是按照张量维度从左到右、从外到内的顺序进行比较的。3. 参考文献[1] 梦并不遥远. 4.3Python数据处理篇之Matplotlib系列(三)—plt.plot().[2] 我的明天不是梦. python使用matplotlib:subplot绘制多个子图."
  },
  
  {
    "title": "天文学基础（时间和历法）",
    "url": "/posts/astronomy-basic-time-calender/",
    "categories": "Academic, Knowledge",
    "tags": "astronomy",
    "date": "2020-10-20 21:00:19 +0800",
    





    
    "snippet": "本文介绍了天文学中基本的时间和历法知识。  1. 背景          1.1. 国际地球自转和参考系服务      1.2. 国际天文学联合会        2. 时间          2.1. 太阳时      2.2. 恒星时      2.3. 格林尼治标准时间（GMT）      2.4. 世界时（UT）      2.5. 原子时（TAI）      2.6. 协调世界时（U...",
    "content": "本文介绍了天文学中基本的时间和历法知识。  1. 背景          1.1. 国际地球自转和参考系服务      1.2. 国际天文学联合会        2. 时间          2.1. 太阳时      2.2. 恒星时      2.3. 格林尼治标准时间（GMT）      2.4. 世界时（UT）      2.5. 原子时（TAI）      2.6. 协调世界时（UTC）      2.7. GPS时间      2.8. 历书时      2.9. 力学时      2.10. 地球时      2.11. 各时间的转换关系        3. 历法          3.1. 儒略历（Julian calendar）      3.2. 格里高利历（Gregory Calendar）      3.3. 儒略记日法（Julian Day）      3.4. 儒略日数（JDN）      3.5. 儒略日（JD）      3.6. 简化的儒略日      3.7. 标准历元（J2000.0）      3.8. 由格里历计算儒略日JD      3.9. 由格里历算简化的儒略日      3.10. 计算标准历元起的儒略日      3.11. 计算标准历元起的儒略世纪        4. 参考文献1. 背景1.1. 国际地球自转和参考系服务国际地球自转和参考系服务（International Earth Rotation and Reference System, IERS）（官网：https://www.iers.org/IERS/EN/Home/home_node.html ）的主要目标是通过提供国际陆空参考系统的入口来为天文学、测地学和地球物理学的研究团体服务。该网站提供了有关国际地球自转服务中心的任务、机构设置、成员以及相关产品的详细信息，同时还提供了通向其数据库和公告中的观测数据与研究结果的入口。国际地球自转服务(International Earth Rotation Service-简称IERS)由国际大地测量学和地球物理学联合会及与国际天文学联合会联合创办，用以取代国际时间局(BIH)的地球自转部分和原有的国际极移服务(IPMS)。1.2. 国际天文学联合会国际天文学联合会（International Astronomical Union, IAU）（官网：https://www.iau.org/ ）是世界各国天文学术团体联合组成的非政府性学术组织，其宗旨是组织国际学术交流，推动国际协作，促进天文学的发展。国际天文学联合会于1919年7月在布鲁塞尔成立。天文学联盟有73个成员国，其中包括专业天文学研究达到较高程度的大多数国家。天文学联盟的一个主要从事地面和空间天文学各学科的10528 多名成员的直接参与。2. 时间2.1. 太阳时太阳时（Solar time）是一种以地球自转为基础的时间计量系统，以地球相对于太阳的自转周期为基准，用太阳对于该地子午圈的时角来量度，基础时间单位为太阳日。太阳时的初始时刻，以太阳在该地下中天瞬间作为太阳时零时。太阳时的类型分别为真太阳时（apparent solar time或sundial time）和平太阳时（mean solar time或clock time）。地球表面活动的人们，习惯以太阳在天球上的位置来确定时间，因此将太阳连续两次经过上中天的时间间隔称为真太阳日，地方真太阳日12时为太阳在该地上中天瞬时。然而，地球绕太阳公转运动的轨道是椭圆，太阳位于该椭圆的一个焦点上，所以地球在轨道上做的是不等速运动，真太阳周日视运动的速度是不均匀的，不易选做计时单位。为了得到以真太阳周日视运动为基础而又克服其不均匀性的时间计量系统，人们引入了平太阳日的概念。天文学上假定由一个太阳（平太阳）在天赤道上（而不是在黄赤道上）作等速运行，其速度等于运行在黄赤道上真太阳的平均速度，这个假想的太阳连续两次上中天的时间间隔，叫做一个平太阳日。这也相当于把一年中真太阳日的平均称为平太阳日，并且把1/24平太阳日取为1平太阳时。人们日常生活中使用的“日”和“时”，就是平太阳日和平太阳时的简称。平太阳时的基本单位是平太阳日，1平均太阳日等于24平均太阳小时，1平均太阳小时等于86400平均太阳秒。2.2. 恒星时恒星时（Sidereal time）是一种以地球自转为基础的时间计量系统，以地球相对于恒星的自转周期为基准。恒星时基础时间单位为恒星日，将春分点相继两次经过上中天的时间间隔称为恒星日，并以春分点在该地上中天的瞬间作为这个计量系统的起点，即恒星时零时。由于地球的章动，春分点在天球上并不固定，而是以18.6年的周期围绕着平均春分点摆动。因此恒星时又分为真恒星时和平恒星时。真恒星时是通过直接测量子午线与实际的春分点之间的时角获得的，平恒星时则忽略了地球的章动。真恒星时与平恒星时之间的差异最大可达约0.4秒。受到地球公转的影响，一个恒星日的长度要比一个太阳日的长度略短，一个平恒星日约等于23时56分4.09秒平太阳时。任何给定地点的恒星时将比当地民用时间每24小时增加约4分钟，直到一年过去后，与过去的太阳日数相比，恒星时要多一个恒星日。2.3. 格林尼治标准时间（GMT）格林尼治标准时间（Greenwich Mean Time, GMT）是英国伦敦格林尼治 当地的平太阳时，以平子夜作为0时开始。历史上格林尼治标准时间的定义和计算较为混乱。比如，天文学领域常以正午12时作为格林尼治标准时间开始的计算方法，也有地方将其作为协调世界时UTC+0的别名。在导航领域，GMT常常被认为与UT1等同。正因为如此混乱的定义与使用，格林尼治标准时间不可以被单独作为精确的时间标准。1935年，国际天文学联合会推荐使用“世界时”一词，作为比格林威治标准时间更精确的术语，用以指代以平子夜作为0时开始的格林尼治标准时间。但在一些应用中（英国广播公司国际频道、英国气象局、英国皇家海军、中东广播中心等），格林威治标准时间一词在民用计时方面一直沿用至今。2.4. 世界时（UT）世界时（Universal Time, UT）是一种以地球自转为基础的时间计量系统。世界时理论上通过观测太阳的日运动来定义，但由于精确观测太阳十分困难，因此往往退而求其次，使用长基线干涉测量法确定遥远类星体位置、对月球和人造卫星进行激光测距、以及对GPS卫星进行轨道确定来计算。世界时包含四个版本，区别在于包含不同的修正项调整来接近太阳时。世界时的四个版本定义如下：      UT0：UT0是通过天文太观测恒星或河外射电源的日运动以及对月球和人造地球卫星的测距观测确定的世界时。UT0不包含任何校正，并且已不再常用；        UT1：UT1是在UT0的基础上增加地球极移修正后得到的，是世界时的主要形式。在确定UT0时，假定天文台的位置在地球参考系（如国际地球参考系）中坐标固定。但是，地球自转轴的位置并不固定，而是在地球表面漂移，即极移。因此，定义UT1时考虑并增加了极移修正；        UT1R：UT1R是在UT1的基础上增加周期性潮汐变化修正后得到的，它包括62个修正项，周期从5.6天到18.6年不等；        UT2：是在UT1的基础上增加季节性变化修正后得到的，已经不再常用。  世界时曾长期被认为是稳定均匀的时间计量系统，历史上得到广泛应用。后文如无特别说明，世界时均指的是UT1。2.5. 原子时（TAI）1955年铯原子钟的发明，提供了一种比天文观测更稳定且更方便的授时机制。1967年第13届国际计量大会上通过一项决议，给出了新的国际单位“秒”的定义，一秒为铯-133原子基态两个超精细能级间跃迁辐射振荡9192631770周所持续的时间，其稳定度可以达到{10}^{-14}以上。原子时（Temps Atomique International，TA或TAI）就是根据上述秒的定义确定的一种新的国际参照时标，其初始时间为1958年1月1日世界时0时，即在这一瞬间TA和UT1重合 。目前，国际原子时由国际计量局收集50多个国400多个实验室的原子钟比对和时号发播资料进行综合处理后建立，可参考：  Bureau International des Poids et Mesures (BIPM) Time Department”. Report of the International Association of Geodesy 2011-2013. http://iag.dgfi.tum.de/fileadmin/IAG-docs/Travaux2013/08_BIPM.pdf各个国家为了满足各个行业对实时时间信号的需要，建立各国的实时的时间尺度——地方原子时TA（k），k为实验室代号。TA（JATC）是由国家授时中心联合国内其他单位成立综合原子时委员会（Joint Atomic Time Commission）负责建立的独立地方原子时尺度，1987年起参加国际原子时TAI计算，从未中断。2.6. 协调世界时（UTC）C协调世界时（英语Coordinated Universal Time，法语Temps Universel Coordonné，二者妥协后简称UTC）是最主要的世界时间标准，其以原子时秒长为基础，作为格林尼治标准时间的替代，在时刻上尽量接近于格林尼治标准时间（也即世界时UT1）。虽然国际原子时更为精密，但在实际应用中人们希望时间系统更加接近世界时，因为其更加贴近人们日常感官上的时间流逝。因此，1972年提出协调世界时的折中时标，它既保持时间尺度的均匀性，又能近似地反映地球自转的变化。协调世界时由国际计量局（Bureau International des Poids et Mesures，BIPM）维护。由于协调世界时与世界时的时间单位的不一致性，二者之差逐年积累，便采用跳秒（闰秒）的方法使二者的时刻相差不超过1秒。1972年，国际计量大会决定，当世界时与协调世界时之间时刻相差超过0.9秒时，就在协调世界时上加上或减去1秒，以尽量接近世界时，这就是闰秒。闰秒一般在12月31日或6月30日末加入。具体日期由国际地球自转服务组织（1ERS）安排井通告。由于几十年来地球自转正在逐渐变慢，国际计时机构一共实行了二十多次闰秒操作，确保我们协调世界时与地球自转速度相匹配，截至目前协调世界时已经正闰秒37秒。国家授时中心每月均会发布《时间频率公报》，其中包含协调世界时和原子时之间的时差，可在知网查看和下载【2】。以2021年12月31日为例，原子时和协调世界时之差为\\[\\begin{aligned}&amp;\\rm UTC = UT1 + DUT1 = UT1+37s+63.901us\\\\&amp;(DUT1 &lt; 0.9s)\\end{aligned}\\]经过闰秒调整之后，协调世界时与世界时的差值称为DUT1，可以从美国国家标准与技术研究院（National Institute of Standards and Technology，NIST）获得【1】，以2021年12月31日为例，差值为\\[\\rm DUT1 = UT1-UTC = -110.4ms\\]也可以通过IERS官网保持更新的 Bulletin D 来查询最新的DUT1，以2021年12月31日为例，查询得到的结果为\\[\\rm DUT1 = -0.1s\\]UTC与TAI的差值由IERS保持更新的 Bulletin C 来查询，以2021年12月31日为例，查询得到的结果为\\[\\rm UTC-TAI=-37s\\]  IERS Bulletin 发布网址：https://www.iers.org/IERS/EN/Publications/Bulletins/bulletins.html北京时间为 $\\rm UTC^{+8}$，与 $\\rm UTC$ 的关系为\\[\\rm UTC^{+8} = UTC + 8\\]2.7. GPS时间GPS时间，也就是GPS原子时，参照美国海军天文台（United States Naval Observatory，USNO）的主时钟（Main Clock，MC）为基准。GPS时间的初始原点定义为在1980年1月6日0点与世界协调时相等，以后按原子时秒长累积计时且不包含闰秒。GPS时间跟UTC时间之差为秒的整倍数。GPS导航采用GPS时间，计量单位为GPS周和GPS秒。由于1980年1月6日，协调世界时已经正闰秒19秒，因此截至目前（2021年12月31日）GPS时与世界协调时的时差为18秒。2.8. 历书时前面所述的太阳时、恒星时和世界时都是以地球自转为基础的时间计量系统。然而，地球自转一直在变缓，而且变缓规律难以预测，这使地球自转为基础的时间计量系统是一种不均匀的时间系统。但是，天文学家们需要一个更加均匀的时间标尺来进行精确计算（虽然UTC是一种均匀的时间计量系统，但它需要随时通过跳秒来保持与世界时的一致，这种不连续性使其无法用于天文计算）。1958年，国际天文学联合会决议，自1960年开始用历书时（Ephemeral Time，ET）代替世界时作为基本的时间计量系统，并规定世界各国天文年历的太阳、月球、行星历表，都以历书时为准进行计算。历书时基于地球公转定义，历书时秒的定义为1900年1月0日12时正回归年长度的1/31556925.9747（也就是平太阳时的1秒）。历书时可以通过对太阳、月球或其他行星的观测二获得。相比于地球自转，地球公转要稳定的多，但仍然不是严格均匀的运动，只能达到 $10^{-10}s$ 级别。由于历书时的测定精度较低，1967年起已用原子时代替历书时作为基本的时间计量系统，但当时在天文历表上仍用历书时。1976年第十六届国际天文学联合会决议，从1984年起天文计算和历表上所用的时间单位，也都以原子时秒为基础（力学时）。2.9. 力学时由于历书时所用的基准地球运动的理论框架是牛顿力学，根据广义相对论可知，在以太阳为中心的坐标系和以地球为中心的坐标系中时间将会不同。因此，在1979年国际天文学联合会第17届大会分别定义了两个新的相对论时间标准：太阳系质心力学时（Barycentric Dynamical Time，TDB）和地球力学时（Terrestrial Dynamical Time，TDT）。质心力学时和地球力学时可以看作是历书时分别在两个坐标系中的继承。国际天文学联合会（IAU）规定TDT与TDB之间的平均钟速相等，二者之差不存在长期项，只存在周期性差异，且这种周期性差异是由于相对论效应而引起的。TDT主要用于给出天体在底薪坐标系中的视位置，计算天体在地心坐标系中的方程中的时间变量也应该使用TDT。月球、太阳、行星的历表则以TDB为时间变量，岁差、章动计算公式也是以TDB为时间变量的。TDB和TDT的引入并没有完全解决时间基准面临的问题，反而出现了很多争议，如：1）对“动力学”（Dynamical）一词如何解释？；2）TDT被定义为“TAI理想化形式”的时候是坐标时，但在某些情况下又被解释成是在地心的本征时；等等。2.10. 地球时为了解决引入 $\\rm TDB$ 和 $\\rm TDT$ 存在的问题，1991年国际天文学联合会第21届大会做出决议，定义地球时（Terrestrial Time，TT）取代 $\\rm TDT$ 作为视地心历表的时间变量，同时定义了相对论框架下的太阳系之心天球参考系（BCRS）和地球质心天球参考系（GCRS）。地球时的秒长与原子时相同，时间原点定义为在原子时1977年1月1日00:00:00瞬间，地球时的读数为1977年1月1日00:00:32.184。 $\\rm TT$ 与 $\\rm TDT$ 的秒长和时间原点相同，可以认为是等价的。不过TT更加明确为一种坐标时，从而解决了TDT定义在时间性质方面的不确定性。即\\[\\rm TT = TAI + 32.184s\\]$\\rm TT$ 与 $\\rm UT1$ 之间的时差 $\\rm \\Delta T$ 可有美国海军天文台发布的historic_deltat.data、deltat.data、deltat.preds三个数据文件提供（包括1657-2023年间的具体数值），且定期对数据进行更新。还可以由IERS发布的 EOP 08 C04 模型中的  $\\rm DUT1$ 、IERS Bulletin C 中的 LeapSecond 数据经计算后得到\\[\\rm \\Delta T=TT-UT1=LeapSecond+32.184-DUT1\\]$\\rm TDB$ 和 $\\rm TT$ 之间没有长期漂移，只有周期项变化，即\\[\\rm TDB = TT + 0.001658sin(M)+0.000014sin(2M)+\\frac{V_e(X-X_0)}{c^2}\\]其中，$M$ 为地球绕日公转的平近点角，$V_e$ 为地球质心在太阳系质心坐标系中的公转速度矢量，$X_0$ 为地心在太阳系质心坐标系中的位置矢量，$X$ 为地面钟在太阳系质心坐标系中的位置矢量，$X-X_0$ 实际上就是在太阳系质心坐标系下地面钟相对于地心的位置矢量，$c$ 为真空光速。可以采用 $\\rm TT$ 代替 $\\rm TDB$，因为二者之间的差带来的影响可以忽略不计。所以虽然 JPL 星历使用 TDB ，但是可以直接用 TT 来代替。参考：赵玉晖《深空探测中的轨道设计和轨道力学》2.11. 各时间的转换关系参考：赵玉晖《深空探测中的轨道设计和轨道力学》3. 历法3.1. 儒略历（Julian calendar）儒略历（Julian calendar）是由罗马共和国独裁官儒略·凯撒采纳埃及亚历山大的数学家兼天文学家索西琴尼的计算后，于公元前45年1月1日起执行的取代旧罗马历法的一种历法。儒略历中，一年被划分为12个月，大小月交替；四年一闰，平年365日，闰年366日为在当年二月底增加一闰日，年平均长度为365.25日。由于实际使用过程中累积的误差随着时间越来越大，1582年教皇格里高利十三世颁布、推行了以儒略历为基础改善而来的格里历，即公历。3.2. 格里高利历（Gregory Calendar）是由意大利医生兼哲学家 Aloysius Lilius 对儒略历加以改革而制成的一种历法——《格里历》。1582年，时任罗马教皇的格列高利十三世予以批准颁行。格里历即为现行的公历，日期包括年、月、日。格里历 + UTC 即为日常的日期时间的定义。3.3. 儒略记日法（Julian Day）Julian Day，儒略记日法是在儒略周期内以连续的日数计算时间的计时法，是一种不用年月的长期记日法。由 Joseph Justus Scaliger 发明，为了将所有历史日期用一个系统表述，天文学家经常用JD来赋予每天一个唯一的数字，方便追朔日期。  https://en.wikipedia.org/wiki/Julian_day Julian day is the continuous count of days since the beginning of the Julian Period and is used primarily by astronomers, and in software for easily calculating elapsed days between two events (e.g. food production date and sell by date).[1]3.4. 儒略日数（JDN）Julian Day Number，指从UT1时正午开始的一整天，是一个整数。  https://en.wikipedia.org/wiki/Julian_day The Julian Day Number (JDN) is the integer assigned to a whole solar day in the Julian day count starting from noon Universal time, with Julian day number 0 assigned to the day starting at noon on Monday, January 1, 4713 BC, proleptic Julian calendar (November 24, 4714 BC, in the proleptic Gregorian calendar),[2][3][4] a date at which three multi-year cycles started (which are: Indiction, Solar, and Lunar cycles) and which preceded any dates in recorded history.[5] For example, the Julian day number for the day starting at 12:00 UT on January 1, 2000, was 2 451 545.[6]JDN0 指定为：  格里历4714BC的11月24日UT1时12:00:00开始的24小时或  儒略历4713BC的1月1日UT1时12:00:00开始的24小时。例如，格里历2000年1月1日UT1时12:00:00开始的JDN是2451545。3.5. 儒略日（JD）Julian Date，JD 等于 JDN 加上从 UT1 时 12 时起的小数日部分。2013年1月1日UT1时00:30:00.000，JD = 2456293.5208332020年3月30日UTC时01:35:00.000，JD = 2458937.62847= 2020年3月30日UT1时01:35:00.100历史上，儒略日基于 $\\rm GMT$ 来记录，自1997来，IAU建议以 $\\rm TT$ 为单位记录JD。Seidelmann 指出儒略日期可以与国际原子时（$\\rm TAI$）、地球时间（$\\rm TT$）、协调质心时间（$\\rm TCB$）、协调世界时（$\\rm UTC$）一起使用，当差异显著时，应指示刻度。通过将中午后的小时、分钟和秒数转换为等效的小数部分，可以找到一天中的小数部分。  https://en.wikipedia.org/wiki/Julian_day The Julian date (JD) of any instant is the Julian day number plus the fraction of a day since the preceding noon in Universal Time. Julian dates are expressed as a Julian day number with a decimal fraction added.[7] For example, the Julian Date for 00:30:00.0 UT January 1, 2013, is 2 456 293.520 833.[8]Current value is as of 01:35, Monday, March 30, 2020 (UTC)  Historically, Julian dates were recorded relative to Greenwich Mean Time (GMT) (later, Ephemeris Time), but since 1997 the International Astronomical Union has recommended that Julian dates be specified in Terrestrial Time.[12] Seidelmann indicates that Julian dates may be used with International Atomic Time (TAI), Terrestrial Time (TT), Barycentric Coordinate Time ( $\\rm TCB$ ), or Coordinated Universal Time (UTC) and that the scale should be indicated when the difference is significant.[13] The fraction of the day is found by converting the number of hours, minutes, and seconds after noon into the equivalent decimal fraction. Time intervals calculated from differences of Julian Dates specified in non-uniform time scales, such as UTC, may need to be corrected for changes in time scales (e.g. leap seconds).[7]3.6. 简化的儒略日由于儒略日的整数部分过长，为了便于使用，1957年史密松天体物理天文台，将儒略日进行了简化，并将其命名为简化儒略日，其定义为：MJD=JD-2400000.5。JD2400000是1858年11月16日中午12时，因为JD从中午开始计算，所以简化儒略日的定义中引入偏移量0.5，这意味着MJD0相当于1858年11月17日0时。每一个简化儒略日都在世界时午夜开始和结束。简化儒略日有两个目的：1) 日期从午夜而不是中午开始；2) 儒略日的整数部分由7位数减为5位数，节省计算机储存空间。3.7. 标准历元（J2000.0）标准历元（J2000.0）是天文学上使用的历元，前缀J表示是一个儒略纪元。1994年IAU决议明确了新的标准历元为  2000年1月1日 TT时  12:00:00= 2000年1月1日 TAI时 11:59:27.816= 2000年1月1日 UTC时 11:58:55.816记为 J2000.0。3.8. 由格里历计算儒略日JD首先根据日期时间得到年 $Y$，月 $M$，日 $D$然后调整 $Y$ 和 $M$\\[\\begin{aligned}\\left\\{\\begin{matrix}&amp;M = M+2, Y = Y - 1&amp;\\quad(M&lt;3)\\\\ &amp;M = M, Y = Y&amp;\\quad(M\\geq3)\\end{matrix}\\right.\\end{aligned}\\]换句话说，如果日期在 1 月或者 2 月，则被看作时前一年的 13 月或 14 月。然后计算辅助系数 $A$ 和 $B$\\[\\begin{aligned}A &amp;= floor(Y/100)\\\\B &amp;= 2-A+floor(A/4)\\end{aligned}\\]然后计算 JD\\[JD=floor(365.25\\times (Y+4716))+floor(30.6001\\times(M+1))+D+B-1524.5\\]计时间为时 $H$，分 $N$，秒 $S$，毫秒 $MS$，微秒 $US$，将其转换为天为单位，叠加到 JD\\[JD = JD + H/24 + N / 1440 + S/86400 + MS / 86400000 + US / 86400000000\\]特别地，J2000.0 被定义为2000年1月1.5日（TT时），则J2000.0 的儒略日为\\[JD_{J2000.0} = 2451545.0\\quad TT\\]由于儒略日JD是一个整数部分和小数部分均很长的double，按照本节直接计算得到的JD，其小数部分的有效位数会被整数部分挤占而不足15位，这在儒略日转为格里历日期时间时会出现精度损失，导致时间中的毫秒和微秒数据不对。因此，不建议直接采用本节的计算方法计算JD，而是采用类似IAU的sofa程序包的方法，计算简化的儒略日MJD，并在计算过程中分别计算整数部分和小数部分。同时，建议将儒略日的定义，从原先的一个double变为一个struct，struct包含两个double即整数部分double和小数部分double。相应的修改所有以JD作为形参的函数。若需要完整的JD，则将整数部分和小数部分相加即可。3.9. 由格里历算简化的儒略日参考 sofa 程序 iauCal2jd.c 。3.10. 计算标准历元起的儒略日计算当前时刻的 JD_Current_UTC将其转化为 TT 时JD_Current_TT = JD_Current_UTC + 64.184 / 86400.0计算 J2000.0 时刻的 JD_J2000_TT（因为 J2000.0 本身就定义在TT下）作差，得到 JD_FromJ2000JD_FromJ2000 = JD_Current_TT – JD_J2000_TT3.11. 计算标准历元起的儒略世纪JulianCentry = JDFromJ2000 / 365.25 / 100其中365.25是儒略年。4. 参考文献无。"
  },
  
  {
    "title": "天文学基础（JPL星历）",
    "url": "/posts/astronomy-basic-JPL-ephemeris/",
    "categories": "Academic, Knowledge",
    "tags": "astronomy",
    "date": "2020-10-18 21:49:19 +0800",
    





    
    "snippet": "本文介绍了 JPL （美国喷气实验室）的星历（DE405）的基本概念，数据组织方式，以及具体的行星数据查询方法。  1. JPL星历          1.1. 概念      1.2. 版本      1.3. 算法        2. 行星位置计算          2.1. 基本概念      2.2. DE405的结构      2.3. DE405的计算      2.4. 地球太...",
    "content": "本文介绍了 JPL （美国喷气实验室）的星历（DE405）的基本概念，数据组织方式，以及具体的行星数据查询方法。  1. JPL星历          1.1. 概念      1.2. 版本      1.3. 算法        2. 行星位置计算          2.1. 基本概念      2.2. DE405的结构      2.3. DE405的计算      2.4. 地球太阳矢量计算        3. 参考文献1. JPL星历1.1. 概念JPL planetary ephemerides are generally created to support spacecraft missions to the planets. Selected ephemerides are recommended for more general use.JPL星历表给出了太阳、月球和九大行星过去和将来的位置信息，并且是开放可使用的。JPL星历表在20世纪60年代由喷气推进实验室建立，最初用作行星探测导航的目的，随着观测技术的不断提高，新的观测数据不断获得，JPL星历表仍在不断修正和完善。JPL星历表是对描述太阳系动力学系统的微分方程组进行数值积分的结果，因此它的建立基于两个假设：1.微分方程组精确代表了已知的动力学定律，至少在目前观测精度下是如此；2.数值积分程序精度足够高。在这两个假设的前提下，可以构建一个动力学系统，它与太阳系动力学系统是否一致还需要看初始条件和参数是否一致，初始条件和参数通过观测数据来进行最小二乘拟和。观测数据包括：行星探测飞船的测距数据、雷达行星测距数据、月球激光测距、光学观测的测角数据和一些最新的测量手段。JPL星历表为了精确的表示长时间范围内的天体位置，把长时间范围（数百年）分成短的时间区间（数天），对于每个短的时间区间，它提供一组切比雪夫插值系数，要计算某一时刻的天体位置，首先找到这个短的时间区间，得到切比雪夫插值系数，然后根据切比雪夫插值公式计算天体位置。1.2. 版本The latest JPL ephemeris with fully consistent treatment of planetary and lunar laser ranging data is DE430 (Folkner et al 2014). The dynamical model for DE430 includes a frictional damping between the fluid core and the elastic mantle. This damping term is not suitable for extrapolation more than several centuries into the past. In order to cover a longer time span, the ephmeris DE431 was integrated without the lunar core/mantle damping term. The positions of the planets for DE431 agree with the positions on DE430 to within one meter over the time covered by DE430. For the Moon DE431 differs from DE430 mainly in the estimated tidal damping term causing a difference in along-track position of the Moon of 20 meters 100 years from the present and growing quadratically for times more thna 100 years from present.1.3. 算法The JPL planetary ephemerides are saved as files of Chebyshev polynomials fit to the Cartesian positions and velocities of the planets, Sun, and Moon, typically in 32-day intervals. The positions are integrated in astronomical units (au), but with polynomials stored in units of kilometers. The integration time units are days of barycentric dynamical time (TDB). Prior to DE430, the value of the astronomical unit was estimated from measurements of planetary orbits using the Gaussian gravitational constant k. Starting with DE430, the astronomical units has been fixed to the value 149597870.700 km as adopted by the International Astronomical Union in 2012.《高健. 日月、行星位置计算》：JPL-DE405给出的是瞬时日月和行星在ICRS下的位置和速度http://en.wikipedia.org/wiki/Jet_Propulsion_Laboratory_Development_Ephemeris  DE405 was released in 1998. It added several years’ extra data from telescopic, radar, spacecraft, and VLBI observations (of the Galileo spacecraft at Jupiter, in particular). The method of modeling the asteroids’ perturbations was improved, although the same number of asteroids were modeled. The ephemeris was more accurately oriented onto the ICRF. DE405 covered 1600 to 2200 to full precision.2. 行星位置计算2.1. 基本概念已知某一瞬时时刻（格里历日期+UTC时刻）转换成儒略日（儒略纪元）输入 JPL-DE405，得到 ICRS （BCRS）下的太阳、月球、各大行星的位置和速度然后转至 ITRS 或 J2000 下。两个关键点：  JPL查表计算  ICRS到ITRS或J2000的坐标变换。2.2. DE405的结构根据创建时间不同 JPL 星历表有多个版本，这里采用 DE405，它是 1997 年创建的，包括从 1599 年到 2201 年太阳系九大行星和月球的位置。DE405 的文件包括头文件 header.405 和系数文件 ascp****.405 ，**** 代表系数文件的起始时间，每个系数文件包含 20 年天体位置切比雪夫插值系数，例如从 2000 年到 2020 年的系数包含在文件 ascp2000.405 里。DE405 的头文件 header.405 包含了 DE405 的数据信息、天文常数和数据索引。数据索引是一个 3 行 13 列的表，每列数据代表一个天体的位置数据在数据块内的位置，依次为水星、金星、地月系统、火星、木星、土星、天王星、海王星、冥王星、月球、太阳，第12列数据代表章动角（nutations），包含两个角度：黄经章动 $\\Psi$ 和交角章动 $\\epsilon$ ，第13列数据代表岁差参数，包含三个欧拉角：$\\zeta, z, \\theta$ 。每列的第一行指示该天体数据在数据块的起始位置，第二行表示切比雪夫多项式的阶数，第三行表示该天体的数据被划分成几个子区间。下表展示的 DE421 与 DE405 的数据结构相同，最后一列是数据的维度（ 3 表示三轴）。例如水星的数据索引为3、14、4，其中：  数字 3 表示水星的数据从数据块内第 3 个数据开始，  数字 14 为切比雪夫多项式阶数，即每轴位置用 14 个切比雪夫系数表示，共有 $x$、$y$、$z$ 三轴的系数，  数字 4 为划分的子区间个数，由于星体运动周期不同，划分的子区间个数也不一样，周期较短，运动不规则的星体子区间个数较多（其中月球最多为8个子区间），同样的时间内表示位置的数据量也大水星在 32 天内表示位置的数据个数为 $14\\times 4\\times 3=168$ 个，等式中的 3 代表三个轴。系数文件 ascp2000.405 则由若干个数据块组成，每个数据块为 32 天的数据。DE405 的数据信息包括起始时间、结束时间、数据块的个数、每个数据块的数据个数、数据块的时间长度；天文常数包括光速、天文单位、地月质量比等；数据索引用来指示某一天体的数据在数据块内的位置。系数文件 ascp2000.405 由 229 个数据块组成，每个数据块代表 32 天，包含 1018 个数据。每个数据块第一行是标号和数据个数，从第二行开始，每三个数据一行，第一个数据是数据块起始时间，第二个数据是数据块终止时间，然后依次是水星、金星等的位置数据和章动、岁差数据。一个完整的DE星历表结构如下图所示。某个数据块内的数据如下表所示。某个数据块内水星子块的时间跨度如下表所示。某数据块内水星子块的各个数据的含义如下表所示。2.3. DE405的计算JPL 星历采用儒略日形式的 TDB 时刻作为插值时刻，双精度数，可用 TT 代替，精度损失可忽略。JPL 星历采用 ICRS 参考系？DE405采用的坐标系是以太阳系质心为原点，J2000地球平赤道面为 $xy$ 平面， J2000 平春分点方向为 $x$ 方向的直角坐标系。插值得到的位置坐标是在这个坐标系下的值（除月球外，月球坐标以地心为原点）。要得到其它坐标系下天体位置的表示，需要进行坐标的平移和旋转变化，在轨道动力学中使用的惯性坐标系一般以地球质心为原点，J2000 地球平赤道为 $xy$ 面和平春分点方向为 $x$ 方向，从 DE405 的坐标转换到地心惯性坐标系，只需要进行坐标平移。DE405的时间单位为日，$1 day = 86400 s(SI)$，距离单位为 km，速度单位为 km/day。2.4. 地球太阳矢量计算由于 JPL 星历只给出了地月系统的坐标和月球的坐标，需要通过几何方式算出地球的位置坐标。祭出不忍直视的草图。如图所示，假设 $x$ 为地球质心指向地月系质心（地月系统质心）的矢量，$m_e,m_m$ 分别为地球和月球质量，$P_m$ 为以地球中心为原点的月球坐标（星历查询可得），那么有\\(x=\\frac{m_m}{m_m+m_e}P_m=\\frac{1}{1+\\frac{m_e}{m_m}}P_m\\)其中，$m_e/m_m=0.813005600000000044\\times 10^2$ 是地月质量比。那么，地球矢量 $P_e=P_{em}-x$，以地球为中心的太阳矢量 $SunVec=x+P_s-P_{em}$。其中，$P_s$ 为星历查询得到的太阳位置矢量。3. 参考文献[1] 高健. 《日月、行星位置计算》.[2] Wikipedia. JPL Ephemeris."
  },
  
  {
    "title": "深度学习基础（LSTM）",
    "url": "/posts/deep-learning-LSTM/",
    "categories": "Academic, Knowledge",
    "tags": "deep learning",
    "date": "2020-10-04 10:39:19 +0800",
    





    
    "snippet": "本文介绍了 LSTM （长短时记忆网络）的基本概念，以及正/反向传播的推导过程，然后分析了 LSTM 如何克服 RNN 的梯度消失问题，最后介绍了 PyTorch 的 LSTM 模块的实现。  1. LSTM          1.1. 概念      1.2. 模型      1.3. 前向传播      1.4. 如何解决梯度消失      1.5. 如何解决梯度爆炸        2....",
    "content": "本文介绍了 LSTM （长短时记忆网络）的基本概念，以及正/反向传播的推导过程，然后分析了 LSTM 如何克服 RNN 的梯度消失问题，最后介绍了 PyTorch 的 LSTM 模块的实现。  1. LSTM          1.1. 概念      1.2. 模型      1.3. 前向传播      1.4. 如何解决梯度消失      1.5. 如何解决梯度爆炸        2. 实际案例          2.1. LSTM 的 PyTorch 类      2.2. LSTM 实现 MNIST 识别        3. 常见错误          3.1. CUDNN_STATUS_BAD_PARAM        4. 参考文献1. LSTM1.1. 概念长短期记忆（Long short-term memory, LSTM）是一种特殊的RNN（Gers et al.,2000; Hochreiter et al., 1997），主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现。LSTM 与 RNN 的主要输入输出区别如下图所示1.2. 模型LSTM 网络的循环单元结构如下图所示其中，LSTM 引入三个门来控制信息的传递，分别为遗忘门 $\\boldsymbol{f}_t$、输入门 $\\boldsymbol{i}_t$、输出门 $\\boldsymbol{o}_t$。三个门的作用是：  遗忘门 $\\boldsymbol{f}t$ 控制上一个时刻的内部状态 $\\boldsymbol{c}{t-1}$ 需要遗忘多少信息；  输入门 $\\boldsymbol{i}_t$ 控制当前时刻的候选状态 $\\boldsymbol{c}_t$ 有多少信息需要保存；  输出门 $\\boldsymbol{o}_t$ 控制当前时刻的内部状态 $\\boldsymbol{c}_t$ 有多少信息需要输出给外部状态 $\\boldsymbol{h}_t$。1.3. 前向传播三个门的计算方式为：\\[\\begin{aligned}\\boldsymbol{f}_t &amp;= \\sigma(\\boldsymbol W_f \\boldsymbol{h}_{t-1} + \\boldsymbol{U}_f \\boldsymbol{x}_t + \\boldsymbol{b}_f)=\\sigma([\\boldsymbol W_f, \\boldsymbol{U}_f]\\cdot[\\boldsymbol{h}_{t-1}, \\boldsymbol{x}_t]^T + \\boldsymbol{b}_f)\\\\\\boldsymbol{i}_t &amp;= \\sigma(\\boldsymbol W_i \\boldsymbol{h}_{t-1} + \\boldsymbol{U}_i \\boldsymbol{x}_t + \\boldsymbol{b}_i)=\\sigma([\\boldsymbol W_i, \\boldsymbol{U}_i]\\cdot[\\boldsymbol{h}_{t-1}, \\boldsymbol{x}_t]^T + \\boldsymbol{b}_f)\\\\\\boldsymbol{o}_t &amp;= \\sigma(\\boldsymbol W_o \\boldsymbol{h}_{t-1} + \\boldsymbol{U}_o \\boldsymbol{x}_t + \\boldsymbol{b}_o)=\\sigma([\\boldsymbol W_o, \\boldsymbol{U}_o]\\cdot[\\boldsymbol{h}_{t-1}, \\boldsymbol{x}_t]^T + \\boldsymbol{b}_f)\\\\\\end{aligned}\\]其中，$\\sigma$ 为 $sigmoid$ 激活函数，输出区间为 $[0,1]$。也就是说，LSTM 网络中的“门”是一种“软”门，取值在 $[0,1]$ 之间，表示以一定的比例允许信息通过。注意到，等式右边包含一个对 $\\boldsymbol{h}_{t-1}$ 和 $\\boldsymbol{x}_t$ 向量拼接的操作，相应的参数也因此进行了拼接。相比 RNN，LSTM 引入了一个新的状态，称为细胞状态（cell state），表示为 $\\boldsymbol{c}_t$，专门进行现行的循环信息传递，同时输出（非线性地）输出信息给隐层状态 $\\boldsymbol{h}_t\\in \\mathbb{R}^D$。计算公式如下\\[\\begin{aligned}\\boldsymbol{c}_t &amp;= \\tanh(\\boldsymbol W_c \\boldsymbol{h}_{t-1} + \\boldsymbol{U}_c \\boldsymbol{x}_t + \\boldsymbol{b}_c)=\\tanh([\\boldsymbol W_c, \\boldsymbol{U}_c]\\cdot[\\boldsymbol{h}_{t-1}, \\boldsymbol{x}_t]^T + \\boldsymbol{b}_f)\\\\\\boldsymbol{c}_t &amp;= \\boldsymbol{f}_t \\odot \\boldsymbol{c}_{t-1} + \\boldsymbol{i}_t \\odot \\boldsymbol{c}_t\\\\\\boldsymbol{h}_t &amp;= \\boldsymbol{o}_t \\odot \\tanh(\\boldsymbol{c}_t)\\end{aligned}\\]其中，  $\\boldsymbol{c}_t\\in\\mathbb{R}^D$ 是通过非线性函数（$\\tanh$）得到的候选状态，  $\\boldsymbol{c}_{t-1}$ 是上一时刻的记忆单元，  $\\odot$ 是向量的元素乘积。在每个时刻，LSTM 网络的细胞状态 $\\boldsymbol{c}_t$ 记录了截至当前时刻的历史信息。根据不同的门状态取值，可以实现不同的功能。当 $\\boldsymbol{f}_t = 0,\\boldsymbol{i}_t = 1$ 时，记忆单元将历史信息清空，并将候选状态向量 $\\boldsymbol{c}_t$ 写入，但此时记忆单元 $\\boldsymbol{c}_t$ 依然和上一时刻的历史信息相关。当$\\boldsymbol{f}_t = 1,\\boldsymbol{i}_t = 0$ 时，记忆单元将复制上一时刻的内容，不写入新的信息。需要注意的是，LSTM 中的 $\\boldsymbol{c}_t$ 对应于传统 RNN 中的 $\\boldsymbol{h}_t$，通常是上一个传过来的历史状态乘以遗忘门后加上一些新信息得到，因此更新比较缓慢。而 LSTM 中的 $\\boldsymbol{h}_t$ 则变化剧烈的多，在不同的时刻下的取值往往区别很大。再次进行维度分析，$\\boldsymbol{h}_t,\\boldsymbol{c}_t,\\boldsymbol{i}_t,\\boldsymbol{f}_t,\\boldsymbol{o}_t \\in \\mathbb R^D$ 且 $\\boldsymbol{b}_f,\\boldsymbol{b}_i,\\boldsymbol{b}_o,\\boldsymbol{b}_c \\in \\mathbb R^D$，$\\boldsymbol{x}_t\\in \\mathbb R^M$，那么 $\\boldsymbol W_f,\\boldsymbol W_i,\\boldsymbol W_o,\\boldsymbol W_c \\in \\mathbb R^{D\\times M}$， $\\boldsymbol{U}_f,\\boldsymbol{U}_i,\\boldsymbol{U}_o,\\boldsymbol{U}_c \\in \\mathbb R^{D\\times D}$。则上面所有式子可简洁描述为\\[\\begin{aligned}\\begin{bmatrix} \\boldsymbol{c}_t\\\\  \\boldsymbol{o}_t\\\\ \\boldsymbol{i}_t\\\\ \\boldsymbol{f}_t \\end{bmatrix}=\\begin{bmatrix} \\tanh\\\\  \\sigma\\\\ \\sigma\\\\ \\sigma \\end{bmatrix}\\left( \\boldsymbol W\\begin{bmatrix} \\boldsymbol{h}_{t-1}\\\\  \\boldsymbol{x}_t\\end{bmatrix}+\\boldsymbol b \\right)\\end{aligned}\\]其中\\[\\begin{aligned}\\boldsymbol W &amp;=\\begin{bmatrix} \\boldsymbol W_c &amp; \\boldsymbol{U}_c\\\\  \\boldsymbol W_o &amp; \\boldsymbol{U}_o\\\\ \\boldsymbol W_i &amp; \\boldsymbol{U}_i\\\\  \\boldsymbol W_f &amp; \\boldsymbol{U}_f\\end{bmatrix} \\in \\mathbb R^{4D\\times (D+M)}\\\\\\boldsymbol b &amp;= \\begin{bmatrix} \\boldsymbol{b}_c\\\\  \\boldsymbol{b}_o\\\\ \\boldsymbol{b}_i\\\\ \\boldsymbol{b}_f \\end{bmatrix}\\in \\mathbb R^{4D}\\end{aligned}\\]循环神经网络中的隐状态 $\\boldsymbol h$ 存储了历史信息，可以看作一种记忆（Memory）。在简单循环网络中，隐状态每个时刻都会被重写，因此可以看作一种短期记忆（Short-Term Memory）。在神经网络中，长期记忆（Long-Term Memory）可以看作网络参数，隐含了从训练数据中学到的经验，其更新周期要远远慢于短期记忆。而在 LSTM 网络中，记忆单元 $\\boldsymbol c$ 可以在某个时刻捕捉到某个关键信息，并有能力将此关键信息保存一定的时间间隔。记忆单元 $\\boldsymbol c$ 中保存信息的生命周期要长于短期记忆 $\\boldsymbol h$，但又远远短于长期记忆，长短期记忆是指长的“短期记忆”。因此称为长短期记忆（Long Short-Term Memory）。1.4. 如何解决梯度消失LSTM如何来避免梯度弥散和梯度爆炸？LSTM 通过引入门机制，把矩阵乘法变成了 element-wise 的 Hadamard product（哈达玛积，逐元素相乘）。这样做后，细胞状态 $\\boldsymbol{c}_t$ （对应于 RNN 中的隐状态 $\\boldsymbol{h}_t$）的更新公式变为\\[\\boldsymbol{c}_t = \\boldsymbol{f}_t \\odot \\boldsymbol{c}_{t-1} + \\boldsymbol{i}_t \\odot \\tanh(\\boldsymbol W_c \\boldsymbol{h}_{t-1} + \\boldsymbol{U}_c \\boldsymbol{x}_t + \\boldsymbol{b}_c)\\]进一步推导\\[\\begin{aligned}\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol{c}_{t-1}} &amp;= \\frac{\\partial L}{\\partial c_t}\\frac{\\partial c_t}{\\partial c_{t-1}} = \\frac{\\partial L}{\\partial c_t} \\odot diag(f_t+\\cdots)\\end{aligned}\\]公式里其余的项不重要，这里就用省略号代替了。可以看出当 $f_t=1$ 时，就算其余项很小，梯度仍然可以很好地传导到上一个时刻，此时即使层数较深也不会发生 Gradient Vanish 的问题；当 $f_t=0$ 时，即上一时刻的信号不影响到当前时刻，则此项也会为0。$f_t$ 在这里控制着梯度传导到上一时刻的衰减程度，与它 Forget Gate 的功能一致。这样的方式本质上类似 Highway Network 或者 ResNet（残差连接），使得梯度的信息可以“贯穿”时间线，缓解梯度消散。这里需要强调的是：LSTM不是让所有远距离的梯度值都不会消散，而是只让具有时序关键信息位置的梯度可以一直传递。另一方面，仅在 $c_t$ 通路上缓解了梯度消失问题，而在 $h_t$ 通路上梯度消失依然存在。1.5. 如何解决梯度爆炸关于梯度爆炸问题： $f_t$ 已经在 $[0,1]$ 范围之内了。而且梯度爆炸爆炸也是相对容易解决的问题，可以用梯度裁剪(gradient clipping)来解决：只要设定阈值，当提出梯度超过此阈值，就进行截取即可。另一种解读参见 [1] 。2. 实际案例2.1. LSTM 的 PyTorch 类官方文档链接在此（https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html ）CLASStorch.nn.LSTM(*args, **kwargs)参数列表如下      input_size – The number of expected features in the input x        hidden_size – The number of features in the hidden state h        num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1        bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True        batch_first – If True, then the input and output tensors are provided as (batch, seq, feature). Default: False        dropout – If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0        bidirectional – If True, becomes a bidirectional LSTM. Default: False  我们再次将 LSTM 的前向传播列写如下便于比对\\[\\begin{aligned}\\boldsymbol{f}_t &amp;= \\sigma(\\boldsymbol W_f \\boldsymbol{h}_{t-1} + \\boldsymbol{U}_f \\boldsymbol{x}_t + \\boldsymbol{b}_f)\\\\\\boldsymbol{i}_t &amp;= \\sigma(\\boldsymbol W_i \\boldsymbol{h}_{t-1} + \\boldsymbol{U}_i \\boldsymbol{x}_t + \\boldsymbol{b}_i)\\\\\\boldsymbol{o}_t &amp;= \\sigma(\\boldsymbol W_o \\boldsymbol{h}_{t-1} + \\boldsymbol{U}_o \\boldsymbol{x}_t + \\boldsymbol{b}_o)\\\\\\boldsymbol{c}_t &amp;= \\tanh(\\boldsymbol W_c \\boldsymbol{h}_{t-1} + \\boldsymbol{U}_c \\boldsymbol{x}_t + \\boldsymbol{b}_c)\\\\\\boldsymbol{c}_t &amp;= \\boldsymbol{f}_t \\odot \\boldsymbol{c}_{t-1} + \\boldsymbol{i}_t \\odot \\boldsymbol{c}_t\\\\\\boldsymbol{h}_t &amp;= \\boldsymbol{o}_t \\odot \\tanh(\\boldsymbol{c}_t)\\end{aligned}\\]前面我们已经假设，$\\boldsymbol{h}_t,\\boldsymbol{c}_t,\\boldsymbol{i}_t,\\boldsymbol{f}_t,\\boldsymbol{o}_t \\in \\mathbb R^D$ 且 $\\boldsymbol{b}_f,\\boldsymbol{b}_i,\\boldsymbol{b}_o,\\boldsymbol{b}_c \\in \\mathbb R^D$，$\\boldsymbol{x}_t\\in \\mathbb R^M$，那么 $\\boldsymbol W_f,\\boldsymbol W_i,\\boldsymbol W_o,\\boldsymbol W_c \\in \\mathbb R^{D\\times M}$， $\\boldsymbol{U}_f,\\boldsymbol{U}_i,\\boldsymbol{U}_o,\\boldsymbol{U}_c \\in \\mathbb R^{D\\times D}$。input_size 就是输入层维度 $M$，比如某个词或者某张图的 embedding dim （特征维度）。hidden_size 就是隐层 $h_t$ 的维度 $D$。num_layers 是 LSTM 堆叠的层数。LSTM 可以按照下图的形式进行堆叠。batch_first 是一个可选参数，指定是否将 batch_size 作为输入输出张量的第一个维度，如果是，则输入和输入的维度顺序为（batch_size， seq_length，input_size），否则，输入和输出的默认维度顺序是（seq_length, batch_size, input_size）。2.2. LSTM 实现 MNIST 识别注意，后文中的所有代码均为片段，全部凑在一起时无法直接运行的！旨在辅助进行理解。考虑到网络每一时刻输入的是一个 vector，我们可以假设这个 vector 对应的是 图像的一行，有多少行就对应多少时刻，那最后一个时刻输入的是最后一行。最后输出的 $h_t$ 实际上就是该图像对应的类别。MNIST 手写数字图片大小为 28*28，那么可以将每张图片看作长为28的序列，序列中的每个元素的特征维度是28，这样就将图片变成了一个序列。那么有input_size = 28 # image widthsequence_size = 28 # image height (time step)hidden_size = 100 # user definedoutput_size = 10 # 10 classes of number from 0 to 9num_layers = 2 # user defined其中 hidden_size 和 num_layers 均由用户自定义。然后我们开始构建 LSTM 网络的类。class MNIST_LSTM(nn.Module):    def __init__(self, input_size, hidden_size, num_layers, output_dim):        super(MNIST_LSTM,self).__init__()        self.lstm = nn.LSTM(            input_size,            hidden_size,            num_layers,            batch_first=True)        # fully connect        self.fc = nn.Linear(hidden_dim, output_dim)    def forward(self, x):        # x -     [batch_size, sequence_dim, input_dim]        # r_out - [batch_size, sequence_dim, hidden_size]        # h_n -   [layer_dim, batch_size, hidden_size]        # h_c -   [layer_dim, batch_size, hidden_size]        r_out, (h_n, h_c) = self.lstm(x, None)        # out -   [batch_size, output_size]        out = self.fc(r_out[:,-1,:])        return out在网络初始化时，我们引入了定义的 4 个形参 input_size, hidden_size, num_layers, output_size，确定网络的结构中的输入维度，隐层神经元个数，隐层层数，输出维度。然后，按照上面定义的结构定义一个 torch 官方提供的 torch.nn.LSTM 单元，并且设定其 batch_first=True，即将数据的批数放到输入输出向量的第一个维度。最后，定义一个全连接层，将隐层信息映射到输出维度。在定义网络前向传播时，首先给 LSTM 传入输入向量 x 和 初始隐层向量 (h_n,h_c)。此处 x 维度为 [batch_size, sequence_size, input_size]，初始隐层向量为 None，即表示初始时刻隐层向量均为 0 。经过前向传播，LSTM 单元的输出为 r_out, (h_n, h_c)。其中  r_out 也就是上面图中的 output 保存了最后一层，每个 time step 的输出 h，如果是双向 LSTM，每个 time step 的输出 h = [h正向, h逆向] (同一个 time step 的正向和逆向的h连接起来)。          所以 r_out 无需层维度信息，而包含时间序列信息，其维度为 [batch_size, sequence_size, output_size]；      如果 num_layers=1，lstm 只有一层，则 r_out 为每个 time step 的输出。        h_n 保存了每一层，最后一个time step 的输出 h，如果是双向LSTM，单独保存前向和后向的最后一个 time step 的输出 h。          所以 h_n 包含层维度信息，无需时间序列信息，其维度为 [layer_size, batch_size, hidden_size]；注意到 batch_first=True 不会影响到 h_n，因此第一个维度是层个数；      如果 num_layers=1，lstm 只有一层，则 h_n 为最后一个 time step 的输出。        c_n 与 h_n 一致，只是它保存的是 c 的值。继续经过全连接层，输入 r_out 输出 out ：  r_out[:,-1,:] 表示读取 r_out 第二维的倒数第一个元素对应的其余维度数据。由于 r_out 的第二维是 sequence_size 也就是 time step，倒数第一个元素对应的其余维度数据也就是最后一个时刻的数据 [batch_size, hidden_size]；  当 layer_size = 1 时，r_out[:,-1,:] = h_n[-1,:,:]；  经过全连接层，得到 batch 中每张图片的最终分类结果 [batch_size, output_size]。最后设计训练和测试环节。def main():    root = \"./mnist/MNIST/raw/\"    train_mean = 0.1307    train_std = 0.3081    batch_size = 64    test_batch_size = 50    kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}    transform = transforms.Compose([        transforms.ToTensor(),        transforms.Normalize((train_mean,), (train_std,))        ])    train_loader = torch.utils.data.DataLoader(        DATA(root, train=True, transform=transform),        batch_size=batch_size, shuffle=True, **kwargs)    test_loader = torch.utils.data.DataLoader(        DATA(root, train=False, transform=transform),        batch_size=test_batch_size, shuffle=True, **kwargs)    model = MNIST_LSTM(input_size, hidden_size, layer_num, output_size)    if use_cuda:        model.to(device)    lossfcn = nn.CrossEntropyLoss()    learning_rate = 0.01    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)    loss_list = []    accuracy_list = []    iteration_list = []    EPOCHS = 20    iter = 0    for epoch in range(1,EPOCHS+1):        print(\"EPOCH: {}\".format(epoch))        loss = 999.0        for batchidx, (images, labels) in enumerate(train_loader):            model.train()            # 一个batch 转换为RNN的输入维度            images = images.view(-1, sequence_size, input_size)            images = images.requires_grad_()            labels = labels.long() # cross entropy requires a long scalar            # 移入GPU            if use_cuda:                images, labels = images.to(device), labels.to(device)            # 梯度清零            optimizer.zero_grad()            # 前向传播            output = model(images)            # 计算损失            loss = lossfcn(output, labels)            # 反向传播            loss.backward()            # 更新参数            optimizer.step()            iter += 1            # 打印训练信息            if batchidx % 50 == 0:                print(\"batch index: {}, images: {}/{}+[{}], loss: {}\".format(                    batchidx,                    batchidx*batch_size,                    train_loader.dataset.data.shape[0],batch_size,                    loss.data.cpu().numpy()))        # 模型验证        model.eval()        correct = 0.0        total = 0.0        # 迭代测试集，获取数据，预测        with torch.no_grad():            for images, labels in test_loader:                images = images.view(-1, sequence_size, input_size).to(device)                # 模型预测                output = model(images)                # 获取预测概率最大值的下标                _, predict = torch.max(output.data, axis=1)                # 统计测试集的大小                total += labels.size(0)                # 统计预测正确的数量                if use_cuda:                    predict, labels = predict.to(device), labels.to(device)                correct += (predict == labels).sum()            accuracy = correct / total * 100            # 保存accuracy，loss，iteration            loss_list.append(loss.data)            accuracy_list.append(accuracy)            iteration_list.append(iter)            # 打印信息            print(\"iter: {}, Loss: {}, Accu: {}%\".format(iter, loss.item(), accuracy))            print()if __name__ == '__main__':    main()注意，上述代码并没有采用一般教程中的使用 Pytorch 代码直接下载并使用 MNIST 数据集，而是将数据集下载好后，提取出其中所有图片，保存在 raw 文件夹中，然后构造一个 DataLoader 类型的 DATA 来实现数据加载，这样可以便于我们之后将网络迁移至自己的数据集上训练。为了便于比较，这里给出一段借助 torchvision.datasets 直接下载和加载 MNIST 数据集的代码# MNIST Datasettrain_dataset = torchvision.datasets.MNIST(root='./data/',                                           train=True,                                            transform=transforms.ToTensor(),                                           download=True)test_dataset = torchvision.datasets.MNIST(root='./data/',                                          train=False,                                           transform=transforms.ToTensor())# Data Loader (Input Pipeline)train_loader = torch.utils.data.DataLoader(dataset=train_dataset,                                           batch_size=batch_size,                                            shuffle=True)test_loader = torch.utils.data.DataLoader(dataset=test_dataset,                                          batch_size=batch_size,                                           shuffle=False)最终也得到了用于训练和测试的 train_loader, test_loader。其中  root='./data/' 表明将下载的数据集存放于代码同级路径下的 data 文件夹；  train=true 表明下载的数据集是用于训练的数据集；  transform=transforms.ToTensor() 表明对下载的数据集进行一个数据处理操作：ToTensor(object) Convert a numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].  download=True 表明如果检测到 root 下没有数据集时自动下载数据所有数据，包括训练数据和测试数据，因此在 train=True 时设置一次即可。PyTorch 官方给出的基于 CNN 的 MNIST 手写数字识别代码在此（https://github.com/pytorch/examples/blob/master/mnist/main.py ），以供参考。注意到上述链接的代码中，除了 ToTensor() 之外还用到了另一个转换，Normalize() 如下：transform=transforms.Compose([                           transforms.ToTensor(),                           transforms.Normalize((0.1307,), (0.3081,))                       ])总结而言，ToTensor() 能够把灰度范围从 0-255 变换到 0-1 之间，而后面的 transform.Normalize() 则把 0-1 数据执行以下操作：image=(image-mean)/std如果取 mean=0.5, std=0.5 那么 Normalize 把 0-1 数据变换到 (-1,1)，号称可以加快模型收敛速度 [2]。当然此处MNIST应用时 mean=0.1307, std=0.3081 。当 seed=0 时，即use_cuda = torch.cuda.is_available()device = torch.device('cuda:0' if use_cuda else 'cpu')seed = 0torch.manual_seed(seed)if use_cuda:    torch.cuda.manual_seed(seed)20 次迭代后的训练结果如下......EPOCH: 20batch index: 0, images: 0/60000+[64], loss: 0.14547616243362427batch index: 50, images: 3200/60000+[64], loss: 0.04679613187909126batch index: 100, images: 6400/60000+[64], loss: 0.05385994166135788batch index: 150, images: 9600/60000+[64], loss: 0.044658079743385315batch index: 200, images: 12800/60000+[64], loss: 0.08235453814268112batch index: 250, images: 16000/60000+[64], loss: 0.12099026888608932batch index: 300, images: 19200/60000+[64], loss: 0.04762731492519379batch index: 350, images: 22400/60000+[64], loss: 0.07588448375463486batch index: 400, images: 25600/60000+[64], loss: 0.03385855257511139batch index: 450, images: 28800/60000+[64], loss: 0.056658919900655746batch index: 500, images: 32000/60000+[64], loss: 0.10723046958446503batch index: 550, images: 35200/60000+[64], loss: 0.029729364439845085batch index: 600, images: 38400/60000+[64], loss: 0.21459335088729858batch index: 650, images: 41600/60000+[64], loss: 0.023649774491786957batch index: 700, images: 44800/60000+[64], loss: 0.2532099485397339batch index: 750, images: 48000/60000+[64], loss: 0.044361311942338943batch index: 800, images: 51200/60000+[64], loss: 0.08944762498140335batch index: 850, images: 54400/60000+[64], loss: 0.22417518496513367batch index: 900, images: 57600/60000+[64], loss: 0.1285378485918045iter: 18760, Loss: 0.034618619829416275, Accu: 97.50999450683594%注意，如果不改变 seed 那么重复多次训练的结果不会变。随机数种子影响神经网络初始参数的随机初始化取值。3. 常见错误3.1. CUDNN_STATUS_BAD_PARAM在 LSTM 的 forward 过程中，下述语句def forward(self, x):    r_out, (h_n, h_c) = self.lstm(x, None)提示 RuntimeError发生异常: RuntimeErrorcuDNN error: CUDNN_STATUS_BAD_PARAM  File \"xxx.py\", line xx, in forward    r_out, (h_n, h_c) = self.lstm(x, None)参考此处（https://blog.csdn.net/daixiangzi/article/details/107671246 ）核心问题在于，LSTM 的 forward 要求输入数据的类型为 float32，而在实际代码中我们将其输入为了float64或者其它类型的数据。因此需要在输入模型训练之前进行数据转换即可解决问题trainX, trainY = trainX.to(torch.float32), trainY.to(torch.float32)4. 参考文献[1] 谓之小一. LSTM如何解决RNN带来的梯度消失问题.[2] 小研一枚. pytorch的transform中ToTensor接着Normalize."
  },
  
  {
    "title": "深度学习基础（RNN）",
    "url": "/posts/deep-learning-RNN/",
    "categories": "Academic, Knowledge",
    "tags": "deep learning",
    "date": "2020-09-29 09:43:19 +0800",
    





    
    "snippet": "本文介绍了 RNN （循环神经网络）的基本概念，以及正/反向传播的推导过程。最后分析了 RNN 的梯度消失和梯度爆炸问题。  1. RNN          1.1. 概念      1.2. 模型      1.3. 前向传播      1.4. 反向传播      1.5. 梯度消失      1.6. 梯度爆炸        2. 参考文献1. RNN1.1. 概念在前馈神经网络中，信...",
    "content": "本文介绍了 RNN （循环神经网络）的基本概念，以及正/反向传播的推导过程。最后分析了 RNN 的梯度消失和梯度爆炸问题。  1. RNN          1.1. 概念      1.2. 模型      1.3. 前向传播      1.4. 反向传播      1.5. 梯度消失      1.6. 梯度爆炸        2. 参考文献1. RNN1.1. 概念在前馈神经网络中，信息传递是单向的[1]。前馈神经网络可以看作一个复杂的函数，每次输入都是独立的，即网络的输出只依赖于当前的输入．但是在很多现实任务中，网络的输出不仅和当前时刻的输入相关，也和其过去一段时间的输出相关。此外，前馈网络难以处理时序数据，比如视频、语音、文本等．时序数据的长度一般是不固定的，而前馈神经网络要求输入和输出的维数都是固定的，不能任意改变．因此，当处理这一类和时序数据相关的问题时，就需要一种能力更强的模型．循环神经网络（Recurrent Neural Network，RNN）是一类具有短期记忆能力的神经网络．在循环神经网络中，神经元不但可以接受其他神经元的信息，也可以接受自身的信息，形成具有环路的网络结构．和前馈神经网络相比，循环神经网络更加符合生物神经网络的结构．循环神经网络已经被广泛应用在语音识别、语言模型以及自然语言生成等任务上。RNN 用于分类的简单例子参考：  根据人名判断国家：字符级 RNN 对单词分类。输入人名单词，将每个字符进行编码后读取（one-hot），在每一步输出预测和“隐藏状态”，将其先前的隐藏状态输入至下一时刻。将最终时刻输出作为预测结果，即表示该词属于哪个类（哪个国家的人名）。  根据句子判断语言：单词级 RNN 对句子分类。输入一个句子，将每个单词进行编码后读取（word2vec），在每一步输出预测和“隐藏状态”，将其先前的隐藏状态输入至下一时刻。将最终时刻输出作为预测结果，即表示该词属于哪个类（哪个国家的语言）。上述例子中，输入是对 字符 / 单词 序列的编码，编码方式可以是 one-hot 形式也可以采用 word2vec 方法。期望输出一般是一个 one-hot 向量，比如 10 种国家 / 语言，预测输出一般是一个多分类概率结果。1.2. 模型循环神经网络（Recurrent Neural Network，RNN）通过使用带自反馈的神经元，能够处理任意长度的时序数据。给定一个输入序列 $\\boldsymbol x_{1:T} = (\\boldsymbol x_1,…,\\boldsymbol x_t,…,\\boldsymbol x_T)$，通过下面的公式更新隐层活性值 $\\boldsymbol h_t$：\\[\\boldsymbol h_t = f(\\boldsymbol h_{t-1},\\boldsymbol x_t)\\]其中，$\\boldsymbol h_0 = 0$，$f(\\cdot)$ 是非线性函数，可以是一个前馈网络。网络结构如下图所示从数学上讲，上述公式可以堪称一个动力系统，因此隐层活性值在很多文献中也称为隐状态（hidden state）。由于循环神经网络具有短期记忆能力，因此其计算能力十分强大，可以近似任意非线性动力系统（程序），相比较而言，前馈神经网络可以模拟任何连续函数。1.3. 前向传播如果我们把每个时刻的状态都看作前馈神经网络的一层，循环神经网络可以看作在时间维度上权值共享的神经网络。一个简单的循环神经网络按时间展开后如下图所示令 $\\boldsymbol x_t \\in \\mathbb R^M$ 为 $t$ 时刻的网络输入向量，则在该时刻的网络隐状态 $\\boldsymbol h_t \\in \\mathbb R^D$ 和网络输出 $\\boldsymbol y_t \\in \\mathbb R^N$ 的更新公式为\\[\\begin{aligned}\\boldsymbol h_t &amp;= f(\\boldsymbol U \\boldsymbol h_{t-1} + \\boldsymbol W \\boldsymbol x_t + \\boldsymbol b)\\\\\\boldsymbol y_t &amp;= g(\\boldsymbol V \\boldsymbol h_t + \\boldsymbol c)\\end{aligned}\\]其中 $\\boldsymbol U \\in \\mathbb R^{D\\times D}$ 是状态-状态权重矩阵，$\\boldsymbol W \\in \\mathbb R^{D\\times M}$ 是状态-输入权重矩阵，$\\boldsymbol b \\in \\mathbb R^D, \\boldsymbol c \\in \\mathbb R^N$ 是偏置向量，$\\boldsymbol V \\in \\mathbb R^{N\\times D}$ 是状态-输出权重矩阵，$f(\\cdot)$ 是激活函数，如 $sigmoid$ 或 $tanh$ 函数，$g(\\cdot)$ 也是激活函数，如 $softmax$ 或 $purlin$ 函数。注意到，第二个方程的具体形式与模型的具体使用方式有关，比如其中的常数项 $\\boldsymbol c$ 的有无，激活函数 $g(\\cdot)$ 的选取等。1.4. 反向传播有了RNN前向传播算法的基础，就容易推导出RNN反向传播算法的流程了。RNN 反向传播算法的思路和 DNN 是一样的，即通过梯度下降法一轮轮的迭代，得到合适的RNN模型参数 $\\boldsymbol U,\\boldsymbol W,\\boldsymbol V,\\boldsymbol b,\\boldsymbol c$。由于我们是基于时间反向传播，所以 RNN 的反向传播有时也叫做 BPTT (back-propagation through time)。当然这里的 BPTT 和 DNN 的 BP 也有很大的不同点，即这里所有的 $\\boldsymbol U, \\boldsymbol W,\\boldsymbol V,\\boldsymbol b,\\boldsymbol c$ 在序列的各个位置是共享的，反向传播时我们更新的是相同的参数。RNN反向传播过程中，需要计算 $\\boldsymbol U,\\boldsymbol W,\\boldsymbol V,\\boldsymbol b,\\boldsymbol c$ 等参数的梯度。清晰起见，我们将前向传播过程整理如下\\[\\begin{aligned}\\boldsymbol a_t &amp;= \\boldsymbol W \\boldsymbol h_{t-1} + \\boldsymbol U \\boldsymbol x_t + \\boldsymbol b\\\\\\boldsymbol h_t &amp;= f(\\boldsymbol a_t)\\\\\\boldsymbol o_t &amp;= \\boldsymbol V \\boldsymbol h_t + \\boldsymbol c\\\\\\hat{\\boldsymbol y_t} &amp;= g(\\boldsymbol o_t)\\end{aligned}\\]反向传播的形象的分析如下图所示。途中绿线是正向传播过程，红线是反向传播过程。可以看出，在输出端的 $V,c$ 参数仅与 $t$ 时刻的反向传播通路有关，因此分别求导数后求和即可。而输入端 $U,W,b$ 参数的梯度受到两个反向传播通路的影响，分别是 $t$ 时刻的输出端反向通路，以及 $t+1$ 时刻隐层信息的反向通路。为了简化描述，这里的损失函数我们为交叉熵损失函数，输出的激活函数 $g(\\cdot)$ 为 softmax 函数。对于 RNN，由于在序列的每个位置（任意 $t$ 时刻）都有输出 $\\hat y_t$，也即都有损失函数，因此最终损失 $L$ 为\\[\\boldsymbol L = \\sum_{t=1}^T \\boldsymbol L_t = \\sum_{t=1}^T \\left[ - \\boldsymbol y_t ln\\hat{\\boldsymbol y_t} \\right]\\]注意到，对于任意时刻 $t$ 的损失函数 $\\boldsymbol L_t$，在 $N$ 分类问题中其与每个维度分量均有关，因此损失函数可以进一步写为\\[\\boldsymbol L = \\sum_{t=1}^T \\boldsymbol L_t = -\\sum_{t=1}^T\\sum_{j=1}^N y_{tj}{\\rm ln} \\hat{y_{tj}}\\]上式就是负对数似然函数的形式。首先计算比较简单的 $V,c$ 的梯度。在输出端的 $V,c$ 参数仅与 $t$ 时刻的反向传播通路有关，因此分别求导数后求和即可，有[1]\\[\\begin{aligned}\\frac{\\partial L}{\\partial \\boldsymbol c} &amp;= \\sum_{t=1}^T \\frac{\\partial \\boldsymbol L_t}{\\partial \\boldsymbol c}= \\sum_{t=1}^T \\frac{\\partial \\boldsymbol L_t}{\\partial \\hat{\\boldsymbol y_t}} \\frac{\\partial \\hat{\\boldsymbol y_t}}{\\partial \\boldsymbol o_t} \\frac{\\partial \\boldsymbol o_t}{\\partial \\boldsymbol c}\\\\&amp;= \\sum_{t=1}^T -(\\frac{\\boldsymbol y_t}{\\hat{\\boldsymbol y_t}})\\cdot softmax'\\cdot \\boldsymbol I\\\\\\end{aligned}\\]由于 $softmax’$ 需要分情况讨论，当 $j=i$ 时 $softmax’ = \\hat y_j(1-\\hat y_j)$；当 $j\\neq i$ 时 $softmax’ = \\hat y_j\\hat y_i$，那么有\\[\\begin{aligned}\\frac{\\partial L}{\\partial \\boldsymbol c}&amp;= \\sum_{t=1}^T \\sum_{j=1}^N -\\frac{y_{tj}}{\\hat y_{tj}}\\cdot\\left\\{\\begin{matrix}&amp;\\hat y_{tj}(1-\\hat y_{tj})\\quad &amp;j=i\\\\ &amp;\\hat y_{tj}\\hat y_{ti} \\quad &amp; j\\neq i\\end{matrix}\\right.\\\\&amp;= - \\sum_{t=1}^T \\sum_{j=1}^N \\left\\{\\begin{matrix}&amp;y_{tj}(1-\\hat y_{tj})\\quad &amp;j=i\\\\ &amp;y_{tj}\\hat y_{ti} \\quad &amp; j\\neq i\\end{matrix}\\right.\\\\\\end{aligned}\\]由于 $\\boldsymbol y_{t} = [y_{t1},y_{t2},…,y_{tj},…,y_{tN}]$ 是一个 one-hot 向量，假设第 $j$ 个分量 $y_{tj} = 1$，可以将第二个累加符号消去（因为其它分量为 0，不影响累加求和）\\[\\begin{aligned}\\frac{\\partial L}{\\partial \\boldsymbol c}&amp;= - \\sum_{t=1}^T \\left\\{\\begin{matrix}&amp;[0,0,...,y_{tj}(1-\\hat y_{tj}),...,0]\\quad &amp;j=i\\\\ &amp;[0,0,...,y_{tj}\\hat y_{ti},...,0] \\quad &amp; j\\neq i\\end{matrix}\\right.\\quad (y_{tj} = 1)\\end{aligned}\\]进一步分析  $j=i:\\quad y_{tj}(1-\\hat y_{tj}) = 1-\\hat y_{tj} = y_{tj} - \\hat{y_{tj}}$  $j\\neq i:\\quad y_{tj}\\hat y_{ti} = \\hat y_{ti} = y_{tj} - \\hat{y_{tj}}$可以发现，二者在形式上可以写成统一的形式 $\\boldsymbol y_{tj} - \\hat {\\boldsymbol y_{tj}}$，那么有\\[\\begin{aligned}\\frac{\\partial L}{\\partial \\boldsymbol c} = - \\sum_{t=1}^T (\\boldsymbol y_{tj} - \\hat {\\boldsymbol y_{tj}}) =\\sum_{t=1}^T (\\hat {\\boldsymbol y_{tj}} - \\boldsymbol y_{tj})\\end{aligned}\\]那么对 $\\boldsymbol V$ 的偏导为\\[\\begin{aligned}\\frac{\\partial L}{\\partial V} &amp;= \\sum_{t=1}^T \\frac{\\partial L_t}{\\partial c}= \\sum_{t=1}^T \\frac{\\partial \\boldsymbol L_t}{\\partial \\hat {\\boldsymbol y_t}} \\frac{\\partial \\hat {\\boldsymbol y_t}}{\\partial \\boldsymbol o_t} \\frac{\\partial \\boldsymbol o_t}{\\partial \\boldsymbol V}\\\\&amp;= \\sum_{t=1}^T (\\hat {\\boldsymbol y_t}-\\boldsymbol y_t)\\boldsymbol h_t\\end{aligned}\\]$\\boldsymbol U,\\boldsymbol W,\\boldsymbol b$ 的梯度计算就比较复杂了，误差传播源来自于两个反向传播通路的方向，分别是 $t$ 时刻的输出端反向通路，以及 $t+1$ 时刻隐层信息的反向通路。这里假设隐藏层的激活函数 $f(\\cdot)$ 为 tanh 函数。在进一步求解前，首先要考虑矩阵对向量求导的布局。根据布局约定（layout conventions），谁是列向量就是什么布局[2]：  分子布局（numerator layout）： 分子为列向量且分母为行向量  分母布局（denominator layout）：分子为行向量且分母为列向量二者使用完全依据习惯而定，二者结果之间差一个转置。这里讨论了两种布局下的优劣。如果我们采用分母布局（点此参考），即分母保持列向量，分子按行向量展开，那么有\\[\\begin{aligned}\\frac{\\partial \\boldsymbol {Ax}}{\\partial \\boldsymbol x} &amp;= \\partial\\begin{bmatrix}A_{11} &amp;A_{12}&amp;\\cdots&amp;A_{1n}\\\\A_{21} &amp;A_{22}&amp;\\cdots&amp;A_{2n}\\\\\\vdots &amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\A_{m1} &amp;A_{n2}&amp;\\cdots&amp;A_{mn}\\\\\\end{bmatrix}\\begin{bmatrix}x_1 \\\\x_2\\\\\\vdots\\\\x_n\\\\\\end{bmatrix} / \\partial \\boldsymbol x\\\\&amp;= \\begin{bmatrix}\\partial (A_{11}x_1 + A_{12} x_2 + \\cdots + A_{1n} x_n) &amp;\\cdots &amp;\\partial (A_{m1}x_1 + A_{m2} x_2 + \\cdots + A_{mn} x_n)\\\\\\end{bmatrix}/\\partial \\boldsymbol x\\quad &lt;row!&gt;\\\\&amp;= \\begin{bmatrix}\\partial (A_{11}x_1 + A_{12} x_2 + \\cdots + A_{1n} x_n)/\\partial \\boldsymbol x &amp;\\cdots &amp;\\partial (A_{m1}x_1 + A_{m2} x_2 + \\cdots + A_{mn} x_n)/\\partial \\boldsymbol x\\\\\\end{bmatrix}\\\\&amp;= \\begin{bmatrix}\\partial (A_{11}x_1 + A_{12} x_2 + \\cdots + A_{1n} x_n)/\\partial x_1 &amp; \\cdots &amp; \\partial (A_{m1}x_1 + A_{m2} x_2 + \\cdots + A_{mn} x_n)/\\partial x_1\\\\\\partial (A_{11}x_1 + A_{12} x_2 + \\cdots + A_{1n} x_n)/\\partial x_2 &amp; \\cdots &amp; \\partial (A_{m1}x_1 + A_{m2} x_2 + \\cdots + A_{mn} x_n)/\\partial x_2\\\\\\vdots &amp; \\cdots &amp; \\vdots\\\\\\partial (A_{11}x_1 + A_{12} x_2 + \\cdots + A_{1n} x_n)/\\partial x_n &amp; \\cdots &amp; \\partial (A_{m1}x_1 + A_{m2} x_2 + \\cdots + A_{mn} x_n)/\\partial x_n\\\\\\end{bmatrix}\\\\&amp;=\\begin{bmatrix}A_{11} &amp;A_{21}&amp;\\cdots&amp;A_{m1}\\\\A_{12} &amp;A_{22}&amp;\\cdots&amp;A_{m2}\\\\\\vdots &amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\A_{1n} &amp;A_{2n}&amp;\\cdots&amp;A_{mn}\\\\\\end{bmatrix} = \\boldsymbol A^T\\end{aligned}\\]需要注意的是，分母布局下，求导的链式法则的顺序是反向的，假设 $\\boldsymbol u = \\boldsymbol u(\\boldsymbol x)$，那么\\[\\frac{\\partial \\boldsymbol f(\\boldsymbol g(\\boldsymbol u)}{\\partial \\boldsymbol x}= \\frac{\\partial \\boldsymbol u}{\\partial \\boldsymbol x}\\frac{\\partial \\boldsymbol g}{\\partial \\boldsymbol u}\\frac{\\partial \\boldsymbol f}{\\partial \\boldsymbol g}\\]我们先计算最后时刻 $t=T$ 的隐层梯度（分母布局链式法则方向相反）\\[\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_T} = \\frac{\\partial \\boldsymbol o_T}{\\partial \\boldsymbol h_T} \\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol o_T}\\]前面求 $\\boldsymbol V, \\boldsymbol c$ 的梯度时已经求出\\[\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol o_T} = \\frac{\\partial \\boldsymbol L}{\\partial \\hat {\\boldsymbol y_T}}\\frac{\\partial \\hat {\\boldsymbol y_T}}{\\partial \\boldsymbol o_T} = \\hat {\\boldsymbol y_T}-\\boldsymbol y_T = \\nabla_{\\boldsymbol o_T}\\boldsymbol L\\]假定 $\\boldsymbol {Vh}_T$ 的结果是列向量，而 $\\boldsymbol h_T$ 也是列向量，根据分母布局，有\\[\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_T} = \\frac{\\partial \\boldsymbol o_T}{\\partial \\boldsymbol h_T} \\nabla_{\\boldsymbol o_T}\\boldsymbol L = \\frac{\\partial \\boldsymbol {Vh}_T}{\\partial \\boldsymbol h_T} \\nabla_{\\boldsymbol o_T}\\boldsymbol L= \\boldsymbol V^T\\nabla_{\\boldsymbol o_T}\\boldsymbol L\\]对于 $T$ 时刻之前的任意时刻 $t$，根据迭代关系，$\\boldsymbol h_t$ 与 $\\boldsymbol o_t$ 和 $\\boldsymbol h_{t+1}$ 均有关，即\\[\\begin{aligned}\\boldsymbol h_{t+1} &amp;= f(\\boldsymbol a_{t+1}) =f(\\boldsymbol W \\boldsymbol h_t + \\boldsymbol U \\boldsymbol x_{t+1} + \\boldsymbol b)\\\\\\boldsymbol o_t &amp;= \\boldsymbol V \\boldsymbol h_t + \\boldsymbol c\\\\\\end{aligned}\\]对两个反向通路方向的梯度求和，有（分母布局链式法则方向相反）\\[\\begin{aligned}\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_t}&amp;=\\frac{\\partial \\boldsymbol h_{t+1}}{\\partial \\boldsymbol h_t}\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_{t+1}} + \\frac{\\partial \\boldsymbol o_t}{\\partial \\boldsymbol h_t}\\frac{\\partial \\boldsymbol L_t}{\\partial \\boldsymbol o_t}\\\\&amp;=\\frac{\\partial \\boldsymbol h_{t+1}}{\\partial \\boldsymbol h_t}\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_{t+1}} + \\boldsymbol V^T\\nabla_{\\boldsymbol o_t}\\boldsymbol L\\end{aligned}\\]下面考察 $\\partial \\boldsymbol h_t / \\partial \\boldsymbol a_t$，因为 $\\boldsymbol h_t, \\boldsymbol a_t$ 均为列向量，若采用分母布局，将分子 $\\boldsymbol h_t$ 看作行向量展开，那么\\[\\begin{aligned}\\frac{\\partial \\boldsymbol h_t }{ \\partial \\boldsymbol a_t} &amp;= \\partial[h_1,h_2,\\cdots,h_D]/\\partial \\boldsymbol a_t\\quad&lt;row!&gt;\\\\&amp;=\\begin{bmatrix}\\partial h_1/\\partial a_1&amp;\\partial h_2/\\partial a_1&amp;\\cdots&amp;\\partial h_D/\\partial a_1\\\\\\partial h_1/\\partial a_2&amp;\\partial h_2/\\partial a_2&amp;\\cdots&amp;\\partial h_D/\\partial a_2\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\\\partial h_1/\\partial a_D&amp;\\partial h_2/\\partial a_D&amp;\\cdots&amp;\\partial h_D/\\partial a_D\\\\\\end{bmatrix}\\\\&amp;= diag(f'(a_{t}))\\end{aligned}\\]其中 $diag$ 为对角线矩阵，因为下标不同的项偏导为 0 ，只有对角线元素非 0 。若 $f(\\cdot)$ 为 $tanh$ 函数，有 $tanh’=1-tanh^2$，那么\\[\\frac{\\partial \\boldsymbol h_{t+1}}{\\partial \\boldsymbol a_{t+1}} = diag(tanh'(a_{t+1})) = diag(1-tanh(a_{t+1})^2) = diag(1-h_{t+1}^2)\\]那么（分母布局链式法则反向）\\[\\frac{\\partial \\boldsymbol h_{t+1}}{\\partial \\boldsymbol h_t} = \\frac{\\partial \\boldsymbol a_{t+1}}{\\partial \\boldsymbol h_t} \\frac{\\partial \\boldsymbol h_{t+1}}{\\partial \\boldsymbol a_{t+1}} = W^T diag(1-h_{t+1}^2)\\]带回隐层梯度公式有\\[\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_t} = \\boldsymbol W^T diag(1- h_{t+1}^2)\\cdot\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_{t+1}} + \\boldsymbol V^T\\nabla_{\\boldsymbol o_t}\\boldsymbol L\\]稍作整理有\\[\\nabla_{\\boldsymbol h_t}\\boldsymbol L = \\boldsymbol W^T diag(1- h_{t+1}^2)\\cdot\\nabla_{\\boldsymbol h_{t+1}}\\boldsymbol L + \\boldsymbol V^T\\nabla_{\\boldsymbol o_t}\\boldsymbol L\\]可以看出，隐层梯度 $\\nabla_{\\boldsymbol h_t}\\boldsymbol L$ 可以采用递归的方式求解。下面即可写出 $\\boldsymbol W,\\boldsymbol U,\\boldsymbol b$ 的梯度表达式（分母布局链式法则方向相反）\\[\\begin{aligned}\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol b} &amp;= \\sum_t \\frac{\\partial \\boldsymbol a_t}{\\partial \\boldsymbol b}\\frac{\\partial \\boldsymbol h_t}{\\partial \\boldsymbol a_t}\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_t} = \\sum_t \\boldsymbol I\\cdot diag(1-h_t^2)\\nabla_{\\boldsymbol h_t}\\boldsymbol L\\\\\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol W} &amp;= \\sum_t \\frac{\\partial \\boldsymbol a_t}{\\partial \\boldsymbol W}\\frac{\\partial \\boldsymbol h_t}{\\partial \\boldsymbol a_t}\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_t} = \\sum_t \\frac{\\partial \\boldsymbol a_t}{\\partial \\boldsymbol W}\\cdot diag(1-h_t^2)\\nabla_{\\boldsymbol h_t}\\boldsymbol L\\\\\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol U} &amp;= \\sum_t \\frac{\\partial \\boldsymbol a_t}{\\partial \\boldsymbol U}\\frac{\\partial \\boldsymbol h_t}{\\partial \\boldsymbol a_t}\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_t} = \\sum_t \\frac{\\partial \\boldsymbol a_t}{\\partial \\boldsymbol U}\\cdot diag(1-h_t^2)\\nabla_{\\boldsymbol h_t}\\boldsymbol L\\end{aligned}\\]对于 $\\boldsymbol W$ 和 $\\boldsymbol U$，需要进一步分析 $\\boldsymbol a$ 对矩阵 $\\boldsymbol W, \\boldsymbol U$ 的偏导。因为\\[\\boldsymbol a_t = \\boldsymbol W \\boldsymbol h_{t-1} + \\boldsymbol U \\boldsymbol x_t + \\boldsymbol b\\]以 $\\boldsymbol a$ 对 $\\boldsymbol W$ 的偏导为例，采用分母布局，即求导过程中的分母 $\\boldsymbol W$ 保持为正常矩阵形式，而对分子中的 $\\boldsymbol W \\boldsymbol h$ 按行向量展开，有\\[\\begin{aligned}&amp;\\frac{\\partial \\boldsymbol a}{\\partial \\boldsymbol W} = \\frac{\\partial \\boldsymbol W \\boldsymbol h}{\\partial \\boldsymbol W}=\\partial\\begin{bmatrix}w_{11}&amp;w_{12}&amp;\\cdots&amp;w_{1D}\\\\w_{21}&amp;w_{22}&amp;\\cdots&amp;w_{2D}\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\w_{D1}&amp;w_{D2}&amp;\\cdots&amp;w_{DD}\\end{bmatrix}\\begin{bmatrix}h_1\\\\h_2\\\\\\vdots\\\\h_D\\end{bmatrix}/ \\partial \\boldsymbol W\\\\&amp;=\\begin{bmatrix}w_{11}h_1+w_{12}h_2+\\cdots+w_{1D}h_D\\\\w_{21}h_1+w_{22}h_2+\\cdots+w_{2D}h_D\\\\\\vdots\\\\w_{D1}h_1+w_{D2}h_2+\\cdots+w_{DD}h_D\\\\\\end{bmatrix}^T/ \\partial \\boldsymbol W \\quad &lt;row!&gt;\\\\&amp;=\\begin{bmatrix}(w_{11}h_1+w_{12}h_2\\cdots+w_{1D}h_D)/\\partial w_{11}&amp;(w_{21}h_1+w_{22}h_2\\cdots+w_{2D}h_D)/\\partial w_{12}&amp;\\cdots&amp;(w_{D1}h_1+w_{D2}h_2\\cdots+w_{DD}h_D)/\\partial w_{1D}\\\\(w_{11}h_1+w_{12}h_2\\cdots+w_{1D}h_D)/\\partial w_{21}&amp;(w_{21}h_1+w_{22}h_2\\cdots+w_{2D}h_D)/\\partial w_{22}&amp;\\cdots&amp;(w_{D1}h_1+w_{D2}h_2\\cdots+w_{DD}h_D)/\\partial w_{2D}\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\(w_{11}h_1+w_{12}h_2\\cdots+w_{1D}h_D)/\\partial w_{D1}&amp;(w_{21}h_1+w_{22}h_2\\cdots+w_{2D}h_D)/\\partial w_{D2}&amp;\\cdots&amp;(w_{D1}h_1+w_{D2}h_2\\cdots+w_{DD}h_D)/\\partial w_{DD}\\end{bmatrix}\\\\&amp;=\\begin{bmatrix}h_1&amp;0&amp;\\cdots&amp;0\\\\0&amp;h_2&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\0&amp;0&amp;\\cdots&amp;h_D\\end{bmatrix}=diag (h^T)\\end{aligned}\\]对 $\\boldsymbol U$ 的求导同理，最终有\\[\\frac{\\partial \\boldsymbol a_t}{\\partial \\boldsymbol W} = diag(h_{t-1}^T)\\quad\\quad\\quad \\frac{\\partial \\boldsymbol a_t}{\\partial \\boldsymbol U} = diag(x_t^T)\\]其中 $\\boldsymbol h_t \\in \\mathbb R^D,\\boldsymbol x_t \\in \\mathbb R^M$ 是列向量。带入上面的$\\boldsymbol W,\\boldsymbol U,\\boldsymbol b$ 的梯度表达式，有\\[\\begin{aligned}\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol W} &amp;= \\sum_t \\frac{\\partial \\boldsymbol a_t}{\\partial \\boldsymbol W}\\frac{\\partial \\boldsymbol h_t}{\\partial \\boldsymbol a_t}\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_t} = \\sum_t diag (h_{t-1}^T)\\cdot diag(1-h_t^2)\\nabla_{\\boldsymbol h_t}\\boldsymbol L = \\sum_t \\cdot diag(1-h_t^2)\\nabla_{\\boldsymbol h_t}\\boldsymbol L \\cdot \\boldsymbol h_{t-1}^T\\\\\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol U} &amp;= \\sum_t \\frac{\\partial \\boldsymbol a_t}{\\partial \\boldsymbol U}\\frac{\\partial \\boldsymbol h_t}{\\partial \\boldsymbol a_t}\\frac{\\partial \\boldsymbol L}{\\partial \\boldsymbol h_t} = \\sum_t diag (x^T)\\cdot diag(1-h_t^2)\\nabla_{\\boldsymbol h_t}\\boldsymbol L = \\sum_t diag(1-h_t^2)\\nabla_{\\boldsymbol h_t}\\boldsymbol L \\cdot \\boldsymbol x^T\\end{aligned}\\]与参考链接 [6]，[7] 的结果相同。最后将 $\\boldsymbol h_{t-1}, \\boldsymbol x_t$ 提到末尾的操作应该是成立的，懒得推导了…… 0.01.5. 梯度消失RNN 存在时间维度上的梯度消失问题。为了具体解释梯度消失的原因，首先将前面推导出来的 $t$ 时刻的 $\\boldsymbol L$ 对隐层 $\\boldsymbol h$ 的梯度递推过程列写如下\\[\\nabla_{\\boldsymbol h_t}\\boldsymbol L = \\boldsymbol W^T diag(1- h_{t+1}^2)\\cdot\\nabla_{\\boldsymbol h_{t+1}}\\boldsymbol L + \\boldsymbol V^T\\nabla_{\\boldsymbol o_t}\\boldsymbol L\\]注意到，$diag(1- h_{t+1}^2) = tanh(\\boldsymbol h_{t+1})’$，那么上式可以改写为\\[\\nabla_{\\boldsymbol h_t}\\boldsymbol L = \\boldsymbol W^T tanh(\\boldsymbol h_{t+1})'\\cdot\\nabla_{\\boldsymbol h_{t+1}}\\boldsymbol L + \\boldsymbol V^T\\nabla_{\\boldsymbol o_t}\\boldsymbol L\\]那么，对于 $t-1$ 时刻\\[\\begin{aligned}\\nabla_{\\boldsymbol h_{t-1}}\\boldsymbol L &amp;= \\boldsymbol W^T tanh(h_{t})'\\cdot\\nabla_{\\boldsymbol h_{t}}\\boldsymbol L + \\boldsymbol V^T\\nabla_{\\boldsymbol o_{t-1}}\\boldsymbol L\\\\&amp;=\\boldsymbol W^T tanh(h_{t})'\\cdot (\\boldsymbol W^T tanh(\\boldsymbol h_{t+1})'\\nabla_{\\boldsymbol h_{t+1}}\\boldsymbol L + \\boldsymbol V^T\\nabla_{\\boldsymbol o_t}\\boldsymbol L) + \\boldsymbol V^T\\nabla_{\\boldsymbol o_{t-1}}\\boldsymbol L\\\\&amp;=\\boldsymbol W^T tanh(h_{t})'\\cdot (\\boldsymbol W^T tanh(\\boldsymbol h_{t+1})'\\nabla_{\\boldsymbol h_{t+1}}\\boldsymbol L + \\boldsymbol V^T\\nabla_{\\boldsymbol o_t}\\boldsymbol L) + \\boldsymbol V^T\\nabla_{\\boldsymbol o_{t-1}}\\boldsymbol L\\\\&amp;=\\boldsymbol W^T tanh(h_{t})'\\cdot (\\boldsymbol W^T tanh(\\boldsymbol h_{t+1})'\\cdots(\\boldsymbol W^T tanh(\\boldsymbol h_T)'\\cdots) + \\boldsymbol V^T\\nabla_{\\boldsymbol o_t}\\boldsymbol L) + \\boldsymbol V^T\\nabla_{\\boldsymbol o_{t-1}}\\boldsymbol L\\\\\\end{aligned}\\]稍微整理并展开，令 $\\boldsymbol W^T tanh’(h) = WT$ 表示包含 $tanh’$ 的项，$\\boldsymbol V^T \\nabla_{\\boldsymbol o}\\boldsymbol L = \\nabla$ 表示不含高阶次方的项，进行简化描述有（注意此处为简化描述，连乘表示为次方关系，略去了下标）\\[\\begin{aligned}\\nabla_{\\boldsymbol h_{t-1}}\\boldsymbol L &amp;= (WT)^{T-t+1}\\nabla_TL+(WT)^{T-t+2}\\nabla+(WT)^{T-t+3}\\nabla+...+(WT)^{1}\\nabla+\\nabla\\end{aligned}\\]而对 $tanh$ 及  $tan’h$  进行画图如下可以看出，由于 $tanh’$ 的值域在 $(0,1)$ 之间，对于训练过程大部分情况下 $tanh’$ 是小于 1 的。若 $\\boldsymbol W^T$ 的取值较小导致 $WT = \\boldsymbol W^T tanh’(h) &lt;1$，多项连乘会导致最终的值趋近于0。因此，随着 $t$ 与 $T$ 的逐渐拉大，隐层梯度中包含的 $WT$ 项的次方越来越高，其取值越来越接近 0 。这会导致较长时间 $t$ 前的梯度项 $\\nabla_{\\boldsymbol h_{t-1}}\\boldsymbol L$ 中的第一项十分接近 0 ，即导致较长时间 $t$ 前的 $\\boldsymbol L$ 对参数的梯度项仅与那个时刻的输出有关（上式中的 $\\nabla$ 项），而不再包含 $\\boldsymbol L$ 的信息。也就是说，在时间维度上较前时刻的权重无法根据最终的 loss 信息来更新。RNN 中参数的梯度被近距离梯度主导，导致模型难以学到远距离的依赖关系。注意，RNN 中总的梯度是不会消失的。即便梯度越传越弱，那也只是远距离的梯度消失，由于近距离的梯度不会消失，所有梯度之和便不会消失。RNN 梯度消失的本质：由于时间维度共享了参数矩阵，导致计算隐态 $\\boldsymbol h_t$ 的梯度时会循环计算矩阵乘法，所以 BPTT 算法求解梯度时出现了参数矩阵的累乘，使得当时间尺度过长时的隐层梯度丢失。1.6. 梯度爆炸另一方面，若 $\\boldsymbol W^T$ 的取值较大，导致 $\\boldsymbol W tanh(\\boldsymbol h)$ 的值大于1，那么连乘的每一项均大于1，就会导致梯度爆炸现象。梯度爆炸会使得学习不稳定， 参数变化太大导致无法获取最优参数。2. 参考文献[1]  刘建平Pinard. 循环神经网络(RNN)模型与前向反向传播算法.[2]  维基百科. 矩阵微积分-布局约定.[3] 仙守. 数学-矩阵计算（4）两种布局.[4] 谓之小一. LSTM如何解决RNN带来的梯度消失问题.[5] thinkando. 机器学习中的矩阵、向量求导.[6] Leo蓝色. RNN正向及反向传播.[7] 小米粥. RNN的反向传播-BPTT."
  },
  
  {
    "title": "深度学习文章阅读（FDNN）",
    "url": "/posts/deep-learning-FDNN/",
    "categories": "Academic, Paper",
    "tags": "fuzzy, deep learning",
    "date": "2020-09-28 09:43:19 +0800",
    





    
    "snippet": "FDNN 于2016年由 Deng Yue 提出，是一种模糊深度神经网络的混合架构，在图像分类和区域划分方面优于传统的深度神经网络等多种方法。  1. 网络架构          1.1. 模糊逻辑表示部分      1.2. 神经表示部分      1.3. 混合部分      1.4. 任务驱动部分      1.5. 总结        2. 训练  3. 实验  4. 参考文献1. ...",
    "content": "FDNN 于2016年由 Deng Yue 提出，是一种模糊深度神经网络的混合架构，在图像分类和区域划分方面优于传统的深度神经网络等多种方法。  1. 网络架构          1.1. 模糊逻辑表示部分      1.2. 神经表示部分      1.3. 混合部分      1.4. 任务驱动部分      1.5. 总结        2. 训练  3. 实验  4. 参考文献1. 网络架构2016.《A Hierarchical Fused Fuzzy Deep Neural Network for Data Classification》混合架构由四部分组成：模糊逻辑表示部分（黑色）、神经表示部分（蓝色）、混合部分（绿色）、任务驱动部分（红色）。假设 $l$ 为层编号，$a_i^{(l)}$ 为第 $l$ 层第 $i$ 个神经元的输入，$o_i^{(l)}$ 为对应的输出。假设我们输入的图像有 $k=15$ 个类别，每张图像有 $n=200$ 个特征，那么输入层维度为200，隶属度函数层维度为 $15\\times 200$。输出层维度为15。1.1. 模糊逻辑表示部分输入层的每一个神经元均于多个隶属度函数相连接，隶属度函数用来表征任意输入元素的语言标签，这里的输入元素即输入层的单一神经元，也即输入向量的一个特征维度。隶属度函数层将输入计算为属于某个模糊集的程度。文中采用高斯隶属度函数，将第 $i$ 个模糊神经元映射的第 $k$ 个输入转化为模糊度\\[o_i^{(l)} = u_i(a_k^{(l)})=e^{-\\frac{-(a_k^{(l)}-\\mu_i)^2}{\\sigma_i^2}},\\forall i\\]对于输入的每一个特征维度（$\\forall n$），隶属度函数层均会计算其在每个类别（$k$）中的模糊度。文中均值 $\\mu$ 和方差 $\\sigma$ 的选取遵循前人研究：  C.-T. Lin, C.-M. Yeh, S.-F. Liang, J.-F. Chung, and N. Kumar, “Support-vector-based fuzzy neural network for pattern classification,” Fuzzy Systems, IEEE Transactions on, vol. 14, no. 1, pp. 31–41, 2006.  F.-J. Lin, C.-H. Lin, and P.-H. Shen, “Self-constructing fuzzy neural network speed controller for permanent-magnet synchronous motor drive,” Fuzzy Systems, IEEE Transactions on, vol. 9, no. 5, pp. 751–759, 2001.以某个例子为例，假设输入的图像是一个自行车，被转化为一组 $n=6$ 维的特征向量：{圆圈个数，长直线个数，颜色，特征1，特征2，特征3}，则输入层（Input layer）为 6 个神经元。假设图像的类别为 $k=4$ 类，分别为 {篮球，海滩，自行车，显示器}，那么对于输入层的每个神经元（图像特征向量的每个元素），其针对每个类别均可以设计一个隶属度函数，那么隶属度函数总共为 $6\\times 4=24$ 个，也即隶属度函数层的神经元个数为 $6\\times 4=24$。根据常识，图像特征向量的第一个元素圆圈个数，对应 4 个类别中的期望取值不妨设为 ${1,0.2,2,0}$ ，因为篮球一般就 1 个圆圈，海滩一般没圆圈但是不排除有热气球混入，自行车一般有 2 个圆圈车轮但是不排除还有独轮车和三轮车，显示器一般没有圆圈特征。那么这四个隶属度函数分别可能的形状为（试图画 4 个不同的高斯函数未果，大家凑活看）：对于输入的自行车图像，假设其第一个特征元素的值（通过各种图像特征提取方法处理后）为 2.12，经过四个隶属度函数的计算后取值分别为 {0.08, 0.14, 0.96, 0.02}，即为隶属度函数层的输出，传递到模糊规则层。模糊规则层执行模糊 AND 逻辑，定义为求连乘，假设 $\\Omega_i$ 是第 $l-1$ 层所有与第 $l$ 层第 $i$ 个神经元节点相连的神经元，有：\\[o_i^{(l)} = \\prod_j o_j^{(l-1)},\\forall j\\in \\Omega_i\\]连乘后的结果仍然是模糊度。模糊规则层的神经元个数与类别个数 $k$ 相同。接着举例，依然是输入自行车的图像，其 6 个特征维度分别经过隶属度函数后，对应第三类的模糊度应该都很高。那么经过模糊规则层其连乘后，第三个神经元的取值相比其它神经元而言是一个大值（比如 $0.96\\times 0.91\\times 0.82\\times 0.93\\gg0.1\\times0.2\\times0.12\\times0.23$）。反之，如果输入一个手机的图像，其在各方面特征都比较符合显示器的特征，那么可能在模糊规则层上第四个神经元的连乘结果较大，但因为它又不是一个显示器，那么可能其连乘结果 $0.76\\times 0.82\\times 0.89\\times 0.75$ 可能又小于输入显示器图像时的结果 $0.89\\times0.93\\times0.88\\times0.95$。1.2. 神经表示部分该部分用来将输入转化为某种高层表达，采用全连接神经网络，激活函数为Sigmoid，参数为权重和方差 $\\theta^{(l)} = {\\boldsymbol w^{(l)},\\boldsymbol b^{(l)}}$，有\\[o_i^{(l)} = \\frac{1}{1+e^{-a_i^{(l)}}},\\quad a_i^{(l)} = \\boldsymbol w_i^{(l)}\\boldsymbol o^{(l-1)} + \\boldsymbol b_i^{(l)}\\]1.3. 混合部分该部分受到已有研究的启发，采用一个被广泛使用的多模型混合神经网络结构：  J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, and A. Y. Ng, “Multimodal deep learning,” in Proceedings of the 28th International Conference on Machine Learning (ICML-11), 2011, pp. 689–696.\\[\\begin{aligned}o_i^{(l)} &amp;= \\frac{1}{1+e^{-a_i^{(l)}}}\\\\a_i^{(l)} &amp;= (\\boldsymbol w_d)_i^{(l)}(\\boldsymbol o_d)^{(l-1)} + (\\boldsymbol w_f)_i^{(l)}(\\boldsymbol o_f)^{(l-1)} + \\boldsymbol b_i^{(l)}\\end{aligned}\\]其中，$\\boldsymbol o_d$ 表示（深度）神经表示部分的输出，$\\boldsymbol o_f$ 表示模糊逻辑表示部分的输出，二者通过权重$\\boldsymbol w_d, \\boldsymbol w_f$ 来混合。然后，混合后的信息，通过与神经表示部分类似的多层全连接层来进行更深度的变换，输出结果结合了模糊度和神经表达，而不再是模糊度。1.4. 任务驱动部分在该部分中，设置分类层，将混合表达信息对应到相应的分类中，采用softmax函数。假设 $(\\boldsymbol f_i,y_i)$ 是第 $i$ 个输入以及其对应的标签， $\\pi_\\Theta(\\boldsymbol f_i)$ 表示 FDNN 的前向传播过程，那么对于第 $c$ 个通道的 softmax 函数的计算过程如下\\[\\hat y_{(ic)} = p(y_i\\vert\\boldsymbol f_i) = \\frac{e^{\\boldsymbol w_c\\pi_\\Theta(\\boldsymbol f_i)+b_c}}{\\sum_c e^{\\boldsymbol w_c\\pi_\\Theta(\\boldsymbol f_i)+b_c}}\\]其中，$\\boldsymbol w_c, b_c$ 分别为第 $c$ 个类别的回归系数和回归偏差，$\\hat \\boldsymbol y=[\\hat y_{i1},\\cdots,\\hat y_{ik}]$ 表示 $k$ 类的预测的标签输出。在 $m$ 个训练样本上，采用 MSE 作为损失函数\\[C = \\frac{1}{m}\\sum_i^m \\vert\\vert \\hat \\boldsymbol y_i-\\boldsymbol y_i \\vert\\vert_2^2\\]1.5. 总结虽然有多种其它可选方法来提取深度混合信息，这里作者仍然倾向于使用模糊学习，原因有如下三点：  模糊学习可以方便的降低输入数据的不确定性，这种重要的模糊度降低追求是模糊系统不可或缺的特性，是其它学习系统无法替代的。  模糊学习自然会产生 $(0,1)$ 范围内的软逻辑值（模糊表示）。模糊量（原文fusion有误，应为fuzzy）和神经输出量在相同的范围内，使得这两种输出在融合部分很容易融合。  模糊学习部分允许任务驱动的参数学习。在这里，通过反向传播的智能数据驱动学习，可以代替精疲力竭的手工参数调整步骤。2. 训练模型可以被分为模糊逻辑表示部分和神经网络部分（包括神经表示、混合、任务驱动部分），待学习的参数为模糊逻辑表示部分的 $\\mu, \\sigma$ 以及神经网络部分的 $\\omega, b$。不妨假设：\\[\\theta = [\\mu, \\sigma, \\omega, b]\\]对上述模型进行训练主要包括两个步骤：初始化和微调。  首先进行初始化。对于神经部分，所有神经元节点的 $b=0$。权重在以下区间内均匀采样随机初始化\\[\\omega_i^{(l)} \\sim U[-\\frac{1}{\\sqrt n^{(l-1)}},\\frac{1}{\\sqrt n^{(l-1)}}]\\]其中 $U$ 表示均匀分布，$n^{(l-1)}$ 表示第 $l-1$ 层的神经元节点个数。对于混合部分，$n^{(l-1)}$ 是上一层也即模糊表示部分的输出层和神经表示部分的输出层的神经元节点个数之和。对于模糊表示部分，所有层（即隶属度层和模糊规则层）的权值均为1（后续学习中固定不变？）。隶属度函数层的神经元节点包括两个的未知参数：第 $i$ 个模糊神经元节点的模糊中心 $\\mu_i$ 和模糊宽度 $\\sigma_i$。作者根据输入数据的 k-均值聚类结果（k与分类数相等），采用下面参考文献中的方法初始化这些参数。  N. Kasabov and Q. Song, “Denfis: dynamic evolving neural-fuzzy inference system and its application for time-series prediction,” Fuzzy Systems, IEEE Transactions on, vol. 10, no. 2, pp. 144–154, Apr 2002.  然后进行微调（训练）。作者采用著名的反向传播算法来计算所有参数的梯度，从而进行训练\\[\\frac{\\partial C}{\\partial \\theta^{(l)}} = \\sum_n (\\frac{\\partial C_n}{\\partial o_i^{(l)}})\\frac{\\partial o_i^{(l)}}{\\partial a_i^{(l)}}\\frac{\\partial a_i^{(l)}}{\\partial \\theta_i^{(l)}}\\]其中，第一项被称为BP项，后两项是与层相关的求导项。神经表示部分、混合部分和任务驱动部分的神经元的反向传播求导，根据前面的式子，因为使用的激活函数和参数比较简单，因此求导很简单。模糊表示部分，根据前面的式子，包括参数对 $\\theta = (\\mu_i,\\sigma_i)$ （原文有误，写为了 $\\theta = (m_i,\\sigma_i)$），根据前面隶属度函数的定义，其对参数的导数也容易求得。采用动量梯度下降法训练。\\[\\begin{aligned}  v(t) &amp;= \\gamma v(t-1)+\\alpha\\frac{\\partial C}{\\partial \\theta^{(l)}}\\\\  \\theta^{(l)}(t+1) &amp;= \\theta^{(l)}(t)-v(t)\\end{aligned}\\]其中，$v(t)$ 是速度向量，由上一时刻的速度和当前的梯度决定，$t$ 表示迭代计数，$\\gamma \\in [0,1]$ 控制由上一时刻梯度贡献的信息的影响大小。$\\alpha &lt; 1$ 是学习率。作者参考如下文献，经验定给一个较小的梯度记忆系数 $\\gamma=0.1$ 和学习率 $\\alpha = 0.05$。  I. Sutskever, J. Martens, G. Dahl, and G. Hinton, “On the importance of initialization and momentum in deep learning,” in Proceedings of the 30th international conference on machine learning (ICML-13), 2013, pp. 1139–1147.为解决过拟合问题，作者采用了 dropout 策略，在每次训练迭代中随机选择 $p\\%$ 的神经元，它们的梯度将不会被更新。3. 实验作者设计了三个不同的网络结构 C1，C2 和 C3，复杂程度逐渐增加。                   Input      Fuzzy      Neural      Fusion      Output                  C1      $n$      $k\\times n$      $64(2)$      $64(2)$      $k$              C2      $n$      $k\\times n$      $128(2)$      $128(2)$      $k$              C3      $n$      $k\\times n$      $256(2)$      $256(2)$      $k$      作者采用2个分类任务来进行实验：自然场景图像分类和股票走势预测。自然场景分类中，数据集一共包含4500个自然图片，共15个类。作者采用 kernel assignment algorithm 为每个图片产生一个直方图作为特征来分类。每张图像最终包括200个码字，因此 $k=15, n=200$。kernel assignment algorithm 算法参考文献如下  J. C. van Gemert, J.-M. Geusebroek, C. J. Veenman, and A. W. Smeulders, “Kernel codebooks for scene categorization,” in Computer Vision–ECCV 2008. Springer, 2008, pp. 696–709.股票走势预测中，从分类的角度理解，其目标是预测股票在未来某个时间 $(t+\\mathcal H)$ 的状态是涨，跌，还是持平。其中 $\\mathcal H$ 是预测时间间隔。作者采用上证金融指数期货的高频 tick 行情数据进行分析，tick 数据每秒更新2次，一个交易日多达 32000 个 tick 数据。作者参考如下文献的方法，从价格、成交量和订单量中提取多个指标，归纳为一个长向量（$\\mathbb R^{76}$），各分量元素归一化到 $[-1,1]$ 区间。因此 $k=3, n=76$。更进一步，考虑两种预测时间间隔，即 $\\mathcal H = 5, \\mathcal H = 10$，分别代表 5 和 10 个 tick 间隔。  Y. Deng, Y. Kong, F. Bao, and Q. Dai, “Sparse coding-inspired optimal trading system for hft industry,” Industrial Informatics, IEEE Transactions on, vol. 11, no. 2, pp. 467–475, April 2015.4. 参考文献无。"
  },
  
  {
    "title": "自适应网络模糊推理系统（ANFIS）",
    "url": "/posts/deep-learning-ANFIS/",
    "categories": "Academic, Paper",
    "tags": "fuzzy, deep learning",
    "date": "2020-09-26 08:55:19 +0800",
    





    
    "snippet": "本文介绍了 1993 年发表的自适应网络模糊推理系统（ANFIS），Adaptive-Network-Based Fuzzy Inference System。  1. 基础知识          1.1. 模糊推理系统      1.2. 自适应网络      1.3. ANFIS 结构      1.4. ANFIS 学习算法        2. 程序文件组成  3. membershi...",
    "content": "本文介绍了 1993 年发表的自适应网络模糊推理系统（ANFIS），Adaptive-Network-Based Fuzzy Inference System。  1. 基础知识          1.1. 模糊推理系统      1.2. 自适应网络      1.3. ANFIS 结构      1.4. ANFIS 学习算法        2. 程序文件组成  3. membership.py          3.1. make_anfis()      3.2. make_gauss_mfs()      3.3. GaussMemFunc()        4. anfis.py          4.1. AnfisNet()      4.2. FuzzifyVariable 类      4.3. ConsequentLayer 类      4.4. PlainConsequentLayer 类        5. 参考文献1. 基础知识1.1. 模糊推理系统Fuzzy Inference System（FIS），由五个功能模块组成：  包含若干模糊if-then规则的规则库；  定义关于使用模糊if-then规则的模糊集的隶属函数的数据库；  在规则上的执行推理操作的决策单元；  将明确输入转化为与语言价值匹配的程度的模糊界面；  将推理得到的模糊结果转化为明确输出的去模糊界面。通常，1、2被联合称为知识库。1.2. 自适应网络自适应网络是一个由节点和连接节点的定向链路组成的多层前馈网络，其中每个节点对传入的信号以及与此节点相关的一组参数执行一个特定的功能(节点函数)。自适应网络的结构中包含有参数的方形节点和无参数的圆形节点，自适应网络的参数集是每个自适应节点的参数集的结合。他们的输出依赖于这些节点相关的参数，学习规则指定如何更改这些参数。Jyh-Shing Roger Jang 于 1993 年发表的《ANFIS : Adaptive-Network-Based Fuzzy Inference System》。当时对于处理模糊不确定系统，使用传统数学工具的系统建模并不能得到令人满意的效果。考虑采用模糊if-then规则的模糊推理系统不需要精确的定量分析就可以对人的知识和推理过程进行定性建模，作者提出了一种基于自适应网络的模糊推理系统。1.3. ANFIS 结构ANFIS的模型结构由自适应网络和模糊推理系统合并而成，在功能上继承了模糊推理系统的可解释性的特点以及自适应网络的学习能力，能够根据先验知识改变系统参数，使系统的输出更贴近真实的输出。为简单起见，假定所考虑的模糊推理系统有2个输入x和y，单个输出z。对于一阶 Takagi-Sugeno 模糊模型，如果具有以下2条模糊规则  rule 1: if $x$ is $A_1$ and $y$ is $B_1$ then $f_1=p_1x+q_1y+r_1$  rule 2: if $x$ is $A_2$ and y is $B_2$ then $f_2=p_2x+q_2y+r_2$那么该一阶T-S模糊推理系统的ANFIS网络结构如图所示输入x，y在第一层进行模糊化，模糊化的方法：用隶属函数（menbership functions，MFs，一般为钟形函数，钟形函数参数为前向参数）对输入特征x，y进行模糊化操作，得到一个[0,1]的隶属度（menbership grade），通常用mu表示。在第二层，每个特征的隶属度mu相乘得到每个规则的触发强度（firing strength）。第三层将上一层得到的每条规则的触发强度做归一化，表征该规则在整个规则库中的触发比重，即在整个推理过程中使用到这条规则的程度（用概率理解）。第四层计算规则的结果，一般由输入特征的线性组合给出（假设输入有n个特征，$f_i=c_0+c_1x_1+c_2x_2+…+c_nx_n$。$c_0,c_1,…,c_n$为后向参数）。第五层去模糊化得到确切的输出，最终的系统输出结果为每条规则的结果的加权平均（权重为规则的归一化触发程度，理解为计算期望）。ANFIS is a way of presenting a fuzzy inference system (FIS) as a series of numeric layers so that it can be trained like a neural net.The canonical reference is the original paper by Jyh-Shing Roger Jang:  Jang, J.-S.R. (1993). “ANFIS: adaptive-network-based fuzzy inference system”. IEEE Transactions on Systems, Man and Cybernetics. 23 (3): 665–685. doi:10.1109/21.256541Note that it assumes a Takagi Sugeno Kang (TSK) style of defuzzification rather than the more usual Mamdani style.1.4. ANFIS 学习算法文章W中给出的学习算法（参数更新方法）为 LSE-GD 混合学习算法。即更新参数同时在前向传递和反向传递中进行。在正向传播中，我们固定前向参数，在输入传递到第四层时，通过最小二乘估计（least square estimate，LSE）更新后向参数，在这种前向参数（隶属度函数的参数）固定的前提下，得到的后向参数（第四蹭线性组合参数）估计是最优的，这样，混合学习算法比单纯的GD算法要快很多。2. 程序文件组成ANFIS（https://github.com/jfpower/anfis-pytorch ）The ANFIS framework is mainly in three files:      anfis.py This is where the layers of the ANFIS system are defined as Torch modules.        membership.py At the moment I only have Bell and Gaussian membership functions, but any others will go in here too.        experimental.py The experimental infrastructure to train and test the FIS, and to plot some graphs etc.  There are then some runnable examples:      jang_examples.py these are four examples from Jang’s paper (based partly on the details in the paper, and particle on the example folders in his source code distribution).        vignette_examples.py these are three examples from the Vignette paper. Two of these use Gaussians rather than Bell MFs.  3. membership.py定义了隶属度函数。3.1. make_anfis()def make_anfis(x, num_mfs=5, num_out=1, hybrid=True):    '''        Make an ANFIS model, auto-calculating the (Gaussian) MFs.        I need the x-vals to calculate a range and spread for the MFs.        Variables get named x0, x1, x2,... and y0, y1, y2 etc.    '''    num_invars = x.shape[1]    minvals, _ = torch.min(x, dim=0)    maxvals, _ = torch.max(x, dim=0)    ranges = maxvals-minvals    invars = []    for i in range(num_invars):        sigma = ranges[i] / num_mfs        mulist = torch.linspace(minvals[i], maxvals[i], num_mfs).tolist()        invars.append(('x{}'.format(i), make_gauss_mfs(sigma, mulist)))    outvars = ['y{}'.format(i) for i in range(num_out)]    model = AnfisNet('Simple classifier', invars, outvars, hybrid=hybrid)    return model输入 x 的列数作为输入状态量的个数，求 x 跨行间比较的最大值和最小值（即沿着每列求最大值和最小值） minvals, maxvals，即可得到输入各个状态量的取值范围 ranges。num_mfs 为隶属度函数的个数。对于每个输入状态量，采用取值范围除以 num_mfs 来初始化 sigma，采用在取值范围内均匀取 num_mfs 个点来初始化 mulist。用得到的 sigma, mulist 来初始化高斯隶属度函数 make_gauss_mfs()。最终，将得到的隶属度函数，与一个字符串 'x{}'.format(i) 一起，组成一个元组（tuple），添加到列表 invars 中作为后续建立网络的输入。假设输入状态量维度（列数）为2，则 invars 的成员为invars[0] = ['x0', [GaussMembFunc(), GaussMembFunc(), GaussMembFunc()]]invars[1] = ['x1', [GaussMembFunc(), GaussMembFunc(), GaussMembFunc()]]outvars 列表通过遍历输出状态量的维度来建立，是一个字符串列表。假设输出状态量维度为3，则 outvars 的成员为outvars = ['y0', 'y1', 'y2']最后，将 invars 和 outvars  作为参数传入 AnfisNet() 建立 ANFIS 网络。转到 AnfisNet() 查阅。3.2. make_gauss_mfs()def make_gauss_mfs(sigma, mu_list):    '''Return a list of gaussian mfs, same sigma, list of means'''    return [GaussMembFunc(mu, sigma) for mu in mu_list]make_gauss_mfs 输入 sigma, mulist ，根据 mulist 的个数（也就是之前 make_anfis() 函数中传入的隶属度函数的个数 num_mfs），调用 GaussMembFunc()，返回一个成员为 membership.GaussMembFunc 类型的列表。3.3. GaussMemFunc()class GaussMembFunc(torch.nn.Module):    '''        Gaussian membership functions, defined by two parameters:            mu, the mean (center)            sigma, the standard deviation.    '''    def __init__(self, mu, sigma):        super(GaussMembFunc, self).__init__()        self.register_parameter('mu', _mk_param(mu))        self.register_parameter('sigma', _mk_param(sigma))    def forward(self, x):        val = torch.exp(-torch.pow(x - self.mu, 2) / (2 * self.sigma**2))        return val    def pretty(self):        return 'GaussMembFunc {} {}'.format(self.mu, self.sigma)该函数包括 mu, sigma 两个可反向求导的参数，同时在 foward 中定义了函数的前向传播表达式并返回函数值 val，即一个高斯函数\\[val = e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\]4. anfis.py定义了 ANFIS 的层。4.1. AnfisNet()定义了 5 层的 ANFIS 网络类容器。class AnfisNet(torch.nn.Module):    '''        This is a container for the 5 layers of the ANFIS net.        The forward pass maps inputs to outputs based on current settings,        and then fit_coeff will adjust the TSK coeff using LSE.    '''    def __init__(self, description, invardefs, outvarnames, hybrid=True):        super(AnfisNet, self).__init__()        self.description = description        self.outvarnames = outvarnames        self.hybrid = hybrid        varnames = [v for v, _ in invardefs]        mfdefs = [FuzzifyVariable(mfs) for _, mfs in invardefs]        self.num_in = len(invardefs)        self.num_rules = np.prod([len(mfs) for _, mfs in invardefs])        if self.hybrid:            cl = ConsequentLayer(self.num_in, self.num_rules, self.num_out)        else:            cl = PlainConsequentLayer(self.num_in, self.num_rules, self.num_out)        self.layer = torch.nn.ModuleDict(OrderedDict([            ('fuzzify', FuzzifyLayer(mfdefs, varnames)),            ('rules', AntecedentLayer(mfdefs)),            # normalisation layer is just implemented as a function.            ('consequent', cl),            # weighted-sum layer is just implemented as a function.            ]))在函数的初始化中，首先对 invardefs 进行拆分，前面已知invardefs[0] = ['x0', [GaussMembFunc(), GaussMembFunc(), GaussMembFunc()]]invardefs[1] = ['x1', [GaussMembFunc(), GaussMembFunc(), GaussMembFunc()]]这里将其拆分为两个部分：varnames 和 mfdefs  varnames = ['x0', 'x1'] 为 invardefs 的前半部分  mfdefs 是一个列表，列表的成员为 FuzzifyVariable 类（anfis.FuzzifyVariable），类的形参输入为 invardefs 的后半部分，即隶属度函数列表，经过类初始化后得到如下形式的列表mfdefs = [FuzzifyVariable(  (mfdefs): ModuleDict(    (mf0): GaussMembFunc()    (mf1): GaussMembFunc()    (mf2): GaussMembFunc()  )),FuzzifyVariable(  (mfdefs): ModuleDict(    (mf0): GaussMembFunc()    (mf1): GaussMembFunc()    (mf2): GaussMembFunc()  ))]跳转到 FuzzifyVariable() 类 查阅更多。self.num_rules 将所有隶属度函数个数做元素积，这里[len(mfs) for _, mfs in invardefs] = [3,3]np.prod[3,3] = 9然后将self.num_in，self.num_rules，self.num_out 作为参数传给 PlainConsequentLayer() 类。 最终，形成一个三层网络结构 self.layer。其中，self.num_in，self.num_rules 在实例化 AnfisNet 时确定，而 self.num_out 是通过下面代码根据 self.outvarnames 的长度得到的    @property    def num_out(self):        return len(self.outvarnames)其中，@property 装饰器[1] 把 num_out 的 getter 方法变成属性，但是没有定义 num_out.setter 方法，从而将 num_out 变为一个 私有的只读属性。该属性无法在外部进行更改，而是在实例化 AnfisNet 时根据 outvarnames 自动确定的。与之相反，coeff 定义时既包括 @property 又包括 @coeff.setter 方法，那么 coeff 就可以在外部进行赋值更改。    @property    def coeff(self):        return self.layer['consequent'].coeff    @coeff.setter    def coeff(self, new_coeff):        self.layer['consequent'].coeff = new_coeff这样做的好处是可以在赋值时进行一些复杂的操作，比如上述代码中的 self.layer['consequent'].coeff = new_coeff 操作，或者如参考文献 [1] 中的取值类型和范围的限定报错提示操作。    def fit_coeff(self, x, y_actual):        '''            Do a forward pass (to get weights), then fit to y_actual.            Does nothing for a non-hybrid ANFIS, so we have same interface.        '''        if self.hybrid:            self(x)            self.layer['consequent'].fit_coeff(x, self.weights, y_actual)    def input_variables(self):        '''            Return an iterator over this system's input variables.            Yields tuples of the form (var-name, FuzzifyVariable-object)        '''        return self.layer['fuzzify'].varmfs.items()    def output_variables(self):        '''            Return an list of the names of the system's output variables.        '''        return self.outvarnames    def extra_repr(self):        rstr = []        vardefs = self.layer['fuzzify'].varmfs        rule_ants = self.layer['rules'].extra_repr(vardefs).split('\\n')        for i, crow in enumerate(self.layer['consequent'].coeff):            rstr.append('Rule {:2d}: IF {}'.format(i, rule_ants[i]))            rstr.append(' '*9+'THEN {}'.format(crow.tolist()))        return '\\n'.join(rstr)    def forward(self, x):        '''            Forward pass: run x thru the five layers and return the y values.            I save the outputs from each layer to an instance variable,            as this might be useful for comprehension/debugging.        '''        self.fuzzified = self.layer['fuzzify'](x)        self.raw_weights = self.layer['rules'](self.fuzzified)        self.weights = F.normalize(self.raw_weights, p=1, dim=1)        self.rule_tsk = self.layer['consequent'](x)        # y_pred = self.layer['weighted_sum'](self.weights, self.rule_tsk)        y_pred = torch.bmm(self.rule_tsk, self.weights.unsqueeze(2))        self.y_pred = y_pred.squeeze(2)        return self.y_pred4.2. FuzzifyVariable 类class FuzzifyVariable(torch.nn.Module):    '''        Represents a single fuzzy variable, holds a list of its MFs.        Forward pass will then fuzzify the input (value for each MF).    '''    def __init__(self, mfdefs):        super(FuzzifyVariable, self).__init__()        if isinstance(mfdefs, list):  # No MF names supplied            mfnames = ['mf{}'.format(i) for i in range(len(mfdefs))]            mfdefs = OrderedDict(zip(mfnames, mfdefs))        self.mfdefs = torch.nn.ModuleDict(mfdefs)        self.padding = 0该类的初始化步骤如下：  通过 isinstance() 判断输入的 mfdefs 是否是列表；  如果是，则给 mfdefs 中的每个成员取名为 mf{}.format(i)，并形成列表 mfnames；  通过 zip() 将 mfnames 和 mfdefs 组合成一个成员为元组的列表（a list of tuples）；  将上述列表传入 OrderDict 得到有序字典 mfdefs  mfdefs 传入 torch.nn.ModuleDict() 得到 self.mfdefs。mfdefs = OrderedDict([    ('mf0', GaussMembFunc()),    ('mf1', GaussMembFunc()),    ('mf2', GaussMembFunc())])self.mfdefs = ModuleDict(  (mf0): GaussMembFunc()  (mf1): GaussMembFunc()  (mf2): GaussMembFunc())torch.nn.ModuleDict() 自动将 mfdefs 注册为参数（可被反向传播且可被迁移到GPU上加速计算）。注意，传入 torch.nn.ModuleDict() 的类必须是 torch.nn.Module 的子类。    @property    def num_mfs(self):        '''Return the actual number of MFs (ignoring any padding)'''        return len(self.mfdefs)    def members(self):        '''            Return an iterator over this variables's membership functions.            Yields tuples of the form (mf-name, MembFunc-object)        '''        return self.mfdefs.items()    def pad_to(self, new_size):        '''            Will pad result of forward-pass (with zeros) so it has new_size,            i.e. as if it had new_size MFs.        '''        self.padding = new_size - len(self.mfdefs)    def fuzzify(self, x):        '''            Yield a list of (mf-name, fuzzy values) for these input values.        '''        for mfname, mfdef in self.mfdefs.items():            yvals = mfdef(x)            yield(mfname, yvals)    def forward(self, x):        '''            Return a tensor giving the membership value for each MF.            x.shape: n_cases            y.shape: n_cases * n_mfs        '''        y_pred = torch.cat([mf(x) for mf in self.mfdefs.values()], dim=1)        if self.padding &gt; 0:            y_pred = torch.cat([y_pred,                                torch.zeros(x.shape[0], self.padding)], dim=1)        return y_pred4.3. ConsequentLayer 类class ConsequentLayer(torch.nn.Module):    '''        A simple linear layer to represent the TSK consequents.        Hybrid learning, so use MSE (not BP) to adjust coefficients.        Hence, coeffs are no longer parameters for backprop.    '''    def __init__(self, d_in, d_rule, d_out):        super(ConsequentLayer, self).__init__()        c_shape = torch.Size([d_rule, d_out, d_in+1])        self._coeff = torch.zeros(c_shape, dtype=dtype, requires_grad=True)    @property    def coeff(self):        '''            Record the (current) coefficients for all the rules            coeff.shape: n_rules * n_out * (n_in+1)        '''        return self._coeff    @coeff.setter    def coeff(self, new_coeff):        '''            Record new coefficients for all the rules            coeff: for each rule, for each output variable:                   a coefficient for each input variable, plus a constant        '''        assert new_coeff.shape == self.coeff.shape, \\            'Coeff shape should be {}, but is actually {}'\\            .format(self.coeff.shape, new_coeff.shape)        self._coeff = new_coeff4.4. PlainConsequentLayer 类继承自 ConsequentLayer 类5. 参考文献[1] luyuze95 只顾风雨兼程. python中@property装饰器的使用.[2] Rudolf Kruse. Fuzzy neural network.[3] Milan Mares. Fuzzy Sets.[4] L.A. Zadeh. Fuzzy sets.[5] Pranav Gajjewar. Understanding Fuzzy Neural Network using code and animation"
  },
  
  {
    "title": "深度学习基础（Fuzzy，FNN）",
    "url": "/posts/deep-learning-fuzzy-basic/",
    "categories": "Academic, Knowledge",
    "tags": "fuzzy, deep learning",
    "date": "2020-09-25 08:55:19 +0800",
    





    
    "snippet": "本文介绍了模糊的基础知识，包括模糊集，模糊逻辑，模糊决策，模糊神经网络（FNN）。  1. 基础知识          1.1. 模糊集与隶属度      1.2. 模糊集运算      1.3. 模糊度      1.4. 模糊逻辑      1.5. 模糊决策        2. 模糊神经网络  3. 参考文献1. 基础知识1.1. 模糊集与隶属度  A fuzzy set is a c...",
    "content": "本文介绍了模糊的基础知识，包括模糊集，模糊逻辑，模糊决策，模糊神经网络（FNN）。  1. 基础知识          1.1. 模糊集与隶属度      1.2. 模糊集运算      1.3. 模糊度      1.4. 模糊逻辑      1.5. 模糊决策        2. 模糊神经网络  3. 参考文献1. 基础知识1.1. 模糊集与隶属度  A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. —— Fuzzy sets by L.A. Zadeh, 1965模糊集是一类具有连续隶属度的对象。这样一个集合可以用一个成员（特征）函数来表征，该函数为每个对象分配0到1之间的成员级别。  Fuzzy set is a mathematical model of vague qualitative or quantitative data, frequently generated by means of the natural language. —— Fuzzy Sets Milan Mares @ scholarpedia模糊集是一种模糊的定性或定量数据的数学模型，经常借助自然语言生成。该模型是基于经典的集合及其特征函数概念的推广。  The attempts to use the computing technology for processing such models have pointed at the fact that the traditional probabilistic processing of uncertainty is not adequate to the properties of vagueness. Meanwhile the probability, roughly speaking, predicts the development of well defined factor (e.g., which side of a coin appears, which harvest we can expect, etc.), the fuzziness analyzes the uncertain classification of already existing and known factors, e.g., is a color “rather violet” or “almost blue”? “Is the patient’s temperature a bit higher, or is it a fever?”, etc. —— Fuzzy Sets Milan Mares @ scholarpedia利用计算技术处理这类模型的尝试表明，传统的不确定性概率处理方法不足以处理模糊特性。粗略地说，概率用来预测定义明确的因素的发展（例如，硬币的哪一面出现了，我们期望的收获情况等），而模糊性分析已经存在和已知的因素的不确定分类，例如，颜色是“相当紫罗兰色”还是“几乎蓝色”，病人的体温“有点高，还是发烧？”等等。  In classical set theory, the membership of elements in a set is assessed in binary terms according to a bivalent condition — an element either belongs or does not belong to the set. By contrast, fuzzy set theory permits the gradual assessment of the membership of elements in a set; this is described with the aid of a membership function valued in the real unit interval [0, 1]. —— wikipedia在经典集合论中，一个集合中元素的隶属度是根据一个二价条件（一个元素要么属于集合，要么不属于集合）用二元项来评估。相比之下，模糊集理论允许逐步评估集合中元素的隶属度；这是借助于以实数单位区间 $[0,1]$ 取值的隶属函数来描述的。  任何科学理论都有它的研究对象，这些对象构成一个不空的集合，称为论域。在形式科学里，论域（或称做论述全集），是指在某些系统化的论述里的一些令人感兴趣的变数之上，由其中的实体所组成的集合。给定一个论域（universe of discourse） $U$ ，那么从 $U$ 到单位区间 $[0,1]$ 的一个映射 $\\mu_A:U\\rightarrow[0,1]$ 称为 $U$ 上的一个模糊集。  要注意，严格地说，模糊集或子集是映射所确定的序对集，但由于模糊子集完全由其隶属函数所确定，因而我们不区分映射和映射所确定的序对集，而总是直接把模糊子集定义为一个满足上述定义的映射。模糊集可以记为 $A$，映射（函数）$\\mu(\\cdot)$ 或简记为 $\\mu_A$ 叫做模糊集 $A$ 的隶属度函数（membership function）。对于每一个 $x\\in U$ ，$\\mu_A(x)$ 叫做元素 $x$ 对模糊集 $A$ 的隶属度。传统集合在模糊集理论中通常称作“明确集（crisp set），而隶属度函数只能取 0 或者 1 时，对应于传统集合的指示函数（indicator function）。模糊集可以表示为：  解析法：也即给出隶属度函数的具体表达式（或者如上图的曲线形式）；  Zadeh 记法：$A = \\frac{1}{x_1} + \\frac{0.7}{x_2} + \\frac{0}{x_3}$，分母是论域中的元素，分子是对应的隶属度；  续偶法：$A = {(x_1,1),(x_2,0.7),(x_3,0)}$；  向量法：在有限论域的场合，给论域中元素规定一个表达的顺序，那么可以将上述序偶法简写为隶属度的向量式，如 $A=(1,0.7,0)$。一个模糊集的实例，假设 $Age\\in[0,100]$ 是一个论域，，我们可以定义两个模糊集 young ，midlife，和 old。对于模糊集 young 可以定义为下图的形式。当然也可以定义为其它形式。另一个模糊集的实例：一个常用的隶属度函数为高斯隶属度函数\\[A(x)=e^{-\\frac{-(x-\\mu)^2}{\\sigma^2}}\\]其中 $\\mu, \\sigma$ 分别为高斯隶属度函数的中心和宽度。1.2. 模糊集运算首先建立公共假设：$A,B,C\\sim U,\\forall x \\in U$  Standard fuzzy set operations are union, intersection and complement模糊集的关系包括：相等、包含。      若 $\\mu_A(x) = \\mu_B(x)$，则称 $B$ 和 $A$ 相等，记为 $A = B$；        若 $\\mu_A(x)\\leq \\mu_B(x)$，则称 $B$ 包含 $A$，记为 $A \\subseteq B$。  标准的模糊集运算包括：交（取小）、并（取大）、补。      模糊集的交集定义为取模糊集中的最小值。$C=A\\cap B:\\mu_C(x) = min{\\mu_A(x),\\mu_B(x)} = \\mu_A(x)\\land \\mu_B(x)$        模糊集的交集定义为取模糊集中的最大值。$C=A\\cup B:\\mu_C(x) = max{\\mu_A(x),\\mu_B(x)} = \\mu_A(x)\\lor \\mu_B(x)$        模糊集的交集定义为取模糊集中的反值。$C = A^C:\\mu_C(x) = \\mu_{A^C}(x) = 1-\\mu_A(x)$  下面给一个并（取大）和交（取小）的例子。1.3. 模糊度一个模糊集 $A$ 的模糊程度的衡量，直观定义如下：设映射 $D:F(U)\\rightarrow [0,1]$ 满足下述5个性质：  清晰性：$D(A) = 0$ 当且仅当 $A\\in P(U)$。（经典集的模糊度恒为0）  模糊性：$D(A) = 1$ 当且仅当 $\\forall x \\in U, A(x) = 0.5$。（隶属度都为 0.5 的模糊集最模糊）  单调性：$\\forall x\\in U$，如果 $A(x)\\leq B(x) \\leq 0.5$ 或者 $A(x) \\geq B(x) \\geq 0.5$，则 $D(A)\\leq D(B)$。（元素隶属度越靠近 0.5 的模糊集越模糊）  对称性：$\\forall A\\in F(U)$，有 $D(A^c)=D(A)$。（补集的模糊度相等）  可加性：$D(A\\cup B) + D(A\\cap B) = D(A) + D(B)$。则称 $D$ 是定义在 $F(U)$ 上的模糊度函数，而 $D(A)$ 为模糊集 $A$ 的模糊度。可以证明，符合上述定义的模糊度是存在的。一个常用模糊度的公式（分别针对有限和无限论域）为\\[\\begin{aligned}  D_p(A) &amp;= \\frac{2}{n^{1/p}}\\left( \\sum_{i=1}^n \\vert A(x_i) - A_{0.5}(x_i) \\vert^p \\right)^{1/p}\\\\  D(A) &amp;= \\int_{-\\infty}^{+\\infty}\\vert A(x)-A_{0.5}(x) \\vert dx\\end{aligned}\\]其中，$p&gt;0$ 是参数，称为 Minkowski 模糊度。特别地，当 $p=1$ 时称为 Hamming 模糊度或者 Kaufmann 模糊指标。当 $p=2$ 时称为 Euclid 模糊度。1.4. 模糊逻辑模糊逻辑是对布尔逻辑的推广，针对隶属度进行计算。模糊逻辑的定义形式有很多种，比较常见的被称为是 Zadeh operators，如下表所示            Boolean      Fuzzy                  AND(x,y)      MIN(x,y)              OR(x,y)      MAX(x,y)              NOT(x)      1-x      另一种 AND/OR 算子基于乘法定义x AND y = x*yNOT x = 1-xHence,x OR y = NOT( AND ( NOT(x), NOT(y) ) )x OR y = 1-(1-x*(1-y))1.5. 模糊决策最大隶属度法：取推理结果中隶属度最大的一项作为输出。简单易行，但是完全派出了隶属度较小的其它量的影响和作用，没有充分利用推理过程取得信息。加权平均法：\\[U = \\frac{\\sum_{i=1}^n\\mu(x_i)x_i}{\\sum_{i=1}^n\\mu(x_i)}\\]中位数法：论域上把隶属度函数曲线与横坐标围成的面积平分为两部分的元素，称为模糊集中的中位数。将中位数作为输出。由于模糊推理不需要很精确，可以直接取靠近中位数的一个结果作为结果。中位数法相比最大隶属度法利用了更多信息，但计算复杂，特别是隶属度函数连续时还要计算积分，因此应用场合比加权平均法少。加权平均法比中位数法具有更佳的性能，更好的静态性能，但是相比中位数法的动态性能稍逊。2. 模糊神经网络  将模糊逻辑用于神经网络：将模糊集合的概念应用于神经网络的计算和学习，用模糊技术提高神经网络的学习性能；  将神经网络用于模糊系统：          用神经网络的学习能力实时调整知识库，在线提取或调整模糊规则或其它参数；      用神经网络完成模糊推理过程。        模糊系统和神经网络的全面结合，构造完整意义上的模糊神经网络和算法。模糊神经网络（Fuzzy Neural Network, FNN）（又称为神经模糊系统，Neuro-Fuzzy System, NFS）是一个学习机，通过利用神经网络的近似技术来找寻一个模糊系统的参数（如模糊集，模糊规则）。  A fuzzy neural network or neuro-fuzzy system is a learning machine that finds the parameters of a fuzzy system (i.e., fuzzy sets, fuzzy rules) by exploiting approximation techniques from neural networks.Fuzzy neural network —— Rudolf Kruse @ scholarpedia神经网络控制和模糊控制的优劣比较如下表所示。            Neural Networks      Fuzzy Systems                  no mathematical model necessary      no mathematical model necessary              learning from scratch      apriori knowledge essential              several learning algorithms      not capable to learn              black-box behavior      simple interpretation and implementation      从表中可以看出，如果将二者结合，可以充分发挥二者的优势，弥补二者的劣势。  采用基于神经网络理论的数据驱动学习方法，对基于底层模糊系统的神经模糊系统进行训练。这种启发式算法只考虑局部信息引起基本模糊系统的局部变化。  它可以表示为学习过程中任何时刻（比如学习前，学习中或学习后）的模糊规则集。因此，系统可以根据模糊规则在有无先验知识的情况下进行初始化。  学习过程受到约束，以保证底层模糊系统的语义特性。  神经模糊系统近似于一个 n 维未知函数，该函数可由训练样本部分表示。因此，模糊规则可以解释为训练数据的模糊原型。  神经模糊系统被表示为特殊的三层前馈神经网络：          第一层对应于输入变量。      第二层象征着模糊规则。      第三层表示输出变量。      模糊集被转换为（模糊）连接权。        有些方法还使用五层，其中模糊集分别编码为第二层和第四层的神经元。但是，五层模型可以转换为三层体系结构。          第一层为输入层，缓存输入信号。      第二层为模糊化层，对输入信号进行模糊化。      第三层为模糊规则层。      第四层为模糊决策层，主要针对满足一定条件的量进行分类并将模糊量去模糊化。      第五层为输出层，输出运算结果      两种常见的神经模糊模型：  Mamdani 模型: 着重研究模型的可解释性  Takagi-Sugeno-Kang (TSK) 模型：着重研究模型的精确程度Mamdani 模型的模糊规则示意如下：IF x1 is A1 and x2 is A2 and ... xn is An   THEN y = c1IF funding is adequate and staff is small   THEN risk is low可以看出，Mamdani 模型的输出（后件）为模糊集，需要加上解模糊的环节。TSK 模型的模糊规则示意如下：IF x1 is A1 and x2 is A2 and ... xn is An   THEN y = a0+a1*x1+...+an*xnIF funding is adequate and staff is small   THEN risk is 0.2可以看出，TSK 模型的 THEN 部分是清晰的，它的输出（后件）是一个函数，是所有输入变量的线性组合，因此具有较好的可解释性和精确性。三种 FNN 的部署 方式：  真实输入，模糊权重  模糊输入，真实权重  模糊输入，模糊权重3. 参考文献无。"
  },
  
  {
    "title": "电影《信条》个人解析",
    "url": "/posts/movie-tenet/",
    "categories": "Diary",
    "tags": "other",
    "date": "2020-09-10 13:31:19 +0800",
    





    
    "snippet": "诺兰的新电影《信条》，凭借硬核的科幻背景和烧脑的剧情回路，成功绕晕了广大观影群众。本文试图从电影中的科学概念出发，一步步解析电影剧情的时间线索。  1. 前言  2. 熵          2.1. 熵的定义      2.2. 熵增定律      2.3. 熵减的误区      2.4. 电影中的熵减        3. 时间旅行          3.1. 如何从未来帮助自己？     ...",
    "content": "诺兰的新电影《信条》，凭借硬核的科幻背景和烧脑的剧情回路，成功绕晕了广大观影群众。本文试图从电影中的科学概念出发，一步步解析电影剧情的时间线索。  1. 前言  2. 熵          2.1. 熵的定义      2.2. 熵增定律      2.3. 熵减的误区      2.4. 电影中的熵减        3. 时间旅行          3.1. 如何从未来帮助自己？      3.2. 祖父悖论与时间旅行      3.3. 自己和自己能否相见？        4. 时间钳形作战          4.1. 追车抢夺钚241      4.2. 最终决战        5. 其它          5.1. 电影本身的探讨      5.2. Q/A      5.3. 诺兰的电影        6. 参考文献1. 前言这个记录贴的本意，是给自己观影做一个总结，主要包括各种知识、技术、理论的总结和整理。电影本身的故事、拍摄手法、剧情、演技等内容不是重点讨论范围哈 0.0这不是一个剧情分析贴，而更像是一个电影背后的知识和技术解析，旨在帮助人们更加形象和深入的理解电影《信条》背后的知识和理论。由于个人水平所限，帖子中难免会出现各类疏忽和错漏，希望大家海涵 0.0另外，本贴的阅读可能需要一定的数学、力学、物理学基础，以及一定的想象力和逻辑推理能力。2. 熵2.1. 熵的定义「熵」是一个热力学概念，是热力学中表征物质状态的参量之一，其物理意义是体系混乱程度的度量，反映自发过程不可逆性的物质状态参量。在热力学中，熵是系统的状态函数，一个系统的熵等于该系统在一定过程中所吸收（或耗散）的热量除以它的绝对温度，如下。\\[S = \\int dQ/T\\]其中，$S$ 表示熵，$Q$ 表示热量，$T$ 表示温度。2.2. 熵增定律热力学第二定律定义了热量不能从低温的物体自发地转移到高温的物体，之于熵来说就等于世界上的事物都无法自发地趋于有序，而是越来越混乱。这就是所谓的熵增定律。简而言之，熵的变化永远是从 有序 到 无序 的状态，从一个自发进行的过程来考察：两个冷热程度不同的物体相互接触（比如两杯水），热量 $Q$ 由高温($T_1$)物体传至低温($T_2$)物体，高温物体的熵减少 $dS_1=dQ/T_1$，低温物体的熵增加 $dS_2=dQ/T_2$，把两个物体合起来当成一个系统来看，有 $dQ_1 = -dQ_2,\\quad T_1&gt;T_2$，则熵的变化是 $dS=dS_2-dS_1 &gt; 0$，即熵是增加的。举另一个例子，一个独立不受外界影响的容器，里面有规律的间隔，隔开空气区间和真空区间；一旦撤除容器内部所有间隔，整个容器就会形成一整个均匀的状态。这是一个自然的过程，也是熵增的过程。（如下图）先描述一下容器开始的状态：空气区间和真空区间是明确分开的。也就是说，孤立系统局部状态是不同的，我们说这是“有序的”。再描述最后均匀的状态：最终容器中任何一个点的气体密度都相同，温度也相同。也就是说，整个孤立系统内所有局部状态到处都是相同的，我们说系统变得更加混乱了，也就是“无序的”。孤立系统总是趋向于熵增，最终达到熵的最大状态，也就是系统的最混乱无序状态。你可以继续追问：为什么取消区隔，空气会向没有空气的真空移动？空气移动的动力或者动机到底是什么？这个问题从本质来看，是在问，为什么自然状态下孤立系统总是从有序变成无序？其实这个问题本身，就是答案本身。也就是说，答案是熵增定律：世界就是要从有序变无序。宇宙运动的动机，就是要从有序变成无序，无序是一个最稳定的状态。所以空气，会从有空气的地方走向没有空气的地方；热量会从热量高的地方，流向热量低的地方；最终达到一个混乱但是非常稳定的状态。2.3. 熵减的误区有人会说，如果以绝热房间内放一工作的电冰箱为例，冰箱内温度变低，冰箱外的房间内温度变高，那么这个绝热房间不就实现了熵减了么？实际上，冰箱需要通电，这相当于外界在做功，从而拉开温差。仅就室内的冰箱内外来说，如果考虑了电流的热效应，这个室内的总熵变化仍旧是增的。外界做功不能使绝热系统内的熵减少，不论是电能、机械能等非热能做功(通常不能避免热效应)都不能使绝热系统内的熵减少，所以说，我们认为熵增原理准确的表述应为：“在等势面上，绝热系统内的熵永不减少”。2.4. 电影中的熵减将熵的概念扩大到整个宇宙，就可以与电影中开始挂钩了。宇宙到底是不是孤立的系统？人类还无法确定这个问题的答案，但现阶段人类认识宇宙主要有两个理论：宇宙大爆炸理论和宇宙膨胀理论。然而无论是宇宙大爆炸理论还是宇宙膨胀理论，都会推导至一个结论：宇宙是有边界的。宇宙有边界，那我们可以认为宇宙是一个孤立的系统。那么，就可以认为宇宙的正向发展也是处于熵增的状态，从有序到无序。电影中的 旋转门 就是一种能够让熵逆向减小的机器，它把「熵减」的概念套到人身上，从人走出机器的那一刻开始，所有的一切都是逆向的。在这个人的身上，时间可以局部逆向流动，而不是整个世界的时间可以逆向流动。从世界上任意观察者看来，这个逆向的人所有的动作都是逆向的，反着走路，反着开车，等等。而逆向的人看到全世界的所有运动都是反着的。在你的眼里，时间会开始倒流，身边的人会倒走，飞鸟会倒飞，火焰不会烧伤你，而是冻伤你。甚至连空气都是逆向的，所以需要佩戴特殊的氧气面罩，才能在正向的世界中，保证自己已经被逆向了的肺呼吸到逆向的空气。这也是区分影片中的人，是不是逆向很重要的一个点。一个不准确的理解就是，当你从旋转门中出来时，你相当于生活在一个倒带中的世界（世界的时间对你而言在逆行倒流，只有你仍然在正向前进）。而事实是，从全世界的角度，只有你一个人在逆着时间运动，其它世界上所有的事物仍然保持随着时间正常的正向运动。此时，在某个之前的时刻，世界上将会存在两个你，一个正向的你，一个逆向的你。且两个你的动作是镜像反向的。换一种更为严谨的说法，处于逆时间中的人或事物，结果会发生在原因之前。扔掉的逆子弹会回到手中。正常子弹：你做出扔子弹动作 –&gt; 子弹从手中被扔到桌上。逆子弹：子弹从桌上回到手中 –&gt; 你做出扔子弹动作所以，影片中有一句反复出现的台词：「所有未发生的事情必定会发生，所有已经发生的事情无法改变。」3. 时间旅行3.1. 如何从未来帮助自己？先从一个最简单的例子说起。假设我们拥有了旋转门，如何帮助自己中下周二开奖的彩票呢？首先，如果一切顺利，你一定会在周一的时候，在某个显眼的地方看到一张彩票号码，按照这个号码去投注，妥妥中奖。这就是「所有未发生的事情必定会发生，所有已经发生的事情无法改变。」为了使时间（逻辑）闭环（避免造成一些不可控的混沌发生，蝴蝶效应），你必须做如下的事情使得上述结果完备。      首先，根据看到的彩票号码在周一投注        然后，在家躺到下周二，等到彩票开奖，然后写下中奖号码        然后，带着彩票号码进入旋转门，旋转过后出来变成逆向（记得带氧气面罩），此时你将会沿着时间倒流的方向前行；        等待时间倒流到周二开奖前的周一，趁着正向的你不在的时候，将彩票号码放到某个正向的你一定会看到的地方；        然后，找个舒服的地方躺着回到稍微早些的时候（比如上周日），最后通过旋转门回到正向（当然你不想回去也行，就一直向着过去活下去，那就和中奖没什么关系了，你也在未来的世界消失了）。        不出意外，正向的你将会在周一看到彩票，并投注，中奖，然后进入旋转门（貌似进入死循环了？其实没有，进入传送门的就是现在的你）  做完上述步骤后，如果你在第5步选择回到正向，那么世界上从周二之后，只剩下了唯一的一个正向的你，原先那个正向的你已经进入旋转门了（也就是现在的你）。用 windows 自带的画图画，的略粗糙请谅解 0.0还有另一种选择更加简单一些，就是当你在第3步第一次穿过旋转门变成逆向后，不将彩票号码写下来告诉正向的自己，而是逆向等到彩票开奖之前，再次通过旋转门返回正向，然后改头换面偷偷投注。开奖后，原本正向的你默默记住开奖号码进入旋转门（就是第3步）。而现在的自己，已经是经过两次旋转后的自己了，同样也变成了百万富翁。两个选择的区别在于，第一种选择需要借助一张记有彩票号码的纸来传递消息，逻辑闭环的复杂度更高。虽然更加复杂了，但是这并不意味着第一种选择不好。比如，当时间跨度非常长的时候，仅靠人力本身已经难以企及时（比如你想让四十年前的自己中彩票，就必须逆向生活四十年，再逆转回正向生活四十年），就不得不借助能够在大尺度时间上记录和保存的媒介。正如《信条》中的那样，未来人类不可能派遣某个人逆向返回到现时（在他们眼中久远的过去）然后从零开始建造旋转门（募集资金、筹备原料，招募人员对未来人员而言很可能是一项难以完成的工作），而是通过埋下一个个时间胶囊，并且在历史中挑选一个人作为代理人（也就是电影中的反派萨托）来完成这些工作。从另一个角度而言，从历史中挑选代理人，也无需特意进行，因为历史已经是既定的事实，所有未发生的事情必定会发生，所有已经发生的事情无法改变。因此，只需要埋下时间胶囊，历史上自然会有人（萨托）挖出来完成后续工作。3.2. 祖父悖论与时间旅行我们看到，由于可以逆向回到过去，并且可以通过回到过去后的某些行为影响到世界，那么其实这就是某种意义上的时间旅行了。那么，就会出现这么一个悖论，即外祖母悖论，或称为祖父悖论，由法国科幻小说作家赫内·巴赫札维勒（René Barjavel）在1943年小说《不小心的旅游者》（Le Voyageur Imprudent）中提出。悖论情形如下：假如你回到过去，在自己父亲出生前把自己的祖（父）母杀死，但此举动会产生一矛盾的情况：你回到过去杀了你年轻的祖（父）母，祖（父）母死了就没有父亲，没有父亲也不会有你，那么是谁杀了祖（父）母呢？ 或者看作：你的存在表示，祖母没有因你而死，那你何以杀死祖（父）母？目前，所有科幻电影中均在极力避免祖父悖论的产生（没错，包括《信条》在内）。悖论之所以被认为是悖论，就是因为他是不可解的，人们不知道这个问题的答案是什么。为什么呢？这需要提到另一个物理学知识。在已知的宏观世界中，按照相对论，时间只能拉伸或者压缩，但是不能逆转倒退。这一点，在诺兰的另一个经典科幻电影 《星际穿越》 中有过专门的镜头描述。简而言之，经典物理学中时间旅行无法实现。既然时间旅行不可实现，那么人们当然无法回到过去杀死自己的祖父祖母，也就无法获得这个悖论的答案了。一句话，祖父悖论经常被用来证明，从经典物理学的角度来看，时间旅行不能实现。但是，至少在微观世界，时间旅行在量子尺度上已经被证明是可以实现的。在2014年，澳大利亚昆士兰大学的科学家首次使用两个光量子（光子）模拟了量子粒子在时间中的旅行并对其“一举一动”进行了研究。因为量子粒子的行为不符合经典物理学，所以就回避了祖父悖论。那么，如何在宏观层面上回避祖父悖论，进行时间旅行呢？现在一般有几种比较主流的假说：      霍金的解释：霍金认为，也许我们看到的宇宙是这样正是因为宇宙就是这样。什么意思？有点绕口…其意思是，我们生活的这个宇宙可能就是已经被时间旅行改变过的世界了。        平行宇宙：平行宇宙理论认为，我们的每一次选择，都会产生你能选择的所有平行宇宙。比如你在读大学的时候，在物理和计算机专业里纠结不已，最后你选择了物理。但是在另一个平行宇宙里，你选择的是计算机。所以你每一次的选择，都会产生一个或者几个平行宇宙。当你选择回到过去阻止你祖父母在一起的时候，你是从一个你已经出生的世界，前往一个你不会出生的平行宇宙。你在平行宇宙的行为，并不会影响你所在的世界。所以悖论不存在。        弦理论  让我们回到《信条》电影，在电影中如何避免祖父悖论的产生呢？回答是，严格遵守时间和逻辑闭环，哪怕来自未来的你逆向回到了过去，那么所做的行为也要务必恪守不影响世界运行的准则。比如，反派逆转后，哪怕已经经历过高速车战和绑架环节，知道手上拿的箱子是空箱子，也要逆向陪着主角，顺着时间流动的正向再“演”一遍绑架女主角索要箱子的桥段。又比如，男二号尼尔，已经与主角认识多年，在正向时间中却要装作与主角素未谋面。3.3. 自己和自己能否相见？这个问题涉及到很深刻的哲学背景和物理背景。首先从哲学的角度看，或者哲学不恰当或者太宽泛，就假如你在现实生活中突然看到或者发现了另一个你的身影，你会怎么想？怎么办？反正我是想象不来，可能会导致某种灾难性后果也说不定？（比如都想杀死对方，作为世界唯一的你的存在，等等）然后从物理学的角度来看，《信条》在片中阐述了一个物理学概念，CPT对称。物理学定律满足宇称对称、电荷正负对称、时间反演对称这三种对称。物理学定律在C、P和T的联合作用下保持不变。CPT定理是物理学最基本的守恒定律。如果粒子用反粒子替换，右手征用左手征替换，以及所有粒子的速度都反向，则物理定律不变，这被称作CPT定理。CPT定律是一个物理界最基本的守恒定律。简单的来说就是宇称对称，电荷正负对称和时间反演对称三者是严格守恒的。电影中，通过旋转门逆向的人或事物，不仅仅是位姿反转了（宇称C反转），动量也反向了（时间T反转），组成本体的物质也是反转的（电荷P反转）。就是这个物质反转（P反转）导致了以下结论：未来的自己不能和过去的自己接触，否则会发生正反物质湮灭。所谓湮灭反应，就是正反物质相遇所产生的爆炸。大家几乎都知道在宇宙这个”自然界”有原理或工作正好相反的物质，我们为区分它们，所以叫它们正物质与反物质。这两种物质一旦相遇便会产生爆炸。在基本情况下，湮灭就是完全的质量-能量转换，湮灭的两个粒子会释放全部的能量同归于尽。可以想象一下，现在的核裂变（原子弹）和核聚变（氢弹）爆炸的剧烈程度，仅仅是粒子的裂变和聚变反应释放出的些许能量。如果两个粒子完全湮灭并释放出全部能量，其爆炸威力会有多大？因此，正向的你和逆向的你绝对不可以触碰彼此，因为你们是由完全相同的正反粒子组成的，接触将会直接发生湮灭反应，你全身的质量都将转化为能量，然后爆炸。boom的一声估计半个大陆就没了。这里我们再次回到电影中，主角和尼尔回到过去，试图从机场再次进入旋转门前，然后出现的自己和自己的打斗场景。在场景中，逆向的主角全副武装，带着头盔，一方面避免了过去的正向的自己认出自己，一方面避免了直接接触过去的正向自己，避免发生湮灭。并且，还要和过去的正向自己完成过去已经完成过的一系列打斗，从而完成时间（逻辑）闭环。前面还有个小细节，还记得男二号尼尔也和另外一个全副武装的人打斗么，并且在最后还脱掉了那个人的头盔。后来我们知道，那个就是逆向的主角自己。而尼尔在看到主角的面目后，在之后正向的主角击倒全副武装的未来主角，准备杀死对方时，并没有告诉正向主角对方的身份，而只是阻止主角杀人。这也暗含了电影本身的意思有时候，无知是最大的优势因为尼尔必须要保证主角在当时不知情，才能做出最符合的举动，保证时间（逻辑）闭环。否则很可能因为蝴蝶效应而导致不可预知的混沌。4. 时间钳形作战4.1. 追车抢夺钚241前面铺垫了这么多，下面终于进入电影《信条》中两个最难懂的时间钳形作战之一：【追车抢夺钚241】的解析。需要指出的是，下面的图片来自于解析视频【大聪看电影】的启发和参考。首先上第一张图，以正向主角的视角来审视整个过程。这张图的上半部分是正向时间流动方向，也就是红色箭头的方向，下半部分是逆向时间流动方向，也就是蓝色箭头的方向。分析的起点位于上左上角，红色箭头尾部。下面我们来一步步解析：  建议将上面的图片截取保存后对照下面的文字比对阅读。首次阅读可以忽略【中括号里的字，留待后续阅读】，阅读难点均已加粗字体显示：=== 以下是主角的正向时间视角下的过程解析 ===      主角在拿到箱子后，突然一辆倒着的车出现，撞恢复了原本碎裂的主角车的后视镜（表明对方是逆行回来的人开的车），然后倒着与主角并排行驶。    车窗打开，反派萨托用枪威胁女主（此时女主是被萨托从军火仓库中挟持出来的）。注意到萨托带着氧气面罩，意味着萨托此时是逆行的（也就是从未来而来的逆向萨托，他在未来某个时刻 $t$ 开始逆转然后一路回到此处）。  萨托掰指头倒计时。僵持中，主角发现，他和对面逆行萨托的前方有一辆车，原本是翻车状态，但是随着接近，该车从翻车状态变成正常状态，并同样被反向驾驶着来到主角和逆转萨托的中间。【后面我们知道，中间这两车子是逆行主角开回来的】  萨托掰指头倒计时结束，主角被逼无奈，将手提箱通过中间那辆反向行驶的轿车，扔给了萨托，但是偷偷将箱子内的钚241扔进了中间反向行驶的车子。  萨托拿到箱子后，和手下换了一辆车走人，主角爬到只剩下女主的对面逆行车子，千钧一发用手踩下刹车，救下女主。（同时，萨托发现箱子是空的，丢弃箱子）  男主，尼尔，女主三人下车后，被萨托手下劫持，带到红蓝审问室。仓库被划分为红蓝两个部分，男主被带进蓝色区域，萨托带着女主进入蓝色部分。【此时萨托没带氧气面罩，反而是女主被带上面罩，因此表明对面蓝色区域是逆转区域，逆转萨托无需面罩而女主需要面罩呼吸正向空气】  逆转萨托威胁男主要强杀女主，逼问男主箱子内的东西在哪里。期间，男主看到对面的逆转萨托对着女主腹部开了一枪（逆转子弹），然后指着女主头部威胁。男主无奈撒谎说箱子内的东西在之前开车的副驾驶座位上。  另一个萨托（正向萨托，一直隐藏在审问室）出现在红色区域，继续审问男主。直到救兵闯入红色区域。  主角救兵赶到，萨托进入红色旋转门，逆转回到过去（从蓝色逆转门出来）。  主角为了拯救女主凯特的伤，同时为了阻止反派萨托，带着凯特进入红色旋转门逆转。=== 以下是主角的逆转时间视角下的过程解析 ===  主角逆转后，开车退回到前面的飙车现场，直到开到之前主角和萨托两辆车之间时，才意识到中间那辆从翻车状态起来的车正式自己开的这辆车。  此时，逆转萨托发现了逆转的主角在中间开着的车，然后撞翻了主角的车，并点燃了汽油。但是由于逆转主角的热传导是逆向的，车子温度反而越来越低，救了主角一命。  之后，困在车中爆炸低温的逆转主角，被逆转尼尔救出，二人随即带着受伤的凯特前往过去的机场。  前面我们已经直到，逆转凯特需要保持逆转大约一周才能伤势痊愈，然后需要再次借助旋转门回到正向，但是一周前审问室的旋转门在反派萨托的控制中，肯定不能通过这里的旋转门回去，那么三人只能选择前往一周前的机场，因为正好一周前主角和尼尔在那里进行了一次飞机撞大楼的骚操作，机场那里的旋转门防守薄弱。  也就是在那里，主角和逆转主角搏斗了一波。如果还没太看明白，没关系，下面上第二张图，以反派萨托的视角来审视整个过程。=== 以下是反派萨托正向时间视角下的过程解析 ===  再次提醒，这场戏全场都是萨托执行的时间钳形作战。  萨托和女主凯特去往港口，二者吵了一架，凯特用枪指着萨托但没有开枪，萨托对凯特进行了一番家暴后离开。  萨托离开后，带上耳机，听着正反世界传来的信息，一直躲在红蓝审问室中观察情况。  一直等到主角被押入红色区域，被对面蓝色区域的萨托问出演算机的下落时，从暗处出来猛击主角，并继续审问。  萨托看到蓝色房间的逆转自己开始往逆转门方向走，于是意识到自己应该进入红色逆转门进行逆转了。      萨托姑且相信了主角说的话，此时主角的救兵感到，萨托（和手下司机）因此进入红色逆转门，从蓝色逆转门出来【因此前面主角视角下，对面蓝色区域的萨托就是这个刚刚逆转之后的萨托】。    进入逆转萨托的审问表演时间，逆转萨托的视角下，红色区域的正向主角的行为过程是逆向的，他必须按照刚刚躲在暗处时听到的逆向自己审问萨托的过顺序，再逆向进行一次审问过程，使得时间（逻辑）闭环完备。          萨托进入蓝色区域时，区域内的凯特已经是被逆转子弹打伤后的状态（如果难以理解，在翻过去看一下主角正向视角，此时是整个时间线的末端状态了）      前面主角在正向时间中看到的顺序：逆转萨托用枪打中凯特腹部，然后用抢指着凯特头部      因此现在逆转萨托理应表演的顺序：用抢指着凯特头部，然后开枪打中凯特腹部      注意此时逆转萨托开枪时，子弹应从玻璃上飞回手枪，而女主凯特也应该从中枪受伤状态变为没有中枪状态；      最后，萨托带着没有中弹的凯特离开。        逆转萨托带着凯特出来后，和逆转司机回到车中，开车来到之前劫持正向主角和凯特的地方，放任凯特自行逆向行动【本质上是正向主角和凯特的正向运动，在此时的逆转萨托看来是反过来的逆向行动而已。在正向时间中，凯特被正向主角救下后，被萨托手下劫持并交给萨托带进红蓝审问室，此处就是其逆过程】。  萨托放任凯特自行逆向行动后，来到主角的车的副驾驶处摸索。此时背景正是劫持正向主角和凯莉的过程，萨托搜索后未能发现演算机，意识到主角骗了自己。  逆转萨托于是和逆转司机开车继续往时间逆向追溯，期间被他在正向时间里扔掉的空箱子飞回到他的手中。  （同时，主角也已经通过旋转门逆转，并开车追了上来）下面进入比较复杂难以理解的地方，再次绘制一张超现实主义抽象派图示，辅助理解  逆转萨托在正向主角准备营救凯特之前，追上并换到只有凯特一个人乘坐的车上。  逆转萨托看到一辆车插入他和正向主角中间，发现是逆转主角在开车，也看到了箱子内的演算机从中间这辆车中飞到主角手中【即正向主角在正向时间里，将演算机扔到中间的车子里】。自此，逆转萨托才真正知道演算机的位置。  逆转萨托将箱子举出窗外，松手，箱子经过中间这辆车，飞回正向主角手中。  逆转萨托别翻中间那辆逆向主角开的车。【但是他不是立刻下车点燃翻了的车，因为他要继续把下面的戏演完】  逆转萨托逆向倒计时举手指1，2，3，示意正向主角把箱子扔给他。  逆转萨托关闭车窗，和正向主角分道扬镳。  逆转萨托返回之前被他别翻的逆向主角开的车，点着泄露的汽油后，返回车子将凯特送回军械仓库。期间，逆转萨托通知正向手下，前往逆转主角开的那辆车中取走演算机部件。          【这辆车之前停在红蓝审问房的外面，在逆转主角上车之前，正向手下取走，然后手下再通过逆转，将演算机部件逆转后交给逆转萨托】      【也就是说，逆转主角出红蓝审问房后，开的那辆车，演算机部件一直在里面。从逆转视角来看，在他上车前，是正向的手下倒退回来放到车里的】        逆转萨托将车停在码头军械仓库门口，等待正向萨托家暴正向凯特后，正向萨托带上耳机，正逆转萨托开始沟通信息  【很可能逆向萨托直接将未来的整个表演都告知正向萨托，比如：你现在直接去红蓝审问室等着，等到对面蓝色区域的我问出演算机位置后，冲出去继续审问，然后进入红色旋转门，其他的不多说了，最后肯定能拿到演算机（为什么不多说？因为无知是最大的优势）】  逆转萨托完成整套表演，车继续停在码头军械仓库门口，等到正向萨托和正向凯特进入军械库。  【完成表演后为什么还要等呢？电影中有个特写，正向凯特进入仓库前，隔着栏杆看到带着氧气面罩的逆转司机坐在车里，逆转司机感到有目光注视，回头也看到了正向凯特。】  【逆转司机可能告诉了逆转萨托自己被凯特看到了，为了保证时间（逻辑）闭环，必须要保证车子和逆转司机呆在这里，直到时间逆流到被正向凯特看到】  至此，逆转萨托收集齐了所有演算机部件，逆转萨托继续逆行，一直到返回到越南的蜜月期间，准备执行自杀毁灭世界计划。至此，整个追车环节基本剖析完毕。什么？还没看懂！？不慌！最后以凯特视角再来过一遍！  凯特被家暴后，被军械仓库外的逆转萨托挟持并带上车。  逆转萨托带着凯特开上高速，期间停车，萨托下车，过了一会儿后上车。【萨托下车去把翻车的逆转主角的车给点燃了】  逆转萨托回来后继续驱车挟持凯特，直到见到正向主角的车，萨托摇下车窗开始掰手指倒计时威胁；  倒计时到1时，前方一辆翻到的车恢复了正常，并开始倒着行驶；  主角将箱子，通过中间的车子借力，扔给了逆转萨托；  逆转萨托留下凯特一人，和司机中途换上了另一辆车；  凯特被独自一人捆绑在车内，直到正向主角扑过来用手刹车就下她；  二人随后被萨托手下控制，并带到红蓝审问室；  凯特被逆转萨托带到蓝色审问室；  逆转萨托将自己的氧气面罩摘下，给凯特带上另一个氧气面罩【保证她能在蓝色的逆转空气中呼吸】；  凯特被逆转萨托带进蓝色审问室，被逆转萨托开枪击中腹部，然后被逆转萨托手枪指着头威胁；  凯特中枪倒地。稍后，对面的红色审问室中冲出另一个萨托（正向萨托）继续审问正向主角；  逆转萨托倒退进入蓝色旋转门；  正向萨托看到逆转萨托进入旋转门，此时正向主角救兵赶到，正向萨托随即进入红色旋转门。整个追车抢夺战，萨托的目标就是得到主角先前抢得的钚241（演算机部件），并借助上述整个过程，在逆转后得到了逆转后的演算机部件。4.2. 最终决战这是电影《信条》中两个最难懂的时间钳形作战之一：【最终决战】环节的解析。首先给2个电影截图，提供时间钳形作战的一个直观认识我们假设爆炸发生在10分钟时刻，爆炸前10分钟也就是0时刻。电影的这个片段，正是0时刻之后，红队着陆进入战场开始打仗，以及蓝队已经完成战斗逆向撤离的过程。什么？没搞懂为什么蓝队已经撤退了？因为蓝队是从未来逆转回来的，他们的时间流动时反向的，他们从爆炸发生时开始战斗，一直战斗到爆炸发生前10分钟。以空间上的钳形战术为例，即从目标所在坐标位置的正反两个空间方向进行夹击。空间钳形战术的目的在于，让目标在空间上被锁死。而时间钳形战术这是针对固定时间段的战斗，从正反两个时间方向进行攻击。时间钳形战术的目的在于，让目标在这个时间段上呈现出的所有战术动作都被提前掌握。这个在后面会根据图解详细分析。以影片中最后的分组突击为例。主角所在的红色军队以10分钟为跨度进行正向攻击，尼尔所在的蓝色军队以10分钟为跨度进行逆向攻击。也就是说，蓝色军队比红色军队晚出发10分钟，但红色军队朝着时间的正向移动，蓝色军队朝着时间的逆向移动。在最终决战中，各方的目的如下：  逆转萨托：阻止主角拿到演算机，在手下放下演算机引爆炸弹的同一时间服毒，毁灭世界；          逆转萨托死亡会导致：1、引爆炸弹，掩埋演算机；2、给未来人发邮件，告知自己死亡的时间，即演算机何时埋在这里，待未来人挖出使用毁灭世界；        男主角：男主要假装阻止爆炸失败，但是趁机抢夺演算机；  女主角：要在男主抢到演算机后，爆炸发生前，在越南杀死逆转萨托；          这样，萨托死亡后爆炸发生，但演算机已经被抢走，不再被掩埋，未来人无法在未来挖到，毁灭世界失败。      下面进行详细的解释：      红蓝两队大张旗鼓的作战并不是为了阻止爆炸，而是声东击西，让男主角和大胡子队长进入洞穴，把萨托手下要埋下去的演算机拿到手。这里参考来源Nixes：                  为什么萨托要到这个地方、这个时间点放下演算机？因为爆炸是为了封存这个演算机，类似之前的时间胶囊。萨托死后触发炸弹10s后爆炸，同时会发送一封邮件告诉未来人，自己的死亡时间，告诉演算机何时埋在这里，在未来可以取出并使用，从而毁灭世界。【注意，这里给出的是最终符合逻辑的解答，详细分析过程已经超纲了，请参考Nixes，简要列写如下】                  结合之前提到的时间胶囊，可以推断出来这个地方就是为了放时间胶囊。【爆炸只是为了更好地封存时间胶囊】。而电影在作战会议的时候只提到了＂萨托的离世会发送出一封邮件＂。那么这个邮件就有两种可能。一，直接启动算法；二，告诉未来人他埋下算法的时间点。结合最后女主的留言让主角成功鲨掉了印度女，还有上文提到的时间胶囊，我偏向于这只是告诉未来人时间的邮件。因为如果邮件就可以直接启动算法，那么萨托完全可以把算法放到任何地方，就算要花一段时间才能毁灭世界，那主角也不可能去阻止的。所以可以肯定【算法的启动需要未来人的帮助】。那未来人又怎么才能帮到他呢？也只能逆时回到开战前，然后在地下放一个激活装置。或者在未来拿出来改装完又逆时送回去，然后改装好的算法收到萨托的邮件才能启动。但是这样就有bug了，激活装置也好，逆时送回来也罢，如果是这些操作的话，女主完全没有必要留萨托一命。如果是放激活装置到地底，先不说为什么不提早几年把装置送给萨托，只要萨托一挂，那么个装置就一定在地底了，之后什么时候扔算法进去都一样。如果是要先让未来人改装好的，那在送给他们改装前先干掉萨托不是更好？（就算改装好了也不能激活）再结合上文提到的＂更好封存时间胶囊＂，我推测【算法是单向给未来人的】。‍‍综上所述可以得出结论，【算法＂毁灭世界＂的时间点不在当下，而在未来】                            为什么主角不能让萨托在自己抢到演算机之前挂掉？因为萨托挂了，就会引爆炸弹，同时给未来人发送一封邮件。而如果主角还没抢到演算机，那么演算机就依然会被埋在地底。                  红蓝两队可以借助时间钳形作战，互相共享未来的战斗信息，知己知彼。          电影中，红色军队出发前，指挥官在讲战术时特别提到，当前的作战方案是战友同志们浴血换来来的宝贵经验。      主角所在的红色军队以10分钟为跨度进行正向攻击，尼尔所在的蓝色军队以10分钟为跨度进行逆向攻击。也就是说，蓝色军队比红色军队晚出发10分钟，但红色军队朝着时间的正向移动，蓝色军队朝着时间的逆向移动。      当蓝色军队逆行10分钟，且目睹了整场战斗过程时，他们就可以将信息情报告知正在10分钟前点整装待发的红色军队。反之，让红色军队从正向前进10分钟后，他们同样可以将自己看到的情报告知正在10分钟后整装待发的蓝色军队。      这里需要再补充一张图片辅助理解。需要注意的是，敌方也存在红蓝一正一逆两部分战队，需要从两个方向进行作战。即蓝色逆转战队面对逆转的敌方队伍，红色正向战队面对敌方正常队伍。参考这张图，开始分析电影中的最终作战情节，其中一级列表从上往下为正向时间，二级列表从下往上为逆转时间。二级列表所述事件的发生时间和一级列表的正向事件发生时间相同。  起点，统一按照倒数计时，正时间从10min到0min的倒数计时。  正时间1天前（随便猜的，只要时间足够凯特抵达越南即可）          逆转凯特返回正向，从欧洲飞往越南；        正时间1小时前（随便猜的，只要时间足够准备即可）          逆转主角和尼尔转回正向，和一堆队友准备作战。        正时间10min，红队开始作战，主角随行。          蓝队等待，尼尔随行。      逆转蓝队撤离完毕，逆转尼尔2已死亡；        正时间5min，红队正在作战，逆转蓝队正在作战。一起炸楼；          逆转尼尔发现萨托手下安装隧道口炸药，于是脱离逆转蓝队，转为正向试图阻止主角进入隧道；        主角和大胡子队长进入隧道，触发炸弹引信，退路被封死；          尼尔开车追赶阻止未遂，转而开车前往洞穴上方；        主角来到尽头，门被锁，地上实体带着吊坠。萨托手下在门对门埋演算机，主角和逆转萨托通话；          逆转尼尔2进入洞穴，帮主角开门，挡枪死亡（正时间顺序是主角看到尸体尼尔挡枪，活过来开门，倒退离开洞穴）；        主角冲过去搏斗，最终将萨托手下推下洞穴，夺得演算机；          逆转凯特在越南游艇杀死逆转萨托，炸弹倒计时启动；      尼尔从洞穴上方扔下绳索；        主角和大胡子队长得到演算机，倒计时马上归零要爆炸，从天而降绳索，二人开始捆绑；          尼尔在时间归零前，只得开车拉动绳索；        正时间0min，爆炸，主角和大胡子队长成功被拉逃离；          蓝队等待完毕，开始逆转，准备作战。        正时间继续往后，主角，正尼尔，大胡子队长三方谈话，拆分演算机。          主角意识到尼尔将要逆转帮自己挡枪，红眼告别；      尼尔告诉主角自己时未来的主角招募的；        尼尔再次逆转，称为逆转尼尔2，返回帮主角开锁，然后挡枪赴死；最后，上一张最完整的示意图，展示整个电影的脉络。5. 其它5.1. 电影本身的探讨解析视频【大聪看电影】的后半部分已经说的很多了，我基本是赞同的，不再赘述。5.2. Q/A下面是十分不严谨的问答环节，以下观点仅代表个人想法。需要指出的是，下面绝大部分内容得到了解析视频【大聪看电影】的启发和参考。Q：既然反派萨托注定会失败并作为历史事实，为什么未来的人类还要埋藏时光胶囊，执行整个电影的故事呢？A：因为一部分未来人类不相信祖父悖论，相信平行宇宙理论。因此仍然进行了这些尝试。比如，如果现在有技术让人们穿越到第一次鸦片战争前夕，可以和1840年的人联系，那么自然会有一部分人试图通过这个技术指导过去的人如何阻止战争爆发。当然作为我们世界的历史，最后的结论就是，战争仍然爆发了。Q：逆转门是未来人送回到过去的，还是现代人根据未来人的指引打造的？A：逆转门的制造是一个祖父悖论，因此无解。类似于某人制造出了时光机，但时光机的图纸是未来人借助时光机回到过去给他的，那么到底是未来人后来才研制出时光机并且送回图纸，还是现代人先研制出来然后未来人才拥有时光机技术呢？Q：逆转回去的话，必须所以动作都要反着做？A：不用刻意反着行动。电影中，当一个人逆转之后，从自身的视角来看，自己仍然是按照正常的运动模式去运动的，正常走路，跑步，开车。只不过，从世界上其他观察者的视角来看，你的所有动作都是反的。比如逆转的你在密封的逆转环境中喝水，正常的正向世界的人看来，你就在吐水。Q：逆转回去的人，为什么跑步时候风会从后面吹到背上？A：因为这里的风是正向世界的空气。逆转的人在正向世界中运动，实际让是倒着的，从正向世界（时间）的角度看，倒着跑的人，风当然是吹到这个人的背后了。转到逆转人的视角，虽然自己在正着跑，但是人体的感觉还是遵循正向世界的风的反馈，因此背后感受到风。Q：逆转回去的人，能一直逆转下去么？能逆转多久？A：因为穿越者必须亲自往过去逆行，其所经历的事件，也必须是实实在在存在于此时间轴上的，只是时间演变方向相反。这就代表着，这位穿越者能够穿越到的最大范围，就是自己实际生命长度的极限。在诺式穿越中，因为穿越者能够逆行行驶的时间跨度有限，故需要通过时间胶囊的方式来对于一个来自未来的信息进行“接力棒”式的传递。这也是剧中希望毁灭世界的未来人向当下世界传递信息的主要方式。Q：逆转回去的人能改变过去么？A：这个很好理解，完全沿着时间轴逆行，这就意味着历史未曾被改变（或者说，哪怕是一些微小的改变也没有引起巨大的变化，因为任何小改变都已经是历史了，而历史上发生的已经发生）。根据《命运石之门》中所提到的世界线收束的概念，我们可以想象到，在诺式旋转门穿梭的前提下，即便回到了过去，也不过是在倒放演变历史，一直没有跳出收束的世界线。除非你对历史进行了不可修补的破坏，跳出了原本收束的世界线范围，进入收束到另一个结局的世界线范围，否则无论你如何穿越，历史的趋向都不可能改变。这点很像石头门中凶真不断穿越却不断目睹麻由里死亡的剧情，最后凶真通过在关键时间节点施以破坏的方式，才将世界线偏差率提高到了1%以上，实现了从α世界的逃离。5.3. 诺兰的电影诺兰的科幻电影一贯以硬核和烧脑闻名：2000.《记忆碎片》不按照攻略看根本看不懂（意识，现实），获得奥斯卡提名2010.《盗梦空间》经典当代科幻（哲学，意识，梦境，现实）2015.《星际穿越》经典宇宙科幻（空间）2020.《信条》经典时空科幻（时间，空间）其它的还有2006.《致命魔术》、2008.《黑暗骑士》、2012.《蝙蝠侠：黑暗骑士崛起》等。6. 参考文献[1] 百度百科. 熵定律.[2] 百度百科. 湮灭反应."
  },
  
  {
    "title": "科研Tips（文献查询、下载和管理）",
    "url": "/posts/research-tips-paper-download-arrange/",
    "categories": "Tutorial, Writing",
    "tags": "other",
    "date": "2020-09-05 14:23:19 +0800",
    





    
    "snippet": "乏味的科研生活中，文献查阅、下载和整理工作无疑是工作量枯燥的一个环节之一，本文将各类文献的查询和检索方法罗列如下，并引入Zotero这个文献管理软件来管理已经下载的文献。  1. 文献号查询          1.1. 百度学术查询      1.2. 图书馆数据库查询      1.3. ResearchGate查询      1.4. 注意事项        2. 文献下载       ...",
    "content": "乏味的科研生活中，文献查阅、下载和整理工作无疑是工作量枯燥的一个环节之一，本文将各类文献的查询和检索方法罗列如下，并引入Zotero这个文献管理软件来管理已经下载的文献。  1. 文献号查询          1.1. 百度学术查询      1.2. 图书馆数据库查询      1.3. ResearchGate查询      1.4. 注意事项        2. 文献下载          2.1. doi号下载      2.2. ResearchGate下载      2.3. 谷歌学术下载      2.4. sci-hub下载      2.5. arXiv下载      2.6. 中文硕博士论文下载        3. Zotero文献管理          3.1. 设置数据存储位置      3.2. 添加文献条目      3.3. 导出文献条目      3.4. 层级管理和同步        4. 参考文献1. 文献号查询1.1. 百度学术查询直接百度学术搜索文章标题1.2. 图书馆数据库查询如果是SCI，通过校图书馆-「数据库列表」-「Web Of Science」-「SCIE」搜索文章标题1.3. ResearchGate查询ResearchGate（https://www.researchgate.net/）1.4. 注意事项注意，有些会议文章可能搜不到 DOI 号；注意，有些文章可能仅上传于 arXiv，没 DOI 号；注意，有些专著没有 DOI 号，而是用 ISBN 号。2. 文献下载2.1. doi号下载直接在 DOI 号（如10.1016/j.asr.2017.11.035）前增加 https://doi.org/，然后通过浏览器访问，能重定向到论文原始出处，如果有权限（比如在校园网内且学校购买了相关数据资源），可以直接下载。2.2. ResearchGate下载ResearchGate（https://www.researchgate.net/） 上不但能检索到文献的 DOI 号，有的资源还可以直接下载。2.3. 谷歌学术下载本方法一般需要翻墙。访问 https://scholar.google.com，搜索文献题目，若该文献有能够下载的来源，右侧会出现包含 [PDF] 的下载连接。谷歌学术查询的文献，还可以查询到引用信息，作为额外的信息参考。还可以导出为 bibTex 格式。2.4. sci-hub下载俄罗斯大佬开发的神器：https://sci-hub.tw输入 DOI 号就能检索和下载 pdf 文献，虽然可能版本不是最新的，但胜在好用。DOI 号不用教怎么查了吧？某度学术，某歌学术，某 WOS，某 Gate，都可以输入文献名称去查。2.5. arXiv下载参考：如何快速下载 arxiv 论文arXiv（X依希腊文的χ发音，读音如英语的archive）（https://arxiv.org/）是一个收集物理学、数学、计算机科学、生物学与数理经济学的论文预印本（preprint）的网站，始于1991年8月14日。截至2008年10月，arXiv已收集超过50万篇预印本[2][3]；至2014年底，藏量达到1百万篇[4][5]。截至2016年10月，提交率已达每月超过10,000篇[5][6]。arxiv 在中国有官方镜像 http://cn.arxiv.org，通过使用 chrome 插件将 arxiv 的链接自动重定向到中国镜像网站链接即可，这样当你点击一篇文章的arxiv链接后就可以自动到cn.arxiv.org，速度很快。如果 http://cn.arxiv.org/ 仍然难以访问，但是中科院理论物理所也有一个备选网址： http://xxx.itp.ac.cn/ ，但是也不是特别稳定。首先安装 tampermonkey（油猴插件），这是一款功能强大的脚本插件，可以通过脚本对浏览器上网页进行修改编辑等，更多介绍可以参考 https://zhuanlan.zhihu.com/p/28869740。这里我们使用该插件对网页中的 arxiv 链接进行重定向到 cn.arxiv.org。油猴插件在各类浏览器中（如Chrome，Microsoft Edge等）均可以安装。推荐使用 Chrome  Webstore 或微软的浏览器插件商城（https://microsoftedge.microsoft.com/addons/Microsoft-Edge-Extensions-Home?hl=zh-CN）下载油猴插件，在 crx4chrome 网站搜索并下载也可以，这里给出crx4chrome网站上tampermonkey插件的下载链接。然后添加 arxiv 重定向脚本。 代码更新时间2017年12年04日，自动转到pdf链接。 代码需要全部复制粘贴，部分看似注释的代码也有用处，代码如下：// ==UserScript==// @name        Redirect arxiv.org to CN.arxiv.org/pdf// @namespace   uso2usom// @description On any web page it will check if the clicked links goes to arxiv.org. If so, the link will be rewritten to point to cn.arxiv.org// @include     http://*.*// @include     https://*.*// @version     1.2// @grant       none// ==/UserScript==// This is a slightly brute force solution, but there is no other way to do it using only a userscript.// Release Notes// version 1.2// Focus on pdf link only!// Add '.pdf' link  automatically. Convenient for saving as pdf.// version 1.1// Redirect arxiv.org to CN.arxiv.orgdocument.body.addEventListener('mousedown', function(e){    var targ = e.target || e.srcElement;    if ( targ &amp;&amp; targ.href &amp;&amp; targ.href.match(/https?:\\/\\/arxiv.org\\/pdf/) ) {        targ.href = targ.href.replace(/https?:\\/\\/arxiv\\.org/, 'http://cn.arxiv.org');    }    if ( targ &amp;&amp; targ.href &amp;&amp; targ.href.match(/http?:\\/\\/arxiv.org\\/pdf/) ) {        targ.href = targ.href.replace(/http?:\\/\\/arxiv\\.org/, 'http://cn.arxiv.org');    }    if ( targ &amp;&amp; targ.href &amp;&amp; targ.href.match(/https?:\\/\\/arxiv.org\\/abs/) ) {        targ.href = targ.href.replace(/https?:\\/\\/arxiv\\.org\\/abs/, 'http://cn.arxiv.org/pdf');    }    if ( targ &amp;&amp; targ.href &amp;&amp; targ.href.match(/http?:\\/\\/arxiv.org\\/abs/) ) {        targ.href = targ.href.replace(/http?:\\/\\/arxiv\\.org\\/abs/, 'http://cn.arxiv.org/pdf');    }    if (targ &amp;&amp; targ.href &amp;&amp; targ.href.match(/http?:\\/\\/cn.arxiv.org\\/pdf/) &amp;&amp; !targ.href.match(/\\.pdf/) )    {       targ.href = targ.href + '.pdf';    }});最后，测试配置是否成功，下面是 arxiv 上的一篇文章，点击pdf测试下载速度。之后可以手动去掉“cn.”前缀对比速度。 Relation Networks for Object Detection另外，由于 http://cn.arxiv.org 并不是主站点，是 arxiv 在中国区的镜像，因此更新有大约半天的延迟，对于当天提交的文章，可能更新不及时。对于当天文章可以手动删除“cn.”前缀解决。 如果出现 pdf 正在自动从源文件生成等提示，为正常现象，稍后即可获取pdf论文。2.6. 中文硕博士论文下载知网中论文只能下载到caj版本（垃圾知网只坑国人），如果处于校园网内，可以去知网海外版（www.oversea.cnki.net）下载到pdf版（垃圾知网不坑洋人）。点击Download PDF从此告别CNKI阅读器，垃圾流氓软件，拜拜了您嘞。3. Zotero文献管理文献管理软件可以有效的帮助研究人员管理参考文献，加速论文写作过程。这里介绍开源的文献管理软件 Zotero 的基本功能。注意，此处假设主要以英文论文书写为例，若以中文写作为主要工作，可使用 NoteExpress 作为文献管理软件，一般各高校图书馆均提供学校特别版下载安装，NoteExpress 可方便的从中国知网下载和导入文献。Zotero 官网（https://www.zotero.org/）可以免费下载该软件，软件支持中文。3.1. 设置数据存储位置下载安装后，打开「编辑」-「首选项」，切换到「高级」- 「文件和文件夹]选项卡，可以将参考文献索引和存放路径修改到「自定义的数据存储位置」：3.2. 添加文献条目  英文文献将下载到本地的 pdf 文献拖入 Zotero 软件界面即可添加该文献，等待一会儿后，软件会自动分析出论文的信息并形成一个条目，并将该文献的 pdf 文件拷贝至前面设置的自定义的数据存储位置，因此刚下载到本地的 pdf 文件即可删除了。点击右侧的第二栏 “笔记” 可以查看和增删对该论文的笔记双击该条目，可以打开外部 pdf 查看器来查看论文。  中文文献需要借助一个插件来让 Zotero 自动抓取中文文献的 metadata。插件 jasminum 下载地址 在此。该插件针对知网下载的文献均可正常抓取，其它如万方下载的文献，将文献的 PDF 文件名名字命名为【文献名.pdf】或者【文献名_第一作者.pdf】也可抓取。jasminum 实现的功能有：  拆分或合并 Zotero 中条目作者姓和名（也即增加或移除 metadata 中中文姓名之间的逗号）  根据知网上下载的文献文件来抓取引用信息（就是根据文件名）  添加中文PDF/CAJ时，自动拉取知网数据，该功能默认关闭。需要到设置中开启，注意添加的文件名需要含有中文，全英文没有效果  为知网的学位论文 PDF 添加书签下载得到 .xpi 格式的插件文件后，打开 Zotero，点击【工具】-【插件】打开插件管理器。然后点击左上角的齿轮-【Install Add-on From File…】，找到并选择刚刚下载的 .xpi 格式的插件文件，安装后根据提示重启 Zotero 完成安装。然后在导入的中文文献上右击，选择【知网】图标的更新元信息即可。3.3. 导出文献条目右键该条目，可以转到 pdf 文件的存放位置（自定义的数据存储位置），或者导出该文献的引文目录。根据写文章所需要的参考文献格式（此处以 IEEE 为例），选择引文目录，然后选择复制到剪贴板，即可在比如Word中所写论文的参考文献中，插入自动复制的引文条目：  [1] H. Hu, J. Gu, Z. Zhang, J. Dai, and Y. Wei, “Relation Networks for Object Detection,” arXiv:1711.11575 [cs], Jun. 2018, Accessed: Sep. 05, 2020. [Online]. Available: http://arxiv.org/abs/1711.11575.还可以右键选择「导出条目」导出为 bib 格式的条目信息，即可在 latex 中的 bib 文件插入该参考文献条目以供正文引用。3.4. 层级管理和同步Zotero 另一个优点是可以建立多层级的目录树，便于分门别类的整理参考文献条目。另一个方法是针对每一篇写的文章建立一个目录，将所有引用的参考文献放入其中，这样可以统一将整个目录的所有参考文献导出参考文献列表。当注册了Zotero账户后，可以方便的将整个文献库进行云端存储和同步，当两地办公写作时，可以在一处更新参考文献库后，在另一处联网同步，即可无缝保持两地的文献库的同步。账户设置位于「首选项」-「同步」中，设置完毕后，点击软件界面右上角的小图标即可进行同步。更进一步，可以 此处 下载 zotfile 插件。zotfile 可以极大的增强 Zotero 的文献管理功能，比如一键规范所有条目的文献 pdf 文件的标题等。4. 参考文献[1] 德谟赛斯. 如何快速下载 arxiv 论文.[2]  strange_jiong. Latex编译出现字体获取不到的情况.[3]  开心鲨鱼. 配置VScode编辑LaTeX及正反向搜索等设置.[4] LaTeX工作室. LaTeX技巧932：如何配置Visual Studio Code作为LaTeX编辑器新版更新."
  },
  
  {
    "title": "LaTeX+VSCode环境配置",
    "url": "/posts/LateX-VSCode/",
    "categories": "Tutorial, Writing",
    "tags": "latex, vscode",
    "date": "2020-08-28 09:17:19 +0800",
    





    
    "snippet": "VSCode作为一个小巧而又功能强大的编辑器，已经成为我进行仿真程序开发调试的唯一工具，是否可以直接拿VSCode来写LaTeX？当然可以，从此一个程序内仿真、画图、码字一气呵成。  1. 前言  2. LaTeX配置          2.1. 安装MikTeX      2.2. 配置环境变量（绿色版）        3. 配置VSCode的LaTeX环境          3.1. 安...",
    "content": "VSCode作为一个小巧而又功能强大的编辑器，已经成为我进行仿真程序开发调试的唯一工具，是否可以直接拿VSCode来写LaTeX？当然可以，从此一个程序内仿真、画图、码字一气呵成。  1. 前言  2. LaTeX配置          2.1. 安装MikTeX      2.2. 配置环境变量（绿色版）        3. 配置VSCode的LaTeX环境          3.1. 安装LaTeX Workshop      3.2. 配置json      3.3. 编译测试      3.4. 快捷键      3.5. 安装LTeX        4. 参考文献1. 前言由于VSCode太牛逼，所有的C和Python仿真均已经迁移至该编辑器下完成，偶然发现其还可编译LaTeX，狂喜，遂研究之，步骤列于下。下面以 MikTeX 20.6 + VSCode 1.48.2 为例进行安装和部署讲解。2. LaTeX配置2.1. 安装MikTeX参考此处。此处摘录如下：官网的下载页面 包括三种下载（安装）方式，如图分别为安装程序（Installer）、绿色版（Portable Edition）以及命令行（Command-line installer）。对于Windows开发环境，不考虑命令行方式，因此可以任意选择安装程序或者绿色版。需要注意的是，绿色版并没有单独的压缩包，而是直接对应安装版的安装程序，只不过将安装程序重命名为 MiKTeX-portable.exe，然后双击安装即可。绿色版与安装版的区别在于，绿色版不会向系统盘写入配置信息，也不会注册环境变量，意味着之后如果需要安装编辑器，无法自动获取系统中已经安装的LaTeX版本，而需要手动配置。懒人推荐安装版，省去配置环境变量等步骤（虽然后面是以绿色版介绍的）。双击下载的 exe 文件进行安装，路径任意。2.2. 配置环境变量（绿色版）将 miktex 附带的 xelatex.exe 和 pdflatex.exe 等工具所在的路径加入系统 Path 环境变量。假设安装的MiKTeX为绿色版，安装根目录为X:\\ProgramFiles\\MiKTeX\\，则上述路径均位于X:\\ProgramFiles\\MiKTeX\\texmfs\\install\\miktex\\bin\\x64相应的，安装版的路径位于X:\\ProgramFiles\\MiKTeX\\miktex\\bin\\x64注意，如果在 VSCode 打开的情况下改变了环境变量，需要重启 VSCode 使其能够获取最新的环境变量。3. 配置VSCode的LaTeX环境3.1. 安装LaTeX WorkshopLaTeX Workshop 几乎可以认为是 VSCode 标配的 LaTeX 编译扩展，挂上翻墙通过扩展商店搜索 latex 弹出的第一个就是。安装完成后，ctrl+, 打开设置面板（或通过左下角的小齿轮点击进入），搜索 json 然后点击 「在settings.json 中编辑」，打开 settings.json。3.2. 配置json在 settings.json 中新增如下代码：{\t\"latex-workshop.latex.recipes\": [      {        \"name\": \"pdflatex -&gt; bibtex -&gt; pdflatex*2\",        \"tools\": [          \"pdflatex\",          \"bibtex\",          \"pdflatex\",          \"pdflatex\"        ]      }    ],    \"latex-workshop.latex.tools\": [      {        \"name\": \"xelatex\",        \"command\": \"xelatex\",        \"args\": [          \"-synctex=1\",          \"-interaction=nonstopmode\",          \"-file-line-error\",          \"%DOC%\"        ]      },      {        \"name\": \"latexmk\",        \"command\": \"latexmk\",        \"args\": [          \"-synctex=1\",          \"-interaction=nonstopmode\",          \"-file-line-error\",          \"%DOC%\"        ]      },      {        \"name\": \"pdflatex\",        \"command\": \"pdflatex\",        \"args\": [          \"-synctex=1\",          \"-interaction=nonstopmode\",          \"-file-line-error\",          \"%DOC%\"        ]      },      {        \"name\": \"bibtex\",        \"command\": \"bibtex\",        \"args\": [          \"%DOCFILE%\"        ]      }    ],    \"latex-workshop.view.pdf.viewer\": \"tab\",}最终效果如下（忽略前面的若干主体配置项）：注意，latex-workshop.latex.tools 字段定义了编译 LaTeX 的序列操作，默认为 xelatex -&gt; bibtex -&gt; xelatex*2，这里将其修改为 pdflatex -&gt; bibtex -&gt; pdflatex*2，对应的顺序为调用1次 pdflatex，1次 bibtex，2次 pdflatex，与texstudio保持一致，确保生成的 pdf 文件字体和格式一致。进阶配置还包括：设置禁止保存时自动build，以及设定自动清理中间文件的类型。{    \"latex-workshop.latex.autoBuild.run\": \"never\", //禁止保存时自动build      \"latex-workshop.latex.clean.fileTypes\": [  //设定清理文件的类型        \"*.aux\",        \"*.bbl\",        \"*.blg\",        \"*.idx\",        \"*.ind\",        \"*.lof\",        \"*.lot\",        \"*.out\",        \"*.toc\",        \"*.acn\",        \"*.acr\",        \"*.alg\",        \"*.glg\",        \"*.glo\",        \"*.gls\",        \"*.ist\",        \"*.fls\",        \"*.log\",        \"*.fdb_latexmk\",        \"*.nav\",        \"*.snm\",        \"*.synctex.gz\"      ],}设置仅针对 LaTeX 的自动换行{    \"latex-workshop.view.pdf.viewer\": \"tab\",    \"[latex]\": {      \"editor.wordWrap\": \"on\", // &lt;== auto wrap      \"editor.formatOnPaste\": false,      \"editor.suggestSelection\": \"recentlyUsedByPrefix\"    },}3.3. 编译测试快捷键 ctrl+alt+B 编译 .tex文件，快捷键 ctrl+alt+v 或者右上角的「查看pdf」图标查看 .pdf 文件。3.4. 快捷键快捷键的更改根据个人习惯而定。打开键盘快捷方式面板(左下侧齿轮，或快捷键ctrl+k,ctrl+s)：      搜索”切换侧栏可见性”，设置快捷键为ctrl+k ctrl+b。        搜索 latex build，将默认的ctrl+alt+b替换为ctrl+b(与Sublime Text 3统一)。        搜索latex recipe，设置快捷键为ctlr+r，方便点菜(选择编译方式)！(ST3中是显示文档大纲)。        其他常用的快捷键：              ctrl+k ctrl+a： 切换活动栏可见性(左侧图标开关)      ctrl+alt+x：显示LaTeX面板(左侧编译命令面板和文档大纲)。      ctrl+alt+c：清除辅助文件      ctrl+alt+v：查看编译的pdf文件(预览)      ctrl+alt+j：正向搜索。当设置\"latex-workshop.view.pdf.viewer\": \"tab\";时，在LaTeX源文件中按下快捷键，定位到PDF文档相应位置。(反向搜索见后面)      根据 latex-workshop.latex.recipes 中的name段设定，可在 .tex 文件首行指定编译方式。如 %!TEX program = xelatex 表示用 xelatex 编译文件，而 %!TEX program = PDFlatex 表示用 latexpdf 编译文件。多个文件情况，还可以用 % !TEX root 指定主文件，% !TEX bib 指定 bib 的编译方式。示例%! TeX program = pdflatex\\documentclass{article}\\begin{document}    press ctrl+b to complie，press ctrl+alt+v to view pdf\\end{document}3.5. 安装LTeX用过 LaTeX 的都知道，对比 Office 家族，LaTeX 的语言纠错功能非常不方便。因为本身没这功能，需要借助外部工具才能实现。这个缺点对于我等「外语渣」是非常要命的。当然，解决方法也不是没有。典型的，如果你用的是 TeXstudio 这个编辑器，可以通过外挂 LanguageTool （简称: LT） 这个检查工具，实现拼写和语法检查。具体怎么配置，网上有很多教程。VS Code 的插件市场其实是有提供一些插件， 让 Code 能够调用 LT 进行拼写检查。比如 「LanguageTool for Visual Studio Code」和 「LanguageTool Linter」。 但是邪门的是——他们竟然只支持纯文本 或者 Markdown 文件的拼写检查，不支持 .tex 文件! 不过幸运就降临在今天，在浏览扩展时，无意发现了「LTeX」 这个插件，下载使用后直呼内行，直接在 VS Code 插件市场搜索并安装，然后重启 VSCode 后打开任意 .tex 文档即可开始进行拼写、语法检查（不包括中文）。有些品牌，网络词汇等可能会被识别为拼写错误，可以把他们加入词典避免误判：\"ltex.de.dictionary\": [Niubility, Zhihu], //注意根据要对应语言，ltex.&lt;LANGUAGE&gt;.dictionary有些环境内的语言可能不需要检查，比如代码块里的程序代码，可以参照如下设置过滤：\"ltex.environments.ignore\": [\"lstlisting\", \"verbatim], 有些自定义命令也可以设置过滤避免检查\"ltex.commands.ignore\": [\"\\\\documentclass[]{}\", \"\\\\renewcommand*{}[]{}\"]其他诸如「自定义规则」，「错误提醒风格」等的可以自己参照说明设置。语法检查的效果如下4. 参考文献[1]  当年老王. 论文写作的又一利器：VSCode + Latex Workshop + MikTex + Git.[2]  strange_jiong. Latex编译出现字体获取不到的情况.[3]  开心鲨鱼. 配置VScode编辑LaTeX及正反向搜索等设置.[4] LaTeX工作室. LaTeX技巧932：如何配置Visual Studio Code作为LaTeX编辑器新版更新."
  },
  
  {
    "title": "Python基础（绘图plot）",
    "url": "/posts/python-basic-plot/",
    "categories": "Tutorial, Coding",
    "tags": "python",
    "date": "2020-08-22 15:58:19 +0800",
    





    
    "snippet": "由于科研需要，早已不复年轻的我又要从头开始学习一门新的语言——Python。由于老年痴呆愈发严重，只得将各种学习笔记记录在此。本文主要针对Python中画图部分展开，包括plot、subplot等。  1. plot          1.1. 颜色控制      1.2. 线形控制      1.3. 点形控制      1.4. 另一种设置方法        2. subplot    ...",
    "content": "由于科研需要，早已不复年轻的我又要从头开始学习一门新的语言——Python。由于老年痴呆愈发严重，只得将各种学习笔记记录在此。本文主要针对Python中画图部分展开，包括plot、subplot等。  1. plot          1.1. 颜色控制      1.2. 线形控制      1.3. 点形控制      1.4. 另一种设置方法        2. subplot          2.1. 规则划分      2.2. 不规则划分      2.3. 二维三维混合子图      2.4. 多图刷新        3. 图中图  4. 清理绘图  5. 参考文献1. plotplot 用以展示变量的趋势变化。plot() 函数的本质就是根据点连接线。根据x(数组或者列表) 和y(数组或者列表)组成点，然后连接成线。简单示例如下import matplotlib.pyplot as pltimport numpy as npx = np.linspace(0.05, 10, 1000)y = np.cos(x)plt.plot(x, y, ls=\"-\", lw=2, label=\"plot figure\")plt.legend()plt.show()1.1. 颜色控制要想使用丰富，炫酷的图标，我们可以使用更复杂的格式设置，主要颜色，线的样式，点的样式。默认的情况下，只有一条线，是蓝色实线。多条线的情况下，生成不同颜色的实线。            字符      颜色                  ‘b’      blue              ‘g’      green              ‘r’      red              ‘c’      cyan 青色              ‘m’      magenta平红              ‘y’      yellow              ‘k’      black              ‘w’      white      1.2. 线形控制            字符      类型                  ’-‘      实线              ’–’      虚线              ’-.’      虚点线              ’:’      点线              ’ ‘      空类型，不显示线      例如import matplotlib.pyplot as pltx = [1, 2, 3, 4]y1 = [1, 2, 3, 4]y2 = [1, 4, 9, 16]y3 = [1, 8, 27, 64]y4 = [1, 16, 81, 124]# 创建一个画布plt.figure()# 在figure下线plt.plot(x, y1, \"-o\") #实线plt.plot(x, y2, \"--o\") #虚线plt.plot(x, y3, \"-.o\") #虚点线plt.plot(x, y4, \":o\") # 点线# 展现画布plt.show()绘制效果为1.3. 点形控制            点型      类型                  ’.’      点              ’,’      像素点              ‘o’      原点              ’^’      上三角点              ‘v’      下三角点              ’&lt;’      左三角点              ’&gt;’      右三角点              ‘1’      下三叉点              ‘2’      上三叉点              ‘3’      左三叉点              ‘4’      右三叉点              ’s’      正方点              ’+’      加号点              ‘x’      乘号点              ‘D’      实心菱形点              ‘d’      细菱形点      示例import matplotlib.pyplot as pltx = [1, 2, 3, 4]y1 = [1, 2, 3, 4]y2 = [1, 4, 9, 16]y3 = [1, 8, 27, 64]y4 = [1, 16, 81, 124]# 创建一个画布plt.figure()# 在figure下的线plt.plot(x, y1, \"-.\") # 点plt.plot(x, y2, \"-,\") # 像素点plt.plot(x, y3, \"-o\") # 圆点# 展现画布plt.show()绘制效果为1.4. 另一种设置方法color=”green” 指定颜色为绿色linestyle=”dashed” 指定线形为dashed类型marker=”o” 指定标记类型为o点markerfacecolor=”blue”指定标记的颜色为蓝色markersize=20 指定标记的大小为20比如import matplotlib.pyplot as pltimport numpy as npx = np.arange(10)y1 = x * 1.5y2 = x * 2.5y3 = x * 3.5y4 = x * 4.5y5 = x * 5.5plt.plot(x, y1, \"-P\")plt.plot(x, y2, \"-|\")plt.plot(x, y3, color=\"#000000\")plt.plot(x, y4, \"-o\", markersize=20)plt.plot(x, y5, \"-^\", markerfacecolor=\"blue\")plt.show()2. subplot有些时候, 我们希望把一组图放在一起进行比较, 有没有什么好的方法呢？matplotlib 中提供的 subplot 可以很好的解决这个问题。matplotlib 下, 一个 Figure 对象可以包含多个子图(Axes), 可以使用 subplot() 快速绘制, 其调用形式如下 :subplot(numRows, numCols, plotNum)  图表的整个绘图区域被分成 numRows 行和 numCols 列；  然后按照从左到右，从上到下的顺序对每个子区域进行编号，左上的子区域的编号为1；  plotNum 参数指定创建的 Axes 对象所在的区域；  如果 numRows, numCols 和 plotNum 这三个数都小于 10 的话, 可以把它们缩写为一个整数, 例如 subplot(323) 和 subplot(3,2,3) 是相同的（缩写便于循环）；  subplot在 plotNum 指定的区域中创建一个轴对象. 如果新创建的轴和之前创建的轴重叠的话，之前的轴将被删除。2.1. 规则划分示例import matplotlibimport matplotlib.pyplot as pltfor i,color in enumerate(\"rgby\"):    plt.subplot(221+i, axisbg=color) # 221 = 2,2,1plt.show()绘制结果为2.2. 不规则划分有时候我们的划分并不是规则的, 比如如下的形式这种应该怎么划分呢?首先将整个表按照 2*2 划分，前两个简单, 分别是 (2, 2, 1) 和 (2, 2, 2)；但是第三个图呢, 他占用了 (2, 2, 3) 和 (2, 2, 4)；因此，需要对整个图重新划分, 按照 2 * 1 划分；前两个图占用了 (2, 1, 1) 的位置，因此第三个图占用了 (2, 1, 2) 的位置。代码如下import matplotlib.pyplot as pltimport numpy as npdef f(t):    return np.exp(-t) * np.cos(2 * np.pi * t)if __name__ == '__main__' :    t1 = np.arange(0, 5, 0.1)    t2 = np.arange(0, 5, 0.02)    plt.figure(12)    plt.subplot(221)    plt.plot(t1, f(t1), 'bo', t2, f(t2), 'r--')    plt.subplot(222)    plt.plot(t2, np.cos(2 * np.pi * t2), 'r--')    plt.subplot(212)    plt.plot([1, 2, 3, 4], [1, 4, 9, 16])    plt.show()2.3. 二维三维混合子图import matplotlib.pyplot as pltfig = plt.figure(1)ax1 = fig.add_subplot(2, 2, 1)ax2 = fig.add_subplot(2, 2, 2)ax3 = fig.add_subplot(2, 2, 3)ax4 = fig.add_subplot(2, 2, 4, projection='3d')for i in range(100):  ax1.set_title('x-axis')  ax1.plot(ind, pred_x, label=\"prediction\", color=(i,0,1))  ax1.plot(ind, outputs_x, label=\"true\", color=(0,1,0))  ax1.legend(loc=\"lower right\")  ......  fig = plt.figure(1) # re-assign to figure 1 to refresh it  plt.pause(0.01) # leave some time for plotting finished  plt.show(block=False) # plot without blocking running可以绘制两行量列的子图，其中右下角第四个图是三维图。注意不要将上述代码置于循环中，否则会出现DuplicateWarning。多次绘制在同一个figure中的效果如下：2.4. 多图刷新注意，如果有多张图需要同时刷新，需要按照如下的设计思路书写代码import matplotlib.pyplot as pltfig = plt.figure(1) # 在循环外定义包含多个subplot的figure 1ax1 = fig.add_subplot(2, 2, 1)ax2 = fig.add_subplot(2, 2, 2)ax3 = fig.add_subplot(2, 2, 3)ax4 = fig.add_subplot(2, 2, 4, projection='3d')for i in range(100):  ......[other codes]  ax1.cla() # 清空当前轴  ax2.cla()  ax3.cla()  ax4.cla()  plt.pause(0.01)  ax1.set_title('x-axis')  ax1.plot(ind, pred_x, label=\"prediction\", color=(i,0,1))  ax1.plot(ind, outputs_x, label=\"true\", color=(0,1,0))  ax1.legend(loc=\"lower right\")  ......[other codes]  fig = plt.figure(1) # 重新指定fig的对象为figure 1  plt.pause(0.01) # 必须暂停短暂的时间以供绘图完成而不出现白板  plt.show(block=False) # 刷新figure 1，且不阻塞    figloss = plt.figure(2) # 指定fig的对象为figure 2  plt.cla() # 清空当前轴  plt.pause(0.01)  plt.plot(iterNum, avgloss, '-o')  plt.xlabel('iterations',fontsize=10)  plt.ylabel('MSE',fontsize=10)  plt.pause(0.01)  plt.show(block=False) # 刷新figure 2，且不阻塞          在循环外定义包含多个subplot的figure 1，避免循环内定义报DuplicatedWarning；  单张图可在循环内直接定义和绘制（如figure 2）；  循环内每次重新绘制时，需通过 fig = figure(x) 指定相应的第x个图才能正确刷新。3. 图中图代码如下import numpy as npimport matplotlib.pyplot as pltfig = plt.figure(1)plt.plot(listiter_meta, ground_truth, '-.', label='ground truth', color=\"black\")plt.plot(listiter_meta, pretrained, '--', label='pretrained', color=\"green\")plt.plot(listiter_meta, meta, '-', label='meta learned (ours)', color=\"red\")plt.xlim(0,100)plt.xlabel(\"iteration\")plt.ylabel(\"mse\")plt.legend(loc=\"upper right\")left, bottom, width, height = 0.5,0.3,0.4,0.2ax1 = fig.add_axes([left,bottom,width,height])ax1.plot(listiter_meta, ground_truth, '-.', color=\"black\")ax1.plot(listiter_meta, pretrained, '--', color=\"green\")ax1.plot(listiter_meta, meta, '-', color=\"red\")ax1.set_xlabel(\"iteration\")ax1.set_ylabel(\"mse\")ax1.set_title('zoom-in')ax1.set_ylim(0,0.2)plt.savefig('msecompare.png')plt.show(block=False)结果如下图所示4. 清理绘图cla() 函数可以清除当前figure中活动的axes，其它axes保持不变。clf() 函数清除当前figure的所有axes，但是不关闭这个window，可以继续复用于其它的plot。close() 关闭 window，如果没有指定，则指当前 window。5. 参考文献[1] 梦并不遥远. 4.3Python数据处理篇之Matplotlib系列(三)—plt.plot().[2] 我的明天不是梦. python使用matplotlib:subplot绘制多个子图."
  },
  
  {
    "title": "Python基础（数据结构）",
    "url": "/posts/python-basic-data-type/",
    "categories": "Tutorial, Coding",
    "tags": "python",
    "date": "2020-08-15 21:17:19 +0800",
    





    
    "snippet": "本文主要针对Python中数据类型和数据处理方式的介绍，包括mat、list、ndarray等。  1. mat          1.1. MATLAB保存mat文件      1.2. Python读取mat文件        2. list          2.1. 复制      2.2. 合并      2.3. 插入新元素      2.4. 获取列表中的值        3....",
    "content": "本文主要针对Python中数据类型和数据处理方式的介绍，包括mat、list、ndarray等。  1. mat          1.1. MATLAB保存mat文件      1.2. Python读取mat文件        2. list          2.1. 复制      2.2. 合并      2.3. 插入新元素      2.4. 获取列表中的值        3. tuple  4. ndarray          4.1. 概念      4.2. 数组属性      4.3. 创建数组      4.4. 数组拼接      4.5. list和array的区别        5. dict          5.1. 定义，更新和添加      5.2. 内置函数      5.3. 内置方法      5.4. 特性      5.5. OrderedDict        6. 参考文献1. mat1.1. MATLAB保存mat文件如下例子所示clearclcmaindir = 'Results';subdir  = dir( maindir );j = 1;for ii = 1 : length( subdir )    if( isequal( subdir( ii ).name, '.' )||...        isequal( subdir( ii ).name, '..')||...        ~subdir( ii ).isdir) % skip if not dir        continue;    end        matfile = fullfile( maindir, subdir( ii ).name, 'Result.mat' );    condition = split(subdir( ii ).name, '_');    load(matfile)    dataCell{j,1} = condition(2);    dataCell{j,2} = condition(3);    dataCell{j,3} = DesireStatus;    dataCell{j,4} = DesireControl;    j = j + 1;endsave('MixResults.mat','dataCell');最终保存的文件形式如图所示1.2. Python读取mat文件import scipy.io as sioimport numpy as npload_path = 'MixResults.mat'load_data = sio.loadmat(load_path)此处得到的 load_data 是如下形式的值{'__globals__': [],'__header__': b'MATLAB 5.0 MAT-file,...00:47 2020','__version__': '1.0','dataCell': array([[array([[arra...pe=object)}其中，scipy读入的mat文件是个dict类型，会有很多不相关的keys，一般输出四种keys：__globals__，__header__，__version__，data。其中最后一个data才是我们要的数据。本例中，数据为 dataCell ，内容为array([[array([[array(['wty0.0'], dtype='&lt;U6')]], dtype=object),        array([[array(['-30deg'], dtype='&lt;U6')]], dtype=object),        array([[ 0.00000000e+00, -8.66025400e+00,  0.00000000e+00, ...,         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],       [ 1.31815433e-01, -8.66003375e+00,  3.20285361e-12, ...,        -6.21551560e-19,  0.00000000e+00,  0.00000000e+00],       [ 2.63630865e-01, -8.65933419e+00,  1.29989166e-11, ...,        -3.17675810e-19,  0.00000000e+00,  0.00000000e+00],       ...,       [ 4.58717705e+01, -2.75108745e+00,  2.14124086e-11, ...,         2.86948290e-17, -5.53482295e-17,  5.27271879e-15],       [ 4.60035859e+01, -2.75027966e+00, -4.46901743e-12, ...,         1.32056047e-17, -4.37313113e-17, -2.42826591e-16],       [ 4.61354014e+01, -2.75000000e+00,  2.89500769e-27, ...,        -2.77555756e-17, -1.30104261e-17, -1.48286602e-14]]),        array([[ 0.00000000e+00,  2.40730441e+00,  6.83370983e-08, ...,         2.87639504e+00, -3.90482776e-07,  2.65632451e-01],       [ 1.31815433e-01,  2.77247364e+00,  2.88899127e-04, ...,         1.27018538e+00, -2.19925908e-07,  1.26745599e-01],       [ 2.63630865e-01,  3.06865475e+00,  1.11303404e-03, ...,         6.74119805e-02, -9.25865826e-08,  2.27535649e-02],       ...,       [ 4.58717705e+01, -3.25427728e+00,  5.09348887e-03, ...,         2.01213062e-02,  1.28660157e-03,  2.75940695e+00],       [ 4.60035859e+01, -3.15266928e+00,  1.21336612e-03, ...,         1.97145055e-02,  1.30781251e-03,  3.95909773e+00],       [ 4.61354014e+01, -3.04097330e+00,  1.01612056e-07, ...,         1.87656241e-02,  1.31095528e-03,  5.18427291e+00]])],       ...,       dtype=object)可以按照如下方式拼命取出 dataCell 中的各个元素&gt;&gt;&gt; targetw = []&gt;&gt;&gt; targetw.append(load_data['dataCell'][i][0][0][0][0]) # wty'wty0.0'&gt;&gt;&gt; position = []&gt;&gt;&gt; position.append(load_data['dataCell'][i][1][0][0][0]) # deg'-30deg'&gt;&gt;&gt; trajectory = np.zeros((tnum,1))&gt;&gt;&gt; trajectory = load_data['dataCell'][i][2]&gt;&gt;&gt; control = np.zeros((tnum,1))&gt;&gt;&gt; control = load_data['dataCell'][i][3]得到的数据为 ndarray ，数据结构为取出其中 wty 的数值，可以借助 strip 砍掉 “wty” 三个字符。注意 strip 返回的是一个字符串，需要通过强制格式转换转为数字wt = wty.strip('wty') # 0.0wt = float(wt)提取 trajectory 中的第一行数据，最后一行数据，以及 wt，合并后形成一个新的向量，借助 np.hstack 实现：trow = trajectory.shape[0]vec = np.hstack((trajectory[0,1:4],trajectory[trow-1,1:4],wt))# trajectory: t, rx, ry, rz, vx, ...; [1:4] is rx ry and rz2. list列表（list）是用来存储一组有序数据元素的数据结构，元素之间用逗号分隔。列表中的数据元素应该包括在方括号中，而且列表是可变的数据类型，一旦创建了一个列表，你可以添加、删除或者搜索列表中的元素。在方括号中的数据可以是 int 型，也可以是 str 型。新建一个空列表A = []当方括号中的数据元素全部为int类型时，这个列表就是int类型的列表。str类型和混合类型的列表类似A = [1,2,3]A = [\"a\",'b','c'] # 单引号和双引号都认A = [1,\"b\",3]2.1. 复制列表的复制和字符串的复制类似，也是利用 * 操作符A = [1,2,3]A*2 # A = [1,2,3,1,2,3]2.2. 合并列表的合并就是将两个现有的list合并在一起，主要有两种实现方式，一种是利用+操作符，它和字符串的连接一致；另外一种用的是extend()函数。直接将两个列表用+操作符连接即可达到合并的目的，列表的合并是有先后顺序的。a = [1,2]b = ['a','b']m = [\"c\",\"c\"]c=a+b+m # c = [1,2,'a','b','c','c']d=b+a+m # d = ['a','b',1,2,'c','c']将列表b合并到列表a中，用到的方法是a.extend(b)，将列表a合并到列表b中，用到的方法是b.extend(a)。2.3. 插入新元素向列表中插入新元素。列表是可变的，也就是当新建一个列表后你还可以对这个列表进行操作，对列表进行插入数据元素的操作主要有 append() 和 insert() 两个函数可用。这两个函数都会直接改变原列表，不会直接输出结果，需要调用原列表的列表名来获取插入新元素以后的列表。函数 append() 是在列表末尾插入新的数据元素，如下：a = [1,2]a.append(3) # a = [1,2,3]函数 insert() 是在列表指定位置插入新的数据元素，如下：a = [1,2,3]a.insert(3,4) # a = [1,2,3,4]，在列表第四位（从0开始算起）插入4a = [1,2]a.insert(2,4) # a = [1,2,4,3]，在列表第三位（从0开始算起）插入42.4. 获取列表中的值获取指定位置的值利用的方法和字符串索引是一致的，主要是有普通索引和切片索引两种。  普通索引：普通索引是活期某一特定位置的数，如下：&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; a[0] # 获取第一位数据1&gt;&gt;&gt; a[2]3  切片索引：切片索引是获取某一位置区间内的数，如下：&gt;&gt;&gt; a = [1,2,3,4,5]&gt;&gt;&gt; a[1:3] # 获取第2位到第4位的数据，不包含第4位[2,3]假设 a = [1,2,3,4,5,6,7,8,9]，对应的标号为 [0,1,2,3,4,5,6,7,8]；print a[1:2:3] 输出为2 ，从下标表为1的地方开始到小于下标为2的位置，其中3为步长；print a[1:4:1] 输出为2，3，4,以上面类似，只是步长为1了；print a[1::1] 输出为2，3，4，5，6，7，8，9。中间为空表示默认，则从小标为1到最后；print a[-1:-4:-1] 反向索引，从最后一位开始放过来取值，注意这里的步长要为-1，因为反向。3. tupletuple，元组，与列表 list 类似，不同之处在于元组（指向）的元素不能修改。一般来说，tuple 是不可变的（immutable）可以包含多种类型成员的数据结构，list 是可变的包含同类型成员的数据结构。元组使用小括号，列表使用方括号。元组创建很简单，只需要在括号中添加元素，并使用逗号隔开即可。如果创建一个空元组，直接使用小括号即可；如果要创建的元组中只有一个元素，要在它的后面加上一个逗号’，’。&gt;&gt;&gt; temp = ()&gt;&gt;&gt; type(temp)     &lt;class 'tuple'&gt;&gt;&gt;&gt; temp = (1,)&gt;&gt;&gt; type(temp)    &lt;class 'tuple'&gt;&gt;&gt;&gt; temp = (1)&gt;&gt;&gt; type(temp)    &lt;class 'int'&gt;&gt;&gt;&gt; 8 * (8)    64&gt;&gt;&gt; 8 * (8,)    (8, 8, 8, 8, 8, 8, 8, 8)灵剑. python 的 tuple 是不是冗余设计？  最重要的好处是可以做dict的key（如果内部也是immutable的类型）。次一点的好处是由于确保不能修改，可以安全地在多个对象之间共享。  tuple类型对于Python自身来说是非常重要的数据类型，比如说函数调用，实际上会将顺序传入的参数先组成一个tuple；多返回值也是靠返回一个tuple来实现的。因为太常用，所以需要一个更有效的数据结构来提高效率，一个不可变的tuple对象从实现上来说可以比list简单不少。再比如说code对象会记录自己的参数名称列表，free variable名称列表等等，这些如果用list，就可能被从外部修改，这样可能导致解释器崩溃；那就只能选择改成一个函数每次都返回一个新的列表，这样又很浪费。所以即使是从解释器自身实现的角度上来说引入这样一个不可变的序列类型也是很重要的。  对程序员来说如果没有什么美学上的追求的话，tuple最大的便利在于它是一个hashable的类型，而且hash算法与值直接对应，这样在Python里很容易用多个值的组合来做key生成一个dict，比如说我们网络里有20台交换机，每个交换机有24个口，那要唯一标识每个口就需要用(交换机ID，口编号），这个tuple可以做dict的key的话，编写程序起来就很方便了。函数如果有多个返回值，返回的是一个 tuple。4. ndarrayNumpy是Python的一个扩充程序库，支持高阶大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。对于数据的运算，用矩阵会比python自带的字典或者列表快好多。4.1. 概念NumPy 最重要的一个特点是其 N 维数组对象 ndarray，它是一系列同类型数据的集合，以 0 下标为开始进行集合中元素的索引。ndarray 对象是用于存放同类型元素的多维数组。ndarray 中的每个元素在内存中都有相同存储大小的区域。ndarray 内部由以下内容组成：  一个指向数据（内存或内存映射文件中的一块数据）的指针。  数据类型或 dtype，描述在数组中的固定大小值的格子。  一个表示数组形状（shape）的元组，表示各维度大小的元组。  一个跨度元组（stride），其中的整数指的是为了前进到当前维度下一个元素需要”跨过”的字节数。创建一个 ndarray 只需调用 NumPy 的 array 函数即可：numpy.array(object, dtype = None, copy = True, order = None, subok = False, ndmin = 0)参数说明            名称      描述                  object      数组或嵌套的数列              dtype      数组元素的数据类型，可选              copy      对象是否需要复制，可选              order      创建数组的样式，C为行方向，F为列方向，A为任意方向（默认）              subok      默认返回一个与基类类型一致的数组              ndmin      指定生成数组的最小维度      例子&gt;&gt;&gt; import numpy as np &gt;&gt;&gt; a = np.array([1,2,3])  &gt;&gt;&gt; print (a)[1, 2, 3]&gt;&gt;&gt; a = np.array([[1,  2],  [3,  4]])  &gt;&gt;&gt; print (a)[[1, 2]  [3, 4]]4.2. 数组属性NumPy 数组的维数称为秩（rank），秩就是轴的数量，即数组的维度，一维数组的秩为 1，二维数组的秩为 2，以此类推。在 NumPy中，每一个线性的数组称为是一个轴（axis），也就是维度（dimensions）。比如说，二维数组相当于是两个一维数组，其中第一个一维数组中每个元素又是一个一维数组。所以一维数组就是 NumPy 中的轴（axis），第一个轴相当于是底层数组，第二个轴是底层数组里的数组。而轴的数量——秩，就是数组的维数。很多时候可以声明 axis。axis=0，表示沿着第 0 轴进行操作（沿着行移动），即对每一列进行操作；axis=1，表示沿着第1轴进行操作（沿着列移动），即对每一行进行操作。4.3. 创建数组  numpy.zeros 创建指定大小数组，数组元素以 0 来填充：&gt;&gt;&gt; import numpy as np &gt;&gt;&gt; x = np.zeros(5) &gt;&gt;&gt; print (x)[0. 0. 0. 0. 0.]&gt;&gt;&gt; y = np.zeros((5,), dtype = np.int) &gt;&gt;&gt; print (y)[0 0 0 0 0]  numpy.ones 创建指定形状的数组，数组元素以 1 来填充：&gt;&gt;&gt; import numpy as np [0. 0. 0. 0. 0.]&gt;&gt;&gt; x = np.ones(5)[1. 1. 1. 1. 1.]&gt;&gt;&gt; print (x)&gt;&gt;&gt; y = np.ones((2,2), dtype = np.int) &gt;&gt;&gt; print (y)[[1 1] [1 1]]  numpy.arange 创建数值范围并返回 ndarray 对象，函数格式如下：numpy.arange(start, stop, step, dtype)生成数组示例如下：&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; x = np.arange(5) # = np.arrange(0,1,5)&gt;&gt;&gt; print (x)[0  1  2  3  4]&gt;&gt;&gt; x = np.arange(5, dtype =  float)&gt;&gt;&gt; print (x)[0.  1.  2.  3.  4.]&gt;&gt;&gt; x = np.arange(10,20,2)  &gt;&gt;&gt; print (x)[10  12  14  16  18]&gt;&gt;&gt; x = np.arange(0,1,0.1)&gt;&gt;&gt; print (x)[ 0.  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9]  numpy.reshape 在不改变数据内容的情况下，改变一个数组的格式，参数及返回值：&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; x = np.arange(6)&gt;&gt;&gt; print (x)[0  1  2  3  4  5]&gt;&gt;&gt; y = x.reshape((2,3))&gt;&gt;&gt; print (y)[[0 1 2] [3 4 5]]&gt;&gt;&gt; z = x.reshape(-1,2)&gt;&gt;&gt; print (z)[[0 1] [2 3] [4 5]]通过 reshape 生成的新数组和原始数组共用一个内存，也就是改变了原数组的元素，新数组的相应元素也将发生改变。-1 表示要根据另一个维度自动计算当前维度。reshape(-1,2) 即我们想要2列而不知道行数有多少，让numpy自动计算。  numpy.linspace 创建一个一维数组，数组是一个等差数列构成的，格式如下：np.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)参数说明：            参数      描述                  start      序列的起始值              stop      序列的终止值，如果 endpoint 为 true，该值包含于数列中              num      要生成的等步长的样本数量，默认为 50              endpoint      该值为 true 时，数列中包含 stop 值，反之不包含，默认是 true。              retstep      如果为 true 时，生成的数组中会显示间距，反之不显示。              dtype      ndarray 的数据类型      示例：&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; a = np.linspace(1,10,10)&gt;&gt;&gt; print(a)[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]4.4. 数组拼接两个拼接数组的方法：np.vstack() 在竖直方向上堆叠np.hstack() 在水平方向上平铺&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; arr1=np.array([1,2,3])&gt;&gt;&gt; arr2=np.array([4,5,6])&gt;&gt;&gt; print np.vstack((arr1,arr2))[[1 2 3] [4 5 6]]&gt;&gt;&gt; print np.hstack((arr1,arr2,arr1))[1 2 3 4 5 6 1 2 3]&gt;&gt;&gt; a1=np.array([[1,2],[3,4],[5,6]])&gt;&gt;&gt; a2=np.array([[7,8],[9,10],[11,12]])&gt;&gt;&gt; print np.hstack((a1,a2))[[ 1  2  7  8] [ 3  4  9 10] [ 5  6 11 12]]4.5. list和array的区别&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; a=np.array([1,2,3,4,55,6,7,77,8,9,99]) # transfer a list to an array&gt;&gt;&gt; b=np.array_split(a,3) # split the array into 3 parts&gt;&gt;&gt; print (b) # a list containing 3 arrays[array([1, 2, 3, 4]), array([55,  6,  7, 77]), array([ 8,  9, 99])]&gt;&gt;&gt; print (b[0:2]+b[1:3]) # a list containing 4 arrays[array([1, 2, 3, 4]), array([55,  6,  7, 77]), array([55,  6,  7, 77]), array([ 8,  9, 99])]&gt;&gt;&gt; c = np.hstack((brr1_folds[:2]+brr1_folds[1:3]))&gt;&gt;&gt; print (c) # list[ 1  2  3  4 55  6  7 77 55  6  7 77  8  9 99]5. dict字典是另一种可变容器模型，且可存储任意类型对象。字典的每个键值 key=&gt;value 对用冒号 : 分割，每个键值对之间用逗号 , 分割，整个字典包括在花括号 {} 中 ,格式如下所示：d = {key1 : value1, key2 : value2 }5.1. 定义，更新和添加&gt;&gt;&gt; dict = {'Name': 'Zara', 'Age': 7, 'Class': 'First'}&gt;&gt;&gt; dict['Age'] = 8 # 更新&gt;&gt;&gt; dict['School'] = \"RUNOOB\" # 添加&gt;&gt;&gt; print \"dict['Age']: \", dict['Age']&gt;&gt;&gt; print \"dict['School']: \", dict['School']    dict['Age']:  8    dict['School']:  RUNOOB&gt;&gt;&gt; del dict['Name']  # 删除键是'Name'的条目&gt;&gt;&gt; dict.clear()      # 清空字典所有条目&gt;&gt;&gt; del dict          # 删除字典5.2. 内置函数cmp(dict1, dict2) # 比较两个字典元素len(dict) # 计算字典元素个数，即键的总数str(dict) # 输出字典可打印的字符串表示type(dict) # 返回输入的变量类型（字典类型）5.3. 内置方法dict.clear() # 删除字典内所有元素dict.copy() # 返回一个字典的浅复制dict.fromkeys(seq[, val]) # 创建一个新字典，以序列 seq 中元素做字典的键，val 为字典所有键对应的初始值dict.get(key, default=None) # 返回指定键的值，如果值不在字典中返回default值dict.has_key(key) # 如果键在字典dict里返回true，否则返回falsedict.items() # 以列表返回可遍历的(键, 值) 元组数组dict.keys() # 以列表返回一个字典所有的键dict.setdefault(key, default=None) # 和get()类似, 但如果键不存在于字典中，将会添加键并将值设为defaultdict.update(dict2) # 把字典dict2的键/值对更新到dict里dict.values() # 以列表返回字典中的所有值pop(key[,default]) # 删除字典给定键 key 所对应的值，返回值为被删除的值。key值必须给出。 否则，返回default值。popitem() # 返回并删除字典中的最后一对键和值。字典值可以没有限制地取任何python对象，既可以是标准的对象，也可以是用户定义的，但键不行。5.4. 特性两个重要的点需要记住：  不允许同一个键出现两次。创建时如果同一个键被赋值两次，后一个值会被记住；  键必须不可变，所以可以用数字，字符串或元组充当，所以用列表就不行。5.5. OrderedDict有序字典，可以按字典中元素的插入顺序来输出。有序字典的作用只是记住元素插入顺序并按顺序输出。如果有序字典中的元素一开始就定义好了，后面没有插入元素这一动作，那么遍历有序字典，其输出结果仍然是无序的，因为缺少了有序插入这一条件，所以此时有序字典就失去了作用，所以有序字典一般用于动态添加并需要按添加顺序输出的时候。OrderedDict 使用前必须引入包 collections。下面是插入元素的操作import collectionsmy_order_dict = collections.OrderedDict()my_order_dict[\"name\"] = \"lowman\"my_order_dict[\"age\"] = 45my_order_dict[\"money\"] = 998my_order_dict[\"hourse\"] = Nonefor key, value in my_order_dict.items():    print(key, value)输出name lowmanage 45money 998hourse None而如果在定义有序字典时初始化了初始值，并没有按序添加的操作，那么遍历时仍然是无序的。如import collectionsmy_order_dict = collections.OrderedDict(name=\"lowman\", age=45, money=998, hourse=None)for key, value in my_order_dict.items():    print(key, value)输出hourse Noneage 45money 998name lowman6. 参考文献[1] CDA数据分析师. Python基础知识详解(三)：数据结构篇.[2] RUNOOB.COM. NumPy 从数值范围创建数组."
  },
  
  {
    "title": "Python基础（lambda,np.random）",
    "url": "/posts/python-basic-np-fcns/",
    "categories": "Tutorial, Coding",
    "tags": "python",
    "date": "2020-08-12 19:06:19 +0800",
    





    
    "snippet": "本文主要针对Python中lamdbda的介绍，和numpy中seed、choice、uniform等的介绍。  1. lambda  2. np.random          2.1. .seed()      2.2. .RandomState()      2.3. .choice()      2.4. .uniform()      2.5. .permutation()    ...",
    "content": "本文主要针对Python中lamdbda的介绍，和numpy中seed、choice、uniform等的介绍。  1. lambda  2. np.random          2.1. .seed()      2.2. .RandomState()      2.3. .choice()      2.4. .uniform()      2.5. .permutation()        3. range()  4. 参考文献1. lambda除了 def 语句，python还提供了一种生成函数对象的表达式形式。由于它与LISP语言中的一个工具类似，所以称为lambda。就像 def 一样，这个表达式创建了一个之后能够调用的函数，但是它返回一个函数而不是将这个函数赋值给一个变量。这些就是 lambda 叫做匿名函数的原因。实际上，他常常以一种行内进行函数定义的方式使用，或者用作推迟执行一些代码。lambda 的一般形式是关键字 lambda 之后跟着一个或多个参数（与一个 def 头部内用括号括起来的参数列表类似），紧跟着是一个冒号，之后是表达式lambda arg1,arg2,argn: expression using arguments由 lambda 表达式所返回的函数对象与由def创建并复制后的函数对象工作起来是完全一致的，但 lambda 有一些不同之处，让其扮演特定的角色时更有用：lambda是一个表达式，而不是一个语句因为这一点，lambda 可以出现在python语法不允许 def 出现的地方。此外，作为一个表达式，lambda 返回一个值（一个新的函数），可以选择性的赋值给一个变量。相反，def 语句总是得在头部将一个新的函数赋值给一个变量，而不是将这个函数作为结果返回。lambda的主题是单个表达式，而不是一个代码块这个 lambda 的主题简单的就好像放在 def 主体 return 语句中的代码一样。简单的将结果写成一个顺畅的表达式，而不是明确的返回。但由于它仅限于表达式，故 lambda 通常要比 def 功能少…你仅能够在 lambda 主体中封装有限的逻辑进去，因为他是一个为编写简单函数而设计的。除了上述这些差别，def 和 lambda 都能过做同样种类的工作。def与lambda的相同用法x = lambda x, y, z: x + y + zx(2, 3, 4)&gt;&gt;&gt; 9y = (lambda a='hello', b='world': a + b)y(b='Python')&gt;&gt;&gt; 'hellopython'为什么使用lambda通常来说，lambda起到一种函数的速写作用，允许在使用的代码内嵌一个函数的定义，他完全是可选的（是可以使用 def 代替他们），但是在你仅需要切入一段可执行代码的情况下，它会带来一个更简洁的书写效果。lambda 通常用来编写跳转表，也就是行为的列表或者字典，能够按照需求执行操作，比如以下（**表示乘方）：l = [lambda x: x ** 2, lambda x: x ** 3]for f in l:    print(f(2))&gt;&gt;&gt; 4&gt;&gt;&gt; 8print(l[0](3))&gt;&gt;&gt; 9实际上，我们可以用python中的字典或者其他的数据结构来构建更多种类的行为表，从而做同样的事情。map 函数程序对列表或者其他序列常常要做的一件事就是对每个元素进行一个操作，并把其结果集合起来。python提供了一个工具map，它会对一个序列对象中的每一个元素应用该的函数，并返回一个包含了所有函数调用结果的列表。举个栗子，我们有一个列表，需要将列表的每一个字段+10，我们该如何操作？list_show = [1, 2, 3, 4]# 方式1new_list_show = []for i in list_show:    new_list_show.append(i + 10)print(new_list_show)# 方式2def adds(x):    return x + 10print(list(map(adds, list_show)))# 更优雅的方式3：print(list(map(lambda x: x + 10, list_show)))filter函数filter 通过字面意思，大家就知道它的用处了，用于数据的过滤操作，它也是 lambda 的一个好基友，举个栗子。我们需要过滤0-9中，能被2整除的数字组成一个列表，我们该如何操作？只需要一行代码：print(list(filter(lambda x: x % 2 == 0,range(10))))&gt;&gt;&gt; [0, 2, 4, 6, 8]2. np.random2.1. .seed()numpy.random.seed() ：设置 seed() 里的数字就相当于设置了一个盛有随机数的“聚宝盆”，一个数字代表一个“聚宝盆”，当我们在 seed() 的括号里设置相同的seed，“聚宝盆”就是一样的，那当然每次拿出的随机数就会相同（不要觉得就是从里面随机取数字，只要设置的seed相同取出地随机数就一样）。如果不设置seed，则每次会生成不同的随机数。（注：seed括号里的数值基本可以随便设置哦）。下面给个例子，表明每次rand之前都要设置一次seed，只要设置的seed相同，那么产生的随机数就相同。&gt;&gt;&gt; np.random.seed(0)&gt;&gt;&gt; np.random.rand(4,3)array([[0.5488135 , 0.71518937, 0.60276338],       [0.54488318, 0.4236548 , 0.64589411],       [0.43758721, 0.891773  , 0.96366276],       [0.38344152, 0.79172504, 0.52889492]])&gt;&gt;&gt; np.random.seed(0)&gt;&gt;&gt; np.random.rand(4,3)array([[0.5488135 , 0.71518937, 0.60276338],       [0.54488318, 0.4236548 , 0.64589411],       [0.43758721, 0.891773  , 0.96366276],       [0.38344152, 0.79172504, 0.52889492]])给随机生成器设置seed的目的是每次运行程序得到的随机数的值相同，这样方便测试。但是 numpy.random.seed() 不是线程安全的，如果程序中有多个线程最好使用 numpy.random.RandomState 实例对象来创建或者使用random.seed() 来设置相同的随机数种子。2.2. .RandomState()numpy.random.RandomState() 是一个伪随机数生成器。那么伪随机数是什么呢？伪随机数是用确定性的算法计算出来的似来自[0,1]均匀分布的随机数序列。并不真正的随机，但具有类似于随机数的统计特征，如均匀性、独立性等。下面我们来看看它的用法：&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; rng = np.random.RandomState(0)&gt;&gt;&gt; rng.rand(4)array([0.5488135 , 0.71518937, 0.60276338, 0.54488318])&gt;&gt;&gt; rng = np.random.RandomState(0)&gt;&gt;&gt; rng.rand(4)array([0.5488135 , 0.71518937, 0.60276338, 0.54488318])看，是不是生成了一样的随机数组呢，这点和numpy.random.seed（）还是很一样的。因为是伪随机数，所以必须在rng这个变量下使用，如果不这样做，那么就得不到相同的随机数组了，即便你再次输入了numpy.random.RandomState()：np.random.RandomState(0)Out[397]: &lt;mtrand.RandomState at 0xddaa288&gt;np.random.rand(4)Out[398]: array([0.62395295, 0.1156184 , 0.31728548, 0.41482621])np.random.RandomState(0)Out[399]: &lt;mtrand.RandomState at 0xddaac38&gt;np.random.rand(4)Out[400]: array([0.86630916, 0.25045537, 0.48303426, 0.98555979])2.3. .choice()choice() 方法返回一个列表，元组或字符串的随机项。注意：choice()是不能直接访问的，需要导入 random 模块，然后通过 random 静态对象调用该方法。&gt;&gt;&gt; import random&gt;&gt;&gt; print \"choice([1, 2, 3, 5, 9]) : \", random.choice([1, 2, 3, 5, 9])choice([1, 2, 3, 5, 9]) :  2&gt;&gt;&gt; print \"choice('A String') : \", random.choice('A String')choice('A String') :  n给定size参数后，可以生成指定size的随机数，如果需要每一次产生的随机数相同，则需要设置随机数种子，random.seed(int) 或者 random.RandomState(int)。import numpy as npseed = 0rng = np.random.RandomState(seed)rng.choice(50, 10)numpy.random.choice(a, size=None, replace=True, p=None)  a : 如果是一维数组，就表示从这个一维数组中随机采样；如果是int型，就表示从0到a-1这个序列中随机采样。  size : 采样结果的数量，默认为1.可以是整数，表示要采样的数量；也可以为tuple，如(m, n, k)，则要采样的数量为m * n * k，size为(m, n, k)。  replace : boolean型，采样的样本是否要更换？这个地方我不太理解，测了一下发现replace指定为True时，采样的元素会有重复；当replace指定为False时，采样不会重复。  p : 一个一维数组，制定了a中每个元素采样的概率，若为默认的None，则a中每个元素被采样的概率相同。2.4. .uniform()uniform() 方法将随机生成下一个实数（浮点数），它在 [x, y] 范围内。注意：uniform()是不能直接访问的，需要导入 random 模块，然后通过 random 静态对象调用该方法。import randomrandom.uniform(x, y)其中x和y是随机数的取值界限，且不包含本身。2.5. .permutation()随机排列一个序列，返回一个排列的序列。&gt;&gt;&gt; np.random.permutation(10)array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6])&gt;&gt;&gt; np.random.permutation([1, 4, 9, 12, 15])array([15,  1,  9,  4, 12])与 random.shuffle(x) 的区别在于，shuffle直接改变原始数组x，而permutation不改变原数组，而是赋值给新数组。如果x是int型，，则返回从0到x-1这个序列的随机顺序。3. range()函数语法：range(start, stop[, step])参数说明：  start: 计数从 start 开始。默认是从 0 开始。例如range（5）等价于range（0， 5）;  stop: 计数到 stop 结束，但不包括 stop。例如：range（0， 5） 是[0, 1, 2, 3, 4]没有5；  step：步长，默认为1。例如：range（0， 5） 等价于 range(0, 5, 1)。4. 参考文献无。"
  },
  
  {
    "title": "Windows10通过应用商店安装Ubuntu",
    "url": "/posts/Ubuntu-In-Windows-10/",
    "categories": "Tutorial, Coding",
    "tags": "linux",
    "date": "2020-07-26 10:55:19 +0800",
    





    
    "snippet": "本文主要介绍 Windows10 下部署 Ubuntu 的一种方法——借助 Microsoft Store 部署。由于科研需要，一些程序和数据需要在 linux 环境下进行操作，在不安装双系统和部署虚拟机的前提下，尝试本方法进行 Ubuntu 的安装。  1. 环境配置  2. 下载和安装  3. 注意事项  4. 基本操作          4.1. 备份、删除和还原      4.2. ...",
    "content": "本文主要介绍 Windows10 下部署 Ubuntu 的一种方法——借助 Microsoft Store 部署。由于科研需要，一些程序和数据需要在 linux 环境下进行操作，在不安装双系统和部署虚拟机的前提下，尝试本方法进行 Ubuntu 的安装。  1. 环境配置  2. 下载和安装  3. 注意事项  4. 基本操作          4.1. 备份、删除和还原      4.2. 切换数据源      4.3. Windows访问Linux文件      4.4. Linux访问Windows文件      4.5. 解压tar文件        5. 参考文献1. 环境配置首先，启用开发者模式：菜单栏打开设置——点击更新和安全——启用开发人员模式（时间会有点长）其次，更改系统功能：必须先启用“适用于 Linux 的 Windows 子系统”可选功能，然后才能在 Windows 上安装 Linux 分发版。以管理员身份打开 PowerShell 并运行dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart或者通过控制面板进行界面配置（需要重启）2. 下载和安装打开 Microsoft Store，并选择你偏好的 Linux 分发版。选择好版本后，选择「获取」，然后点击「安装」。如果多次点击并无反应，可以等待一定时间后返回到Microsoft Store首页，再次前往该分发版的 Linux 应用页面，该应用可能已经在后台安装完毕。点击「启动」，将打开一个控制台窗口，系统会要求你等待一分钟或两分钟，以便文件解压缩并存储到电脑上。 未来的所有启动时间应不到一秒。然后，需要为新的 Linux 分发版创建用户帐户和密码。（注意，linux 系统中，输入密码时默认时不显示任何内容的）提示 Installation successful! 表明系统安装完毕。通过 Windows Store 安装的 Linux 子系统，其存放路径位于C:\\Users\\[YourUserName]\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu20.04onWindows_79rhkp1fndgsc\\LocalState\\rootfs其中 [YourUserName] 是个人的电脑用户名，CanonicalGroupLimited.XXX 是相应的子系统版本。通过上述路径可以方便的进行文件管理。3. 注意事项  WslRegisterDistribution 失败并出现错误 0x8007019e          未启用“适用于 Linux 的 Windows 子系统”可选组件：      打开“控制面板” -&gt; “程序和功能” -&gt; “打开或关闭 Windows 功能”-&gt; 选中“适用于 Linux 的 Windows 子系统”，或使用本文开头所述的 PowerShell cmdlet。        安装失败，出现错误 0x80070003 或错误 0x80370102          请确保在计算机的 BIOS 内已启用虚拟化。 有关如何执行此操作的说明因计算机而异，并且很可能在 CPU 相关选项下。        尝试升级时出错：Invalid command line option: wsl --set-version Ubuntu 2          请确保已启用适用于 Linux 的 Windows 子系统，并且你使用的是 Windows 内部版本 19041 或更高版本。 若要启用 WSL，请在 PowerShell 提示符下以具有管理员权限的身份运行此命令：Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux。 可在此处找到完整的 WSL 安装说明。        由于虚拟磁盘系统的某个限制，无法完成所请求的操作。虚拟硬盘文件必须是解压缩的且未加密的，并且不能是稀疏的。          请检查 WSL GitHub 主题 #4103，其中跟踪了此问题以提供更新的信息。        无法将词语“wsl”识别为 cmdlet、函数、脚本文件或可运行程序的名称。          请确保已安装“适用于 Linux 的 Windows 子系统”可选组件。 此外，如果你使用的是 ARM64 设备，并从 PowerShell 运行此命令，则会收到此错误。 请改为从 PowerShell Core 或从命令提示符运行 wsl.exe。      4. 基本操作对 linux 子系统的操作可基于 windows subsystem for linux (wsl) 来进行。Windows键+R，输入 cmd 回车，打开命令行窗口。输入wsl -l,可以看到我系统里装的 linux 系统发行版本。输入wsl --version 可以看到版本信息和命令行参数一览。4.1. 备份、删除和还原备份子系统非常简单，但一定要先停止子系统之后再备份wsl --export Ubuntu-20.04 c:\\XXX\\Ubuntu-18.04-20200726.tar待完成即可。备份成功后，子系统会被打包成命令中指定名称的tar文件。删除子系统也是一个命令即可：wsl --unregister Ubuntu-12.04还原子系统。 删除了没关系，刚才做了备份，也是一个命令还原：wsl --import Ubuntu-20.04 c:\\AAA c:\\XXX\\Ubuntu-20.04-20200726.tar这里注意指定还原的路径。成功后，子系统又回来了，可以用wsl -l确认一下。4.2. 切换数据源在 Ubuntu 下我们可以通过 apt-get 命令 很方便的安装 / 卸载软件，切换数据源为国内的镜像站点速度会变快。编辑数据源配置文件vi /etc/apt/sources.list继续按enter键进入真正的vi编辑页面  科普：vi编辑器一共有三种模式： 命令模式（command mode） 插入模式（Insert mode） 底行模式（last line mode） 命令模式下我们只能控制屏幕光标的移动，字符、字或行的删除，移动复制某区段及进入Insert mode下，或者到 last line mode等；插入模式下可以做文字输入，按「ESC」键可回到命令行模式；底行模式下，可以将文件保存或退出vi，也可以设置编辑环境，如寻找字符串、列出行号等。当我们进入vi编辑器的时候默认是命令行模式，这时如果想编辑内容，就输入 i 命令就可以了。现在我们要把镜像源改为阿里的，所以插入如下内容：deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse接着按「ESC」退会命令行模式，输入命令：: wq!保存退出就好了。接着输入命令sudo apt-get update然后输入密码，回车，更新配置就可以了，飞速！如果命令行修改文件不习惯（linux下就是这样），可在windows下直接找到文件，用记事本打开后修改保存。文件路径在比如C:\\Users\\[YourUserName]\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu20.04onWindows_79rhkp1fndgsc\\LocalState\\rootfs\\etc\\apt4.3. Windows访问Linux文件通过Windows Store 安装的 Linux 子系统位于C:\\Users\\[YourUserName]\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu20.04onWindows_79rhkp1fndgsc\\LocalState\\rootfs也可以运行子系统后，输入explorer.exe .在资源管理器种打开相应的文件夹。4.4. Linux访问Windows文件在bash种输入以下命令，即为windows系统下cd /mnt接着就是不断的cd进入到你所需的目录下。比如我们进入系统后 dir 或者 ls 一下就可以看到目前 Windows 系统的三个盘符（因人而异）。cd 就可以逐级进入文件夹。4.5. 解压tar文件在 Linux 系统种，通过 tar 命令解压 tar 压缩包。5. 参考文献[1]  Microsoft. 适用于 Linux 的 Windows 子系统安装指南 (Windows 10)."
  },
  
  {
    "title": "元学习文章阅读（Prototypical Network）",
    "url": "/posts/MetaLearning-ProtoNet/",
    "categories": "Academic, Paper",
    "tags": "deep learning, meta learning",
    "date": "2020-07-22 14:35:19 +0800",
    





    
    "snippet": "Prototypical Network 又称为原型网络，是2017年 NIPS 会议论文提出的一种神经网络训练方法，是一种基于度量（Metrix-based）的小样本学习方法，通过计算 support set 中的嵌入中心，然后通过衡量新样本与这些中心的距离来完成分类。  1. Prototypical Network          1.1. 模型      1.2. 算法      ...",
    "content": "Prototypical Network 又称为原型网络，是2017年 NIPS 会议论文提出的一种神经网络训练方法，是一种基于度量（Metrix-based）的小样本学习方法，通过计算 support set 中的嵌入中心，然后通过衡量新样本与这些中心的距离来完成分类。  1. Prototypical Network          1.1. 模型      1.2. 算法      1.3. 进行混合密度估计      1.4. 距离度量        2. 参考文献1. Prototypical Network2017.《Prototypical Networks for Few-shot Learning》本文是2017年NIPS的会议论文，作者来自多伦多大学以及Twitter公司。在论文中作者提出了一种新的基于度量（Metric-based）的少样本学习模型——原型网络（Prototypical Networks）。原型网络首先利用 support  set 中每个类别提供的少量样本，计算它们的嵌入的中心，作为每一类样本的原型（Prototype），接着基于这些原型学习一个度量空间，使得新的样本通过计算自身嵌入与这些原型的距离实现最终的分类，思想与聚类算法十分接近，但出发点有着很大的差异。除此之外，作者在文章中还尝试将原型网络应用于零样本学习（Zero-shot learning）问题上，通过数据集携带的属性向量形成元数据（meta-data），基于这些元数据构建原型，从而实现零样本分类。原型网络在少样本分类与零样本分类任务上的示意图如下所示。1.1. 模型在 few-shot 分类任务中，假设有 $N$ 个标记的样本 $S={(x_1,y_1),…,(x_N,y_N)}$ ，其中 $x_i \\in \\mathbb R^D$ 是 $D$ 维的样本特征向量，$y \\in {1,…,K}$ 是相应的 label 。$S_K$ 表示第 $k$ 类样本的集合。原型网络计算每个类的 $M$ 维原型向量 $c_k \\in \\mathbb R^M$ ，计算的函数为 $f_{\\phi}: \\mathbb R^D \\rightarrow \\mathbb R^M$ ，其中 $\\phi$ 为可学习参数。原型向量 $c_k$ 即为 embedding space 中该类的所有 support set 样本点的均值向量\\[c_k = \\frac{1}{|S_K|} \\sum_{(x_i,y_i) \\in S_K} f_{\\phi}(x_i)\\]给定一个距离函数 $d: \\mathbb R^M \\times \\mathbb R^M \\rightarrow [0,+\\infty)$ ，原型网络通过在 embedding space 中对距离进行 softmax 计算，可以得到一个针对 $x$ 的样本点的概率分布\\[p_{\\phi}(y=k|x)=\\frac{exp(-d(f_{\\phi},c_k))}{\\sum_{k'}exp(-d(f_{\\phi}(x),c_{k'}))}\\]通过在 SGD 中最小化第 $k$ 类的负对数似然函数 $J(\\phi)$ 来推进学习\\[J(\\phi) = -log\\; p(\\phi)(y=k|x)\\]1.2. 算法其中  $N$ 是训练集中的样本个数；  $K$ 是训练集中的类个数；  $N_C \\leq K$ 是每个 episode 选出的类个数；  $N_S$ 是每类中 support set 的样本个数；  $N_Q$ 是每类中 query set 的样本个数；  $RANDOMSAMPLE(S,N)$ 表示从集合 S 中随机选出 N 个元素。下面详细分析算法。首先，算法输入训练集 $D={(x_1,y_1),…,(x_N,y_N)}$，其中 $y_i$ 是标签，$D_k$ 则是标签 $y_i=k$ 的子训练集。算法输出损失函数 $J$。在每个 episode 中：第一步，从训练集中的 $K$ 个类中随机选取 $N_C$ 个类，形成子集 $V$；第二步，对于 $V$ 中的每个类 $k$，相应的训练集为 $D_{Vk}$  随机选取 $D_{Vk}$ 中 $N_S$ 个样本作为 $S_k$ (support set)  剩余样本作为 $S_q$ (query set)  计算该类（第 $k$ 个类）的原型向量 $c_k$，公式如下\\[c_k = \\frac{1}{N_S} \\sum_{(x_i,y_i) \\in S_K} f_{\\phi}(x_i)\\]注意，此处公式与原文不同，原文分母为 $N_C$ ，强烈怀疑写错了，因为本步中对单一类别的所有 support set 计算原型向量，应该通过除以support set 中的样本个数 $N_S$ 而不是类个数 $N_C$ 来计算均值。第二步完成后，可以得到每个类的原型向量。下面开始更新损失函数。首先将损失函数 $J$ 初始化为0，然后进入两个 for 循环，对于每一个类别 $k$ 中的每一个 query set 中的每一个样本，采用下式更新 $J$\\[J\\leftarrow J+\\frac{1}{N_C N_Q}[d(f_\\phi(x),c_k)+log\\sum_{k'} exp(-d(f_\\phi(x),c_{k'}))]\\]为便于理解，对于第 $k$ 类的第 $i$ 个样本，不妨假损失函数更新方向为\\[^kA_i = d(f_\\phi(x_i),c_k)+log\\sum_{i=1}^{N_Q} exp(-d(f_\\phi(x_i),c_{i}))\\]则对于所有类别的所有 query set 的所有样本，最终 $J$ 的更新为以下形式\\[J\\leftarrow J+\\frac{1}{N_C N_Q}({}^1A_1+{}^1A_2+...+{}^{N_C}A_{N_Q})\\]可以看出，括号内总共有 $N_C N_Q$ 项，因此分母除以该值以求均值。1.3. 进行混合密度估计对于特定的距离函数，如 Bregman 散度，原型网络算法相当于对具有指数族密度的支持集进行混合密度估计。原型计算可以用支持集上的硬聚类来表示，每个类有一个簇，每个支持点都被分配给相应的类簇。  the prototypical networks algorithm is equivalent to performing mixture density estimation on the support set with an exponential family density. Prototype computation can be viewed in terms of hard clustering on the support set, with one cluster per class and each support point assigned to its corresponding class cluster.如何理解Bregman divergence？已被证明，对于 Bregman 散度，聚类的均值就是到各类特征的距离的极小值。也就是说，如果采用某个 Bregman 散度距离函数，原型计算 $c_k$ 等价于 support set 中样本标签的最优聚类表示。任何正则指数分布都可以写为一个确定的正则 Bregman 散度。假设该正则指数分布为 $p_\\psi(z\\mid\\theta)$ ，参数为 $\\theta$，累积函数为 $\\psi$，则有\\[p_\\psi(z\\mid\\theta) = exp\\{z^T\\theta-\\psi (\\theta) - g_\\psi(z)\\} = exp\\{-d_\\psi(z,\\mu(\\theta)) - g_\\psi(z)\\}\\]算了算了后面看不懂了。。。1.4. 距离度量作者进行了进一步的分析，以确定距离度量和每Episode中训练classes的数量对原型网络和匹配网络的影响。为了使这些方法更具有可比性，我们使用我们自己的匹配网络实现，它使用与我们的原型网络相同的嵌入架构。在下图中，我们比较了余弦距离与欧式距离，5-way和20-way  training episodes。在1-shot和5-shot场景中，每个Episode每个类中有15个查询点。注意到20-way比5-way获得了更高的准确率，并且推测20-way分类难度的增加有助于网络更好的泛化，因为它迫使模型在嵌入空间中做出更细粒度的决策。此外，使用欧氏距离比预先距离大大提高了性能。这种效果对于原型网络更为明显，在这种网络中，将类原型作为嵌入支持点的平均值进行计算更适合于欧氏距离，因为余弦距离不是Bregman散度。2. 参考文献[1]  Smiler_. 《Prototypical Networks for Few-shot Learning 》论文翻译."
  },
  
  {
    "title": "元学习文章阅读（Reptile）",
    "url": "/posts/meta-learning-Reptile/",
    "categories": "Academic, Paper",
    "tags": "deep learning, meta learning",
    "date": "2020-07-14 14:35:19 +0800",
    





    
    "snippet": "Reptile 于2018年由 OpenAI 提出，是一种非常简单而有效的基于优化的（Optimized-based）小样本学习方法，通过多步梯度下降来学习一个较优的模型初始参数。  1. Reptile          1.1. 算法      1.2. 数学分析      1.3. 梯度的泰勒展开的领头阶      1.4. 另一种推导方式      1.5. 梯度的泰勒展开的领头阶（...",
    "content": "Reptile 于2018年由 OpenAI 提出，是一种非常简单而有效的基于优化的（Optimized-based）小样本学习方法，通过多步梯度下降来学习一个较优的模型初始参数。  1. Reptile          1.1. 算法      1.2. 数学分析      1.3. 梯度的泰勒展开的领头阶      1.4. 另一种推导方式      1.5. 梯度的泰勒展开的领头阶（继续）      1.6. 另一种不严谨的分析      1.7. 实验        2. 比较  3. 算法实现  4. reptile回归sin函数  5. 参考文献1. Reptile2018.《On First-Order Meta-Learning Algorithms》和《Reptile: a Scalable Metalearning Algorithm》Reptile是OpenAI提出的一种非常简单的meta learning 算法。与MAML类似，也是学习网络参数的初始值。1.1. 算法算法伪代码如下其中，$\\phi$ 是模型的初始参数，$\\tau$ 是某个 task，$U_\\tau^k(\\phi)$ 表示从 $\\phi$ 开始对损失函数进行 $k$ 次随机梯度下降，返回更新后的参数 $\\widetilde{\\phi}$。在最后一步中，通过 $\\widetilde{\\phi}-\\phi$ 这种残差形式来更新一次初始参数。如果 $k=1$，该算法等价于「联合训练」（joint training，通过训练来最小化在一系列训练任务上期望损失）。Reptile 要求 $k&gt;1$，更新依赖于损失函数的高阶导数，此时 Reptile 的行为与 $k=1$（联合训练）时截然不同。Reptile 与 MAML 和 FOMAML 紧密相关，但是也存在不同      Reptile 无需对每一个任务进行训练-测试（training-testing）划分。        相比 MAML 需要进行二重梯度计算，Reptile 只需要进行一重梯度计算，计算速度更快。  Reptile 的图例如下。1.2. 数学分析基于优化的元学习问题（Optimization-based Meta-Learning）的目标：找寻一组模型初始参数 $\\boldsymbol \\phi$，使得模型在面对随机选取的新任务 $\\tau \\sim \\mathcal T$ 时，经过 $k$ 次梯度更新，在 $\\tau$ 上的损失函数就能达到很小。用数学语言描述，即\\[\\mathop{minimize}_{\\phi} \\; \\mathbb E_{\\tau}[L_{\\tau}(^{k}_\\tau\\boldsymbol \\phi)]= \\mathop{minimize}_{\\phi} \\; \\mathbb E_{\\tau}[L_{\\tau}(U^k_\\tau(\\boldsymbol \\phi))]\\]其中\\[\\widetilde{\\boldsymbol\\phi} = {}^{k}_\\tau \\boldsymbol \\phi=U^k_\\tau(\\boldsymbol \\phi)\\]是在任务 $\\tau$ 上经过 $k$ 次更新后的模型参数。Reptile 算法中将 $(\\boldsymbol \\phi - \\widetilde{\\boldsymbol\\phi}) / \\alpha$ 看作梯度，其中 $\\alpha$ 为 SGD 中的学习率，即\\[g_{Reptile} = (\\boldsymbol \\phi - \\widetilde{\\boldsymbol\\phi}) / \\alpha\\]注意到，SGD 随机梯度下降的核心是，梯度是期望，期望可使用小规模的样本近似估计。对于采用 SGD 的传统监督学习，模型参数更新方式为\\[\\phi = \\widetilde \\phi = \\phi - \\beta \\cdot \\mathbb E[\\nabla^kL_\\tau] =? \\phi - \\beta \\cdot \\nabla^k\\mathbb E[L_\\tau]\\]问题1：梯度和期望能否交换顺序？传统监督学习的参数更新可简写为 $SGD(\\mathbb E[L_\\tau],\\theta,k)$。采用 SGD 的 Reptile 的模型参数更新方式为：\\[\\phi = \\phi + \\beta\\cdot \\mathbb E[\\widetilde\\phi-\\phi]/\\alpha\\]又因为 $\\widetilde \\phi = SGD(L_\\tau,\\theta,k)$，那么相应的参数更新可简写为 $\\mathbb E[ SGD(L_\\tau,\\theta,k)]$。问题2：$SGD(\\mathbb E[L_\\tau],\\theta,k)$ 与 $\\mathbb E[ SGD(L_\\tau,\\theta,k)]$ 有什么关系？下面需要按照 $k$ 的取值分情况讨论。  如果 $k=1$，那么有\\[\\begin{aligned}g_{Reptile,k=1} &amp;= \\mathbb E_\\tau [(\\boldsymbol \\phi - \\widetilde{\\boldsymbol\\phi}) / \\alpha]\\\\&amp;= \\mathbb E_\\tau [(\\boldsymbol \\phi - U_\\tau(\\boldsymbol \\phi)) / \\alpha]\\\\&amp;= \\mathbb E_\\tau [\\boldsymbol \\phi - U_\\tau(\\boldsymbol \\phi)] / \\alpha\\\\&amp;= \\boldsymbol \\phi / \\alpha - \\mathbb E_\\tau [U_\\tau(\\boldsymbol \\phi)] / \\alpha \\quad where \\; \\alpha,\\phi=const \\\\\\end{aligned}\\]又知道，$U_\\tau(\\boldsymbol\\phi)$ 是计算 $k=1$ 次的梯度算子（省略 $k$）\\[U_\\tau(\\boldsymbol\\phi) = \\boldsymbol \\phi - \\alpha \\nabla_{\\boldsymbol\\phi} L_\\tau(\\boldsymbol\\phi)\\]则\\[\\begin{aligned}\\mathbb E_\\tau [U_\\tau(\\boldsymbol \\phi)] &amp;= \\mathbb E_\\tau[\\boldsymbol \\phi - \\alpha \\nabla_{\\boldsymbol\\phi} L_\\tau(\\boldsymbol\\phi)]\\\\&amp;= \\boldsymbol\\phi - \\alpha \\cdot \\mathbb E_\\tau [\\nabla_{\\boldsymbol\\phi} L_\\tau(\\boldsymbol \\phi)]\\end{aligned}\\]带入上式计算 $g_{Reptile,k=1}$，有\\[g_{Reptile,k=1} = \\mathbb E_\\tau[\\nabla_{\\boldsymbol\\phi} L_\\tau(\\boldsymbol\\phi)]\\]因此有\\[g_{Reptile,k=1} = \\mathbb E_\\tau [(\\boldsymbol \\phi - \\widetilde{\\boldsymbol\\phi}) / \\alpha] = \\mathbb E_\\tau[\\nabla_{\\boldsymbol\\phi} L_\\tau(\\boldsymbol\\phi)]\\]另外，根据此处的讨论，以及后续两处讨论，当损失函数足够光滑和有界时，期望和梯度可以交换顺序  The first step is probably the nastiest (although not in the discrete case I guess), but we can interchange the gradient and expectation assuming L is sufficiently smooth and bounded (which it probably is). See here(1) and here(2).(1) When can we interchange the derivative with an expectation?(2) Expectation of gradients\\[\\mathbb E_{\\tau\\sim \\mathcal T}[\\nabla L_n(\\phi)]=\\nabla \\mathbb E_{\\tau\\sim \\mathcal T}[L_n(\\phi)]\\]那么\\[g_{Reptile,k=1} = \\mathbb E_\\tau [(\\boldsymbol \\phi - \\widetilde{\\boldsymbol\\phi}) / \\alpha] = \\mathbb E_\\tau[\\nabla_{\\boldsymbol\\phi} L_\\tau(\\boldsymbol\\phi)]= \\nabla_{\\boldsymbol\\phi} \\mathbb E_\\tau[L_\\tau(\\boldsymbol\\phi)]\\]即 $k=1$ 时，Reptile 和 在期望损失 $\\mathbb E_\\tau [L_\\tau]$ 上的联合训练 等价。  如果 $k&gt;1$，那么\\[g_{Reptile,k&gt;1} = \\boldsymbol\\phi / \\alpha - \\mathbb E_\\tau [U_{\\phi}^k(\\boldsymbol\\phi)]/\\alpha\\]而\\[U_{\\phi}^k(\\boldsymbol\\phi) = \\boldsymbol \\phi- \\alpha \\boldsymbol g_1- \\alpha \\boldsymbol g_2-...- \\alpha \\boldsymbol g_k\\]其中\\[\\begin{aligned}\\boldsymbol g_1 &amp; = \\nabla_{\\boldsymbol \\theta} L_\\tau(\\boldsymbol \\theta), \\quad {}^1\\boldsymbol \\theta = \\boldsymbol \\theta - \\alpha \\boldsymbol g_1\\\\\\boldsymbol g_2 &amp; = \\nabla_{ {}^1\\boldsymbol \\theta} L_\\tau({}^1\\boldsymbol \\theta)\\\\&amp;= \\nabla_{ {}^1\\boldsymbol \\theta} L_\\tau(\\boldsymbol \\theta - \\alpha \\boldsymbol g_1)\\\\&amp;= \\nabla_{ {}^1\\boldsymbol \\theta} L_\\tau(\\boldsymbol \\theta - \\alpha (\\nabla_{\\boldsymbol \\theta} L_\\tau(\\boldsymbol \\theta)))\\\\...&amp;...\\end{aligned}\\]$\\mathbb E_\\tau [U_{\\phi}^k(\\boldsymbol\\phi)]$ 中包含了高阶项信息，从而与 $\\nabla \\mathbb E[L_\\tau]$ 不再相关。此时 Reptile 收敛到的参数解与传统监督学习完全不同。1.3. 梯度的泰勒展开的领头阶那么，为什么Reptile就这么简单的多更新几步梯度（ k&gt;1 ）就能很好的进行元学习呢？作者通过泰勒展开的领头阶来分析。首先定义四个辅助变量，假设模型初始参数为 $\\phi_1$，$i\\in [1, k]$ 指代第 $i$ 次梯度下降的训练过程：\\[\\begin{aligned}g_i &amp;= L_i'(\\phi_i)\\;\\;(gradient \\; obtained\\; during\\;SGD)\\\\\\phi_{i+1} &amp;= \\phi_i-\\alpha g_i\\;\\;(sequence\\;of\\;parameters)\\\\\\overline{g}_i &amp;= L_i'(\\phi_1)\\;\\;(gradient\\;at\\;initial\\;point)\\\\\\overline{H}_i &amp;= L_i''(\\phi_1)\\;\\;(Hessian\\;at\\;initial\\;point)\\\\\\end{aligned}\\]然后将 $g_i$ 在原始参数 $\\phi_1$ 上泰勒展开至 “二阶导+高次项” 的形式\\[\\begin{aligned}g_i = L_i'(\\phi_i) &amp;= L_i'(\\phi_1) + L_i''(\\phi_1)(\\phi_i - \\phi_1) + O(||\\phi_i - \\phi_1||^2)\\\\&amp;= \\overline{g}_i + \\overline{H}_i(\\phi_i - \\phi_1) + O(\\alpha^2)\\\\&amp;= \\overline{g}_i - \\alpha\\overline{H}_i\\sum_{j=1}^{i-1}g_j + O(\\alpha^2)\\\\&amp;= \\overline{g}_i - \\alpha\\overline{H}_i\\sum_{j=1}^{i-1}\\overline{g}_j + O(\\alpha^2)\\\\\\end{aligned}\\]下面分析上式的推导过程。根据第二个辅助变量的定义，进行链式展开，高阶项的推导过程如下\\[\\begin{aligned}&amp;\\phi_i = \\phi_1 - \\alpha g_1 - \\alpha g_2 - ... - \\alpha g_{i-1}\\\\\\Rightarrow \\quad &amp;O(||\\phi_i - \\phi_1||^2) = O(|| - \\alpha \\sum_{j=1}^{i-1} g_j||^2) = O(\\alpha^2)\\end{aligned}\\]同理，第二个等号右边，Hessian 矩阵右乘的括号和可化为 $g_i$ 的和形式。最后一个等号右边，可以直接将 $g_i$ 替换为 $\\overline g_i$ 是因为\\[\\begin{aligned}\\alpha\\overline{H}_i\\sum_0^{i-1}g_i &amp;= \\alpha\\overline{H}_i\\sum_0^{i-1}L_i'(\\phi_i) \\\\&amp;= \\alpha\\overline{H}_i\\sum_0^{i-1}[L_i'(\\phi_1) + L_i''(\\phi_1)(\\phi_i - \\phi_1)+O(\\alpha^2)]\\\\&amp;=\\alpha\\overline{H}_i\\sum_0^{i-1}[\\overline g_i- \\alpha\\overline{H}_i\\sum_{j=1}^{i-1}g_j + O(\\alpha^2)]\\\\&amp;= \\alpha\\overline{H}_i\\sum_0^{i-1}\\overline g_i + O(\\alpha^2)\\end{aligned}\\]至此，我们可以得到$g_i$ 在原始参数 $\\phi_1$ 上的泰勒展开如下\\[g_i = \\overline{g}_i - \\alpha\\overline{H}_i\\sum_{j=1}^{i-1}\\overline{g}_j + O(\\alpha^2)\\]然后，我们对 $g_{MAML}$ 进行分析\\[\\begin{aligned}g_{MAML} &amp;= \\frac{\\partial}{\\partial\\phi_1}L_k(\\phi_k)\\\\&amp;= L'_k(\\phi_k)\\frac{\\partial\\phi_k}{\\partial\\phi_1}\\\\&amp;= L'_k(\\phi_k)\\frac{\\partial}{\\partial\\phi_1}[U_{k-1}(U_{k-2}(...(U_1(\\phi_1))))]\\\\&amp;= L'_k(\\phi_k)U'_1(\\phi_1)U'_2(\\phi_2)\\cdots U'_{k-1}(\\phi_{k-1})\\\\&amp;= L'_k(\\phi_k)(I-\\alpha L''_1(\\phi_1))\\cdots(I-\\alpha L''_{k-1}(\\phi_{k-1}))\\\\&amp;=L'_k(\\phi_k)\\left(\\prod_{i=1}^{k-1}(I-\\alpha L''_i(\\phi_i))\\right)\\\\&amp;=g_k\\left(\\prod_{i=1}^{k-1}(I-\\alpha L''_i(\\phi_i))\\right)\\end{aligned}\\]此处，令 $\\alpha=0^+$，我们可以给出 $g_{FOMAML}$ 的表达式\\[g_{FOMAML} = g_k\\]根据前面已经推得的 $g_i$ 在原始参数上的泰勒展开式，带入得\\[g_{FOMAML} = \\overline{g}_k - \\alpha\\overline{H}_k\\sum_{j=1}^{k-1}\\overline{g}_j + O(\\alpha^2)\\]继续推导 $g_{MAML}$，借助第四个辅助变量定义，我们对 $\\alpha L’‘_i(\\phi_i)$ 在原始参数上进行泰勒展开\\[\\begin{aligned}\\alpha L''_i(\\phi_i) &amp;= \\alpha L''_i(\\phi_1) + \\alpha H'_i(\\phi_1 - \\phi_1) + O(\\alpha^2) \\\\&amp;= \\alpha \\overline H_i + \\alpha H'_i\\sum \\alpha g_{i-1} + O(\\alpha^2)\\\\&amp;= \\alpha \\overline H_i + O(\\alpha^2)\\end{aligned}\\]带入 $g_{MAML}$，有\\[g_{MAML} = g_k\\left(\\prod_{i=1}^{k-1}(I-\\alpha \\overline H_i)\\right) + O(\\alpha^2)\\]又根据前面已经推得的 $g_i$ 在原始参数上的泰勒展开式，带入得\\[\\begin{aligned}g_{MAML} &amp;= \\left(\\overline{g}_k - \\alpha\\overline{H}_k\\sum_{j=1}^{k-1}\\overline{g}_j\\right) \\left( \\prod_{i=1}^{k-1}(I-\\alpha \\overline H_i)\\right) + O(\\alpha^2)\\\\&amp;= \\left(\\overline{g}_k - \\alpha\\overline{H}_k\\sum_{j=1}^{k-1}\\overline{g}_j\\right) [ (I-\\alpha \\overline H_1)\\cdots(I-\\alpha \\overline H_{k-1}) ] + O(\\alpha^2)\\\\&amp;= \\left(\\overline{g}_k - \\alpha\\overline{H}_k\\sum_{j=1}^{k-1}\\overline{g}_j\\right) [I-\\alpha \\overline H_1 - \\cdots - \\alpha \\overline H_{k-1} + O(\\alpha^2)] + O(\\alpha^2)\\\\&amp;= \\left(\\overline{g}_k - \\alpha\\overline{H}_k\\sum_{j=1}^{k-1}\\overline{g}_j\\right) \\left(I-\\alpha \\sum_{j=1}^{k-1}\\overline H_j\\right) + O(\\alpha^2)\\\\&amp;= \\overline{g}_k - \\alpha\\overline{g}_k\\sum_{j=1}^{k-1}\\overline H_j - \\alpha\\overline{H}_k\\sum_{j=1}^{k-1}\\overline{g}_j + O(\\alpha^2)\\end{aligned}\\]而对于 Reptile 的梯度，根据定义\\[\\begin{aligned}g_{Reptile} &amp;= (\\phi - \\widetilde \\phi)/\\alpha\\\\&amp;= [\\phi - (\\phi - \\alpha g_1 - \\alpha g_2 - \\cdots - \\alpha g_k)]/\\alpha\\\\&amp;= g_1 + g_2 + \\cdots + g_k\\end{aligned}\\]将 MAML、FOMAML 和 Reptile 三者的梯度同时列写如下\\[\\begin{aligned}  g_{MAML} &amp;=\\overline{g}_k - \\alpha\\overline{g}_k\\sum_{j=1}^{k-1}\\overline H_j - \\alpha\\overline{H}_k\\sum_{j=1}^{k-1}\\overline{g}_j + O(\\alpha^2)\\\\  g_{FOMAML} &amp;= \\overline{g}_k - \\alpha\\overline{H}_k\\sum_{j=1}^{k-1}\\overline{g}_j + O(\\alpha^2)\\\\  g_{Reptile} &amp;= g_1 + g_2 + \\cdots + g_k\\end{aligned}\\]为了简化分析，令 $k=2$，有\\[\\begin{aligned}  g_{MAML} &amp; &amp;=\\overline{g}_2 - \\alpha\\overline{g}_2\\overline H_1 - \\alpha\\overline{H}_2\\overline{g}_1 + O(\\alpha^2)\\\\  g_{FOMAML} &amp;= g_2 &amp;=  \\overline{g}_2 - \\alpha\\overline{H}_2\\overline{g}_1 + O(\\alpha^2)\\\\  g_{Reptile} &amp;= g_1 + g_2 &amp;=\\overline{g}_1 + \\overline{g}_2 - \\alpha\\overline{H}_2 g_1 + O(\\alpha^2)\\end{aligned}\\]1.4. 另一种推导方式直接假设 $k=2$，以两步 SGD 为例分析参数更新过程。简化起见，我们将损失函数对模型参数的梯度记为 $L’$，那么两步 SGD 更新后的模型参数为 $\\phi_3$，有\\[\\begin{aligned}\\phi_1 &amp;= \\phi\\\\\\phi_2 &amp;= \\phi_1 - \\alpha L_1'(\\phi_1)\\\\\\phi_3 &amp;= \\phi_2 - \\alpha L_1'(\\phi_1) - \\alpha L_2'(\\phi_2)\\end{aligned}\\]下面定义几个辅助变量，其中 $i\\in [1, k]$ 指代第 $i$ 个 minibatch，也即第 $i$ 次梯度下降的训练过程（？）\\[\\begin{aligned}g_i &amp;= L_i'(\\phi_i)\\;\\;(gradient \\; obtained\\; during\\;SGD)\\\\\\phi_{i+1} &amp;= \\phi_i-\\alpha g_i\\;\\;(sequence\\;of\\;parameters)\\\\\\overline{g}_i &amp;= L_i'(\\phi_1)\\;\\;(gradient\\;at\\;initial\\;point)\\\\\\overline{H}_i &amp;= L_i''(\\phi_1)\\;\\;(Hessian\\;at\\;initial\\;point)\\\\\\end{aligned}\\]首先，采用泰勒展开将 $g_i$ 展开至 “二阶导+高次项” 的形式\\[\\begin{aligned}g_i &amp;= L_i'(\\phi_i) = L_i'(\\phi_1) + L_i''(\\phi_1)(\\phi_i - \\phi_1) + O(||\\phi_i - \\phi_1||^2)\\\\&amp;= \\overline{g}_i + \\overline{H}_i(\\phi_i - \\phi_1) + O(\\alpha^2)\\\\&amp;= \\overline{g}_i - \\alpha\\overline{H}_i\\sum_0^{i-1}g_i + O(\\alpha^2)\\\\&amp;= \\overline{g}_i - \\alpha\\overline{H}_i\\sum_0^{i-1}\\overline{g}_i + O(\\alpha^2)\\\\\\end{aligned}\\]最后一步的依据是，$g_i = \\overline{g}_i + O(\\alpha)$ 带入倒数第二行时，后面的 $O(\\alpha)$ 与求和符号前的 $\\alpha$ 相乘，即变为 $O(\\alpha^2)$ 从而合并为一项。下面取  $k=2$ ，即两步SGD，分别推导 MAML、FOMAML、Reptile 的梯度。这个参考 [3] 考虑了 $k$ 为任意情况下的通解，在  $k=2$ 时的结果与本文相同。对于二阶的MAML，初始参数 $\\phi_1$ 首先在support set上梯度更新一次得到 $\\phi_2$ ，然后将 $\\phi_2$ 在 query set 上计算损失函数，再计算梯度更新模型的初始参数。即 query set 的 loss 要对 $\\phi_2$ 求导，链式法则 loss 对  $\\phi_2$ 求导乘以  $\\phi_2$ 对 $\\phi_1$ 求导\\[\\begin{aligned}g_{MAML} &amp;= \\frac{\\partial}{\\partial\\phi_1}L_2(\\phi_2) = \\frac{\\partial \\phi_2}{\\partial \\phi_1} L_2'(\\phi_2) \\\\ &amp;= (I-\\alpha L_1''(\\phi_1))L_2'(\\phi_2)\\\\ &amp;= (I-\\alpha L_1''(\\phi_1))(L_2'(\\phi_1) + L_2''(\\phi_1)(\\phi_2 - \\phi_1) + O(\\alpha^2))\\\\ &amp;= (I-\\alpha L_1''(\\phi_1))(L_2'(\\phi_1) + L_2''(\\phi_1)(\\phi_2 - \\phi_1)) + O(\\alpha^2)\\\\ &amp;= (I-\\alpha L_1''(\\phi_1))(L_2'(\\phi_1) - \\alpha L_2''(\\phi_1)L_1'(\\phi_1)) + O(\\alpha^2)\\\\ &amp;= L_2'(\\phi_1)-\\alpha L_2''(\\phi_1)L_1'(\\phi_1) - \\alpha L_1''(\\phi_1)L_2'(\\phi_1) + O(\\alpha^2)\\\\ \\end{aligned}\\]对于FOMAML，其一阶简化是简化了参数 $\\phi_2$ 对初始参数 $\\phi_1$ 求导部分，即 $\\frac{\\partial \\phi_2}{\\partial \\phi_1} = const$，则只剩下 loss 对参数 $\\phi_2$ 的求导。\\[\\begin{aligned}g_{FOMAML} &amp;= L_2'(\\phi_2) = L_2'(\\phi_1) + L_2''(\\phi_1)(\\phi_2 - \\phi_1) + O(\\alpha^2)\\\\&amp;= L_2'(\\phi_1) -\\alpha L_2''(\\phi_1)L_1'(\\phi_1) + O(\\alpha^2)\\end{aligned}\\]对于Reptile，根据梯度定义和SGD过程有\\[\\begin{aligned}g_{Reptile} &amp;= (\\phi_1 - \\phi_3)/\\alpha = L_1'(\\phi_1)+L_2'(\\phi_2)\\\\&amp;= L_1'(\\phi_1)+L_2'(\\phi_1)+ L_2''(\\phi_1)(\\phi_2-\\phi_1) + O(\\alpha^2)\\\\&amp;= L_1'(\\phi_1)+L_2'(\\phi_1)-\\alpha L_2''(\\phi_1)L_1'(\\phi_1) + O(\\alpha^2)\\end{aligned}\\]接下来对上面的三个梯度进行变量替换，全部用之前定义的辅助变量来表示\\[\\begin{aligned}g_{MAML} &amp; &amp;= \\overline{g}_2 - \\alpha \\overline{H_2}\\overline{g}_1-\\alpha\\overline{H_1}\\overline{g}_2+O(\\alpha^2)\\\\g_{FOMAML} &amp;= g_2 &amp;= \\overline{g}_2-\\alpha\\overline{H}_2\\overline{g}_1+O(\\alpha^2)\\\\g_{Reptile} &amp;= g_1+g_2 &amp;= \\overline{g}_1+\\overline{g}_2-\\alpha \\overline{H}_2\\overline{g}_1 + O(\\alpha^2)\\\\\\end{aligned}\\]可以得到与上一节一致的结果。1.5. 梯度的泰勒展开的领头阶（继续）再次定义两个期望参数如下。第一个：AvgGrad 定义为loss对初始参数的梯度的平均期望\\[AvgGrad = \\mathbb E_{\\tau,1}[\\overline{g}_1] =\\mathbb E_{\\tau,2}[\\overline{g}_2]\\]（-AvgGrad）是参数 $\\phi$ 在最小化 joint training 问题中的下降方向。就是想在所有batch上减小loss，也就是减小整体的任务损失。  为什么此处 $\\overline{g}_1$ 和 $\\overline{g}_2$ 的期望相等呢，因为它们都是表示的是loss对原始参数的梯度，只不过对应于不同的batch。在minibatch中，一个batch用于进行一次梯度下降，因为batch是随机的，所以loss对原始参数的梯度与batch是无关的。第二个：AvgGradInner\\[\\begin{aligned}AvgGradInner &amp;= \\mathbb E_{\\tau,1,2}[\\overline{H}_1\\overline{g}_2]\\\\&amp;= \\mathbb E_{\\tau,1,2}[\\overline{H}_2\\overline{g}_1]\\\\&amp;= \\frac{1}{2}\\mathbb E_{\\tau,1,2}[\\overline{H}_1\\overline{g}_2+\\overline{H}_2\\overline{g}_1]\\\\&amp;= \\frac{1}{2}\\mathbb E_{\\tau,1,2}[\\frac{\\partial}{\\partial \\phi_1}(\\overline{g}_1\\cdot \\overline{g}_2)]\\end{aligned}\\](-AvgGradInner) 的方向可以增大不同minibatch间梯度的内积，从而提高泛化能力。换句话说，AvgGradInner是 $\\overline{g}_0\\overline{g}_1$ 的对原始参数的导数，因为梯度在参数更新时是加负号的，所以是在最大化同一任务中不同minibatch之间梯度的内积。对其中一个batch进行梯度更新会显著改善另一个batch的的表现，这样就增加了模型的泛化性和快速学习的能力。下面就可以对上述三个梯度进行进一步替换，$k=2$ 时\\[\\begin{aligned}\\mathbb{E}[g_{MAML}] &amp;= (1)AvgGrad - (2\\alpha)AvgGradInner + O(\\alpha^2)\\\\\\mathbb{E}[g_{FOMAML}] &amp;= (1)AvgGrad - (\\alpha)AvgGradInner + O(\\alpha^2)\\\\\\mathbb{E}[g_{Reptile}] &amp;= (2)AvgGrad - (\\alpha)AvgGradInner + O(\\alpha^2)\\\\\\end{aligned}\\]扩展到 $k&gt;2$ 的情况有 [3]\\[\\begin{aligned}\\mathbb{E}[g_{MAML}] &amp;= (1)AvgGrad - (2(k-1)\\alpha)AvgGradInner + O(\\alpha^2)\\\\\\mathbb{E}[g_{FOMAML}] &amp;= (1)AvgGrad - ((k-1)\\alpha)AvgGradInner + O(\\alpha^2)\\\\\\mathbb{E}[g_{Reptile}] &amp;= (2)AvgGrad - (\\frac{1}{2}k(k-1)\\alpha)AvgGradInner + O(\\alpha^2)\\\\\\end{aligned}\\]可以看到三者AvgGradInner与AvgGrad之间的系数比的关系是：MAML &gt; FOMAML &gt; Retile。这个比例与步长 $\\alpha$，迭代次数 $k$ 正相关。综上所述， MAML 和 Reptile 的优化目标相同，都是更好的任务表现（由 AvgGrad 主导）和更好的泛化能力（由 AvgGradInner 主导）。1.6. 另一种不严谨的分析另一种分析有效的方法借助了流形，Reptile 收敛于一个解，这个解在欧式空间上与每个任务的最优解的流形接近。没看懂不管了。作者自己也号称不如泰勒展开严谨。  This is a informal argument and should be taken much less seriously than the preceding Taylor series analysis1.7. 实验少样本分类从两个表格中的数据可以看出，MAML与Reptile在加入了转导（Transduction）后，在Mini-ImageNet上进行实验，Reptile的表现要更好一些，而Omniglot数据集上正好相反。不同的内循环梯度组合比较通过在内循环中使用四个不重合的Mini-Batch，产生梯度数据 g1,g2,g3,g4 ，然后将它们以不同的方式进行线性组合（等价于执行多次梯度更新）用于外部循环的更新，进而比较它们之间的性能表现，实验结果如下图：从曲线可以看出：  仅使用一个批次的数据产生的梯度的效果并不显著，因为相当于让模型用见到过的少量的数据去优化所有任务。  进行了两步更新的Reptile（绿线）的效果要明显不如进行了两步更新的FOMAML（红线），因为Reptile在AvgGradInner上的权重（AvgGradInner与AvgGrad的系数的比例）要小于FOMAML。  随着mini-batch数量的增多，所有算法的性能也在提升。通过同时利用多步的梯度更新，Reptile的表现要比仅使用最后一步梯度更新的FOMAML的表现好。内循环中Mini-Batch 重合比较Reptile和FOMAML在内循环过程中都是使用的SGD进行的优化，在这个优化过程中任何微小的变化都将导致最终模型性能的巨大变化，因此这部分的实验主要是探究两者对于内循环中的超数的敏感性，同时也验证了FOMAML在minibatch以错误的方式选取时会出现显著的性能下降情况。mini-batch的选择有两种方式：  shared-tail（共尾）：最后一个内循环的数据来自以前内循环批次的数据  separate-tail（分尾）：最后一个内循环的数据与以前内循环批次的数据不同采用不同的mini-batch选取方式在FOMAML上进行实验，发现随着内循环迭代次数的增多，采用分尾方式的FOMAML模型的测试准确率要高一些，因为在这种情况下，测试的数据选取方式与训练过程中的数据选取方式更为接近。当采用不同的批次大小时，采用共尾方式选取数据的FOMAML的准确性会随着批次大小的增加而显著减小。当采用full-batch时，共尾FOMAML的表现会随着外循环步长的加大而变差。共尾FOMAML的表现如此敏感的原因可能是最初的几次SGD更新让模型达到了局部最优，以后的梯度更新就会使参数在这个局部最优附近波动。2. 比较再次比较Model Pre-training、MAML 和 Reptile方法。（左：MAML。右：Model Pre-training）（Reptile）Pre-training采用task的loss对参数的梯度更新模型的原始参数。MAML采用task的第二次梯度计算更新模型的原始参数。Reptile采用多次梯度计算更新模型的原始参数。上面这个图不具体，但是很直观的展示了这些算法的区别。$g_i$ 表示第 $i$ 次负梯度计算。这里的MAML是一阶的，沿着 $g_2$ 方向更新，Reptile 沿着 $g_1+g_2$  的方向更新，而我们常规的预训练模型就是沿着 $g_1$ 方向更新。3. 算法实现First-order近似实现Reptile：https://github.com/dragen1860/Reptile-Pytorch4. reptile回归sin函数import numpy as npimport torchfrom torch import nn, autograd as agimport matplotlib.pyplot as pltfrom copy import deepcopyseed = 0plot = Trueinnerstepsize = 0.02 # stepsize in inner SGDinnerepochs = 1 # number of epochs of each inner SGDouterstepsize0 = 0.1 # stepsize of outer optimization, i.e., meta-optimizationniterations = 30000 # number of outer updates; each iteration we sample one task and update on itrng = np.random.RandomState(seed)torch.manual_seed(seed)# Define task distributionx_all = np.linspace(-5, 5, 50)[:,None] # generate 50 x points within [-5,5]ntrain = 10 # Size of training minibatchesdef gen_task():    \"Generate regression problem\"    phase = rng.uniform(low=0, high=2*np.pi)    ampl = rng.uniform(0.1, 5)    f_randomsine = lambda x : np.sin(x + phase) * ampl    return f_randomsine# Define model. Reptile paper uses ReLU, but Tanh gives slightly better resultsmodel = nn.Sequential(    nn.Linear(1, 64),    nn.Tanh(),    nn.Linear(64, 64),    nn.Tanh(),    nn.Linear(64, 1),)def totorch(x):    return ag.Variable(torch.Tensor(x))def train_on_batch(x, y):    x = totorch(x)    y = totorch(y)    model.zero_grad()    ypred = model(x)    loss = (ypred - y).pow(2).mean()    loss.backward()    for param in model.parameters():        param.data -= innerstepsize * param.grad.datadef predict(x):    x = totorch(x)    return model(x).data.numpy()# Choose a fixed task and minibatch for visualizationf_plot = gen_task()xtrain_plot = x_all[rng.choice(len(x_all), size=ntrain)]# Reptile training loopfor iteration in range(niterations): # iterate 30000 times    weights_before = deepcopy(model.state_dict())    # Generate task    f = gen_task()    y_all = f(x_all)    # Do SGD on this task    inds = rng.permutation(len(x_all)) # get random index of 0-50    for _ in range(innerepochs): # SGD 1 times        for start in range(0, len(x_all), ntrain): # from 0-50, select a num every 'ntrain' interval            mbinds = inds[start:start+ntrain] # get randomly index from 'start' to 'ntrain'            train_on_batch(x_all[mbinds], y_all[mbinds])    # Interpolate between current weights and trained weights from this task    # I.e. (weights_before - weights_after) is the meta-gradient    weights_after = model.state_dict()    outerstepsize = outerstepsize0 * (1 - iteration / niterations) # linear schedule    model.load_state_dict({name :        weights_before[name] + (weights_after[name] - weights_before[name]) * outerstepsize        for name in weights_before})    # Periodically plot the results on a particular task and minibatch    if plot and iteration==0 or (iteration+1) % 1000 == 0:        plt.cla()        f = f_plot        weights_before = deepcopy(model.state_dict()) # save snapshot before evaluation        plt.plot(x_all, predict(x_all), label=\"pred after 0\", color=(0,0,1))        for inneriter in range(32):            train_on_batch(xtrain_plot, f(xtrain_plot))            if (inneriter+1) % 8 == 0:                frac = (inneriter+1) / 32                plt.plot(x_all, predict(x_all), label=\"pred after %i\"%(inneriter+1), color=(frac, 0, 1-frac))        plt.plot(x_all, f(x_all), label=\"true\", color=(0,1,0))        lossval = np.square(predict(x_all) - f(x_all)).mean()        plt.plot(xtrain_plot, f(xtrain_plot), \"x\", label=\"train\", color=\"k\")        plt.ylim(-4,4)        plt.legend(loc=\"lower right\")        plt.pause(0.01)        model.load_state_dict(weights_before) # restore from snapshot        print(f\"-----------------------------\")        print(f\"iteration               {iteration+1}\")        print(f\"loss on plotted curve   {lossval:.3f}\") # optimized in one example for brevity  用 $sin$ 函数来测试Reptile算法。          在 $[-5,5]$ 区间内随机取50个$x$点      在 $[0,2\\pi]$ 区间内随机取相位$P$      在 $[0.1,5]$ 区间内随机取幅值$A$            那么就可以随机生成任意相位幅值的50个点的sin函数：$Asin(x+P)$    设置minibatch的个数为ntrain=10，也就是一次训练10个点      先随机产生一个 $sin$ 函数，并在其上随机取10个点，作为测试集    进行外环迭代 niterations=30000次          随机产生一个 $sin$ 函数      进行内环迭代innerepochs=1次                  随机取50个点（$x$）中的10个点（ntrain）          训练一次（SGD）          取5次直到取完所有50个点          [完成内环迭代]                    更新外层学习率 outerstepsize = outerstepsize0 * (1 - iteration / niterations)      更新模型参数 weights_before+ (weights_after - weights_before) * outerstepsize        若外环迭代达到1000次的整数倍，那么将训练的模型在测试集上测试  测试迭代inneriter=32次          在测试集上训练一次（10个离散点）      每过8次画一次图上的曲线（50个离散点）        MSE衡量测试结果  [完成外环迭代]5. 参考文献[1]  Rust-in. MAML 论文及代码阅读笔记.[2] 人工智障. MAML算法，model-agnostic metalearnings?[3] Veagau. 【笔记】Reptile-一阶元学习算法[4] pure water. Reptile原理以及代码详解"
  },
  
  {
    "title": "LaTeX+TexStudio环境配置",
    "url": "/posts/Latex-TexStudio/",
    "categories": "Tutorial, Writing",
    "tags": "latex",
    "date": "2020-07-13 14:35:19 +0800",
    





    
    "snippet": "LaTeX 是一种高质量的排版系统，被广泛的期刊杂志所支持，让笔者仅需要关注内容本身，而无需过多的为格式和排版而费心，具备高质量的表格、公式书写体验。  1. LaTeX简介  2. 下载和安装MiKTeX  3. 下载和安装TeXstudio          3.1. 下载和安装      3.2. 配置      3.3. 测试        4. LaTeX详细指南         ...",
    "content": "LaTeX 是一种高质量的排版系统，被广泛的期刊杂志所支持，让笔者仅需要关注内容本身，而无需过多的为格式和排版而费心，具备高质量的表格、公式书写体验。  1. LaTeX简介  2. 下载和安装MiKTeX  3. 下载和安装TeXstudio          3.1. 下载和安装      3.2. 配置      3.3. 测试        4. LaTeX详细指南          4.1. 主文档      4.2. 宏包安装和管理      4.3. 插入图片                  4.3.1. 添加图片          4.3.2. 引用图片          4.3.3. visio绘图转为无边框PDF                    4.4. 插入公式                  4.4.1. 插入行内公式          4.4.2. 插入行间公式          4.4.3. 引用公式编号                    4.5. 插入参考文献                  4.5.1. 参考文献来源          4.5.2. 参考文献的添加          4.5.3. 参考文献的引用          4.5.4. 参考文献编译          4.5.5. 参考文献字母大写          4.5.6. 附录：参考文献的格式字段                    4.6. 引用章节名称      4.7. 列表        5. 参考文献1. LaTeX简介  LaTeX is a high-quality typesetting system; it includes features designed for the production of technical and scientific documentation. LaTeX is the de facto standard for the communication and publication of scientific documents. LaTeX is available as free software.LaTeX 是一种高质量的排版系统；它包括为制作技术和科学文档而设计的功能。LaTeX 是科学文献交流和出版的事实标准。LaTeX 是免费软件。一个完整的 LaTex 写作环境包括：  TeX 发行版：          Windows下的 MiKTeX（Home - MiKTeX.org）      Linux下的TexLive        编辑器：          跨平台的 TeXstudio （Home - TexXstudio）      Windows下的 WinEdit      跨平台的 VSCode（2020.08.28新增：LaTeX+VSCode环境配置）      下面以 MiKTeX 20.6 + TeXstudio 2.12.22 为例进行安装和部署讲解。2. 下载和安装MiKTeX可以将 MiKTeX 看作是 LaTeX 的一种发行版，类比 C 的发行版 MSC 一样（大雾）。官网的下载页面 为 https://MiKTeX.org/download。包括三种下载（安装）方式，如图分别为安装程序（Installer）、绿色版（Portable Edition）以及命令行（Command-line installer）。对于Windows开发环境，不考虑命令行方式，因此可以任意选择安装程序或者绿色版。需要注意的是，绿色版并没有单独的压缩包，而是直接对应安装版的安装程序，只不过将安装程序重命名为 MiKTeX-portable.exe，然后双击安装即可。绿色版与安装版的区别在于，绿色版不会向系统盘写入配置信息，也不会注册环境变量，意味着之后如果需要安装编辑器，无法自动获取系统中已经安装的LaTeX版本，而需要手动配置。懒人推荐安装版，省去配置环境变量等步骤（虽然后面是以绿色版介绍的）。双击下载的 exe 文件进行安装，路径任意。3. 下载和安装TeXstudio3.1. 下载和安装前往官网，网址为 http://texstudio.sourceforge.net/。选择左侧的“Download”，对于Windows平台，根据需要选择安装版或者绿色版进行下载。下载完成后双击安装，安装路径任意。3.2. 配置第一步：配置语言，将界面语言更改为中文。点击菜单栏的「Options」-「Configure TeXstudio」，在弹出的界面中选择左侧的「General」，下拉「Language」中选择「zh-cn」，点击「OK」即可完成语言更改。第二步：配置 LaTeX 路径，重点路径如图通过各行右侧的「打开」按钮来选择路径。假设安装的MiKTeX为绿色版，安装根目录为X:\\ProgramFiles\\MiKTeX\\，则上述路径均位于X:\\ProgramFiles\\MiKTeX\\texmfs\\install\\miktex\\bin\\x64相应的，安装版的路径位于X:\\ProgramFiles\\MiKTeX\\miktex\\bin\\x64分别对应为  LaTeX：latex.exe  PdfLaTeX：pdflatex.exe  External PDF Viewer：视自己安装的pdf阅读器而定，可不设置  BibTeX：bibtex.exe  BibTex 8位：bibtex8.exe第三步（可选）：配置选择外部 PDF 查看器进行查看。因 LaTeX 直接将文档代码生成为 PDF 文件，因此需要设置 PDF 查看器。TeXstudio 默认设置为内部的 PDF 查看器进行查看，可设置为外部自己安装的第三方 PDF 查看器。如下图更改红框中的设置即可注意，不是所有第三方 PDF 阅读器都支持「热刷新」，即在阅读器打开 PDF 文件的情况下对文件进行修改、保存和刷新显示，而热刷新功能在 LaTeX 写作时是十分必要的功能。因此，如果不肯定自己使用的第三方 PDF 阅读器是否支持热刷新，请慎重设置，或者不修改设置而是直接使用内置 PDF 查看器。支持热刷新的第三方 PDF 阅读器推荐：Sumatra PDF。3.3. 测试完成 TeXstudio 的配置后，新建一个空白的 tex 文档进行测试。点击左上方的「新建」按钮即可新建一个空白文档。在空白文档中写入\\documentclass{article}% 这里是导言区\\begin{document}Hello, world!\\end{document}保存，然后按 F5 进行构建并查看。如果一切顺利的话，下方的消息栏将会提示「完成」，右侧的内置 PDF 查看器将会显示一个 PDF 文档，内容为 “Hello World！”。4. LaTeX详细指南4.1. 主文档LaTeX 写作类似编程，包括构建（类似编译）和显示（类似运行）。在 TeXstudio 中，构建并显示可以作为一步操作，快捷键为 F5 ，单独的构建（编译）快捷键为 F6，显示（查看）快捷键为 F7。三者也有按钮可以点击，点击效果与使用快捷键一致。一个 tex 文档以 \\documentclass{xxx}开头，用以定义该文档的类型。\\documentclass[option]{class}其中，class 指定想要的文档类型，options 参数可以定制文档类的属性。 不同的选项之间须用逗号隔开。标准文档类的最常用class如下表所示。            class（类）      解释                  article      排版科学期刊杂志的论文、 演示文档、 短报告、 程序文档、 邀请函……              proc      一个基于 article 的会议文集类              minimal      非常小的文档类。 只设置了页面尺寸和基本字体。 主要用来查错。              report      排版多章节长报告、 短篇书籍、 博士论文……              book      排版书籍。              slides      排版幻灯片。 该文档类使用大号 sans serif 字体。 也可以选用 FoilTEXa 来得到相同的效果      标准文档类的最常用options如下表所示。            options（设置项）      解释                  10pt, 11pt, 12pt      设置文档中所使用的字体的大小。 如果该项没有指定， 默认使用10pt 字体。              a4paper, letterpaper, . . .      定义纸张的尺寸。 缺省设置为letterpaper， 还可以使用a5paper, b5paper, executivepaper 以及legalpaper。              fleqn      设置行间公式为左对齐， 而不是居中对齐。              leqno      设置行间公式的编号为左对齐， 而不是右对齐。              titlepage, notitlepage      指定是否在文档标题(document title) 后另起一页。 article 文档类缺省设置为不开始新页， report 和book 类则相反。              onecolumn, twocolumn      设置以单栏(one column) 或双栏(two column) 的方式来排版文档。              twoside, oneside      指定文档为双面或单面打印格式。 article 和report 类为单面(single sided) 格式， book 类缺省为双面(double sided) 格式。 注意该选项只是作用于文档样式， 而不会通知打印机以双面格式打印文档。              landscape      将文档的打印输出布局设置为 landscape 模式。              openright, openany      决定新的一章仅在奇数页开始还是在下一页开始。 在文档类型为article 时该选项不起作用， 因为该类中没有定义“章” (chapter)。 report 类默认在下一页开始新一章而book 类的新一章总是在奇数页开始。      文档的的主体部分以 \\begin{document} 开头，以 \\end{document} 结束，以百分号 % 作为注释符号。未完待续4.2. 宏包安装和管理按快捷键 F5 进行编译构建，若使用了第三方提供的模板（比如期刊的排版模板），可能会提示安装依赖的样式包等，点击安装即可。其中，「Change」按钮可以更换宏包的源。MiKTeX 提供了一个专门的宏包管理器，位于texstudio安装路径的mpm.exe。如E:\\ProgramFiles\\MiKTeXPortable\\texmfs\\install\\MiKTeX\\bin\\x64\\mpm.exe双击后可以打开 MiKTeX consule。若采用安装版而不是绿色版的 MiKTeX，则还可在 cmd 中输入 mpm 打开。如下右键任意包可以查看其文件的存放位置。一个包一般分为3部分，sty文件、tpm文件和tar.bz2包文件，在官网此处（https://MiKTeX.org/packages/preprint）可以查看某个包的详细信息，点击「Browse Files」可查看某个包的所有文件。若使用安装版 MiKTeX 则包位置即为显示的路径。若采用绿色版 MiKTeX 则包文件位置分别为：tpm文件：[MiKTeXPortableRoot]\\texmfs\\install\\tpm\\packagessty文件：[MiKTeXPortableRoot]\\texmfs\\install\\tex\\latextar.bz2包文件：[MiKTeXPortableRoot]\\texmfs\\install\\source如果在编译时，遇到包下载和安装失败，可尝试通过 MiKTeX console 进行一次全局更新。然后重新编译 tex 文件，应该能自动提示下载缺失的宏包。4.3. 插入图片4.3.1. 添加图片添加图时，如下\\begin{figure}[!t]  \\centering  \\includegraphics[scale=1.0]{images/Figname.pdf}  \\caption{双七自由度机械臂的一般模型}  \\label{fig:FrameDefinition_Lagrange}\\end{figure}其中，\\label{fig:xxx} 一定紧跟着要放在 \\caption{xxx} 后面，在正文引用时候才能正确编号。对于两栏文章而言，插入跨栏图片为\\begin{figure*}[!t] % add a \"*\" to import a cross column figure  \\centering  \\includegraphics[scale=1.0]{images/Figname.pdf}  \\caption{双七自由度机械臂的一般模型}  \\label{fig:FrameDefinition_Lagrange}\\end{figure*}图形（figure）环境有一个可选参数项允许用户来指示图形有可能被放置的位置，参数位于中括号中。这一可选参数项可以是下列字母的任意组合：  !：表示忽略审美强制排布图片  h：当前位置。将图形放置在 正文文本中给出该图形环境的地方.如果本页所剩的页面不够, 这一参数将不起作用。  t：顶部。将图形放置在页面的顶部。  b：底部。将图形放置在页面的底部。  p：浮动页。将图形放置在一只允许有浮动对象的页面上。注:  如果在图形环境中没有给出上述任一参数,则缺省为 [tbp]。  给出参数的顺序不会影响到最后的结果.因为在考虑这些参数时 LaTeX 总是尝试以 h-t-b-p 的顺序来确定图形的位置.所以 [hb] 和 [bh] 都使 LATEX 以 h-b 的顺序来排版。  给出的参数越多, LaTeX 的排版结果就会越好。[htbp]，[tbp]，[htp]，[tp] 这些组合得到的效果不错.  只给出单个的参数项极易引发问题。如果该图形不适合所指定的位置，它就会被搁置并阻碍对后面的图形 的处理。一旦这些阻塞的图形数目超过了18 幅这一 LaTeX 所能容许的最大值,就会产生 “Too Many Unprocessed Floats” 的错误。当 LaTeX “试图” 放置一浮动图形时，它将遵循以下规则：  图形只能置于由位置参数所确定的地点。  图形的放置不能造成超过版心的错误(overfull page)。  图形只能置于当前页或后面的页中.所以图形只能 “向后浮动”而不能”向前浮动”。  图形必须按顺序出现，这样只有当前面的图形都被放置好之后才能被放置。          只要前面有未被处理的图形，一幅图形就不会被放在当前位置.      一幅 “不可能放置”的图形将阻碍它后面的图形的放置，直到文件结束或达到LaTex的浮动限制。        必须符合一定的审美条件。例如，一页上的浮动对象的数目不能超过totalnumber。在浮动位置选项前加上一个惊叹号(如 \\begin{figure}[!ht]) 会使LaTex忽略应用于文本页的审美条件，试图用最严格的标准来放置浮动图形。不过，!不会影响应用于浮动页4.3.2. 引用图片在正文需要引用图片的地方增加 \\ ref{fig:xxx}，如编译为若编译报错，很可能是没有引入相应的包。在此处，\\includegraphics 依赖宏包 graphicx ，需要在文档开头引入\\usepackage{graphicx}.\\begin{document}.\\end{document}4.3.3. visio绘图转为无边框PDFvisio绘图是矢量图，但是无法直接导入LaTeX使用。PDF也是矢量格式，将visio绘图转为PDF可以插入LaTeX。由于visio直接导出为pdf后四周存在灰色外框和一定宽度的白边，如下设置避免这种情况。  首先调出开发工具选项卡。在工具栏右键，选择【自定义功能区】  勾上【开发工具】  切换到【开发工具】，选择【显示】右下方的小箭头，点击【页】  找到【Print Properties】，将Page Left\\Right\\Top\\Bottom Margin全部设为0，去除四周留白      关闭【Print Properties】，保存visio绘图。        切换到【设计】选项卡，选择【大小】下面的小箭头，点击【适应绘图】，保存visio绘图。    另存为，类型选择【PDF】，点击【选项】，弹出页面取消勾选【辅助功能文档结构标记】，点击【确定】输出为PDF。4.4. 插入公式基本公式规范上标：A^b，编译为 $A^b$下标：A_b，编译为 $A_b$上下标：A_b^c，编译为 $A_b^c$更多参考：https://www.jianshu.com/p/22117d964baf 或者自行百度。4.4.1. 插入行内公式用$$插入行内公式，内容按照latex公式规范书写。如4.4.2. 插入行间公式按照如下形式 插入行间公式。\\begin{equation}…\\end{equation}示例如下（其中 \\nonumber 表示该公式无需编号）：复杂的公式可以先在Word中用 MathType 先进行书写，然后转换为 LaTeX 语言格式，再粘贴出来后，稍作修改即可复制到 LaTeX 文档中。参考：LaTeX公式与MathType公式如何快速转换4.4.3. 引用公式编号在公式中加入label字段，如：引用时用 \\ref 命令，如：编译为：4.5. 插入参考文献4.5.1. 参考文献来源参考文献的数据按照一定格式存放于 .bib 文件中，可以去Google Scholar搜索该参考文献，点击文献下面的引号，弹出引用格式，选择下方第一个BibTex即可中文文献或者无需翻墙的文献，百度学术也可以得到bib格式，如图4.5.2. 参考文献的添加复制给出的bib格式参考文献数据，添加到自己的 .bib 文件中。一些情况下还需要对信息进行增改，比如：  修改缩写，上面参考文献缩写“胡忠华自旋……”太长了，改成规范格式“hzh2016zi”          英文：作者姓+年+标题第一个词（如potter2020magic）；      中文：姓名拼音缩写/姓氏拼音+年+标题第一字拼音（如dong2020wei或dyf2020wei）        补全信息，比如硕士博士论文的出版地（保存地），否则会出现出版地不详，而GBT7714规定，硕士博士论文要列出【保存地：保存年份】4.5.3. 参考文献的引用      使用 \\cite{}，此时引用序号为正文字体大小，即：    Ryan\\cite{ryan2015photometric}在2015年发表了xxxx    编译后得到    Ryan[1]在2015年发表了xxxx        使用 \\upcite{}，此时引用序号为上标，即：    Ryan\\upcite{ryan2015photometric}在2015年发表了xxxx    编译后得到    Ryan[1]在2015年发表了xxxx        使用 \\citep{} 等也可以（具体cite命令可以自行百度）  注意，将参考文献在正文中进行引用后，再进行编译。如果不引用，该参考文献将不会出现在参考文献列表中。4.5.4. 参考文献编译首先保障添加参考文献到.bib文件且在正文引用，然后按照下面四步进行编译：  当前窗口激活为任意 .tex 文件，编译（texStudio快捷键F5） , 这会生成一个.aux 的文件, 这告诉 BibTeX 将使用那些引用，此时文中引用位置显示为 [?]  当前窗口激活为任意 .tex 文件，编译 .bib 文件（texStudio快捷键F8），生成.bbl文件，确保没有任何Warning  当前窗口激活为任意 .tex 文件，再次编译 .tex 文件（texStudio快捷键F5）, 此时参考文献列表中已经包含了该参考文献, 但此时引用的编号可能不正确（比如[?]）  当前窗口激活为任意 .tex 文件，最后再次编译 .tex 文件, （texStudio快捷键F5） 如果一切顺利的话, 这是所有东西都已正常了。编译如果报错，检查：      大括号是否完整；        大括号后面是否漏了逗号；        作者姓名是否用and连接，是否错误采用逗号连接，是否多用了and。  修改后，将当前窗口激活为任意 .tex 文件，重新编译 .bib 文件（F8）4.5.5. 参考文献字母大写部分模板中，bib参考文献题目中大写自动变为小写，比如，参考文献原始标题为：  Real-Time Optimal Approach and Capture of ENVISAT Based on Neural Networks按照GB7717规范引用后在参考文献列表中显示为：  Real-time optimal approach and capture of envisat based on neural networks为了保留大写，在bib中录入时对需要保持原大写的部分添加大括号，即：title = {Real-Time Optimal Approach and Capture of {ENVISAT} Based on Neural Networks},编译后显示为：  Real-time optimal approach and capture of ENVISAT based on neural networks4.5.6. 附录：参考文献的格式字段@article期刊杂志的论文必要域: author, title, journal, year.可选域: volume, number, pages, month, note.@article{px2017qiu,author={潘迅 and 泮斌峰 and 唐硕},title={求解中途飞越燃料最优转移轨道的同伦方法},journal={宇航学报},volume={38},number={4},pages={393--400},year={2017},}@article{lhj2020realtime,  author={Hong Jue Li and Yun Feng Dong and Pei Yun Li},  title={Real-Time Optimal Approach and Capture of {ENVISAT}},  journal = {International Journal of Aerospace Engineering},  volume={2020},  number={},  pages={Article ID 8165147},  year = {2020},}@book公开出版的图书必要域: author/editor, title, publisher, year.可选域: volume/number, series, address, edition, month, note.@book{lb2018kong,  author={梁斌 and 徐文福},  title={空间机器人：建模、规划与控制},  year={2019},  address={北京},  publisher={清华大学出版社},}@booklet无出版商或作者的图书必要域: title.可选域: author, howpublished, address, month, year, note.@conference等价于 inproceedings必要域: author, title, booktitle, year.可选域: editor, volume/number, series, pages, address, month, organization, publisher, note.@inbook书籍的一部分章节必要域: author/editor, title, chapter and/or pages, publisher, year.可选域: volume/number, series, type, address, edition, month, note.@incollection书籍中带独立标题的章节必要域: author, title, booktitle, publisher, year.可选域: editor, volume/number, series, type, chapter, pages, address, edition, month, note.@incollection{izzo2019machine,  author={D. Izzo and C. I. Sprague and D. V. Tailor},  title={Machine learning and evolutionary techniques},  booktitle={Modeling and Optimization in Space Engineering},  publlisher={Springer},  address={Cham},  pages={191--210},  year={2019},}@inproceedings会议论文集中的一篇必要域: author, title, booktitle, year.可选域: editor, volume/number, series, pages, address, month, organization, publisher, note.@inproceedings{sommer2017temporal,  author={S. Sommer and J. Rosebrock and D. Cerutti-Maori},  title={Temporal analysis of Envisat’s rotational motion},  booktitle = {Proceedings of the 7th European Conference on SXX},  editor={},  address={Darmstadt, Germany},  publisher={IEEE},  year={1997},}@manual技术文档必要域: title.可选域: author, organization, address, edition, month, year, note.@mastersthesis硕士论文必要域: author, title, school, year.可选域: type, address, month, note.@misc其他必要域: none可选域: author, title, howpublished, month, year, note.@phdthesis博士论文必要域: author, title, year, school.可选域: address, month, keywords, note.@phdthesis{fbm2007zi,  Author = {丰保民},  title = {自由漂浮空间机器人轨迹规划与轨迹跟踪问题研究},  school = {哈尔滨工业大学},  address = {哈尔滨},  type = {},  month = {},  note = {},  year = {2007},}@proceedings会议论文集必要域: title, year.可选域: editor, volume/number, series, address, month, organization, publisher, note.@techreport教育，商业机构的技术报告必要域: author, title, institution, year.可选域: type, number, address, month, note.@unpublished未出版的论文，图书必要域: author, title, note.可选域: month, year.4.6. 引用章节名称首先在章节名称中添加label，如：\\section{最优控制的描述}\\label{section:zykzdms}然后在其他部分通过\\ref引用，如：如第\\ref{section:zykzdms}节所示编译后表现为：如第1.1节所示4.7. 列表有序列表\\begin{enumerate}\\item This is the first item\\item This is the second item\\item This is the third item\\end{enumerate}最终结果为1) this is the first item2) this is the second item3) this is the third item注意，数字后的符号选取（括号、顿号、句号等与模板有关）。无序列表\\begin{itemize}\\item This is the first item\\item This is the second item\\item This is the third item\\end{itemize}最终结果为  this is the first item  this is the second item  this is the third item5. 参考文献[1]  Latex Project. The LATEX Project."
  },
  
  {
    "title": "元学习文章阅读（MAML）",
    "url": "/posts/meta-learning-MAML/",
    "categories": "Academic, Paper",
    "tags": "deep learning, meta learning",
    "date": "2020-07-13 14:35:19 +0800",
    





    
    "snippet": "MAML 是2017年 Chelsea Finn 大佬提出的一种基于优化（Optimized-based）的小样本学习方法，核心在两个不同的数据集中分别计算梯度和更新参数。  1. MAML          1.1. 算法      1.2. 梯度下降数学分析      1.3. 基于优化的元学习目标      1.4. MAML数学分析      1.5. FOMAML      1.6...",
    "content": "MAML 是2017年 Chelsea Finn 大佬提出的一种基于优化（Optimized-based）的小样本学习方法，核心在两个不同的数据集中分别计算梯度和更新参数。  1. MAML          1.1. 算法      1.2. 梯度下降数学分析      1.3. 基于优化的元学习目标      1.4. MAML数学分析      1.5. FOMAML      1.6. 缺点        2. 各类实现  3. 参考文献1. MAML2017.《Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks》  The key idea underlying our method is to train the model’s initial parameters such that the model has maximal performance on a new task after the parameters have been updated through one or more gradient steps computed with a small amount of data from that new task.本文的设想是训练一组初始化参数，通过在初始参数的基础上进行一或多步的梯度调整，来达到仅用少量数据就能快速适应新task的目的。为了达到这一目的，训练模型需要最大化新task的loss function的参数敏感度（maximizing the sensitivity of the loss functions of new tasks with respect to the parameters），当敏感度提高时，极小的参数（参数量）变化也可以对模型带来较大的改进。本文提出的算法可以适用于多个领域，包括少样本的回归、图像分类，以及增强学习，并且使用更少的参数量达到了当时（2017年）最先进的专注于少样本分类领域的网络的准确率。核心算法示意图如下如上图所示，作者便将目标设定为，通过梯度迭代，找到对于task敏感的参数 $\\theta$ 。训练完成后的模型具有对新task的学习域分布最敏感的参数，因此可以在仅一或多次的梯度迭代中获得最符合新任务的  $\\theta^*$  ，达到较高的准确率。1.1. 算法假设这样一个监督分类场景，目的是训练一个数学模型 $M_{fine-tune}$ ，对未知标签的图片做分类，则两大步骤如下：  利用某一批数据集训练元模型 $M_{meta}$  在另外一批数据集上精调（fine-tune）得到最终的模型 $M_{fine-tune}$ 。MAML在监督分类中的算法伪代码如下：该算法是 meta-train 阶段，目的是得到 $M_{meta}$。下面进行详细分析：参考示意图如下，一个 task 表示为 $\\mathcal T$第一个Require，假设我们有一个很大的图像池，里面有很多很多类别的图像，每类图像有几十个。我们从中随机抽取五个类别，形成一个 task $\\mathcal T$，如此反复随机抽取可以得到一批（e.g. 1000个）task 作为训练集 $p(\\mathcal T)$。假设一个 $\\mathcal T$ 包含5类，每类20个样本，随机选5样本作为support set，剩余15样本为query set。  训练样本就这么多，要组合形成那么多的task，岂不是不同task之间会存在样本的重复？或者某些task的query set会成为其他task的support set？没错！就是这样！我们要记住，MAML的目的，在于fast adaptation，即通过对大量task的学习，获得足够强的泛化能力，从而面对新的、从未见过的task时，通过fine-tune就可以快速拟合。task之间，只要存在一定的差异即可。第二个Require，step size 就是学习率，MAML 是基于二重梯度（gradient by gradient），每次迭代有两次参数更新过程，所以有两个学习率可以调整。1：随机初始化模型参数 $\\theta$；2：循环，对于每个epoch，进行若干batch；3：随机选取若干个（比如4个） $\\mathcal T$  形成一个batch；4：对于每个batch中的第 $i$ 个 $\\mathcal T$ ，进行第一次梯度更新「inner-loop 内层循环」。5：选取 $\\mathcal T_i$ 中的 support set，共  $N\\cdot K$个样本（5-way 5-shot=25个样本）6：计算每个参数的梯度。原文写对每一个类下的 $K$ 个样本做计算。实际上参与计算的总计有 $N\\cdot K$ 个样本。这里的loss计算方法，在回归问题中就是MSE；在分类问题中就是cross-entropy；7：进行第一次梯度更新得到 $\\theta’$，可以理解为对 $\\mathcal T_i$ 复制一个原模型 $f(\\theta)$ 来更新参数；8：挑出训练集中的 query set 数据用于后续二次梯度更新；9：完成第一次梯度更新。10：进行第二次梯度更新，此时计算出的梯度直接通过GD作用于原模型上，用于更新其参数。「outer-loop 外层循环」大致与步骤 7 相同，但是不同点有三处：      隐含了二重梯度，需要计算 $\\mathcal L_{T_i}f(\\theta’)$ 对 $\\theta$ 的导数，而 $\\mathcal L_{T_i}f(\\theta’)$ 是 $\\theta’$ 的函数， $\\theta’$ 又是 $\\theta$ 的函数（见步骤7）；        不再分别利用每个 $\\mathcal T$ 的loss更新梯度，而是计算一个 batch 中模型 $L_{T_i}f(\\theta’)$ 的 loss 总和进行梯度下降；        参与计算的样本是task中的 query set（5way*15=75个样本），目的是增强模型在task上的泛化能力，避免过拟合support set。  11：结束在该batch中的训练，回到步骤3，继续采样下一个batch。总结：MAML使用训练集优化内层循环，使用测试集优化模型，也就是外层循环。外层循环需要计算二重梯度（gradient by gradient）。1.2. 梯度下降数学分析定义神经网络模型的初始的参数为\\[\\boldsymbol{\\theta} = [\\theta_1,\\theta_2,...,\\theta_n]^T\\]假设随机选取的一批任务为 $\\tau$，包含 10 个样本，每个样本输入 6 个量，输出 4 个量。神经网络即为一个 6 输入 2 输出的网络。样本输入矩阵为（行是样本，列是输入维度）\\[\\boldsymbol M_{in} = \\begin{bmatrix} ^1x_1&amp;  ^1x_2&amp;  \\cdots&amp; ^1x_6\\\\  ^2x_1&amp;  ^2x_2&amp;  \\cdots&amp; ^2x_6 \\\\  \\vdots&amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  ^{10}x_1&amp; ^{10}x_2&amp;  \\cdots&amp; ^{10}x_6\\end{bmatrix}\\]同理，输出矩阵为\\[\\boldsymbol M_{out} = \\begin{bmatrix} ^1y_1&amp;  ^1y_2&amp;  \\cdots&amp; ^1y_4\\\\  ^2y_1&amp;  ^2y_2&amp;  \\cdots&amp; ^2y_4 \\\\  \\vdots&amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  ^{10}y_1&amp; ^{10}y_2&amp;  \\cdots&amp; ^{10}y_4\\end{bmatrix}\\]对于参数为 $\\boldsymbol \\theta$ 的模型，其预测输出矩阵为\\[\\boldsymbol M_{pred}(\\boldsymbol \\theta) = \\begin{bmatrix} ^1\\hat{y}_1(\\boldsymbol \\theta)&amp;  ^1\\hat{y}_2(\\boldsymbol \\theta)&amp;  \\cdots&amp; ^1\\hat{y}_4(\\boldsymbol \\theta)\\\\  ^2\\hat{y}_1(\\boldsymbol \\theta)&amp;  ^2\\hat{y}_2(\\boldsymbol \\theta)&amp;  \\cdots&amp; ^2\\hat{y}_4(\\boldsymbol \\theta) \\\\  \\vdots&amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\  ^{10}\\hat{y}_1(\\boldsymbol \\theta)&amp; ^{10}\\hat{y}_2(\\boldsymbol \\theta)&amp;  \\cdots&amp; ^{10}\\hat{y}_4(\\boldsymbol \\theta)\\end{bmatrix}\\]定义一个损失函数 $L_\\tau$ 来衡量模型在任务 $\\tau$ 上的性能（即模型预测输出与期望输出间的距离），可以采用 MSE 来表征，注意到损失函数是关于模型参数的函数\\[L_\\tau(\\boldsymbol \\theta) = MSE_\\tau = \\frac{1}{10\\cdot4} \\cdot [\\frac{1}{2} \\sum_i^{10} \\sum_j^{4}(^i\\hat{y}_j(\\boldsymbol \\theta) - {}^iy_j)^2]\\]如何使得模型的预测输出与期望输出的距离变小呢？按照梯度下降方法（GD），我们可以计算损失函数 $L_\\tau(\\boldsymbol \\theta)$ 关于模型参数 $\\boldsymbol \\theta$ 的梯度，然后沿着这个梯度的负方向更新模型参数即可。假设损失函数关于模型参数的梯度为 $\\boldsymbol g$，则\\[\\begin{aligned}\\boldsymbol g = \\nabla_{\\boldsymbol \\theta} L_\\tau(\\boldsymbol \\theta) = \\frac{\\partial L_\\tau(\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta} = \\begin{bmatrix}\\partial L_\\tau(\\boldsymbol \\theta) / \\partial \\theta_1\\\\ \\partial L_\\tau(\\boldsymbol \\theta) / \\partial \\theta_2\\\\ \\vdots\\\\ \\partial L_\\tau(\\boldsymbol \\theta) / \\partial \\theta_n\\end{bmatrix}\\end{aligned}\\]我们可以计算1次梯度下降，也可以计算多次。假设 $\\boldsymbol g_1$ 是在原始模型参数上进行第1次梯度计算，有\\[\\begin{aligned}\\boldsymbol g_1 &amp; =  \\nabla_{\\boldsymbol \\theta} L_\\tau(\\boldsymbol \\theta_0)\\\\\\boldsymbol \\theta_1 &amp;= \\boldsymbol \\theta_0 - \\alpha \\boldsymbol g_1\\end{aligned}\\]其中，$\\boldsymbol \\theta_1$ 表示经过1次梯度更新后的模型参数，后文以此类推。第2次梯度计算建立在第1次梯度计算的基础上，有\\[\\begin{aligned}\\boldsymbol g_2 &amp;= \\nabla_{\\boldsymbol \\theta_1} L_\\tau(\\boldsymbol \\theta_1)\\\\\\boldsymbol \\theta_2 &amp;= \\boldsymbol \\theta_1 - \\alpha \\boldsymbol g_2\\\\&amp; = \\boldsymbol \\theta_0 - \\alpha \\boldsymbol g_1 - \\alpha \\boldsymbol g_2\\end{aligned}\\]我们将1次，2次，…，直到 $k$ 次梯度计算的过程统一列写如下：\\[\\begin{aligned}initialization:\\quad&amp;\\boldsymbol \\theta_0 = \\boldsymbol \\theta\\\\1^{st}\\;gradient\\;step:\\quad&amp;\\boldsymbol \\theta_1 = U^1_\\tau(\\boldsymbol \\theta)=\\boldsymbol \\theta - \\alpha \\boldsymbol g_1\\\\2^{nd}\\;gradient\\;step:\\quad&amp;\\boldsymbol \\theta_2 = U^2_\\tau(\\boldsymbol \\theta)=\\boldsymbol \\theta- \\alpha \\boldsymbol g_1- \\alpha \\boldsymbol g_2\\\\...&amp;...\\\\k^{th}\\;gradient\\;step:\\quad&amp;\\boldsymbol \\theta_k = U^k_\\tau(\\boldsymbol \\theta)=\\boldsymbol \\theta- \\alpha \\boldsymbol g_1- \\alpha \\boldsymbol g_2-...- \\alpha \\boldsymbol g_k\\\\&amp;\\boldsymbol g_k = \\nabla_{\\boldsymbol \\theta_{k-1}} L_\\tau(\\boldsymbol \\theta_{k-1})\\end{aligned}\\]其中，模型参数 ${}^k_\\tau\\boldsymbol \\theta$ 表示模型参数已经在任务数据 $\\tau$ 上经过 $k$ 次更新，$U^k_\\tau$ 是一个梯度算子，定义为在数据 $\\tau$ 进行 $k$ 次更新，$U^k_\\tau(\\boldsymbol \\theta)={}^{k}_\\tau \\boldsymbol \\theta$。1.3. 基于优化的元学习目标MAML 的目标是：找寻一组模型初始参数 $\\boldsymbol \\theta$，使得模型在面对随机选取的新任务 $\\tau$ 时，经过 $k$ 次梯度更新，在 $\\tau$ 上的损失函数就能达到很小。  We consider the optimization problem of MAML: find an initial set of parameters, $\\boldsymbol \\theta$, such that for a randomly sampled task $\\tau$ with corresponding loss $L_\\tau$, the learner will have low loss after $k$ updates. ——–[Reptile]用数学语言描述，即\\[\\begin{aligned}\\mathop{minimize}_{\\theta} \\; \\mathbb E_{\\tau}[L_{\\tau}(^{k}_\\tau\\boldsymbol \\theta)]= \\mathop{minimize}_{\\theta} \\; \\mathbb E_{\\tau}[L_{\\tau}(U^k_\\tau(\\boldsymbol \\theta))]\\end{aligned}\\]其中，${}^{k}_\\tau \\boldsymbol \\theta$ 是在任务 $\\tau$ 上经过 $k$ 次更新后的模型参数。在前面的梯度数学分析中，我们省略了下标 $\\tau$，因为梯度计算和损失函数计算默认都是对同一批数据，但是在这里加上下标，是因为后面 MAML 并不在同一批数据上计算梯度和计算损失函数，需要下标做区分。这里说的是 MAML 的目标，是因为截至 MAML 文章发表，人们还没有建立起元学习的框架概念，后来人们将 MAML 等寻找最优模型初始参数的方法称作 基于优化的元学习问题（Optimization-based Meta-Learning）的方法，上述数学描述也就成为整个问题的共同目标。1.4. MAML数学分析假设任务 $\\tau$ 可以分解为两个互不相交的数据子集 A（比如包含7个样本） 和 B（包含3个样本），MAML 通过进行 $k=1$ 次梯度算子更新，将上述问题转化为如下问题。省略 $U$ 的上标 $k$，有\\[\\begin{aligned}\\mathop{minimize}_{\\theta} \\; \\mathbb E_{\\tau}[L_{B}(U_{A}(\\boldsymbol \\theta))]\\end{aligned}\\]即 MAML 在数据集 A 上训练，在数据集 B 上计算损失函数 $L_{B}(U_{A}(\\boldsymbol \\theta))$，使得其最小。MAML 中只进行 $k=1$ 次梯度算子更新，作者号称有如下四个原因：      Meta Learning会快很多；        如果能让模型只经过一次梯度下降就性能优秀，当然很好；        Few-shot learning的数据有限，多次梯度下降很容易过拟合；        刚才说的可以在实际应用中多次梯度下降。  为了使损失函数最小，需要计算损失函数对模型原始参数 $\\boldsymbol \\theta$ 的梯度 $\\boldsymbol g_{MAML}$，然后在梯度负方向更新参数。 即\\[\\boldsymbol g_{MAML} = \\nabla_{\\boldsymbol \\theta} L_{B}(U_{A}(\\boldsymbol \\theta))\\]注意到\\[U^{k=1}_\\tau(\\boldsymbol \\theta)={}\\tau \\boldsymbol \\theta_1\\]省略 $k$，那么\\[\\begin{aligned}\\boldsymbol g_{MAML} &amp;= \\nabla_{\\boldsymbol \\theta} L_{B}(U_{A}(\\boldsymbol \\theta))= \\frac{\\partial}{\\partial \\boldsymbol \\theta} L_{B}(U_{A}(\\boldsymbol \\theta))\\\\&amp;= L_{B}'({}_{A}\\boldsymbol \\theta_1) U_{A}'(\\boldsymbol \\theta)\\quad where \\quad {}_{A} \\boldsymbol \\theta_1 = U_{A}(\\boldsymbol \\theta)\\end{aligned}\\]上式中，第一项是使用 A 数据进行一次梯度更新后的模型参数计算损失函数，然后在 B 数据上计算损失函数的导数，这里的导数是对更新后的模型参数求的，因此这一项比较好求。下面计算第二项 $U’_{A}(\\boldsymbol \\theta)$。前面算子更新时我们知道\\[U^1_\\tau(\\boldsymbol \\theta)=\\boldsymbol \\theta - \\alpha \\boldsymbol g_1\\]那么有\\[U_{A}'(\\boldsymbol \\theta) = \\frac{\\partial U_{A}(\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta}= \\frac{\\partial \\boldsymbol \\theta}{\\partial \\boldsymbol \\theta}-\\alpha \\frac{\\partial \\boldsymbol g_1}{\\partial \\boldsymbol \\theta}\\]下面分析第一项 $\\frac{\\partial \\boldsymbol \\theta}{\\partial \\boldsymbol \\theta}$ 的展开，注意到 $\\boldsymbol \\theta = [\\theta_1,\\theta_2,…,\\theta_n]^T$ 的定义，那么该项展开即为 $\\boldsymbol \\theta$ 的每个分量对其自身求偏导，需要分情况讨论\\[\\begin{aligned}\\frac{\\partial \\theta_i}{\\partial \\theta_j} = \\left\\{\\begin{matrix}1 \\quad i=j\\\\ 0 \\quad i \\neq j\\end{matrix}\\right.\\end{aligned}\\]那么第一项即为 $n\\times n$ 单位阵（可以看作一个特殊的 Jacobian 矩阵）\\[\\begin{aligned}\\frac{\\partial \\boldsymbol \\theta}{\\partial \\boldsymbol \\theta} = \\begin{bmatrix}1\\;0\\;\\cdots \\; 0\\\\0\\;1\\;\\cdots \\; 0\\\\\\vdots\\;\\vdots\\;\\ddots \\; \\vdots\\\\0\\;0\\;\\cdots \\; 1\\end{bmatrix} = \\boldsymbol I_{n \\times n}\\end{aligned}\\]然后分析第二项的展开。根据前文知\\[\\begin{aligned}\\boldsymbol g_1 = \\frac{\\partial L_\\tau(\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta} = \\begin{bmatrix}\\partial L_\\tau(\\boldsymbol \\theta) / \\partial \\theta_1\\\\ \\partial L_\\tau(\\boldsymbol \\theta) / \\partial \\theta_2\\\\ \\vdots\\\\ \\partial L_\\tau(\\boldsymbol \\theta) / \\partial \\theta_n\\end{bmatrix}\\end{aligned}\\]代入第二项有\\[\\begin{aligned}\\alpha \\frac{\\partial \\boldsymbol g_1}{\\partial \\boldsymbol \\theta} &amp;= \\alpha \\frac{\\partial L_\\tau(\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta} / \\partial \\boldsymbol \\theta\\\\&amp; = \\alpha \\begin{bmatrix}\\partial L_\\tau(\\boldsymbol \\theta) / \\partial \\theta_1\\\\ \\partial L_\\tau(\\boldsymbol \\theta) / \\partial \\theta_2\\\\ \\vdots\\\\ \\partial L_\\tau(\\boldsymbol \\theta) / \\partial \\theta_n\\end{bmatrix} / \\partial \\boldsymbol \\theta\\\\&amp; = \\alpha \\begin{bmatrix}    \\partial (\\frac{\\partial L_{A}}{\\partial \\theta_1}) / \\partial \\theta_1 &amp;  \\partial (\\frac{\\partial L_{A}}{\\partial \\theta_1}) / \\partial \\theta_2&amp;  \\cdots &amp; \\partial (\\frac{\\partial L_{A}}{\\partial \\theta_1}) / \\partial \\theta_n \\\\     \\partial (\\frac{\\partial L_{A}}{\\partial \\theta_2}) / \\partial \\theta_1 &amp;  \\partial (\\frac{\\partial L_{A}}{\\partial \\theta_2}) / \\partial \\theta_2&amp;  \\cdots &amp; \\partial (\\frac{\\partial L_{A}}{\\partial \\theta_2}) / \\partial \\theta_n \\\\     \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\    \\partial (\\frac{\\partial L_{A}}{\\partial \\theta_n}) / \\partial \\theta_1 &amp;  \\partial (\\frac{\\partial L_{A}}{\\partial \\theta_n}) / \\partial \\theta_2&amp;  \\cdots &amp; \\partial (\\frac{\\partial L_{A}}{\\partial \\theta_n}) / \\partial \\theta_n \\\\     \\end{bmatrix}_{n \\times n}\\\\&amp;= \\alpha \\begin{bmatrix}    \\partial^2 L_{A} / \\partial \\theta_1^2 &amp;  \\partial^2 L_{A} /\\partial \\theta_1 \\partial \\theta_2 &amp;  \\cdots &amp; \\partial^2 L_{A} /\\partial \\theta_1 \\partial \\theta_n \\\\     \\partial^2 L_{A} /\\partial \\theta_2 \\partial \\theta_1 &amp;  \\partial^2 L_{A} / \\partial \\theta_2^2 &amp;  \\cdots &amp; \\partial^2 L_{A} /\\partial \\theta_2 \\partial \\theta_n \\\\     \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\    \\partial^2 L_{A} /\\partial \\theta_n \\partial \\theta_1 &amp;  \\partial^2 L_{A} /\\partial \\theta_n \\partial \\theta_2&amp;  \\cdots &amp; \\partial^2 L_{A} / \\partial \\theta_n^2 \\\\     \\end{bmatrix}_{n \\times n}\\\\&amp;= \\alpha \\boldsymbol H_{A}(\\boldsymbol \\theta)_{n \\times n}\\end{aligned}\\]（向量对向量求偏导，是向量的每个分量对另一个向量的每个分量求偏导后形成矩阵，就是Hessian 矩阵！Hessian 等价于梯度的 Jacobian 矩阵。——Ian Goodfellow所著的《Deep Learning》的P78）最终计算得到的第二项 $U_{A}’(\\boldsymbol \\theta)$的表达式为\\[\\begin{aligned}U_{A}'(\\boldsymbol \\theta) &amp;= \\frac{\\partial U_{A}(\\boldsymbol \\theta)}{\\partial \\boldsymbol \\theta}= \\frac{\\partial \\boldsymbol \\theta}{\\partial \\boldsymbol \\theta}-\\alpha \\frac{\\partial \\boldsymbol g_1}{\\partial \\boldsymbol \\theta}\\\\&amp;= \\boldsymbol I_{n \\times n} - \\alpha \\boldsymbol H_{A}(\\boldsymbol \\theta)_{n \\times n}\\end{aligned}\\]MAML 的作者表示，大部分计算量都在于计算 $H_{A}(\\boldsymbol \\theta)_{n \\times n}$ 这个包含二重梯度的 Hessian 矩阵，导致 MAML 的计算量很大，使得 MAML 以难以训练成名。那么当进行 $k&gt;1$ 次梯度算子更新时又会怎样呢？（作者：我不要面子的？）我们将1次，2次，…，直到 $k$ 次梯度计算的过程改写如下（注意到这里采用数据集 A 来更新参数 $\\boldsymbol\\theta$，但是在式中我们省略了左下标 A）：\\[\\begin{aligned}initialization:\\quad&amp;\\boldsymbol \\theta_0 = \\boldsymbol \\theta\\\\1^{st}\\;gradient\\;step:\\quad&amp;\\boldsymbol \\theta_1 = U^1_A(\\boldsymbol \\theta)=\\boldsymbol \\theta_0 - \\alpha \\boldsymbol g_1\\\\2^{nd}\\;gradient\\;step:\\quad&amp;\\boldsymbol \\theta_2 = U^2_A(\\boldsymbol \\theta)=\\boldsymbol \\theta_1 - \\alpha \\boldsymbol g_2\\\\...&amp;...\\\\k^{th}\\;gradient\\;step:\\quad&amp;\\boldsymbol \\theta_k = U^k_A(\\boldsymbol \\theta)=\\boldsymbol \\theta_{k-1}- \\alpha \\boldsymbol g_k\\\\&amp;\\boldsymbol g_k = \\nabla_{\\boldsymbol \\theta_{k-1}} L_\\tau(\\boldsymbol \\theta_{k-1})\\end{aligned}\\]在外循环中，假设只使用一个task来更新参数，省略求和号，有\\[\\boldsymbol \\theta \\leftarrow \\boldsymbol \\theta - \\beta \\cdot \\boldsymbol g_{MAML}\\]其中\\[\\begin{aligned}\\boldsymbol g_{MAML} &amp;= \\nabla_{\\boldsymbol \\theta} L_{B}(U^k_{A}(\\boldsymbol \\theta))\\\\&amp;= \\nabla_{\\boldsymbol \\theta} L_{B}(\\boldsymbol \\theta_k)\\\\&amp;= \\nabla_{\\boldsymbol \\theta_k} L_{B}(\\boldsymbol \\theta_k)\\cdot(\\nabla_{\\boldsymbol \\theta}\\boldsymbol \\theta_k)\\\\&amp;= \\nabla_{\\boldsymbol \\theta_k} L_{B}(\\boldsymbol \\theta_k)\\cdot(\\nabla_{\\boldsymbol \\theta_{k-1}}\\boldsymbol \\theta_k) \\cdots (\\nabla_{\\boldsymbol \\theta_{1}}\\boldsymbol \\theta_2)\\cdot (\\nabla_{\\boldsymbol \\theta_{0}}\\boldsymbol \\theta_1)\\\\&amp;= \\nabla_{\\boldsymbol \\theta_k} L_{B}(\\boldsymbol \\theta_k)\\cdot\\prod_{i=1}^k (\\nabla_{\\boldsymbol \\theta_{i-1}}\\boldsymbol \\theta_i)\\\\&amp;= \\nabla_{\\boldsymbol \\theta_k} L_{B}(\\boldsymbol \\theta_k)\\cdot\\prod_{i=1}^k (\\nabla_{\\boldsymbol \\theta_{i-1}}(\\boldsymbol \\theta_{i-1}- \\alpha \\boldsymbol g_i))\\\\&amp;= \\nabla_{\\boldsymbol \\theta_k} L_{B}(\\boldsymbol \\theta_k)\\cdot\\prod_{i=1}^k (\\nabla_{\\boldsymbol \\theta_{i-1}}(\\boldsymbol \\theta_{i-1}- \\alpha (\\nabla_{\\boldsymbol \\theta_{i-1}} L_\\tau(\\boldsymbol \\theta_{i-1})))\\\\&amp;= \\nabla_{\\boldsymbol \\theta_k} L_{B}(\\boldsymbol \\theta_k)\\cdot\\prod_{i=1}^k (\\boldsymbol I - \\alpha \\nabla_{\\boldsymbol \\theta_{i-1}} (\\nabla_{\\boldsymbol \\theta_{i-1}} L_\\tau(\\boldsymbol \\theta_{i-1})))\\\\\\end{aligned}\\]当 $k=1$ 时我们发现，后面的连乘项就退化为前面已经推得的 Hessian 矩阵了\\[\\begin{aligned}\\prod_{i=1}^{k=1} (\\boldsymbol I - \\alpha \\nabla_{\\boldsymbol \\theta_{i-1}} (\\nabla_{\\boldsymbol \\theta_{i-1}} L_\\tau(\\boldsymbol \\theta_{i-1}))) &amp;= \\boldsymbol I - \\alpha \\nabla_{\\boldsymbol \\theta_0} \\nabla_{\\boldsymbol \\theta_0} L_\\tau\\boldsymbol (\\theta_0)\\\\&amp; = \\boldsymbol I - \\alpha \\boldsymbol H_{A}(\\boldsymbol \\theta)\\\\\\end{aligned}\\]则\\[\\boldsymbol g_{MAML} = \\nabla_{\\boldsymbol \\theta_k} L_{B}(\\boldsymbol \\theta_k) \\cdot (\\boldsymbol I - \\alpha \\boldsymbol H_{A}(\\boldsymbol \\theta))\\]1.5. FOMAML为了降低二重梯度导致的巨大计算量，作者提出了一种将二重梯度简化计算为一重梯度的方法，即 First-Order MAML (FOMAML)。FOMAML 假设学习率 $\\alpha \\rightarrow 0^+$，则前面与 $\\alpha$ 相乘的项（$k=1$ 时是 Hessian 矩阵，$k&gt;1$ 时是连乘项）因为乘以 $0^+$ 被消去。那么整个 $U_{A}’(\\boldsymbol \\theta)$ 就等于单位阵了，此时 FOMAML 的梯度即为\\[\\boldsymbol g_{FOMAML} = L'_{B}({}_A\\boldsymbol \\theta_k)=\\nabla_{\\boldsymbol \\theta_k} L_{B}({}_A\\boldsymbol \\theta_k)\\]也即仅用最后一次更新的模型参数 $_{A}\\boldsymbol \\theta_k$ 计算梯度。那么，进行 $k=1$ 次梯度算子更新的 FOMAML 的实现过程就很简单了：  采样任务 $\\tau$；  计算在数据集 A 上的梯度因子 $U^{k=1}_{A}(\\boldsymbol \\theta)= _{A} \\boldsymbol \\theta_1 = \\phi$;  计算在数据集 B 上的损失函数 $L_{B}$ 对 $\\phi$ 的（偏）导数：$g_{FOMAML}=\\nabla_{\\phi} L_{B}(\\phi)$；  将 $g_{FOMAML}$ 插入外循环更新参数。简化后的 FOMAML 模型参数更新式为：\\[\\begin{aligned}\\theta_i' \\leftarrow \\theta - \\alpha \\nabla_\\theta L_{Ai}(\\theta)\\\\\\theta \\leftarrow \\theta - \\beta \\nabla_{\\theta'} \\sum L_B(\\theta')\\\\\\end{aligned}\\]可以看出只需要计算一重梯度即可，作者在文中号称约节省了33%的计算量。  This approximation removes the need for computing Hessian-vector products in an additional backward pass, which we found led to roughly 33% speed-up in network computation.一阶近似的MAML可以看作是如下形式的参数更新：假设每个batch只有一个task，某次采用第m个task来更新模型参数，得到$\\hat\\theta^m$，再求一次梯度，沿着该梯度方向更新模型的原始参数$\\phi$，将其从 $\\phi^0$ 更新至 $\\phi^1$，以此类推。与之相比，右边是模型预训练方法，它是将参数根据每次的训练任务一阶导数的方向来更新参数。1.6. 缺点MAML的缺点[2]：      Hard to train：paper中给出的backbone是4层的conv加1层linear，试想，如果我们换成16层的VGG，每个task在算fast parameter的时候需要计算的Hessian矩阵将会变得非常大。那么你每一次迭代就需要很久，想要最后的model收敛就要更久。        Robustness一般：不是说MAML的robustness不好，因为也是由一阶online的优化方法SGD求解出来的，会相对找到一个flatten minima location。然而这和非gradient-based meta learning方法求解出来的model的robust肯定是没法比的。  2. 各类实现dragen-1860 的 Pytorch 实现：https://github.com/dragen1860/MAML-PytorchTensorflow实现：https://github.com/dragen1860/MAML-TensorFlow3. 参考文献[1]  Rust-in. MAML 论文及代码阅读笔记.[2] 人工智障. MAML算法，model-agnostic metalearnings?[3] Veagau. 【笔记】Reptile-一阶元学习算法[4] pure water. Reptile原理以及代码详解[5] Tianhao Wei翻译自Lilian.元学习：学习如何学习【译】"
  },
  
  {
    "title": "元学习基础",
    "url": "/posts/meta-learning-basic/",
    "categories": "Academic, Knowledge",
    "tags": "deep learning, meta learning",
    "date": "2020-07-12 14:35:19 +0800",
    





    
    "snippet": "小样本学习（Few-Shot Learning）问题是一个新兴的机器学习问题，旨在研究当样本个数严重不足时，如何训练一个模型，能够快速的完成学习（分类、回归、强化学习等）任务。进一步引入元学习的思想来解决小样本学习问题。  1. 小样本学习问题  2. 元学习方法  3. 训练过程          3.1. 深度学习的训练过程      3.2. 元学习的训练过程        4. 参考...",
    "content": "小样本学习（Few-Shot Learning）问题是一个新兴的机器学习问题，旨在研究当样本个数严重不足时，如何训练一个模型，能够快速的完成学习（分类、回归、强化学习等）任务。进一步引入元学习的思想来解决小样本学习问题。  1. 小样本学习问题  2. 元学习方法  3. 训练过程          3.1. 深度学习的训练过程      3.2. 元学习的训练过程        4. 参考文献1. 小样本学习问题Few-Shot Learning (FSL)众所周知，现在的主流的传统深度学习技术需要大量的数据来训练一个好的模型。例如典型的 MNIST 分类问题，一共有 10 个类（“0”~“9”，一共10类数字），训练集一共有 6000 个样本，平均下来每个类大约 600 个样本。但是我们想一下我们人类自己，我们区分 0 到 9 的数字图片的时候需要看 6000 张图片才知道怎么区分吗？很显然，不需要！这表明当前的深度学习技术和我们人类智能差距还是很大的，要想弥补这一差距，少样本学习是一个很关键的问题。另外还有一个重要原因是如果想要构建新的数据集，还是举分类数据集为例，我们需要标记大量的数据，但是有的时候标记数据集需要某些领域的专家（例如医学图像的标记），这费时又费力，因此如果我们可以解决FSL问题，只需要每个类标记几张图片就可以高准确率的给剩余大量图片自动标记。这两方面的原因都让FSL问题很吸引人。总结一下，传统的深度学习问题存在两个弊端：      与当前人脑智能存在差距，即人脑无需大量样本即可很好的完成分类等任务，而深度神经网络不行；        某些情况下产生大量标记样本代价很大，只能产生很小量的标记样本用以学习。  下面我们来看一张图，这张图来自论文《Optimization as a Model for Few-Shot Learning》，左边是训练集一共 5 张图片来自 5 个类，每个类只有1张图片。右边是测试集，理论上可以有任意多个图片用于测试，图中只给出了两张实例。如果采用传统的深度学习方法，必须能够提供大量 $D_{train}$ 样本图像，比如上图中需要提供大量鸟类、坦克、狗、人、钢琴的图像，才能训练出一个比较好的深度神经网络，使得网络能够以较高的准确率分辨 $D_{test}$ 中的图像。但是如果无法提供大量图像，那么就会出现严重的过拟合（over-fitting）问题，即因为训练的样本太少了，训练出的模型可能在训练集上效果还行，但是在测试集上面会遭遇灾难性的崩塌。或者换句话说，只有给模型提供训练集中的图片时才能正确分类，提供测试集中存在一定差异的相似图片就无法正确分类。因此，FSL问题的关键是解决过拟合 (overfitting) 的问题，一般可以采用元学习的方法来解决FSL问题。在 FSL 中有一个术语叫做 N-way K-shot，简单的说就是我们需要分类的样本属于 N 个类中一种，但是我们每个类训练集中的样本只有 K 个，即一共只有 N$\\cdot$K 个样本的类别是已知的。上图就是一个 5-way 1-shot 的问题。2. 元学习方法Meta-Learning元学习又被称为学会学习（Learn to learn)，其核心想法是先学习一个先验知识（prior），这个先验知识对解决 FSL 问题特别有帮助。以下面这张图为例，为了学习如何从很少的样本中正确的识别分类“狮子”和“碗”（Meta-Test），首先提供一堆其它不同类别的图像（Meta-Train），喂给神经网络进行训练，期望它能够学到区分不同类别的先验知识，然后当提供包含狮子和碗在内的任务时，能够通过少量的微调，快速得到分类准确的模型。Meta-learning 中有一个术语叫 task ，比如上面图片，是一个 5-way 1-shot 问题，其中每一行 5-way 1-shot 就是一个 task，我们需要先学习很多很多这样的 task，然后再来解决这个新的 task 。最最最重要的一点，这是一个新的 task，这个新的 task 中的类别是之前我们学习过的 task 中没有见过的！ 在 Meta-learning 中之前学习的 task 我们称为 meta-train task，我们遇到的新的 task 称为 meta-test task。因为每一个 task 都有自己的训练集和测试集，因此为了不引起混淆，我们把 task 内部的训练集和测试集一般称为 support set 和 query set。  N-way K-shot：样本包含 N 个类，每个类中的样本只有 K 个，一共有 N$\\cdot$K 个样本  task (meta-task)：任务，一个特定的 N-way K-shot 的任务就是一个 task  meta-train：元训练  meta-test：元测试  meta-train task: 元训练阶段的任务          support set：元训练阶段的训练集      query set：元训练阶段的测试集        meta-test：元测试阶段          train set：元测试阶段的训练集      test set：元测试阶段的测试集      上图展示了 2-way 4-shot 的分类问题。N=2，K=4。希望得到一个模型，能够快速从dogs和otters中进行识别区分。Few-shot Learning 是 Meta Learning 在监督学习领域的应用。在 meta-training 阶段，将数据集分解为不同的 task，去学习类别变化的情况下模型的泛化能力。在 meta-testing 阶段，面对全新的类别，不需要变动已有的模型，只需要通过一步或者少数几步训练，就可以完成分类。3. 训练过程上面已经初步介绍了 Meta-learning 的概念和术语，那么究竟元学习与传统深度学习的差异在哪里，使得元学习能够胜任 FSL 问题呢？3.1. 深度学习的训练过程以分类任务为例，首先介绍一下传统深度学习的训练过程，假设我们要训练一个深度神经网络去分类猫和狗。我们需要构造一个数据集，其中包含一堆类，比如“老虎”、“蜥蜴”、“自行车”、“灰机”、以及“猫”和“狗”等等。每个类包含5000个不同的图像，然后划分为两大部分，4000张图像为训练集，1000张图像为测试集：  先取一个已标记的图像D1（“Dog no.1”表示第1张狗狗图像），训练网络，正向传播可以计算出一个loss，反向传播可以计算出loss对原始模型参数的梯度；  设定一个学习率，可以用上述计算出的梯度的负方向乘以学习率来更新原始模型参数；  再取一个已标记图像C5（“Cat no.5”表示第5张猫猫图像），重复上述过程；  对训练集中的所有图像都训练完后，拿测试集中的图像来测试，通过模型给出的分类与测试图像的标记做对比，统计准确率。可以看出，传统的深度学习训练过程，是拿训练集的样本对模型参数进行更新，然后用测试集的样本进行测试。3.2. 元学习的训练过程同样以分类任务为例，介绍元学习的训练过程，同样假设我们要训练一个深度神经网络去分类猫和狗，首先我们要构造一个数据集，其中包含一堆类，比如“老虎”、“蜥蜴”、“自行车”、“灰机”、以及“猫”和“狗”等等，但是每类的图像可能只有20个（区别于之前的5000个）。N-way K-shot 问题的具体训练过程如下：首先提供一个 few-shot 的数据集，该数据集一般包含了很多的类别，每个类别中又包含了很多个样本（图片）。对训练集进行划分，随机选出若干类别作为训练集，剩余类别作为测试集；meta-train 阶段：  在训练集中随机抽取 N 个类，每个类 K 个样本，为支持集（support set），剩余样本为问询集（query set）；          在query set 中，剩余样本不一定全都要用到，如下图只用了5类中的2类，每类1个样本；      support set 和 query set 构成一个 task；        每次采样一个 task 进行训练，称为一个 episode；一次性选取若干个task，构成一个batch；  一次 meta-train 可以训练多干个 batch（比如10000个）；  遍历所有 batch 后完成训练。meta-test 阶段：  在测试集中随机抽取 N 个类别，每个类别 K 个样本，作为 train set，剩余样本作为 test set；  用 support set 来 fine-tune 模型；  用 test set 来测试模型（这里的 test set 就是真正希望模型能够用于分类的数据）。上述训练过程中，每次训练（episode）都会采样得到不同 task，所以总体来看，训练包含了不同的类别组合，这种机制使得模型学会不同 task 中的共性部分，比如如何提取重要特征及比较样本相似等，忘掉 task 中 task 相关部分。通过这种学习机制学到的模型，在面对新的未见过的 task 时，也能较好地进行分类。在上述过程中，不同的元学习策略有不同的训练方法，如 MAML、FOMAML、Reptile 等。在后文中详细解读。4. 参考文献[1]  CaoChengtai. Few-shot learning（少样本学习）和 Meta-learning（元学习）概述."
  },
  
  {
    "title": "深度学习基础（PyTorch的数据集）",
    "url": "/posts/deep-learning-basic-dataloader/",
    "categories": "Academic, Knowledge",
    "tags": "deep learning, python, pytorch",
    "date": "2020-06-16 16:24:19 +0800",
    





    
    "snippet": "本文介绍了 Pytorch 中针对计算机视觉方面的基本数据库类Dataset，基本的手写数字数据库MNIST，以及数据库加载函数 DataLoader。  1. torchvision  2. Dataset          2.1. 默认类      2.2. 自定义类        3. DataLoader  4. MNIST  5. 参考文献1. torchvisiontorchv...",
    "content": "本文介绍了 Pytorch 中针对计算机视觉方面的基本数据库类Dataset，基本的手写数字数据库MNIST，以及数据库加载函数 DataLoader。  1. torchvision  2. Dataset          2.1. 默认类      2.2. 自定义类        3. DataLoader  4. MNIST  5. 参考文献1. torchvisiontorchvision 是 PyTorch 中专门用来处理图像的库，PyTorch 官网的安装教程也会让你安装上这个包。这个包中有四个大类。  torchvision.datasets  torchvision.models  torchvision.transforms  torchvision.utils这里我们主要介绍前三个。torchvision.datasets 是用来进行数据加载的，PyTorch团队在这个包中帮我们提前处理好了很多很多图片数据集。参考PyTorch中文文档中的相关介绍。  MNIST  COCO  Captions  Detection  LSUN  ImageFolder  Imagenet-12  CIFAR  STL10  SVHN  PhotoTour我们可以直接使用这些数据集，示例如下：mnist_train_data = torchvision.datasets.MNIST('mnist/', train=True, download=True, transform=ToTensor())train_loader = torch.utils.data.DataLoader(mnist_train_data, batch_size=16, shuffle=True)torchvision.datasets 是 torch.utils.data.Dataset 的一个子类，所以他们也可以通过 torch.utils.data.DataLoader 使用多线程（python的多进程）。比如torch.utils.data.DataLoader(coco_cap, batch_size=args.batchSize, shuffle=True, num_workers=args.nThreads)2. Dataset2.1. 默认类torch.utils.data.Dataset 是一个抽象类，是 Pytorch 中图像数据集中最为重要的一个类，也是 Pytorch 中所有数据集加载类中应该继承的父类。用户想要加载自定义的数据必须继承这个类，并且覆写其中的两个方法：      __len__：实现 len(dataset) 返回整个数据集的大小。        __getitem__：用来获取一些索引的数据，使 dataset[i] 返回数据集中第 i 个样本。  不覆写这两个方法会直接返回错误。这个类其实也就是起到了封装我们加载函数的作用，在继承了这个 Dataset 类之后，我们需要实现的核心功能便是 __getitem__()函数，__getitem__() 是 Python 中类的默认成员函数，我们通过实现这个成员函数实现可以通过索引来返回图像数据的功能。那么怎么得到图像从而去返回呢？当然不会直接将图像数据加载到内存中，相反我们只需要得到图像的地址就足够了，然后在调用的时候通过不同的读取方式读取即可。不同的读取方式参见 此处。2.2. 自定义类更多的时候我们需要使用自己的数据集，数据集的形式可能为原始图片、可能为数组。下面以原始图片为例创建自己的数据集。要创建用于分类的自定义数据集，需要准备两部分内容：      图片数据集        标签信息（可用txt文件、csv文件记录，或通过图片文件名划分）  下面是自定义一个Dataset的代码示例class CustomDataset(torch.utils.data.Dataset):# Need to inherit `data.Dataset`    def __init__(self):        # TODO        # 1. Initialize file path or list of file names.        pass    def __getitem__(self, index):        # TODO        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).        # 2. Preprocess the data (e.g. torchvision.Transform).        # 3. Return a data pair (e.g. image and label).        #这里需要注意的是，第一步：read one data，是一个data        pass    def __len__(self):        # You should change 0 to the total size of your dataset.        return 0按照上述模板定义一个自定义数据类，原始数据为 .jpg 图像。采用文件名来定义标签信息，图像文件的命名规范为：[label_no].[label_name].[image_num].jpg # '0.satellite.01.jpg' with label no '0' and label name 'satellite'即文件名由 . 分隔，第一个数字为 label 的编号，第二个字符串为标签名称。采用 scikit_image 包读取图像，则自定义数据类如下# DATA.pyimport numpy as npfrom skimage import io  # scikit-imagefrom torch.utils.data import Datasetimport osos.environ['KMP_DUPLICATE_LIB_OK']='True'def open_image(image_path):    return io.imread(image_path)  # load image by scikit-imageclass DATA(Dataset):    def __init__(self, root, train=True, augment=False, transform=None):        self.train = train        self.augment = augment        self.transform = transform        if self.train:            self.data = np.array([                x.path for x in os.scandir(root + \"train\\\\\")                if x.name.endswith(\".jpg\") or x.name.endswith(\".JPG\")            ])            filename = np.array([                os.path.split(x.path)[1] for x in os.scandir(root + \"train\\\\\")                if x.name.endswith(\".jpg\") or x.name.endswith(\".JPG\")            ])            self.label = np.array([int(x.split('.', 1)[0]) for x in filename])        else:            self.data = np.array([                x.path for x in os.scandir(root + \"test\\\\\")                if x.name.endswith(\".jpg\") or x.name.endswith(\".JPG\")            ])            filename = np.array([                os.path.split(x.path)[1] for x in os.scandir(root + \"test\\\\\")                if x.name.endswith(\".jpg\") or x.name.endswith(\".JPG\")            ])            self.label = np.array([int(x.split('.', 1)[0]) for x in filename])    def __getitem__(self, index):        label = self.label[index]        image = open_image(self.data[index])        if self.augment:            image = self.augment(image)  # augment images        if self.transform is not None:            image = self.transform(image)  # transform images        return image, label    def __len__(self):        return len(self.data)  # return image number在后续使用数据集时，形式如下for batch_index, (data, target) in dataloader:        if use_cuda:            data, target = data.cuda(), target.cuda()        data, target = Variable(data, volatile=True), Variable(target)为什么直接能用 for batch_index, (data, target) In dataloader 这样的语句呢？其实这个语句还可以这么写：for batch_index, batch in train_loader    data, target = batch这样就好理解了，因为这个迭代器每一次循环所得的batch里面装的东西，就是我在 __getitem__ 方法最后 return 回来的，所以想在训练或者测试的时候还得到其他信息的话，就去增加一些返回值即可，只要是能return出来的，就能在每个batch中读取到。3. DataLoadertorch.utils.data.DataLoader  的核心参数包括[1]：      dataset：Dataset，输入数据集；        batch_size：int，每批加载多少样本，default=1；        shuffle：bool，是否打乱顺序，default=False；        sampler：Sampler，定义从数据集中加载样本的策略，如果定义，则 shuffle 必须设为 False；        num_workers：int，采用多少个子进程加载数据集，0表示仅在主进程加载，default = 0；    pin_memory：如果设为 True，DataLoader 会将 tensors 会将拷贝到 CUDA 的锁页内存中，然后再返回它们，default = False；  drop_last：设为 True 扔掉最后一个不完整的 batch。如果数据集大小无法被 batch_size 整除，那么最后一披数据不完整，default = False；num_workers 这个参数必须大于等于0，0的话表示数据导入在主进程中进行，其他大于0的数表示通过多个进程来导入数据，可以加快数据导入速度。pin_memory 就是锁页内存，创建DataLoader时，设置 pin_memory=True，则意味着生成的Tensor数据最开始是属于内存中的锁页内存，这样将内存的Tensor转义到GPU的显存就会更快一些。主机中的内存，有两种存在方式，一是锁页，二是不锁页，锁页内存存放的内容在任何情况下都不会与主机的虚拟内存进行交换（注：虚拟内存就是硬盘），而不锁页内存在主机内存不足时，数据会存放在虚拟内存中。而显卡中的显存全部是锁页内存！当计算机的内存充足的时候，可以设置pin_memory=True。当系统卡住，或者交换内存使用过多的时候，设置pin_memory=False。因为pin_memory与电脑硬件性能有关，pytorch开发者不能确保每一个炼丹玩家都有高端设备，因此pin_memory默认为False。4. MNIST下面以手写数字数据集MNIST为例（介绍参考此处），首先获取训练集和测试集，在此下载。下载得到以下四个文件，即为数据集train-images-idx3-ubyte.gz: training set images (9912422 bytes)train-labels-idx1-ubyte.gz: training set labels (28881 bytes)t10k-images-idx3-ubyte.gz:  test set images (1648877 bytes)t10k-labels-idx1-ubyte.gz:  test set labels (4542 bytes)采用以下代码可以得到原始图片# extractimage.pyimport osfrom skimage import ioimport torchvision.datasets.mnist as mnistimport numpy root = \"./mnist/MNIST/raw/\" # replace directory according to yourself train_set = (    mnist.read_image_file(os.path.join(root, 'train-images-idx3-ubyte')),    mnist.read_label_file(os.path.join(root, 'train-labels-idx1-ubyte'))) test_set = (    mnist.read_image_file(os.path.join(root,'t10k-images-idx3-ubyte')),    mnist.read_label_file(os.path.join(root,'t10k-labels-idx1-ubyte'))) print(\"train set:\", train_set[0].size())print(\"test set:\", test_set[0].size()) def convert_to_img(train=True):    if(train):        f = open(root + 'train.txt', 'w')        data_path = root + '/train/'    else:        f = open(root + 'test.txt', 'w')        data_path = root + '/test/'    if (not os.path.exists(data_path)):        os.makedirs(data_path)    for i, (img, label) in enumerate(zip(test_set[0], test_set[1])):        img_path = data_path + str(int(label)) + '.' + str(i) + '.jpg'        io.imsave(img_path, img.numpy())        f.write(img_path + ' ' + str(label) + '\\n')    f.close() convert_to_img(True)convert_to_img(False)得到的原始图像如下采用以下代码即可进行训练# MNISTNET.pyfrom __future__ import print_functionimport argparseimport torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimfrom torchvision import datasets, transformsfrom DATA import DATAfrom skimage import ioimport numpy as npclass NUMNET(nn.Module):    def __init__(self):        super(NUMNET, self).__init__()        self.conv1 = nn.Conv2d(1, 20, 5, 1)        self.conv2 = nn.Conv2d(20, 50, 5, 1)        self.fc1 = nn.Linear(4*4*50, 500)        self.fc2 = nn.Linear(500, 10)    def forward(self, x): # &lt;- (1,28,28) MNIST image size        x = F.relu(self.conv1(x)) # -&gt; (20, 24, 24)        x = F.max_pool2d(x, 2, 2) # -&gt; (20, 12, 12)        x = F.relu(self.conv2(x)) # -&gt; (50, 8, 8)        x = F.max_pool2d(x, 2, 2) # -&gt; (50, 4, 4)        x = x.view(-1, 4*4*50) # -&gt; (1, 50*4*4)        x = F.relu(self.fc1(x)) # -&gt; (1, 500)        x = self.fc2(x)# -&gt; (500, 10)        return F.log_softmax(x, dim=1) # dim=0 makes sum of column values to be 1, dim=1 makes row ...   def train(args, model, device, train_loader, optimizer, epoch):    model.train() # enter train mode (used for batch normlization and dropout)    for batch_idx, (data, target) in enumerate(train_loader):        data, target = data.to(device), target.long().to(device)        optimizer.zero_grad()        output = model(data)        loss = F.nll_loss(output, target) # must have log_softmax as last        loss.backward()        optimizer.step()        if batch_idx % args.log_interval == 0:            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(                epoch, batch_idx * len(data), len(train_loader.dataset),                100. * batch_idx / len(train_loader), loss.item()))def test(args, model, device, test_loader):    model.eval()    test_loss = 0    correct = 0    with torch.no_grad():        for data, target in test_loader:            data, target = data.to(device), target.to(device)            output = model(data)            test_loss += F.nll_loss(output, target.long(), reduction='sum').item() # sum up batch loss            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability            correct += pred.eq(target.view_as(pred)).sum().item()    test_loss /= len(test_loader.dataset)    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(        test_loss, correct, len(test_loader.dataset),        100. * correct / len(test_loader.dataset)))def main():    # Training settings    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')    parser.add_argument('--batch-size', type=int, default=64, metavar='N',                        help='input batch size for training (default: 64)')    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',                        help='input batch size for testing (default: 1000)')    parser.add_argument('--epochs', type=int, default=50, metavar='N',                        help='number of epochs to train (default: 10)')    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',                        help='learning rate (default: 0.01)')    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',                        help='SGD momentum (default: 0.5)')    parser.add_argument('--no-cuda', action='store_true', default=False,                        help='disables CUDA training')    parser.add_argument('--seed', type=int, default=1, metavar='S',                        help='random seed (default: 1)')    parser.add_argument('--log-interval', type=int, default=10, metavar='N',                        help='how many batches to wait before logging training status')    parser.add_argument('--save-model', action='store_true', default=False,                        help='For Saving the current Model')    args = parser.parse_args()    use_cuda = not args.no_cuda and torch.cuda.is_available()    device = torch.device(\"cuda\" if use_cuda else \"cpu\")    torch.manual_seed(args.seed) # set random seed to make network reproduce same results    if use_cuda:        torch.cuda.manual_seed(args.seed)    kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}    root = \".\\\\mnist\\MNIST\\\\raw\\\\\" # directory where the above images are extracted, i.e. 'train' and 'test' folders    train_mean = 0.1307 # given by mnist providers    train_std = 0.3081 # given by mnist providers    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((train_mean,), (train_std,))])    train_loader = torch.utils.data.DataLoader(        DATA(root, train=True, transform=transform),        batch_size=args.batch_size, shuffle=True, **kwargs)    test_loader = torch.utils.data.DataLoader(        DATA(root, train=False, transform=transform),        batch_size=args.test_batch_size, shuffle=True, **kwargs)    model = NUMNET().to(device)    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)    for epoch in range(1, args.epochs + 1):        train(args, model, device, train_loader, optimizer, epoch)        test(args, model, device, test_loader)    if (args.save_model):        torch.save(model.state_dict(),\"mnist_cnn.pt\")       if __name__ == '__main__':    main()训练打印信息如下Train Epoch: 1 [0/10000 (0%)]   Loss: 2.304347Train Epoch: 1 [640/10000 (6%)] Loss: 2.240660Train Epoch: 1 [1280/10000 (13%)]       Loss: 2.177136Train Epoch: 1 [1920/10000 (19%)]       Loss: 1.999795Train Epoch: 1 [2560/10000 (25%)]       Loss: 1.730417Train Epoch: 1 [3200/10000 (32%)]       Loss: 1.335797Train Epoch: 1 [3840/10000 (38%)]       Loss: 0.853206Train Epoch: 1 [4480/10000 (45%)]       Loss: 0.866024Train Epoch: 1 [5120/10000 (51%)]       Loss: 0.649082Train Epoch: 1 [5760/10000 (57%)]       Loss: 0.667902Train Epoch: 1 [6400/10000 (64%)]       Loss: 0.581703Train Epoch: 1 [7040/10000 (70%)]       Loss: 0.314934Train Epoch: 1 [7680/10000 (76%)]       Loss: 0.493458Train Epoch: 1 [8320/10000 (83%)]       Loss: 0.477450Train Epoch: 1 [8960/10000 (89%)]       Loss: 0.652692Train Epoch: 1 [9600/10000 (96%)]       Loss: 0.406439......5. 参考文献[1]  cdy艳0917. Pytorch学习（三）定义自己的数据集及加载训练.[2]  teeyohuang. Pytorch打怪路（三）Pytorch创建自己的数据集1.[3]  Vincent Dumoulin, Francesco Visin. A guide to convolution arithmetic for deep learning (Github).[4] 知乎. PyTorch 中，nn 与 nn.functional 有什么区别？.[5]  PyTorch. MaxPool2d.[6]  PyTorch. nn.Linear."
  },
  
  {
    "title": "深度学习基础（PyTorch的CNN组成）",
    "url": "/posts/deep-learning-basic-conv2d/",
    "categories": "Academic, Knowledge",
    "tags": "python, pytorch, deep learning",
    "date": "2020-06-14 16:24:19 +0800",
    





    
    "snippet": "本文介绍了深度学习中，卷积网络的基本知识，包括2d卷积层、池化层、线性层、softmax 激活函数、交叉熵损失函数等，并结合它们在 Pytorch 中的定义和实现进行说明。  1. 层          1.1. Conv2d                  1.1.1. dilation          1.1.2. padding                    1.2. Ma...",
    "content": "本文介绍了深度学习中，卷积网络的基本知识，包括2d卷积层、池化层、线性层、softmax 激活函数、交叉熵损失函数等，并结合它们在 Pytorch 中的定义和实现进行说明。  1. 层          1.1. Conv2d                  1.1.1. dilation          1.1.2. padding                    1.2. MaxPool2d      1.3. Linear        2. 激活函数          2.1. conv2d      2.2. softmax      2.3. log_softmax        3. 损失函数          3.1. CrossEntropyLoss      3.2. NLLLoss        4. 参考文献1. 层1.1. Conv2dnn.Conv2d 的输入为 (batch_size, channel, height, width)。nn.Conv2d 的参数包括[1]：  in_channels：int，输入图片的通道数（彩色图像=3，灰度图像=1）；  out_channels：int，卷积输出图片的通道数（也就是卷积核个数）；  kernel_size：int或tuple，卷积核尺寸（赋值单个int时长=宽），default=1；  stride：int或tuple，卷积操作的滑动步长，default=1；  padding：int或tuple，输入图片外围扩充大小（赋值单个int时长=宽），default=0；当采取默认参数时，padding = (kernel_size - 1) /2 可保证输出图片与输入图片尺寸一致；  dilation：卷积核扩充大小，default=1；  groups：从输入通道到输出通道分组的个数，default=1；  bias：bool，输出增加偏差，default=True；假设输入数据为 $(N, C_{in}, H_{in},W_{in})$ （$N$ 张 $C_{in}$ 通道数的高 $H_{in}$ 宽 $W_{in}$ 的图片），对于输入的每一张图片，比如第 $N_i$ 张图片，输出特征图的通道数为 $C_{out}$，具体为\\[out(N_i,C_{out,j})=bias(C_{out,j}) + \\sum_{k=1}^{C_{in}}weight(C_{out,j},k)\\star input(N_i,k)\\]其中 $H_{out}$ 和 $H_{out}$ 为\\[\\begin{aligned}H_{out} &amp;= \\frac{H_{in} + 2\\times padding[0] - dilation[0]\\times (kernel\\_size[0]-1)-1} {stride[0]}+1 \\\\W_{out} &amp;= \\frac{W_{in} + 2\\times padding[1] - dilation[1]\\times (kernel\\_size[1]-1)-1}{stride[1]}+1\\end{aligned}\\]若采 $dilation = 1$，有\\[\\begin{aligned}H_{out} &amp;= \\frac{H_{in} + 2\\times padding[0] - kernel\\_size[0]}{stride[0]}+1 \\\\W_{out} &amp;= \\frac{W_{in} + 2\\times padding[1] - kernel\\_size[1]}{stride[1]}+1\\end{aligned}\\]若采用默认参数，有\\[\\begin{aligned}H_{out} = H_{in} - kernel\\_size[0] + 1 \\\\W_{out} = W_{in} - kernel\\_size[1] + 1\\end{aligned}\\]1.1.1. dilation注意，PyTorch 认为dilation=n 表示卷积核尺寸从 (1x1) 扩充为 nxn，其中原本的卷积核像素在左上角，其它像素填充为0。因此 dilation=1 等价于传统的无扩充的卷积[2]。如果我们设置的 padding=0, dilation=1 的话，蓝色为输入，绿色为输出，卷积核为3*3的卷积效果如图[3]：如果我们设置的 dilation=2 的话，卷积核点与输入之间距离为1的值相乘来得到输出这样单次计算时覆盖的面积（即感受域）由 dilation=0 时的 $3\\times 3=9$ 变为了 dilation=1 时的 $5\\times 5=25$。在增加了感受域的同时却没有增加计算量，保留了更多的细节信息，对图像还原的精度有明显的提升。1.1.2. paddingpadding 是图像周围填充的像素尺寸。在默认参数（dilation=1, padding = 0）的情况下，每经过一次卷积，图像的尺寸都会缩小。比如原始图像为 $5\\times 5$，卷积核大小为 $3\\times 3$，滑动步长 $stride=1$，则卷积输出的特征图为 $(5-3+1)\\times (5-3+1)=3\\times 3$。这样处理有两个缺点：      卷积后的矩阵越变越小（卷积层很多时，最终得到的将是很小的图片）；        输入矩阵边缘像素只被计算过一次，而中间像素被卷积计算多次，意味着丢失图像角落信息。  为了保证输出尺寸与输入尺寸一致，即\\[\\begin{aligned}H_{out} = H_{in} \\\\W_{out} = W_{in}\\end{aligned}\\]需要在图像周围填充一定的像素宽度，计算匹配的 padding 值，将上面的公式变换如下\\[\\begin{aligned}padding[0] = \\frac{stride[0]\\times (H_{out}-1) + dilation[0]\\times (kernel\\_size[0]-1)-H_{in}+1} {2} \\\\padding[1] = \\frac{stride[1]\\times (H_{out}-1) + dilation[1]\\times (kernel\\_size[1]-1)-H_{in}+1} {2} \\\\\\end{aligned}\\]将默认的 stride=1和 dilation=1 参数代入，可得\\[\\begin{aligned}padding[0] = (kernel\\_size[0]-1) / 2 \\\\padding[1] = (kernel\\_size[1]-1) / 2\\end{aligned}\\]也就是说，padding 的取值与 kernel_size 有关。如果采用长宽相等的卷积核，可简写为\\[padding = (kernel\\_size-1) / 2\\]对于上述例子，计算后 padding = 1。即原始图像为 $5\\times 5$，图像周围填充1像素的宽度，尺寸变为$7\\times 7$，经过卷积后特征图尺寸正好又变为 $5\\times 5$。1.2. MaxPool2dnn.MaxPool2d 的参数包括：      kernel_size：(int or tuple) ，max pooling 的窗口大小，可以为tuple，在nlp中tuple用更多（n,1）        stride：(int or tuple, optional) ，max pooling 的窗口移动的步长。默认值是kernel_size        padding：(int or tuple, optional) - 输入的每一条边补充0的层数        dilation：(int or tuple, optional) – 一个控制窗口中元素步幅的参数        return_indices：如果等于 True，会返回输出最大值的序号，对于上采样操作会有帮助        ceil_mode：如果等于 True，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的操作，default=False  下图的 kernel_size = 2, stride = 2，将输入图片尺寸缩减为原来的一半。当输入无法被 kernel_size 整除时，根据 ceil_mode 来决定如何池化1.3. Linearnn.Linear 的参数如下：      in_features：输入维度；        out_features：输出维度；        bias：如果设为 False 则不存在偏置，default: True。  2. 激活函数2.1. conv2dtorch.nn 与 torch.nn.functional 差不多[4]，不过一个包装好的类，一个是可以直接调用的函数。在实现源代码上，torch.nn.Conv2d 类在 forward 时调用了 torch.nn.functional.conv2d。可能会疑惑为什么需要这两个功能如此相近的模块，其实这么设计是有其原因的。如果我们只保留nn.functional下的函数的话，在训练或者使用时，我们就要手动去维护weight, bias, stride这些中间量的值，这显然是给用户带来了不便。而如果我们只保留nn下的类的话，其实就牺牲了一部分灵活性，因为做一些简单的计算都需要创造一个类，这也与PyTorch的风格不符。二者有一些细微的差别：      两者的调用方式不同。nn.Xxx 需要先实例化并传入参数，然后以函数调用的方式调用实例化的对象并传入输入数据。nn.functional.xxx同时传入输入数据和weight, bias等其他参数 。        nn.Xxx继承于nn.Module， 能够很好的与nn.Sequential结合使用， 而nn.functional.xxx无法与nn.Sequential结合使用。        nn.Xxx不需要你自己定义和管理weight；而nn.functional.xxx需要你自己定义weight，每次调用的时候都需要手动传入weight, 不利于代码复用。  两种定义方式得到CNN功能都是相同的，至于喜欢哪一种方式，是个人口味问题，但PyTorch官方推荐：      具有学习参数的（例如，conv2d, linear, batch_norm)采用nn.Xxx方式        没有学习参数的（例如，maxpool, loss func, activation func）等根据个人选择使用nn.functional.xxx或者nn.Xxx方式。  但关于dropout，个人强烈推荐使用nn.Xxx方式，因为一般情况下只有训练阶段才进行dropout，在eval阶段都不会进行dropout。使用nn.Xxx方式定义dropout，在调用model.eval()之后，model中所有的dropout layer都关闭，但以nn.function.dropout方式定义dropout，在调用model.eval()之后并不能关闭dropout。2.2. softmax我们知道 max，假如 a &gt; b，则 max(a, b) = a ，这个结果是确定的，无论计算多少次，max 返回的值永远是 a。但有的时候我不想这样，因为这样会造成值小的那个饥饿。所以我希望分值大的那一项经常取到，分值小的那一项也偶尔可以取到。可以采用某种方法，按照a和b本来的大小来计算取a和b的概率，就可以实现a经常取到，b也会偶尔取到。此时的选取不在遵循 max，而是 softmax 。softmax 的计算方法如下，假设输入为一维向量 $Z = [z_1,z_2,…z_i,…,z_n]\\in(-\\infty,+\\infty)$ ，则第 $i$ 个分量 $z_i$ 的 softmax 输出为\\(y_i = softmax(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\\)我们知道指数函数 $e^x$ 的值域为 $(0,+\\infty)$ ，因此 softmax 将 $(-\\infty,+\\infty)$ 的值映射到 $[0, 1]$。具体来说，softmax 具备下面两个作用      将向量的各个维度 $z_i$ 映射为映射到 $[0, 1]$ 之间的某个值，即为该分量的取值概率；        向量所有维度的取值概率之和为1。  通常情况下，计算softmax函数值不会出现什么问题，例如，当softmax函数表达式里的所有 zi 都是一个“一般大小”的数值 $c$ 时——也就是上图中，$z_1=z_2=z_3=c$ 时，那么，计算出来的函数值 $y_1=y_2=y_3=1$。但是，当某些情况发生时，计算函数值就出问题了：      $c$ 极其大，导致分子计算 $e^c$ 时上溢出（超出float表示的界限，出现NaN）。                                $c$ 为负数，且 $          c          $ 很大，此时分母是一个极小的正数，有可能四舍五入为0，导致下溢出。                    解决方法为，令 $M = max(z_i), i =1,2,3,….,n$，计算 $softmax(z_i - M)$ 的值，就可以解决上溢出、下溢出的问题了，并且，计算结果理论上仍然和  $softmax(z_i)$  保持一致。具体而言：      $z_i - M$ 的取值范围为 $(-\\infty,0]$ ，因此在做指数运算时输入的最大值为 0，从而避免上溢出。        $softmax(z_i - M)$ 的值域为 $[0,1]$ ，因为分母对所有指数求和时，至少有一个指数（对应输入最大值0的指数项）为1，保证了分母不为0，从而避免下溢出。  softmax(input, dim=-1) # dim=0 makes sum of column values to be 1, dim=1 makes row ...2.3. log_softmax在 softmax 的基础上多做一个 log 运算，log_softmax号称能够加快运算速度，提高数据稳定性。在数学上等价于 log(softmax(x)) ，但做这两个单独操作速度较慢，数值上也不稳定。log_softmax 的值域为 $(-\\infty, 0]$。3. 损失函数3.1. CrossEntropyLoss交叉熵损失函数。在说交叉熵之前，先说一下信息量与熵。信息量：衡量一个事件的不确定性；一个事件发生的概率越大，不确定性越小，则它所携带的信息量就越小。假设 $X$ 是一个离散型随机变量，其取值集合为 $X$，概率分布函数为 $p(x)=P(X=x),x\\in X$  ，我们定义事件 $X=x_0$ 的信息量为：$I(x_0)=-log(p(x_0))$。当 $p(x_0) = 1$ 时，熵等于0，也就是说该事件的发生不会导致任何信息量的增加。熵：用来衡量一个系统的混乱程度，代表一个系统中信息量的总和；信息量总和越大，系统不确定性越大。对所有可能事件所带来的信息量求期望，其结果就能衡量事务的不确定度。交叉熵：它主要刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近。假设概率分布 $p$ 为期望输出，概率分布 $q$ 为实际输出， $H(p,q)$ 为交叉熵。其计算方法有两种\\(H(p,q)=-\\sum_i (p_i log q_i + (1-p_i)log(1-q_i))\\)或者\\[H(p,q) = -\\sum_i (p_ilog q_i)\\]假设某个样本对应的标签 $y = [y_1,y_2,…,y_K]\\in R^K$ 为一个向量，PyTorch 中的交叉熵损失函数形式如下\\[L = -\\sum_{i=1}^K (y_ilog s_i)\\]其中，$y_i$ 为真实分类值，$s_i$ 为 softmax 输出值，$i$ 代表神经元节点的标号。假设网络结构为 xx -&gt; Linear -&gt; softmax，即一个全连接层的输出作为 softmax 的输入，有\\[\\begin{aligned}z_i &amp;= \\omega_i \\cdot x_i + b_i \\\\s_i &amp;= \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}\\end{aligned}\\]采用交叉熵损失函数，则损失函数对 softmax 的倒数为\\[\\begin{aligned}\\frac{\\partial L}{\\partial \\omega_i}=\\frac{\\partial L}{\\partial z_i}\\frac{\\partial z_i}{\\partial w_i} \\\\\\frac{\\partial L}{\\partial b_i}=\\frac{\\partial L}{\\partial z_i}\\frac{\\partial z_i}{\\partial b_i}\\end{aligned}\\]由于全连接层\\[\\begin{aligned}\\frac{\\partial z_i}{\\partial w_i} &amp;= x_i \\\\\\frac{\\partial z_i}{\\partial b_i} &amp;= 1\\end{aligned}\\]则核心问题变为求解 $\\frac{\\partial L}{\\partial z_i}$ 。\\[\\begin{aligned}\\frac{\\partial z_i}{\\partial w_i} &amp;= x_i \\\\\\frac{\\partial z_i}{\\partial b_i} &amp;= 1\\end{aligned}\\]由于 softmax 的计算公式中，任意一个 s_i 均包含 z 的所有分类，因此有\\[\\frac{\\partial L}{\\partial z_i} = \\sum_k[\\frac{\\partial L}{\\partial s_k}\\frac{\\partial s_k}{\\partial z_i}]\\]根据损失函数的定义，有\\[\\frac{\\partial L}{\\partial s_k}=-\\frac{y_k}{s_k}\\]下面求解 $\\frac{\\partial s_k}{\\partial z_i}$ ，需要分情况讨论当 $k \\neq i$ 时，有\\[\\begin{aligned}\\frac{\\partial s_k}{\\partial z_i}&amp;= \\frac{\\partial(\\frac{e^{z_k}}{\\sum_j e^{z_j}})}{\\partial z_i}\\\\&amp;= e^{z_k}\\frac{\\partial(\\frac{1}{\\sum_j e^{z_j}})}{\\partial z_i}\\\\&amp;= e^{z_k}(-\\frac{1}{(\\sum_j e^{z_j})^2})\\frac{\\partial \\sum_j e^{z_j}}{\\partial z_i}\\\\&amp;= e^{z_k}(-\\frac{1}{(\\sum_j e^{z_j})^2})e^{z_i}\\\\&amp;= -(\\frac{e^{z_k}}{\\sum_j e^{z_j}})(\\frac{e^{z_i}}{\\sum_j e^{z_j}}) = -s_k\\cdot s_i\\end{aligned}\\]当 $k=i$ 时，有（分式求导法则：上导下不导减下导上不导除以下的平方）\\[\\begin{aligned}\\frac{\\partial s_k}{\\partial z_i}&amp;=\\frac{\\partial s_i}{\\partial z_i}\\\\&amp;=\\frac{\\partial(\\frac{e^{z_i}}{\\sum_j e^{z_j}})}{\\partial z_i}\\\\&amp;=\\frac{e^{z_i}\\sum_j e^{z_i}-(e^{z_i})^2}{(\\sum_j e^{z_i})^2}\\\\&amp;=\\frac{e^{z_i}}{\\sum_j e^{z_i}}\\frac{\\sum_j e^{z_i}-e^{z_i}}{\\sum_j e^{z_i}}\\\\&amp;=\\frac{e^{z_i}}{\\sum_j e^{z_i}}(1-\\frac{e^{z_i}}{\\sum_j e^{z_i}}) = s_i(1-s_i)\\end{aligned}\\]最终得到\\[\\begin{aligned}\\frac{\\partial L}{\\partial z_i} &amp;= -\\frac{y_i}{s_i}s_i(1-s_i)+\\sum_{k \\neq i}(-\\frac{y_k}{s_k}\\cdot-s_ks_i)\\\\&amp;= -y_i + \\sum_{k=1}^K y_k\\end{aligned}\\]对于多分类问题，样本真实标签 $y = [y_1,y_2,…,y_K]$ 是one-hot，即只有一个元素为1，其余元素为0。那么有 $\\sum_{k=1}^K y_k = 1$，因此在多分类问题中\\[\\frac{\\partial L}{\\partial z_i} = s_i - y_i\\]那么有\\[\\begin{aligned}\\frac{\\partial L}{\\partial \\omega_i} &amp;= (s_i - y_i)\\cdot x\\\\\\frac{\\partial L}{\\partial b_i} &amp;= s_i - y_i\\end{aligned}\\]3.2. NLLLoss负对数似然损失函数（Negative Log Likelihood, NLL） 的 输入是一个对数概率向量和一个目标标签。它不会为我们计算对数概率，适合网络的最后一层是 log_softmax。NLLLoss 的数学形式为\\(L(X,label) = -X_{label}\\)其中，X 是 log_softmax 的输出，label 是对应的标签位置，即 NLLLoss 的输出是取 X 中对应于 label 中为1的那个 x 。在分类问题中，CrossEntropy 等价于 log_softmax + nll_loss，也就是说如果使用 CrossEntropy，则前面不要加 softmax 层，因为 CrossEntropy 中内含 softmax。而如果使用 nll_loss，前面就必须要使用 log_softmax 层。理论上，对于单标签多分类问题，直接经过 softmax 求出概率分布，然后把这个概率分布用 CrossEntropy 做一个似然估计误差。但是 softmax 求出来的概率分布，每一个概率都是 $(0, 1)$ 的，这就会导致有些概率过小，导致下溢。 考虑到这个概率分布总归是要经过 CrossEntropy的，而 CrossEntropy的计算是把概率分布外面套一个 -log 来似然，那么直接在计算概率分布的时候加上 log，把概率从 $(0, 1)$ 变为 $(-\\infty, 0)$，这样就防止中间会有下溢出。 所以 log_softmax 说白了就是将本来应该由 CrossEntropy做的 log 的工作提到预测概率分布来，跳过了中间的存储步骤，防止中间数值会有下溢出，使得数据更加稳定。 正是由于把log这一步从计算误差提到前面，所以用 log_softmax 之后，下游的损失函数就应该变成 NLLLoss（它没有套 log 这一步，直接将输入取反，然后计算和标签的乘积求和平均）。4. 参考文献[1]  PyTorch. Conv2d.[2]  Stack Overflow. Default dilation value in PyTorch.[3]  Vincent Dumoulin, Francesco Visin. A guide to convolution arithmetic for deep learning (Github).[4] 知乎. PyTorch 中，nn 与 nn.functional 有什么区别？.[5]  PyTorch. MaxPool2d.[6]  PyTorch. nn.Linear."
  },
  
  {
    "title": "Python基础（万恶的下划线）",
    "url": "/posts/python-basic-1/",
    "categories": "Academic, Coding",
    "tags": "python",
    "date": "2020-06-14 10:40:19 +0800",
    





    
    "snippet": "本文介绍了 Python 一些基本的小知识，如 name = ‘main’、init、super 等等。  1. 模拟的应用程序入口  2. 实例属性初使化  3. 继承自父类的属性初始化  4. 参考文献1. 模拟的应用程序入口if __name__ == '__main__' 为 python 提供模拟的应用程序入口。它的功能为：当.py文件被直接运行时，if __name__ == '...",
    "content": "本文介绍了 Python 一些基本的小知识，如 name = ‘main’、init、super 等等。  1. 模拟的应用程序入口  2. 实例属性初使化  3. 继承自父类的属性初始化  4. 参考文献1. 模拟的应用程序入口if __name__ == '__main__' 为 python 提供模拟的应用程序入口。它的功能为：当.py文件被直接运行时，if __name__ == '__main__': 之下的代码块将被运行；当.py文件以模块形式被导入时，if __name__ == '__main__': 之下的代码块不被运行。参考：https://blog.csdn.net/anshuai_aw1/article/details/82344884假设我们有一个const.py文件，内容如下：PI = 3.14 def main():    print(\"PI:\", PI) main() # 运行结果：PI: 3.14现在，我们写一个用于计算圆面积的area.py文件，area.py文件需要用到const.py文件中的PI变量。从const.py中，我们把PI变量导入area.py：from const import PI def calc_round_area(radius):    return PI * (radius ** 2) def main():    print(\"round area: \", calc_round_area(2)) main() '''运行结果：PI: 3.14round area:  12.56'''我们看到 const.py 中的 main 函数也被运行了，实际上我们不希望它被运行，因为 const.py 提供的 main 函数只是为了测试常量定义。这时 if __name__ == '__main__' 派上了用场，我们把const.py改一下：PI = 3.14 def main():    print(\"PI:\", PI) if __name__ == \"__main__\":    main()运行const.py，输出如下：PI: 3.14运行area.py，输出如下：round area:  12.56如上，我们可以看到 if __name__ == '__main__' 相当于Python模拟的程序入口，Python本身并没有这么规定，这只是一种编码习惯。由于模块之间相互引用，不同模块可能有这样的定义，而程序入口只有一个。到底哪个程序入口被选中，这取决于 __name__ 的值。2. 实例属性初使化定义类的时候，若是添加 __init__ 方法，那么在创建类的实例的时候，实例会自动调用这个方法，一般用来对实例的属性进行初使化。比如：class Student:    def  __init__(self, name, gender):        self.name = name        self.gender = genderXiaoMing = Student(name='XiaoMing', gender='Male')print(XiaoMing.name, XiaoMing.gender)此处，类进行初始化时就会自动调用 __init__ 中的代码，对 self.name 和 self.gender 赋值，之后可以通过 XiaoMing.name 等来访问。self 是个对象（Object），是当前类的实例。在类的代码（函数）中，需要访问当前的实例中的变量和函数的，即：      访问对应变量（property)：Instance.ProperyNam，去读取之前的值和写入新的值        调用对应函数（function）：Instance.function()，即执行对应的动作  新建的实例本身，连带其中的参数，会一并传给 __init__ 函数自动并执行它。所以 __init__ 函数的参数列表会在开头多出一个参数，它永远指代新建的那个实例对象，Python语法要求函数的第一个参数必须是实例对象本身，而名称随意，习惯上就命为 self。当然，如果你非要写为别的比如 me ，也不是不可以，之后的 self.xxx 就要写成 me.xxx 。你开心就好。注意以下三点  __init__ 具备独立的命名空间，也就是说函数内新引入的变量均为局部变量，新建的实例对象对这个函数来说也只是通过第一参数self从外部传入的，故无论设置还是使用它的属性都得利用 self.&lt;属性名&gt;。如果将上面的初始化语句中新增myname = name（ myname 没有用 self. 修饰），则只是在函数内部创建了一个 myname 变量，它在函数执行完就会消失，对新建的实例没有任何影响；  与此对应，self的属性名和函数内其他名称（包括参数）也是不冲突的，所以下面的写法正确而且规范class Student:    def  __init__(self, name, gender):        # self.name是self的属性，单独的name是函数内的局部变量，参数也是局部变量        self.name = name  返回时只能 return，不允许带返回值。3. 继承自父类的属性初始化这是对继承自父类的属性进行初始化。而且是用父类的初始化方法来初始化继承的属性。也就是说，子类继承了父类的所有属性和方法，父类属性自然会用父类方法来进行初始化。当然，如果初始化的逻辑与父类的不同，不使用父类的方法，自己重新初始化也是可以的。特别是在使用 PyTorch 时，自定义网络类（比如类名为 CNN ）一般需要继承 PyTorch 提供的 nn.Module ：class CNN(nn.Module):    def __init__(self):        super(CNN, self).__init__()4. 参考文献无。"
  },
  
  {
    "title": "深度学习基础（基本超参数和优化器）",
    "url": "/posts/deep-learning-basic-hp-and-opt/",
    "categories": "Academic, Knowledge",
    "tags": "python, deep learning",
    "date": "2020-06-13 16:24:19 +0800",
    





    
    "snippet": "本文介绍了深度学习中的基本概念，包括 batch、epoch、iteration、optimizer等，其中优化器包括 BGD、SGD、Adam等，为后深度学习提供基础。  1. 基本超参数          1.1. epoch      1.2. batch \\&amp; batch_size      1.3. iteration        2. 优化器          2.1....",
    "content": "本文介绍了深度学习中的基本概念，包括 batch、epoch、iteration、optimizer等，其中优化器包括 BGD、SGD、Adam等，为后深度学习提供基础。  1. 基本超参数          1.1. epoch      1.2. batch \\&amp; batch_size      1.3. iteration        2. 优化器          2.1. 批量梯度下降（BGD）      2.2. 随机梯度下降（SGD）      2.3. 小批量梯度下降（MBGD）      2.4. 梯度下降的缺点      2.5. 动量（Momentum）      2.6. RMSProp      2.7. Adam        3. 参考文献1. 基本超参数batch（minibatch）、batch_size、epoch、iteration是深度学习中常见的几个超参数[1]：      batch：训练的批次，训练的总批次数称为 batch_number（也就是后面的iteration）；    batch_size：每批（batch）训练使用的样本的个数。也就是一次训练 batch_size 个样本，计算它们的平均损失函数值，更新参数；  iteration：一个 iteration 即迭代训练一次，也就是用 batch_size 个样本训练一次。（iteration = batch_number）；  epoch：一个 epoch 指用训练集中的全部样本训练一次。简单一句话说就是，我们有2000个数据，分成4个batch，那么batch_size就是500。运行所有的数据进行训练，完成1个epoch，需要进行4次iterations，也即batch_number=4。1.1. epoch一个 epoch 指将训练集中全部样本送入神经网络完成一次训练（前向计算及反向传播）的过程。在实际训练时，将所有训练集数据迭代训练一次是不够的，需要反复多次才能拟合收敛。因此，往往设置多次epoch进行训练。随着epoch数量的增加，神经网络中权重更新迭代的次数增多，曲线从最开始的不拟合状态，慢慢进入优化拟合状态，最终进入过拟合。因此，epoch的个数是非常重要的。那么究竟设置为多少才合适呢？恐怕没有一个确切的答案。对于不同的数据库来说，epoch数量是不同的。但是，epoch大小与数据集的多样化程度有关，多样化程度越强，epoch应该越大。1.2. batch &amp; batch_size由于训练集中所有样本的数据往往很大，如果一次就将训练集中的所有样本数据送入计算机，计算机将无法负荷。因此，一般会将整个训练集数据分成几个较小的批（batches），每批采用一定数量的样本进行训练。batch_size 即为每批训练使用的样本的个数。1.3. iteration一个 iteration 指采用 batch_size 个样本训练一次的过程。2. 优化器2.1. 批量梯度下降（BGD）最早期的机器学习采用批量梯度下降（Batch Gradient Decent，BGD）进行参数更新[2]。梯度下降法在每个 epoch 中需要对全部样本进行梯度计算，然后取平均值进行权值更新。即 batch_size 等于训练集样本个数。当数据集较小时该方法尚可。随着数据集迅速增大，这种方法一次开销大进而占用内存过大，速度过慢。Batch gradient descent 对于凸函数可以收敛到全局极小值，对于非凸函数可以收敛到局部极小值。2.2. 随机梯度下降（SGD）后来产生了一次只训练一个样本的方法（batchsize=1），称为随机梯度下降（Stochastic Gradient Decent，SGD）。该方法根据每次只使用一个样本的情况更新一次权值，开销小速度快，但由于单个样本的巨大随机性，全局来看优化性能较差，收敛速度很慢，产生局部震荡，有限迭代次数内很可能无法收敛。SGD 一次只进行一次更新，就没有冗余，而且比较快，并且可以新增样本。缺点是SGD的噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。所以虽然训练速度快，但是准确度下降，并不是全局最优。虽然包含一定的随机性，但是从期望上来看，它是等于正确的导数的。2.3. 小批量梯度下降（MBGD）后来诞生的小批量梯度下降（Mini-Batch Gradient Descent ，MBGD），相当于上述两个“极端”方法的折中：将训练集分成多个mini_batch（即常说的batch）,一次迭代训练一个minibatch（即batch_size个样本），根据该batch数据的loss更新权值。MBGD 每一次利用一小批样本，即 batch_size 个样本进行计算，这样它可以降低参数更新时的方差，收敛更稳定，另一方面可以充分地利用深度学习库中高度优化的矩阵操作来进行更有效的梯度计算。2.4. 梯度下降的缺点两大缺点[3]：  MBGD不能保证很好的收敛性，learning rate 如果选择的太小，收敛速度会很慢，如果太大，loss function 就会在极小值处不停地震荡甚至偏离。（有一种措施是先设定大一点的学习率，当两次迭代之间的变化低于某个阈值后，就减小 learning rate，不过这个阈值的设定需要提前写好，这样的话就不能够适应数据集的特点。）对于非凸函数，还要避免陷于局部极小值处，或者鞍点处，因为鞍点周围的error是一样的，所有维度的梯度都接近于0，SGD 很容易被困在这里。（会在鞍点或者局部最小点震荡跳动，因为在此点处，如果是训练集全集带入即 BGD，则优化会停止不动，如果是 mini-batch 或者 SGD，每次找到的梯度都是不同的，就会发生震荡，来回跳动。）  SGD对所有参数更新时应用同样的 learning rate，如果我们的数据是稀疏的，我们更希望对出现频率低的特征进行大一点的更新。learning rate 会随着更新的次数逐渐变小。2.5. 动量（Momentum）为了应对第一个缺点，采用动量优化器，可以使得梯度方向不变的维度上速度变快，梯度方向有所改变的维度上的更新速度变慢，这样就可以加快收敛并减小震荡。\\[\\begin{aligned}v_{d\\omega}&amp;=\\beta v_{d\\omega}+(1−\\beta)d\\omega \\\\v_{db}&amp;=\\beta v_{db}+(1−\\beta)db \\\\\\omega&amp;=\\omega−\\eta v_{d\\omega} \\\\b&amp;=b−\\eta v_{db} \\\\\\end{aligned}\\]其中，在上面的公式中$v_{d\\omega}$和$v_{db}$分别是损失函数在前 $t−1$ 轮迭代过程中累积的梯度梯度动量，$\\beta$ 是梯度累积的一个指数，这里我们一般设置值为0.9。所以Momentum优化器的主要思想就是利用了类似与移动指数加权平均的方法来对网络的参数进行平滑处理的，让梯度的摆动幅度变得更小。$d\\omega$和$db$分别是损失函数反向传播时候所求得的梯度，下面两个公式是网络权重向量和偏置向量的更新公式，$\\eta$ 是网络的学习率。当我们使用 Momentum 优化算法的时候，可以解决 mini-batch SGD 优化算法更新幅度摆动大的问题，同时可以使得网络的收敛速度更快。2.6. RMSPropRMSProp算法的全称叫 Root Mean Square Prop，是Geoffrey E. Hinton在Coursera课程中提出的一种优化算法，是对Momentum优化算法的进一步优化。为了进一步优化损失函数在更新中存在摆动幅度过大的问题，并且进一步加快函数的收敛速度，RMSProp算法对权重 $W$ 和偏置 $b$ 的梯度使用了指数加权平均数。其中，假设在第 $t$ 轮迭代过程中，各个公式如下所示\\[\\begin{aligned}s_{d\\omega}&amp;=\\beta s_{d\\omega}+(1−\\beta)d\\omega^2 \\\\s_{d\\omega}&amp;=\\beta s_{db}+(1−\\beta)db^2 \\\\\\omega&amp;=\\omega−\\eta \\frac{d\\omega}{\\sqrt{s_{d\\omega}}+\\epsilon} \\\\b&amp;=b−\\eta \\frac{db}{\\sqrt{s_{db}}+\\epsilon} \\\\\\end{aligned}\\]这个分母相当于梯度的均方根 （Root Mean Squared，RMS）。RMSProp算法对梯度计算了微分平方加权平均数。这种做法有利于消除了摆动幅度大的方向，用来修正摆动幅度，使得各个维度的摆动幅度都较小。另一方面也使得网络函数收敛更快。（比如当 $d\\omega$ 或者 $db$ 中有一个值比较大的时候，那么我们在更新权重或者偏置的时候除以它之前累积的梯度的平方根，这样就可以使得更新幅度变小）。为了防止分母为零，使用了一个很小的数值 $\\epsilon$ 来进行平滑，一般取值为$10^{−8}$。2.7. Adam有了上面两种优化算法，一种可以使用类似于物理中的动量来累积梯度，另一种可以使得收敛速度更快同时使得波动的幅度更小。那么讲两种算法结合起来所取得的表现一定会更好。Adam（Adaptive Moment Estimation）算法是将Momentum算法和RMSProp算法结合起来使用的一种算法，我们所使用的参数基本和上面讲的一致，在训练的最开始我们需要初始化梯度的累积量和平方累积量[4]。假设在训练的第 $t$ 轮训练中，我们首先可以计算得到Momentum和RMSProp的参数更新\\[\\begin{aligned}v_{d\\omega}&amp;=\\beta_1 v_{d\\omega}+(1−\\beta_1)d\\omega \\\\v_{db}&amp;=\\beta_1 v_{db}+(1−\\beta_1)db \\\\s_{d\\omega}&amp;=\\beta s_{d\\omega}+(1−\\beta)d\\omega^2 \\\\s_{d\\omega}&amp;=\\beta s_{db}+(1−\\beta)db^2 \\\\\\end{aligned}\\]参数 $\\beta_1$ 所对应的就是Momentum算法中的 $\\beta$ 值，一般取0.9；参数 $\\beta_2$ 所对应的就是RMSProp算法中的 $\\beta$ 值，一般取0.999。由于移动指数平均在迭代开始的初期会导致和开始的值有较大的差异，所以我们需要对上面求得的几个值做偏差修正\\[\\begin{aligned}v^c_{d\\omega}&amp;=\\frac{v_{d\\omega}}{1−\\beta^t_1} \\\\v^c_{db}&amp;=\\frac{v_{d b}}{1−\\beta^t_1} \\\\s^c_{d\\omega}&amp;=\\frac{s_{d\\omega}}{1−\\beta^t_2} \\\\s^c_{db}&amp;=\\frac{s_{db}}{1−\\beta^t_2} \\\\\\end{aligned}\\]通过上面的公式，我们就可以求得在第 $t$ 轮迭代过程中，参数梯度累积量的修正值，从而接下来就可以根据Momentum和RMSProp算法的结合来对权重和偏置进行更新\\[\\begin{aligned}\\omega&amp;=\\omega−\\eta \\frac{v^c_{d\\omega}}{\\sqrt{s_{d\\omega}}+\\epsilon} \\\\b&amp;=b−\\eta \\frac{v^c_{db}}{\\sqrt{s_{db}}+\\epsilon} \\\\\\end{aligned}\\]其中 $\\epsilon$ 是一个平滑项，我们一般取值为 $10^{−8}$，学习率 $\\eta$ 则需要我们在训练的时候进行微调。3. 参考文献[1] XDTY17_LK. 深度学习中的Epoch，Batchsize，Iterations，都是什么鬼？.[2] LLLiuye. 批量梯度下降(BGD)、随机梯度下降(SGD)以及小批量梯度下降(MBGD)的理解.[3] 郭耀华. 深度学习——优化器算法Optimizer详解（BGD、SGD、MBGD、Momentum、NAG、Adagrad、Adadelta、RMSprop、Adam）.[4] William. 深度学习优化算法解析(Momentum, RMSProp, Adam)）."
  },
  
  {
    "title": "日常tips手册（Typora标题自动编号）",
    "url": "/posts/typora-auto-no/",
    "categories": "Diary",
    "tags": "markdown",
    "date": "2020-06-11 12:21:49 +0800",
    





    
    "snippet": "本文介绍了如何在 Markdown 编辑器 Typora 中自动为标题添加编号，包括正文标题自动编号、目录自动编号、侧边栏自动编号。  1. 正文标题自动编号  2. 目录自动编号  3. 侧边栏自动编号  4. 参考文献1. 正文标题自动编号根据官方文档（http://support.typora.io/Auto-Numbering/），首先打开Typora，选择 “文件” =&gt; “...",
    "content": "本文介绍了如何在 Markdown 编辑器 Typora 中自动为标题添加编号，包括正文标题自动编号、目录自动编号、侧边栏自动编号。  1. 正文标题自动编号  2. 目录自动编号  3. 侧边栏自动编号  4. 参考文献1. 正文标题自动编号根据官方文档（http://support.typora.io/Auto-Numbering/），首先打开Typora，选择 “文件” =&gt; “偏好设置”，切换到 “外观” 选项卡，点击 “打开主题文件夹按钮”然后新建一个 .txt 文件，重命名为 base.user.css 文件，填充下列代码/************************************** * Header Counters in Content **************************************//** initialize css counter */#write {    counter-reset: h1}h1 {    counter-reset: h2}h2 {    counter-reset: h3}h3 {    counter-reset: h4}h4 {    counter-reset: h5}h5 {    counter-reset: h6}/** put counter result into headings */#write h1:before {    counter-increment: h1;    content: counter(h1) \". \"}#write h2:before {    counter-increment: h2;    content: counter(h1) \".\" counter(h2) \". \"}#write h3:before,h3.md-focus.md-heading:before /** override the default style for focused headings */ {    counter-increment: h3;    content: counter(h1) \".\" counter(h2) \".\" counter(h3) \". \"}#write h4:before,h4.md-focus.md-heading:before {    counter-increment: h4;    content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \". \"}#write h5:before,h5.md-focus.md-heading:before {    counter-increment: h5;    content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \". \"}#write h6:before,h6.md-focus.md-heading:before {    counter-increment: h6;    content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \".\" counter(h6) \". \"}/** override the default style for focused headings */#write&gt;h3.md-focus:before,#write&gt;h4.md-focus:before,#write&gt;h5.md-focus:before,#write&gt;h6.md-focus:before,h3.md-focus:before,h4.md-focus:before,h5.md-focus:before,h6.md-focus:before {    color: inherit;    border: inherit;    border-radius: inherit;    position: inherit;    left:initial;    float: none;    top:initial;    font-size: inherit;    padding-left: inherit;    padding-right: inherit;    vertical-align: inherit;    font-weight: inherit;    line-height: inherit;}关闭Typora后重启，标题就将会自动增加数字编号。如果不想要数字与标题之间的 . ，则需要修改 .css 文件中，/** put counter result into headings */ 后面的代码，将每个标题最后一个 \". \" 中的句点去掉，即将/** put counter result into headings */#write h1:before {    counter-increment: h1;    content: counter(h1) \". \" /* &lt;--- delete this dot */}...改为/** put counter result into headings */#write h1:before {    counter-increment: h1;    content: counter(h1) \" \" /* &lt;--- dot deleted */}...2. 目录自动编号如果想要在自动生成的目录中附带编号，需要额外再在 .css 文件中增加代码段[2]/************************************** * Header Counters in TOC **************************************/ /* No link underlines in TOC */.md-toc-inner {    text-decoration: none;} .md-toc-content {    counter-reset: h1toc} .md-toc-h1 {    margin-left: 0;    font-size: 1.5rem;    counter-reset: h2toc} .md-toc-h2 {    font-size: 1.1rem;    margin-left: 2rem;    counter-reset: h3toc} .md-toc-h3 {    margin-left: 3rem;    font-size: .9rem;    counter-reset: h4toc} .md-toc-h4 {    margin-left: 4rem;    font-size: .85rem;    counter-reset: h5toc} .md-toc-h5 {    margin-left: 5rem;    font-size: .8rem;    counter-reset: h6toc} .md-toc-h6 {    margin-left: 6rem;    font-size: .75rem;} .md-toc-h1:before {    color: black;    counter-increment: h1toc;    content: counter(h1toc) \". \" /* &lt;--- delete this dot if not wanted */} .md-toc-h1 .md-toc-inner {    margin-left: 0;} .md-toc-h2:before {    color: black;    counter-increment: h2toc;    content: counter(h1toc) \". \" counter(h2toc) \". \" /* &lt;--- delete this dot if not wanted */} .md-toc-h2 .md-toc-inner {    margin-left: 0;} .md-toc-h3:before {    color: black;    counter-increment: h3toc;    content: counter(h1toc) \". \" counter(h2toc) \". \" counter(h3toc) \". \" /* &lt;--- delete this dot if not wanted */} .md-toc-h3 .md-toc-inner {    margin-left: 0;} .md-toc-h4:before {    color: black;    counter-increment: h4toc;    content: counter(h1toc) \". \" counter(h2toc) \". \" counter(h3toc) \". \" counter(h4toc) \". \" /* &lt;--- delete this dot if not wanted */} .md-toc-h4 .md-toc-inner {    margin-left: 0;} .md-toc-h5:before {    color: black;    counter-increment: h5toc;    content: counter(h1toc) \". \" counter(h2toc) \". \" counter(h3toc) \". \" counter(h4toc) \". \" counter(h5toc) \". \" /* &lt;--- delete this dot if not wanted */} .md-toc-h5 .md-toc-inner {    margin-left: 0;} .md-toc-h6:before {    color: black;    counter-increment: h6toc;    content: counter(h1toc) \". \" counter(h2toc) \". \" counter(h3toc) \". \" counter(h4toc) \". \" counter(h5toc) \". \" counter(h6toc) \". \" /* &lt;--- delete this dot if not wanted */} .md-toc-h6 .md-toc-inner {    margin-left: 0;}若要移除数字与标题间的句点，类似上边的做法，将 \". \" 改为 \" \"。3. 侧边栏自动编号如果想要在Typora的侧边栏中附带编号，需要额外再在 .css 文件中继续增加代码段[3]/************************************** * Header Counters in Sidebar **************************************/.sidebar-content {    counter-reset: h1} .outline-h1 {    counter-reset: h2} .outline-h2 {    counter-reset: h3} .outline-h3 {    counter-reset: h4} .outline-h4 {    counter-reset: h5} .outline-h5 {    counter-reset: h6} .outline-h1&gt;.outline-item&gt;.outline-label:before {    counter-increment: h1;    content: counter(h1) \". \" /* &lt;--- delete this dot if not wanted */} .outline-h2&gt;.outline-item&gt;.outline-label:before {    counter-increment: h2;    content: counter(h1) \".\" counter(h2) \". \" /* &lt;--- delete this dot if not wanted */} .outline-h3&gt;.outline-item&gt;.outline-label:before {    counter-increment: h3;    content: counter(h1) \".\" counter(h2) \".\" counter(h3) \". \" /* &lt;--- delete this dot if not wanted */} .outline-h4&gt;.outline-item&gt;.outline-label:before {    counter-increment: h4;    content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \". \" /* &lt;--- delete this dot if not wanted */} .outline-h5&gt;.outline-item&gt;.outline-label:before {    counter-increment: h5;    content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \". \" /* &lt;--- delete this dot if not wanted */} .outline-h6&gt;.outline-item&gt;.outline-label:before {    counter-increment: h6;    content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \".\" counter(h6) \". \" /* &lt;--- delete this dot if not wanted */}若要移除数字与标题间的句点，类似上边的做法，将 \". \" 改为 \" \"。4. 参考文献[1] Typora. Auto Numbering for Headings.[2] Guest. TOC Autonumbering for Typora.[3] Guest. Auto numbering Typora outline."
  },
  
  {
    "title": "精度损失和抖颤",
    "url": "/posts/precision-loss-and-jitter/",
    "categories": "Tutorial, Coding",
    "tags": "simulation, opengl",
    "date": "2020-06-09 20:23:49 +0800",
    





    
    "snippet": "本文介绍了 OpenGL 中因渲染巨型尺度场景时出现的精度损失问题，以及随之而来的抖颤现象，深入分析了问题产生的原因，并最终给出了解决相对中心的渲染和相对视角的渲染解决方案。  1. 抖颤  2. 相对于中心的渲染  3. 相对于视角的渲染  4. 参考文献1. 抖颤使用OpenGL和Direct3D等图形api，图形处理单元（GPU）在内部采用单精度（32位）浮点数字进行操作，这些数字在很...",
    "content": "本文介绍了 OpenGL 中因渲染巨型尺度场景时出现的精度损失问题，以及随之而来的抖颤现象，深入分析了问题产生的原因，并最终给出了解决相对中心的渲染和相对视角的渲染解决方案。  1. 抖颤  2. 相对于中心的渲染  3. 相对于视角的渲染  4. 参考文献1. 抖颤使用OpenGL和Direct3D等图形api，图形处理单元（GPU）在内部采用单精度（32位）浮点数字进行操作，这些数字在很大程度上遵循IEEE 754规范。单精度值通常被认为有7个精确的十进制数字；因此，随着数字越来越大，数字的表示也越来越不精确。在大型场景渲染中，渲染远距离的对象很常见，如果渲染不正确，对象可能会在视觉上发生抖颤（jitter）。当观察者靠近物体时，这个问题变得更加明显。 图 1 无抖颤和存在抖颤时的场景。场景按照真实比例渲染，单位米，两颗卫星运行于地球静止轨道（轨道半径42164137m），相距2.75m。在航天领域的场景渲染中，精确地放置对象是最重要的。我们希望至少有1cm的精度。允许大约1cm增量的最大数字是131071（$2^{17}-1$）m。下面的代码片段显示了代码中正在分配的floatValue值，相应的注释则为该值实际存储在CPU系统内存中的值。可以看到，虽然存储的值不完全等于指定的值，但误差在0.5厘米内。float floatValue;floatValue = 131071.01; // 131071.0078125floatValue = 131071.02; // 131071.0234375floatValue = 131071.03; // 131071.0312500floatValue = 131071.04; // 131071.0390625floatValue = 131071.05; // 131071.0468750floatValue = 131071.06; // 131071.0625000floatValue = 131071.07; // 131071.0703125floatValue = 131071.08; // 131071.0781250floatValue = 131071.09; // 131071.0937500当将floatValue再增加1cm时，其真实的指定值与实际存储的值之间的误差将超出1cm，其中一些不同的指定值对应着相同的存储值（代码中标*的位置）。float floatValue;floatValue = 131072.01; // 131072.0156250 *floatValue = 131072.02; // 131072.0156250 *floatValue = 131072.03; // 131072.0312500floatValue = 131072.04; // 131072.0468750 **floatValue = 131072.05; // 131072.0468750 **floatValue = 131072.06; // 131072.0625000 *floatValue = 131072.07; // 131072.0625000 *floatValue = 131072.08; // 131072.0781250floatValue = 131072.09; // 131072.0937500在1:1的场景中，地球的半径可达6378137m，如果需要将一个物体放置在地球表面或者环绕地球的某个轨道上，其位置将远远大于131071m。物体的渲染精度将会变得很差，甚至难以达到分米级的精度。当观察者近距离观察这样一个对象时，该对象将发生抖颤。如果可以从CPU将双精度（64位）浮点数字传递到GPU，并且GPU内部使用双精度浮点数字操作，那么在地球上或地球附近渲染的对象就不会出现抖动问题。但正如单精度值一样，物体离地球越远，精度就越差，抖动还是会发生。虽然没有进行精确计算，但是如果希望太阳系内的任何东西都能毫无问题地呈现出来，采用双精度浮点数很可能仍然难以胜任。2. 相对于中心的渲染90年代STK推出时，人们很快发现，当渲染地球和轨道上的物体（比如飞行器Space Shuttle时），抖动很快就表现出来了。一种解决方案是将对象相对于观察者进行渲染，而不是相对于世界坐标系原点进行渲染。世界空间中靠近观察者的像素区域要比远离观察者的区域小得多；因此，随着观察者接近对象，需要越来越精确地渲染对象且不能产生抖动。相对于观察者渲染对象可提供所需的精度。首先介绍相对于中心的渲染（Rendering Relative to Center, RTC）技术。RTC技术的核心是重新计算ModelView矩阵，涉及的向量包括：      MV_GPU：从CPU传递到GPU的单精度的ModelView矩阵，用以将飞行器（SpaceShuttle）从世界空间变换至相机空间        MV_CPU：储存在CPU的双精度ModelView矩阵        SpaceShuttle_Eye：飞行器在相机空间中相对于观察者的坐标        SpaceShuttle_World：飞行器在世界空间中的坐标  首先根据Model矩阵和View矩阵计算ModelView矩阵MV_CPU，然后根据行器在世界空间中的坐标计算飞行器相对于观察者的坐标：SpaceShuttle_Eye = MV_CPU * SpaceShuttle_World;然后，将SpaceShuttle_Eye赋值给MV_CPU的平移分量（第四列前三个分量）：MV_CPU[0, 3] = SpaceShuttle_Eye.x;MV_CPU[1, 3] = SpaceShuttle_Eye.y;MV_CPU[2, 3] = SpaceShuttle_Eye.z;最后，将MV_CPU传递给GPU，得到MV_GPU，其中存在双精度向单精度的转换：MV_GPU = MV_CPU;下面采用真实数值来复现上述计算过程。飞行器在世界空间的坐标为SpaceShuttle_World = (16678139.999999, 0.00000, 0.000000)假设相机位于距离飞行器很近的某处MV_CPU = [0.000000  -0.976339   0.216245        -13.7907750.451316  -0.192969  -0.871249   -7527123.0048360.892363   0.097595   0.440638  -14883050.1149440.000000   0.000000   0.000000          1.000000];则飞行器相对于相机观察者的相对坐标为SpaceShuttle_Eye = MV_CPU * SpaceShuttle_World;// = (-13.790775, -11.572596, -95.070125)将上述值插入MV_CPU的平移分量可以得到:MV_CPU = [0.000000  -0.976339   0.216245  -13.790775 0.451316  -0.192969  -0.871249  -11.5725960.892363   0.097595   0.440638  -95.0701250.000000   0.000000   0.000000    1.000000];最后将MV_CPU传递给GPU（着色器），得到MV_GPU。可以看出，通过上述赋值插入，原本很大的平移分量显著的变小了，这样就可以消除抖颤。一旦视角移动，就需要重新计算MV_GPU，但是相比渲染成千上万的飞行器顶点而言，计算矩阵的资源消耗几乎可以忽略不计。3. 相对于视角的渲染一般而言，RTC技术已经足够达到cm级别的精度，只要模型的顶点距离模型中心小于131070m（实际上可能更小，但暂时未有时间分析测试）。但是在某些极端情况下，RTC技术仍然无法消除抖颤。如果一个物体的顶点间隔超过131070米怎么办？当绘制卫星轨道线、物体之间的线和几何平面（如赤道平面）时，这并不少见。此时，没有一个可用的中心可以用来防止抖动。此时，需要采用一种改进的技术，即相对于视角的渲染（Rendering Relative to Eye, RTE）。限于篇幅，此处不再继续展开，有需要可以参看参考文献。4. 参考文献[1]\tSTK. Precisions, Precisions"
  },
  
  {
    "title": "深度缓冲和深度冲突",
    "url": "/posts/depth-buffer-and-z-fighting/",
    "categories": "Tutorial, Coding",
    "tags": "simulation, opengl",
    "date": "2020-06-08 22:21:49 +0800",
    





    
    "snippet": "本文介绍了 OpenGL 中深度缓冲的概念，分析了在渲染巨型尺度场景下的深度冲突问题，并给出了采用对数深度缓冲的具体解决方案。  1. 深度缓冲  2. 深度冲突  3. 对数深度缓冲  4. 参考文献1. 深度缓冲OpenGL是一个右手坐标系。简单来说，就是正x轴在你的右手边，正y轴朝上，而正z轴是朝向后方的。想象你的屏幕处于三个轴的中心，则正z轴穿过你的屏幕朝向你。在OpenGL中采用z...",
    "content": "本文介绍了 OpenGL 中深度缓冲的概念，分析了在渲染巨型尺度场景下的深度冲突问题，并给出了采用对数深度缓冲的具体解决方案。  1. 深度缓冲  2. 深度冲突  3. 对数深度缓冲  4. 参考文献1. 深度缓冲OpenGL是一个右手坐标系。简单来说，就是正x轴在你的右手边，正y轴朝上，而正z轴是朝向后方的。想象你的屏幕处于三个轴的中心，则正z轴穿过你的屏幕朝向你。在OpenGL中采用z坐标来描述深度信息。一般地，z轴的坐标原点在屏幕上，屏幕里为负轴，向外为正轴。OpenGL中的观察者为摄像机。一般地，摄像机的初始位置在OpenGL窗口的正中心。图 1 坐标系定义OpenGL在绘制图形时，有些图形在前，有些图形在后，这时候就用到了z坐标。当然，并不一定图形1的z坐标大于图形2的z坐标，就说图形1会绘制在图形2的前面，因为图形的前后顺序决于我们的观察平面，即摄像机的位置。深度缓冲（Depth Buffer）的原理就是把一个距离观察平面的深度值与窗口的每个像素相关联。在场景绘制时，在片段着色器中，如果遇到两个像素在屏幕上坐标相同的情况，在绘制前将会比较两者的深度（Z值），以判断两者之间谁离观察者更近。如果新的像素深度值大于旧的顶点，则以新像素覆盖原有像素；反之则放弃绘制新像素，保留原有像素。这个比较的过程称为深度测试(deepth testing)。深度缓冲是由窗口系统自动创建的，它会以16、24或32位float的形式储存它的深度值。在大部分的系统中，深度缓冲的精度都是24位的。深度缓冲包含了一个介于0.0和1.0之间的深度值，它将会与观察者视角所看见的场景中所有物体的z值进行比较。观察空间的z值可能是投影平截头体的近平面(Near)和远平面(Far)之间的任何值。我们需要一种方式来将这些观察空间的z值变换到[0, 1]范围之间，其中的一种方式就是将它们线性变换到[0, 1]范围之间。下面这个（线性）方程将z值变换到了0.0到1.0之间的深度值[1]：\\[F_{depth}=\\frac{z-near}{far-near}\\]这里的$near$和$far$值是我们之前提供给投影矩阵设置可视平截头体的近平面（near plane）和远平面（far plane）。这个方程需要平截头体中的一个$z$值，并将它变换到了$[0, 1]$的范围中。可以看出，这个方程计算得到的深度值是线性的，然而，在实践中是几乎永远不会使用这样的线性深度缓冲（Linear Depth Buffer）的。图 2 平截头体和远/近平面要想有正确的投影性质，需要使用一个非线性的深度方程，它是与$ 1/z$ 成正比的。它做的就是在$z$值很小的时候提供非常高的精度，而在$z$值很远的时候提供更少的精度。花时间想想这个：我们真的需要对1000单位远的深度值和只有1单位远的充满细节的物体使用相同的精度吗？线性方程并不会考虑这一点。考虑一种深度缓冲与 $z$ 成反比的非线性方程如下：\\[F_{depth}=\\frac{1/z-1/near}{1/far-1/near}\\]由于深度值与$ 1/z$ 成正比，在1.0和2.0之间的z值将会变换至1.0到0.5之间的深度值，这就是一个float提供给我们的一半精度了，这在z值很小的情况下提供了非常大的精度，而在$z$值很大时，比如$z$在50.0和100.0之间的z值将会只占2%的float精度，这正是我们所需要的。也就是说，深度值很大一部分是由很小的$z$值所决定的，这给了近处的物体很大的深度精度（靠近相机的地方精度更高）。2. 深度冲突非线性深度缓冲在大多数场景中已经足够应用。然而，当两个模型间相距很近、或需要渲染大尺度场景（比如行星际场景）时，使用上述非线性深度缓冲会出现一个很严重的问题——深度冲突（z-fighting）。图 3 深度冲突比如在太阳系场景渲染中，一般需要同时渲染尺寸巨大距离遥远的行星（比如真实绕地飞行的月球）和体型相对很小的人造卫星。此时，需要设置很大的远平面值以保证极远处的物体能够得以渲染，设置很小的近平面值保证距离摄像机很近的物体也能够得以渲染。此时，若两个物体在距离摄像机较远，就没有足够的精度用于判断其远近。两个物体在同一个像素生成的渲染结果很容易对应到一个相同的z值，渲染器就不知道哪个物体在前，哪个物体在后，于是便开始“胡作非为”，这次让这个物体的这个像素在前面，下次让那个物体的这个像素在前面，于是模型的重叠部位便不停的闪烁起来。这便是深度冲突问题。可采用以下措施来减缓深度冲突：  多边形偏移（Polygon_Offset）：永远不要把多个物体摆得太靠近，以至于它们的一些三角形会重叠。通过在两个物体之间设置一个用户无法注意到的偏移值，你可以完全避免这两个物体之间的深度冲突。以放在地板上的一个箱子为例，我们可以将箱子朝上（沿着正y轴）稍微移动一点。箱子位置的这点微小改变将不太可能被注意到，但它能够完全减少深度冲突的发生。然而，这需要对每个物体都手动调整，并且需要进行彻底的测试来保证场景中没有物体会产生深度冲突。  近平面调整：尽可能将近平面设置远一些。在前面我们提到了精度在靠近近平面时是非常高的，所以如果我们将近平面远离观察者，我们将会对整个平截头体有着更大的精度。然而，将近平面设置太远将会导致近处的物体被裁剪掉，所以这通常需要实验和微调来决定最适合你的场景的近平面距离。  提高深度缓冲精度：牺牲一些性能，使用更高精度的深度缓冲。大部分深度缓冲的精度都是24位的，但现在大部分的显卡都支持32位的深度缓冲，这将会极大地提高精度。所以，牺牲掉一些性能，你就能获得更高精度的深度测试，减少深度冲突。上述三个技术是最普遍也是很容易实现的抗深度冲突技术了。然而，上述措施只能减缓深度冲突问题，并不能够完全消除。还有一些更复杂的技术，但它们依然不能完全消除深度冲突：  多平截头体渲染（Multi-Frustums Rendering）  对数深度缓冲（Logarithmic Depth Buffer)多边形平移需要手动设置每个可能发生深度冲突的模型，当模型很多时手动设置的工作量巨大。多平截头体渲染需要根据所渲染的场景的尺寸，设置若干个平截头体，渲染工作量大，平截头体交汇处可能存在渲染问题。3. 对数深度缓冲对数深度缓冲（Logarithmic Depth Buffer）使得大尺寸场景（比如行星际尺寸）能够按照真实比例渲染，而几乎不会出现因精度不足导致的深度冲突现象。公式如下[2]：公式\\[z= \\left( 2\\cdot\\frac{log{(C \\cdot w + 1)}}{log(C \\cdot far + 1)} - 1 \\right)  \\cdot  w\\]其中，$C$是常量。不同的$C$值会影响深度的精度；$w$是gl_Position.w。相应的代码实现如下。顶点着色器中：// vertex shaderout float logz;in float far;void main(){    ...    float C = 1;    float FC = 1.0 / log(far * C + 1);\tlogz = log(gl_Position.w * C + 1) * FC;    gl_Position.z = (2 * logz - 1) * gl_Position.w;}片段着色器中：// fragment shaderin float logz;void main(){    ...    gl_FragDepth = logz;}可对上述代码进行进一步优化[3]：  使用 log2 代替 log: 因为在着色器中，log 是基于 log2 实现的，因此直接使用 log2 避免额外的计算；  避免裁剪问题: 当数值小于等于 0 时，log 函数没有定义。当三角形的某个顶点超出相机平面时 (≤ -1)，会导致该三角形在裁剪之前就被整个删除。将 log 函数的输入值限定在max(1e-6, 1.0 + gl_Position.w)可以避免这个问题；  移除常数C：常数C用来调整近端的精度，但因为一般情况下C=1时的精度已经足够使用，因此将其移除。最终优化的代码如下。顶点着色器中：// vertex shaderout float flogz;out float Fcoef;in float far;...void main(){    ...\tFcoef = 2.0 / log2(far + 1.0);\tflogz = 1.0 + gl_Position.w;\tgl_Position.z = log2(max(1e-6, flogz)) * Fcoef - 1.0;\tgl_Position.z *= gl_Position.w;}片段着色器中：// vertex shaderout float logz;in float far;...void main(){    ...    gl_FragDepth = log2(flogz) * Fcoef * 0.5;}值得注意的是，在某些极端场景下[4]，单纯采用对数深度缓冲仍然会存在深度冲突（如从极远的距离观看极大尺寸的三角面）。此时可以采取“多平截头体渲染+对数深度缓冲”二者混合的模式（Hybrid Multi-Frustum Logarithmic Depth Buffer）来渲染场景。4. 参考文献[1]\tLearnOpenGL. Depth Testing[2]\tOuterra. Maximizing Depth Buffer Range and Precision[3]\tOuterra. Logarithmic depth buffer optimizations &amp; fixes[4]\tCesium. Hybrid Multi-Frustum Logarithmic Depth Buffer[5]\tsirlis. Logarithmic Depth Buffer in OpenGL with glad/glfw"
  },
  
  {
    "title": "ITX机箱购置记录",
    "url": "/posts/itx/",
    "categories": "Diary",
    "tags": "hardware",
    "date": "2020-05-10 22:21:49 +0800",
    





    
    "snippet": "本文介绍了 本人购买和组装第一台 itx 主机的配置和过程。  1. 前言  2. 机箱  3. 主板  4. CPU  5. 硬盘  6. 内存  7. 显卡  8. 其它  9. 其它v21. 前言寒假回家，用了六年的Lenovo Y50笔记本死机了两次，感觉快要寿终正寝了。无奈打算换个机子，恰逢联想五月退出拯救者新品，遂观望，首发无AMD+RTX2060版本，卒。从此看破厂商对笔记本的...",
    "content": "本文介绍了 本人购买和组装第一台 itx 主机的配置和过程。  1. 前言  2. 机箱  3. 主板  4. CPU  5. 硬盘  6. 内存  7. 显卡  8. 其它  9. 其它v21. 前言寒假回家，用了六年的Lenovo Y50笔记本死机了两次，感觉快要寿终正寝了。无奈打算换个机子，恰逢联想五月退出拯救者新品，遂观望，首发无AMD+RTX2060版本，卒。从此看破厂商对笔记本的割韭菜行径，转而寻求自配台式机。由于工作需要各地奔波，需小体积台式机，遂如ITX坑，幸得某 热心市民杨先生 的帮助，敲定配置和机箱如下机箱：水冷快乐盒L 银色                                           450r主板：微星 B450I (MSI B450I GAMING PLUS AC)                    850rCPU：AMD R7 3700X                                            2000r硬盘：三星 PM981 512G (SAMSUNG MZVLB512HAJQ-0000) 系统盘        535r     海康威视 E200P 1T (HKVSN HS-SSD-E200PRO/PLP/1024G) 数据盘  780r内存：科赋 DDR4 16G*2 3200MHz (KLEVV)                          1080r显卡：NVIDIA GeForce RTX 2060 6G (索泰RTX2060 6G 毁灭者)        2160r电源：MuPC定制500W金牌 白色模组线（极致猫同款）                      450r其它：AXP90散热器，顶置12025风扇*2，显卡延长线                     180r+0r+100r总计 ￥8580 ，肉疼。算错不怪我，我数学是体育老师教的。2. 机箱纠结了很久机箱，由于需要方便携带，因此只能选择A4机箱，又要求要有现货，刚好老杨手上有斐虹工业出品的水冷快乐盒L，大小尺寸外形还比较满意，遂敲定。一开始选配的是黑色版，但是老杨装机发现黑色版有缺陷，遂换成银色版。3. 主板我的主板型号为：微星 B450I。主板我啥也不懂，反正跟着CPU走，老杨说啥就是啥了。以下为网络结果和某人观点的结合，不代表本人，有任何意见或建议请憋着。B450I主板主要有4个厂商的版本：微星、技嘉、华硕、华擎。                   优点      缺点                  微星      供电足，6+2相，超频厉害      声卡网卡无线网卡都是低端配置              微星      bios 界面人性化，操作方便      系统自检时间较长              微星      /      m2 接口在背面，散热较差              微星      /      价格略贵              技嘉      声卡无线网卡都是较高端的      供电4+2相，稍少              技嘉      m2 接口在正面，有散热装甲      bios 不友好              技嘉      各方面比较均衡没有明显劣势      /              华硕      双m2插口正面反面都有一个      供电集显部分不足只有1相              华硕      开机信仰加成      m2 接口在背面              华硕      /      价格略贵              华擎      妖板高性价比著称，没钱选他就对，又不是不能用      不知道      4. CPU我的CPU：AMD R7 3700X。由于个人对多线程需求较高，因此选AMD的CPU，别的不说价格真香，花一半的钱买更多的核，还特么7nm工艺。看看对面Intel牙膏厂，都特么0202年了还在11nm挤牙膏。一句话，AMD YES！什么？你说积热？你说超频性能不提升？你说稳定性？你说兼容性？抱歉我没听见。5. 硬盘系统盘我选择了：三星 PM981 512G。没啥，老杨说的，我被逼无奈。数据盘本来打算用1T的机械，后来大家懂得，陷入某人的加价套路，加点钱换成海康威视的1T固态了。（此处应该有图，但是硬盘的图没什么好看的，懒得放了）6. 内存内存真的是惨痛的经历。原本选配的是 海盗船LPX 16G*2 3200MHz ，老杨千辛万苦给装好机子装好系统，寄给我，我拿到手，boom！，无限重启。经过多轮磋商，认定内存和CPU不兼容，于是才换了现在的 科赋 16G*2 3200MHz，老杨说用的是雷霆马甲条，咱也不懂。不说了，又多掏了￥100。7. 显卡我的显卡是NVIDIA RTX 2060，2系列最最最最最底端的一块显卡了。无他，没钱了，我特么也想RTX 2080Ti啊，没人赞助啊。结果，训练神经网络的时候，教程视频那哥们2080Ti已经迭代25次了，我才到第7次……有一点需要注意，ITX机箱特别是A4机箱，显卡宽度和长度务必确保能塞进机箱，一般机箱对显卡的尺寸都是有严格要求的。反正我是没这技术，不过我有老杨，他负责装机，他保证能塞进去，塞得爽，那就行了。（老杨：废话，爸爸配的是短卡，塞不进去才怪）8. 其它电源散热什么的都是老杨配的，咱也不懂，咱也不敢问。9. 其它v2来点开箱照骗好了。"
  },
  
  {
    "title": "VSCode部署Pytorch机器学习框架",
    "url": "/posts/vscode-pytorch/",
    "categories": "Tutorial, Coding",
    "tags": "vscode, python, pytorch",
    "date": "2020-03-22 09:22:19 +0800",
    





    
    "snippet": "本文介绍了 Pytorch 机器学习框架的下载和部署，以及 Pytorch 开发环境的配置。  1. 简介  2. 配置Python开发环境  3. 配置PyTorch          3.1. 部署PyTorch      3.2. 部署其它包                  3.2.1. CUDA          3.2.2. cuDNN          3.2.3. Numpy...",
    "content": "本文介绍了 Pytorch 机器学习框架的下载和部署，以及 Pytorch 开发环境的配置。  1. 简介  2. 配置Python开发环境  3. 配置PyTorch          3.1. 部署PyTorch      3.2. 部署其它包                  3.2.1. CUDA          3.2.2. cuDNN          3.2.3. Numpy          3.2.4. matplotlib          3.2.5. pandas                    3.3. 手动部署CUDA和cuDNN      3.4. 测试        4. 常见错误          4.1. RuntimeError:An attempt has been made…      requires_grad 与 requires_grad_ 混淆        5. 参考文献1. 简介PyTorch是一个开源的Python机器学习库，基于Torch，用于自然语言处理等应用程序。2017年1月，由Facebook人工智能研究院（FAIR）基于Torch推出。它是一个基于Python的可续计算包，提供两个高级功能：1、具有强大的GPU加速的张量计算（类似NumPy）。2、包含自动求导系统的的深度神经网络。吃别人一记强力安利：PyTorch到底好用在哪里？2. 配置Python开发环境参考《VSCode部署Python开发环境》配置。3. 配置PyTorch3.1. 部署PyTorch前往官网（https://pytorch.org/get-started/locally/），根据自身的开发环境，获取PyTorch安装命令行。以Windows 10系统+RTX2060显卡为例，采用pip安装，如图选择，得到安装命令行注意，PyTorch包含两个版本，CPU版（CUDA=None）和GPU版，若计算机没有合适的独立显卡，则CUDA选择None。不过GPU版同样包含CPU版的所有功能，因此完全可以安装GPU版，然后不用GPU计算加速功能。注意，请自行确认独立显卡驱动支持的CUDA版本。打开控制面板，选择查看方式为“小图标”，选择“Nvidia控制面板”，然后如图所示的步骤依次打开“系统信息” =&gt; “组件”，查看 “NVCUDA.DLL” 的产品名称，并选择不超过其版本号的CUDA版本号。确定CUDA版本号后，根据官网给出的命令安装（可以灵活选择，比如用不到torchaudio就删了）。# 20230422 win11 rtx2060 miniconda python 3.9pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113打开Anaconda Navigator，激活相应的环境，打开环境的终端，输入上述命令即可完成PyTorch的安装。【2023.04.22补充】注意，使用 conda 通过官网命令行安装也可能安装为 cpu 版本，推荐 pip 安装。【2020.09.07补充】请务必尽量用官网提供的命令行安装，直接从 Anaconda 界面安装的是 cpu 版本【20210524补充】尝试过各种加速下载的方法，卒，老老实实用官方命令安装吧，且用conda时最好关闭任何fq代理，而且不要用国内源，而是使用官方默认源（也即删除.conrc文件），否则会报如下代理连接错误 ProxyError: Conda cannot proceed due to an error in your proxy configuration.【2021.05.25更新】，经测试可使用的GPU版本的PyTorch包含以下组件：  pytorch 1.8.1  torchvision 0.9.1  cuda 10.2.89  cudnn 7.6.5（与cuda版本有关）【2023.04.22更新】win11+RTX2060，经测试可使用的GPU版本的PyTorch包含以下组件（官网默认源pip安装命令2.1G）：  pytorch 1.12.1+cu113  torchvision 0.13.1+cu113  cuda 11.1.105 （官网下载 cuda_11.1.1_win10_network.exe，命令行 nvcc -V）  cudnn 8.9.0 (官网下载 cudnn-windows-x86_64-8.9.0.131_cuda11-archive.zip 解压覆盖至 CUDA 安装路径)3.2. 部署其它包3.2.1. CUDACUDA（Compute Unified Device Architecture），是NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。 它包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。 开发人员可以使用C语言来为CUDA™架构编写程序。所编写出的程序可以在支持CUDA™的处理器上以超高性能运行。CUDA依赖显卡驱动，提前更新显卡驱动并确认显卡驱动支持的CUDA版本号。  采用命令行安装 PyTorch 时，命令行中已经带有安装CUDA的指令 cudatoolkit=xx.x。CUDA Toolkit 可理解为是 CUDA 的一个子集，其主要包含应用程序在使用 CUDA 相关的功能时所依赖的动态链接库。conda安装只会安装一些计算库，不会安装编译工具。而官方的 CUDA 包包含的东西会完整一些。在运行基于pytorch的代码时会使用conda提供的cudatoolkit包，而忽视Nvidia官方的CUDA Toolkit。这也就是为什么有时候我们通过nvcc -V查看的CUDA运行API版本很低(比如7.5)，但是能成功运行cuda9.0的pytorch的原因。但是需要注意： 如果项目代码需要使用python setup.py develop或./make.sh来编译依赖cuda的torch模块（如C语言脚本）时候，这个时候可能会导致错误，错误原因是编译过程使用的是系统自带的CUDA而不是conda安装的CUDA包，当系统自带CUDA版本不支持项目代码时，会引发一些奇怪的问题，所以最好的办法是保持pytorch安装的cudatoolkit版本与系统自带版本（nvcc -V）查看一致。可通过Anaconda界面安装。若界面安装仍然失败，可尝试手动安装，请前往 手动部署CUDA和cuDNN。3.2.2. cuDNN可通过Anaconda界面安装。若界面安装失败，可尝试手动安装，请前往 手动部署CUDA和cuDNN。3.2.3. NumpyNumPy（Numerical Python）是Python的一种开源的数值计算扩展。这种工具可用来存储和处理大型矩阵，比Python自身的嵌套列表（nested list structure)结构要高效的多（该结构也可以用来表示矩阵（matrix）），支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。  注意！numpy若通过 conda 或 Anaconda 界面安装可能存在问题，需要用 pip 安装  注意！基础包一定要先安装并测试好能用，再安装其他包。比如先装numpy，再安装scipy，matplotlib等。采用命令行安装conda install numpypip install numpy或者通过Anaconda界面进行安装。3.2.4. matplotlibmatplotlib包用以进行绘图，采用命令行安装conda install matplotlib或者通过Anaconda界面进行安装3.2.5. pandaspandas包用于输入输出和处理csv格式数据，采用命令行安装conda install pandas或者通过Anaconda界面进行安装3.3. 手动部署CUDA和cuDNN若自动安装CUDA和cuDNN失败，也可选择手动安装部署CUDA。首先需要更新自己的显卡驱动，此处不再赘述。若要手动部署CUDA和cuDNN，必须遵循先CUDA后cuDNN的顺序。首先前往官网（https://www.nvidia.com/）下载CUDA。【2023.04.22更新】官网下载页面和网址天天变，大家自己找一下把…https://developer.nvidia.com/cuda-downloads?target_os=Windows&amp;target_arch=x86_64&amp;target_version=11&amp;target_type=exe_network然后根据自己的实际情况选择相应的CUDA版本下载安装。手动安装CUDA后需要进行检查。win+R 输入 cmd 回车，打开命令提示符，输入nvcc -V若成功返回cuda版本等信息则表示安装成功。继续输入（其中路径自行根据CUDA安装路径调整）cd C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\demo_suite然后输入 deviceQuery.exe，执行此程序。出现 PASS 即表示CUDA安装成功。然后，前往此处（https://developer.nvidia.com/cudnn ），点击 “Download cuDNN” 按钮下载cuDNN。下载前需要注册账号并登陆。注意，cuDNN版本与CUDA版本间存在匹配关系，下载时一定要注意。下载解压后得到的文件直接覆盖到CUDA安装路径，如下图所示。3.4. 测试在环境中启动终端，激活 pytorch 安装的环境conda activate [name_of_your_env]输入python启动python环境。检查pytorch是否能够正确调用GPU驱动和是否能够启用CUDA，输入：import torchtorch.cuda.is_available()返回 True 即可。然后一行行输入以下命令from __future__ import print_functionx = torch.rand(5, 3)print(x)上面的代码用于产生一个5行3列的随机矩阵（张量），输出应该为下面类似的形式tensor([[0.3380, 0.3845, 0.3217],        [0.8337, 0.9050, 0.2650],        [0.2979, 0.7141, 0.9069],        [0.1449, 0.1132, 0.1375],        [0.4675, 0.3947, 0.1426]])推出 pythonexit()4. 常见错误4.1. RuntimeError:An attempt has been made…RuntimeError:An attempt has been made to start a new process before the current process has finished its bootstrapping phase.         This probably means that you are not using fork to start your        child processes and you have forgotten to use the proper idiom        in the main module:             if __name__ == '__main__':                freeze_support()出错的位置一般在如下位置for i, (inputs, labels) in enumerate(train):解决办法是，在包含这个 for 循环的训练函数前面，包上 main 函数 if __name__==\"__main__\":。因为在 Windows 中，多线程程序要放在主函数中训练。而前面的 train 数据集很可能来源于另一个 .py 文件进行处理的结果，如if __name__ == '__main__':  train = torch.utils.data.DataLoader(      DATA(root, train=True, transform=transform),  # from DATA.py      batch_size=batch_size, shuffle=True, **kwargs)requires_grad 与 requires_grad_ 混淆  所有的 tensor 都有 .requires_grad 属性，可以在初始化时设置这个属性x = tensor.ones(2,4,requires_grad=True)  如果想改变这个属性，就调用 tensor.requires_grad_() 方法：x.requires_grad_(False)5. 参考文献[1] Sunnyside_Bao. Anaconda＋vscode＋pytorch环境搭建."
  },
  
  {
    "title": "VSCode部署Python开发环境",
    "url": "/posts/vscode-python/",
    "categories": "Tutorial, Coding",
    "tags": "vscode, python",
    "date": "2020-03-21 15:22:19 +0800",
    





    
    "snippet": "本文介绍了基于 VSCode 的 Python 开发环境的搭建方法。  1. 简介  2. VSCode下载与安装  3. 配置Python开发环境          3.1. 部署解释器      3.2. 安装Anaconda      3.3. 新建和备份环境      3.4. 配置依赖包                  3.4.1. 更新包管理工具                ...",
    "content": "本文介绍了基于 VSCode 的 Python 开发环境的搭建方法。  1. 简介  2. VSCode下载与安装  3. 配置Python开发环境          3.1. 部署解释器      3.2. 安装Anaconda      3.3. 新建和备份环境      3.4. 配置依赖包                  3.4.1. 更新包管理工具                          3.4.1.1. pip              3.4.1.2. conda              3.4.1.3. 说明                                3.4.2. 更换镜像源                          3.4.2.1. pip镜像源              3.4.2.2. conda镜像源                                3.4.3. 常用命令                    3.5. 生成配置文件                  3.5.1. 解释配置（settings.json）          3.5.2. 调试配置（launch.json）                    3.6. 调试运行测试        4. 常见错误          4.1. 无法将conda项识别为cmdet…      4.2. 无法加载文件 \\WindowsPowerShell\\profile.ps1      4.3. 提示CommandNotFoundError      4.4. OMP: Error #15: Initializing xxx      4.5. Refactor failed…        5. 参考文献1. 简介Python是一种跨平台的计算机程序设计语言。 是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言。最初被设计用于编写自动化脚本(shell)，随着版本的不断更新和语言新功能的添加，越来越多地被用于独立的、大型项目的开发。2. VSCode下载与安装前往官网（https://code.visualstudio.com）下载安装，支持Windows、Linux和Mac系统。可以下载安装版，也可以选择解压即用的绿色版。区别在于安装板会向系统路径写入配置信息，绿色版所有的依赖信息和配置信息均存放于一个目录中。安装版可以在线下载更新和安装更新，绿色版只能下载新版本的绿色安装包解压后覆盖来更新。安装完成后，点击左侧的扩展商店，搜索chinese，下载中文简体汉化包（可能需要翻墙）。安装完成后重启VSCode，即可发现所有界面均已汉化。注意：      VSCode基于文件夹进行编译和调试，每个项目必须对应一个文件夹作为工作路径（根目录），根目录内包含一个.vscode文件夹存放配置文件（json格式）；        VSCode默认编码为UTF8，对中文支持并不完美，特别是打开已有的包含中文注释的源代码文件时要特别注意，可能导致中文乱码，且在保存文件时弹出警告。因此，对于包含中文注释的已有文件，一般需要新建一个空白文件，保存为UTF8编码格式，然后重新输入中文注释部分再进行保存。  3. 配置Python开发环境3.1. 部署解释器扩展商店搜索“python”，安装微软官方出品的Python扩展。然后重启VSCode。然后配置Python解释器。3.2. 安装Anaconda常用Anaconda配置Python环境[1]（若嫌弃庞大可使用Miniconda）。Anaconda是一个方便的python包管理和环境管理软件，一般用来配置不同的项目环境。我们常常会遇到这样的情况，正在做的项目A和项目B分别基于 python 3.7 和 python 3.9，而电脑一般只能安装一个环境，这个时候Anaconda就派上了用场，它可以创建多个互不干扰的环境，分别运行不同版本的软件包，以达到兼容的目的。Anaconda通过管理工具包、开发环境、Python版本，大大简化了你的工作流程。不仅可以方便地安装、更新、卸载工具包，而且安装时能自动安装相应的依赖包，同时还能使用不同的虚拟环境隔离不同要求的项目。Anaconda支持Windows、Linux和Mac平台，从官方网站（https://www.anaconda.com/） 选择对应平台的Anaconda3安装包下载。对于Windows 10平台，推荐下载64-Bit的Python3.8版本的安装包（466M）。采用默认配置安装Anaconda，安装路径可以自定义，但务必记住安装路径。安装无需联网，保险起见请关闭杀毒软件。进行到下图步骤时，均不勾选，后面我们将手动配置环境变量。将Anaconda安装路径的三个路径变量写入系统Path中D:\\XXX\\Anaconda3D:\\XXX\\Anaconda3\\ScriptsD:\\XXX\\Anaconda3\\Library\\bin3.3. 新建和备份环境在开始菜单中找到“Anaconda Navigator”，单击打开后，点击左侧的“Environments”，可以看到默认存在一个 base(root) 环境。点击下方的Create按钮新建一个环境。弹出 Create new environment 界面，输入 Name ，勾选 Python 并下拉选择 3.7 版本。然后记住 Location 对应的环境路径。最后点击 Create 完成环境配置，新建的环境会显示在环境列表中。也可在终端使用如下命令建立一个使用 python 3.9 的新环境：conda create -n [your_env_name] python=3.9注意，envs 内的每一个子文件夹都是一个独立的环境，删除、重命名子文件夹等价于删除、重命名环境。将子文件夹复制到其他机器的Anaconda的envs文件夹中，该机器的Anaconda可直接识别并应用该环境。因此可在配置好一个环境后，对该子文件夹进行备份。激活某个环境的方法为左键单击该环境。打开某个环境的终端为点击环境名称旁边的三角按钮，在弹出菜单中选择 Open Terminal。也可以使用如下命令：conda activate [your_env_name]3.4. 配置依赖包3.4.1. 更新包管理工具3.4.1.1. pipPython默认的包管理工具是pip。输入以下命令查看pip版本pip show pip如果pip版本不是最新的，很多包可能安装不上。可通过命令更新pip。打开环境的终端（Terminal），输入以下命令后回车python -m pip install --upgrade pip如果pip版本不是最新的，会更新到最新版本，如下图所示如果pip版本已经是最新的，会如下图提示3.4.1.2. conda还可以采用第三方的开源跨平台包管理工具conda进行包管理，作为pip无法进行包更新时的备份工具。Anaconda安装后一般默认安装了conda工具。要查看环境是否安装了conda，打开环境的终端，输入conda -V若返回conda的版本号，则表示环境中默认搭载了conda。输入以下命令更新condaconda update -n base conda期间提示是否更新包，输入y确认3.4.1.3. 说明conda和pip通常被认为几乎完全相同。虽然这两个工具的某些功能重叠，但它们设计用于不同的目的。 pip是Python Packaging Authority推荐的用于从Python Package Index安装包的工具。 Pip安装打包为wheels或源代码分发的Python软件。后者可能要求系统安装兼容的编译器和库。conda是跨平台的包和环境管理器，可以安装和管理来自Anaconda repository以 Anaconda Cloud的conda包。 conda包是二进制文件，需要使用编译器来安装它们。另外，conda包不仅限于Python软件。它们还可能包含C或C ++库，R包或任何其他软件。这是conda和pip之间的关键区别。 Pip安装Python包，而conda安装包可能包含用任何语言编写的软件的包。在使用pip之前，必须通过系统包管理器或下载并运行安装程序来安装Python解释器。而conda可以直接安装Python包以及Python解释器，即conda将python本身也当做一个包来管理。另外，conda查看环境中安装的所有包时，可以包含从Anaconda界面安装的包，而pip则只能查看到所有通过命令行安装的包。如下图所示，通过Anaconda界面安装的cudatoolkit和cudnn包，在pip中无法查到。对于用户而言，尽可能从一而终的采用一种包管理工具。若使用Anaconda配置的python环境，则推荐使用conda，配合Anaconda界面使用更加友好，除非某些包无法通过conda安装，则可采用pip安装。3.4.2. 更换镜像源3.4.2.1. pip镜像源pip的默认镜像源在国外，更新包会下载缓慢甚至无法下载，可更换到国内的镜像源（清华、阿里、中科大等）。对于Linux系统，直接修改 ~/.pip/pip.conf (没有就创建一个)， 内容如下[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple对于Windows系统，快捷键 win+R  打开运行，输入 %HOMEPATH% 回车打开用户目录，在此目录下创建 pip 文件夹，在 pip 文件夹内创建 pip.ini 文件, 内容如下[global]timeout = 6000index-url = https://pypi.tuna.tsinghua.edu.cn/simpletrusted-host = pypi.tuna.tsinghua.edu.cn点击 “Update index…” 更新索引3.4.2.2. conda镜像源可通过修改用户目录下的 .condarc 文件来更换源，文件位于Windows：C:\\Users\\xxx\\.condarcLinux：/home/xxx/.condarc其中 xxx 为用户账户名称。如果该路径下没有该文件，可自行新建一个，注意文件全名为 “.condarc”，没有其它任何后缀。若Windows用户无法直接新建该文件，可以先执行以下命令生成该文件conda config --set show_channel_urls yes将下面的代码覆盖文件中所有内容，完成源更换channels:  - defaultsshow_channel_urls: truechannel_alias: https://mirrors.tuna.tsinghua.edu.cn/anacondadefault_channels:  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2custom_channels:  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud运行以下命令清除缓存conda clean -i点击 “Update index…” 更新索引3.4.3. 常用命令  安装包（注意！必须要断开所有VPN等科学上网代理再进行安装！）pip install xxxconda install xxx  显示环境下所有安装的包[conda]  conda list [pip]    pip -v list  显示所有过时包pip list --outdated  更新特定包pip install --upgrade xxxx或者使用conda upgrade xxxx  更新pippython -m pip install --upgrade pip  更新condaconda update -n base -c defaults conda3.5. 生成配置文件在项目工作路径下新建 .vscode 文件夹，其中新建以下两个配置文件，并用下面的内容填充。3.5.1. 解释配置（settings.json）{    \"python.pythonPath\": \"E:\\\\ProgramFiles\\\\Anaconda3\\\\envs\\\\Pytorch\\\\python.exe\"}其中具体的python路径位置因Anaconda安装位置不同而不同，注意转义字符 \\\\。3.5.2. 调试配置（launch.json）{    \"version\": \"0.2.0\",    \"configurations\": [        {            \"name\": \"Python: 当前文件\",            \"type\": \"python\",            \"request\": \"launch\",            \"program\": \"${file}\",            \"console\": \"integratedTerminal\"        }    ]}3.6. 调试运行测试随便新建一个 python 文件，如 printtest.py 进行测试，下图可以看出具备代码智能补全功能。按 F5 运行结果如下4. 常见错误4.1. 无法将conda项识别为cmdet…VSCode 解释 .py 时，终端自动运行命令 conda activate Pytorch(环境名) 时提示无法将“conda”项识别为 cmdlet、函数、脚本文件或可运行程序的名称。解决方法如下。【推荐】要么将Anaconda安装路径的三个路径变量写入系统 Path 中，然后重启电脑。X:\\XXX\\Anaconda3X:\\XXX\\Anaconda3\\ScriptsX:\\XXX\\Anaconda3\\Library\\bin要么打开VSCode的设置（ctrl+,），设置Python插件中的conda的路径然后重启电脑。4.2. 无法加载文件 \\WindowsPowerShell\\profile.ps1以管理员身份打开 PowerShell 输入set-executionpolicy remotesigned4.3. 提示CommandNotFoundErrorVSCode 解释 .py 时，终端自动运行命令 conda activate xxx(环境名) 时提示CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.If using 'conda activate' from a batch script, change yourinvocation to 'CALL conda.bat activate'.解决方法如下。首先在VSCode 的终端中输入 conda init，然后重启VSCode，查看问题是否解决。若出现错误无法加载文件 ******.ps1，因为在此系统中禁止执行脚本。关闭VSCode，然后使用管理员权限打开 cmd，比如按 Win+X，选择 Windows PowerShell（管理员） 打开，输入命令set-ExecutionPolicy RemoteSigned回车执行策略更改 执行策略可以防止您执行不信任的脚本。更改执行策略可能会使您面临 about_Execution_Policies 帮助主题中所述的安全风险。是否要更改执行策略? [Y] 是(Y)  [N] 否(N)  [S] 挂起(S)  [?] 帮助 (默认值为“Y”): y然后输入 y 回车。之后重启VSCode，F5 执行Python文件应该就不会提示错误了。4.4. OMP: Error #15: Initializing xxxOMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized允许副本存在，程序中添加import osos.environ[‘KMP_DUPLICATE_LIB_OK’]=‘True’4.5. Refactor failed…当打开一个 .py 文件，试图通过 F2 快捷键来修改变量名称时，会弹出 Refactor failed....... 一大串错误。这是因为如果该文件没有运行过，VSCode 默认的 Python 自动补齐和静态分析工具 Jedi 必须要求先运行一次 .py 文件才能进行改名。因此可以选择更加新的自动补齐和静态分析工具 Pylance （由微软开发）解决不运行文件而需要改名的操作。左下角齿轮打开设置，输入 jedi ，定位到 Python: Language Server，然后将选项改成 Pylance ，提示需要安装 Pylance 插件，安装后重启 VSCode 即可。5. 参考文献[1] 挖掘机小王子. VSCode+Anaconda打造舒适的Python环境.[2] Eric-Young. python之VSCode安装."
  },
  
  {
    "title": "VSCode部署C/C++开发环境",
    "url": "/posts/vscode-c/",
    "categories": "Tutorial, Coding",
    "tags": "vscode, c/c++",
    "date": "2020-03-18 12:21:49 +0800",
    





    
    "snippet": "本文介绍了基于 VSCode 的 C/C++ 开发环境的搭建方法。  1. 配置 VSCode          1.1. VSCode 简介      1.2. VSCode 下载与安装      1.3. VSCode 注意事项        2. 配置 C/C++ 开发环境          2.1. 安装 C/C++ 插件      2.2. 选择编译器      2.3. 部署 M...",
    "content": "本文介绍了基于 VSCode 的 C/C++ 开发环境的搭建方法。  1. 配置 VSCode          1.1. VSCode 简介      1.2. VSCode 下载与安装      1.3. VSCode 注意事项        2. 配置 C/C++ 开发环境          2.1. 安装 C/C++ 插件      2.2. 选择编译器      2.3. 部署 MinGW-W64 编译器                  2.3.1. 下载和部署          2.3.2. 确认部署情况          2.3.3. 选择工具链          2.3.4. VSCode 工具链配置                          2.3.4.1. 配置 task.json              2.3.4.2. 配置 launch.json              2.3.4.3. 测试工具链                                2.3.5. CMake 工具链配置                          2.3.5.1. 下载和安装              2.3.5.2. 配置 CMakeLists.txt              2.3.5.3. 测试工具链                                          2.4. 部署 MSVC 编译器                  2.4.1. 下载和安装          2.4.2. 配置工具链                          2.4.2.1. VSCode 工具链配置              2.4.2.2. CMake 工具链配置                                            3. VSCode 默认快捷键  4. 参考文献1. 配置 VSCode1.1. VSCode 简介VSCode是微软推出的一款跨平台开源编辑器，凭借强大的第三方插件支持C/C++、Python、Java等众多语言，体积小巧功能丰富，适合小型工程项目的开发调试。注意，VSCode仅仅是一个前端文本编辑器，本质上与记事本并无不同，在没有插件和编译器的情况下只能进行文件的读写，并不能进行源程序编译调试。与之相对，微软自家的Visual Studio是一个集成开发环境（IDE），下载安装后可以直接进行源程序的编译调试。  从源代码转换为可执行程序的完整过程，也就是我们俗称的编译过程。经过几十年的发展，如今标准的编译过程如下：      源代码 (source code) =&gt; test.cpp, test.h    预处理器 (preprocessor) =&gt;    编译器 (compiler) =&gt; g++ -c test.cpp -o test.obj (windows)    汇编程序 (assembler) =&gt;    目标代码 (object code) =&gt; test.obj (windows) 或 test.o (linux)    链接器 (Linker) =&gt;    可执行文件 (executables) =&gt; test.exe (windows) 或 test.out / test.bin / test (linux)  VSCode 本身仅仅是一个源代码编辑器。不过，当配合插件和编译器后，VSCode也能够完成绝大部分的源代码编译调试工作。1.2. VSCode 下载与安装  下载与安装前往官网（https://code.visualstudio.com）下载安装，支持Windows、Linux和Mac系统。可以下载安装版，也可以选择解压即用的绿色版。区别在于安装板会向系统路径写入配置信息，绿色版所有的依赖信息和配置信息均存放于一个目录中。安装版可以在线下载更新和安装更新，绿色版只能下载新版本的绿色安装包解压后覆盖来更新。  安装汉化插件安装完成后，运行 VSCode，点击左侧的扩展商店，搜索 Chinese，下载中文简体汉化插件。安装完成后重启VSCode，即可发现所有界面均已汉化。1.3. VSCode 注意事项  VSCode基于文件夹进行编译和调试，每个项目必须对应一个文件夹作为工作路径（根目录），根目录内包含一个 .vscode 文件夹存放配置文件（json格式）；  VSCode默认编码为UTF8，对中文支持并不完美，特别是打开已有的包含中文注释的源代码文件时要特别注意，可能导致中文乱码，且在保存文件时弹出警告。因此，对于包含中文注释的已有文件，一般需要新建一个空白文件，保存为UTF8编码格式，然后重新输入中文注释部分再进行保存。  后续需要频繁操作系统的环境变量，此处展开介绍具体步骤如下，后文直接作为基本步骤不在赘述：          右键点击【此电脑】或【计算机】，选择【属性】。      点击【高级系统设置】。      在【系统属性】窗口中，点击【环境变量】。      在【系统变量】区域找到并选择【Path】，然后双击下面的空白行输入或复制需要添加的路径。      2. 配置 C/C++ 开发环境2.1. 安装 C/C++ 插件基于 VSCode 进行 C/C++ 项目开发，首先需要安装 C/C++ 插件。步骤如下：  点击左侧扩展商店按钮（按钮图示参考 安装汉化插件时的截图），搜索框输入【C/C++】；  找到 Microsoft 官方出品的 【C/C++】扩展，点击左下角安装；  安装完毕后重启 VSCode。注意，后文许多操作都需要安装 VSCode 的各种插件，后续不再赘述安装步骤。2.2. 选择编译器安装扩展完毕后，需要安装一款 C/C++ 编译器进行代码编译。C/C++ 编译器种类众多，主要包括 GCC 家族，MSC 家族，Clang 和其他编译器。在 Windows 环境下，VSCode 推荐使用 MinGW-w64 编译器或 MSVC 编译器。如果需要在 Windows 环境开发跨平台程序，只能选择 MinGW-W64 编译器。      GCC 家族（GNU Compiler Collection）              GNU C++：GCC家族的根本，其他编译器均从此导出        Cygwin：WIN32平台下的类UNIX环境，包含编译器        Mingw32-w64：WIN32平台的GCC编译器，代替Mingw32              MSVC 家族（Microsoft C/C++）              MSVC：微软 VS IDE 的编译器              LLVM-Clang 家族              Clang：基于LLVM的C/C++编译器，主要面向苹果开发              Borland 家族              TC/TC++        BC              其他              Intel C/C++        Watcom C/C++        …            根据个人编译器选择，跳转至后文对应章节查看。      2.3. 部署 MinGW-W64 编译器        2.4. 部署 MSVC 编译器  2.3. 部署 MinGW-W64 编译器2.3.1. 下载和部署  前往官方 GitHub（https://github.com/niXman/mingw-builds-binaries/releases ）下载编译器（需要FQ）。  版本：建议选择 x86_64-xx.x.0-release-posix-seh-ucrt-rt_v10-rev2.7z 版本；  部署：编译器以 .7z 压缩包的形式提供下载，下载完毕后 解压至全英文路径；  将解压路径的 ./bin 文件夹所在路径添加至系统环境变量 PATH 路径中；  典型路径如 C:/Program Files/mingw64/bin，根据实际情况修改。  关于 MinGW-W64 各版本的额外介绍：      线程模型：跨平台程序选择posix，win程序（要使用WinAPI）选择win32              [ posix ]：线程使用 pthread 的 Windows 版本。posix 是操作系统统一接口标准，不同操作系统需要提供相同的接口以方便应用移植，降低移植成本，但是只支持 POSIX 线程模型。pthread 是在 Linux 下常用的线程库，使用 posix 接口意味着应用的多线程模型移植更方便，哪怕从 Linux 下拉过来一个应用框架也可以较小代价修改代码。但在某些情况下会引起性能下降，毕竟不是 Windows 原生的线程库，C 标准可能到 C11 以上，并且支持 C11（C 语言编码标准）的特性；        [ win32 ]：使用 Windows 原生线程库，性能等方面表现更出色，兼容性更好，没有 C11 那些眼花缭乱的特性，就看你是否熟悉 Windows 相关接口。              异常模型：选择seh              [ seh ]：（Structured Exception Handling）是一种在Windows下特有的异常处理机制。SEH实现了一种结构化的异常处理机制，可以在程序运行过程中捕获并处理程序错误和异常。 SEH采用了一种基于表格的编码方式，在程序运行时会根据表格内的信息来处理异常。        [ dwarf ]：dwarf（DW2，dwarf-2）是一种跨平台的调试信息标准，主要用于UNIX/Linux平台的调试，可以提供更加详细和准确的调试信息，方便程序调试和分析。DWARF则是采用了一种基于编译器输出的调试信息格式，需要编译器在编译时生成相应的调试信息。        [ sjlj ]：【20230517补充】最新版本的 mingw-w64 已经不再支持 sjlj 异常处理，取而代之的是 dwarf2 和 seh 两种处理机制。如果您的程序依赖于 sjlj 异常处理机制，那么您需要考虑升级或修改代码以适应 mingw-w64 的最新版本。如果您仍然想使用 sjlj 异常处理机制，那么您可以考虑使用早期版本的 mingw-w64 或者尝试其他编译器。              C运行时：选择ucrt              [ucrt]：最新的 MinGW 安装包新引入并采用了 Universal C Runtime （UCRT），比 Microsoft Visual C Runtime （MSVCRT）更新。MSVCRT是逐渐被UCRT取代的，因为UCRT提供了一致的API（应用程序接口）和行为，能够让开发人员使用统一的代码来处理相同的任务，不管是哪个Windows平台甚至是通过不同版本编译器编译。但 UCRT 只支持 Windows 10 及其以上的操作系统。        [msvcrt]：MSVCRT（Microsoft Visual C++ Runtime）和UCRT（Universal C Runtime）是Microsoft Windows上的两种C标准库变体。MSVCRT在所有Microsoft Windows版本中都默认可用，但由于向后兼容性问题，它已经过时，不兼容C99并且缺少一些功能。            2.3.2. 确认部署情况完成编译器部署后，在命令提示符（CMD）或 Windows PowerShell 中输入以下命令 查看编译器是否部署成功gcc --version若返回如下信息则表明编译器安装成功gcc.exe (x86_64-posix-seh-rev1, Built by MinGW-Builds project) 13.1.0Copyright (C) 2023 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.上面的命令是用来检测 C编译器是否部署成功的，一般很少出现 C 编译器部署成功但是 C++ 编译器部署失败的情况。如果不放心可通过 g++ --version 检查 C++ 编译器是否安装成功。命令提示符打开方式为：  使用快捷键组合 Win + R；  输入 cmd 回车。Power Shell 打开方式为：  使用快捷键组合 Win + R；  输入 pwsh 回车。2.3.3. 选择工具链安装完编译器后，需要配置工具链（toolchain），告诉 VSCode 如何使用编译器进行编译调试运行操作。工具链有两种配置方式，一种是使用 VSCode 原生的配置，另一种是使用第三方软件 CMake 进行配置。二者的差异在于：  基于 VSCode 原生配置是配置一系列 ./vscode/.json 文件，文件随平台和编译器不同而不同；  基于 CMake 第三方配置是配置 CMakeLists.txt 文件，可实现与平台和编译器无关。推荐使用 CMake 进行工具链配置。根据个人选择，跳转至对应章节查看。  2.3.4. VSCode 工具链配置  2.3.5. CMake 工具链配置2.3.4. VSCode 工具链配置VSCode 提供了一系列基于 .json 文件的配置方式。这些文件存放在项目工作路径的 .vscode 文件夹内。对于 C/C++ 项目，工具链的核心配置文件为  task.json：编译配置，告诉 VSCode 如何调用编译器进行编译  launch.json：调试/运行配置，告诉 VSCode 编译得到可执行文件后，如何进行断点调试和运行。下面给出了两个典型的配置文件内容供复制参考：2.3.4.1. 配置 task.json{    \"version\": \"2.0.0\",    \"tasks\": [        {            \"type\": \"cppbuild\",            \"label\": \"C/C++: g++.exe build\",            \"command\": \"g++.exe\",            \"args\": [                \"-fdiagnostics-color=always\",                \"-std=c++11\",                \"-g\",                \"${workspaceFolder}/*.c\",                \"${workspaceFolder}/xx/*.c\",                \"${workspaceFolder}/*.cpp\",                \"${workspaceFolder}/xx/*.cpp\",                \"-I${workspaceFolder}/include\",                \"-I${workspaceFolder}/xx/xx\",                \"-o\",                \"${workspaceFolder}/XXXX.exe\",                \"-lws2_32\"            ],            \"options\": {                \"cwd\": \"${fileDirname}\"            },            \"problemMatcher\": [                \"$gcc\"            ],            \"group\": \"build\",            \"detail\": \"C/C++: g++.exe build\"        }    ]}其中  label 定义了编译配置的名称，用于界面显示和后续调试运行配置使用；  std=c++11 表明项目采用 C++11 规范编译，需要根据项目情况自行修改；  -g 表示后续内容是待编译的所有文件；  ${workspaceFolder} 是项目的根目录，项目源文件可在其基础上列写；  -I 用来 include 头文件路径；  *.c/*.cpp 可以使用通配符来表示某路径下所有后缀名相同的某文件，当然也可以逐一写出项目所有文件；2.3.4.2. 配置 launch.json{    \"version\": \"0.2.0\",    \"configurations\": [        {            \"name\": \"GCC: Debug and Run\",            \"type\": \"cppvsdbg\",            \"request\": \"launch\",            \"program\": \"${workspaceFolder}/XXXX.exe\",            \"args\": [],            \"stopAtEntry\": false,            \"cwd\": \"${workspaceFolder}\",            \"environment\": [],            \"externalConsole\": true,            \"preLaunchTask\": \"C/C++: g++.exe build\"        },        {            \"name\": \"Python: Current File\",            \"type\": \"python\",            \"request\": \"launch\",            \"program\": \"${file}\",            \"console\": \"integratedTerminal\"        }    ]}其中  program 字段是编译得到的可执行程序的名称，注意与 launch.json 中的 -o 命令后的程序名称 保持一致；  preLaunchTask 字段用来确定进行调试/运行前需要执行的任务，一般设置此项为编译任务（比如本例中的 C/C++: g++.exe build 任务），可以在每次调试/运行前自动完成编译，而无需手动编译。注意名字一定要和 launch.json 中的 \"label\" 字段保持一致；注意，launch.json 是一个跨语言通用的配置文件，意味着不仅仅 C/C++ 使用该文件，其他语言如 Python 也使用该配置文件进行代码解释配置。不同语言的配置通过 \"configurations\" 字段的不同大括号分隔开，并根据用户自定义的配置名称 \"name\": \"xxxx\" 键值对来进行区分。2.3.4.3. 测试工具链  打开项目工程路径中的任意源文件，如 hello.cpp；  按下快捷键 Ctrl + Shift + B（或点击左侧工具栏-【运行和调试】按钮-点击【绿色三角】）运行任务；  任务选择前面在 launch.json 中配置的【\"GCC: Debug and Run\"】，其会自动调用 task.json 中配置的【\"C/C++: g++.exe build\"】  生成完毕后，按 F5 进行调试运行，可在终端中查看运行结果。至此，我们完成了全部的C/C++开发环境部署。2.3.5. CMake 工具链配置CMake 是一个跨平台的安装（编译）工具，可以用简单的语句来描述所有平台的安装（编译过程）。他能够输出各种各样的 makefile 或者 project 文件。CMake 允许开发者编写一种平台无关的 CMakeLists.txt 文件来定制整个编译流程，然后再根据目标用户的平台进一步生成所需的本地化 Makefile 和工程文件，如 Unix 的 Makefile 或 Windows 的 Visual Studio 工程。从而做到 “Write once, run everywhere”。2.3.5.1. 下载和安装  在 Windows 环境下，直接前往官网（https://cmake.org/ ）下载最新的安装包安装；  安装过程中，注意勾选【Add Cmake to the system PATH for all users】;  如果忘记勾选，需手动将 ./cmake/bin 文件夹添加至系统环境变量 PATH 路径中；  安装完成后，通过命令 cmake --version 查看版本来确认安装是否成功；  在 VScode 中，安装 CMake Tools 插件；  将 Cmake Tools 插件设置中的 cmake.cmakePath 设置为 make.exe 的完整路径；  完整路径如 C:/Program Files/cmake/bin/cmake.exe，根据实际情况修改。2.3.5.2. 配置 CMakeLists.txt  若只需要对他人项目进行编译，则可跳过此步骤，直接跳转至 2.3.5.3. 测试工具链使用 CMake 插件创建 CMakeLists.txt 文件（文件名一个字都不能错）。两种创建方式，推荐后者：  手动创建，直接在工程项目的根目录下新建一个 CMakeLists.txt 文件，然后开始手动撰写；  自动创建，通过 VSCode 的 CMake Tools 插件辅助撰写：          按下快捷键组合 Ctrl + Shift + P，然后输入 cmake: quick start 进行快速设置；      首次设置会弹出 Select a Kit 需要选择一个编译器，选择安装的类似 GCC XX.X.X x86-64-w64-mingw32 编译器；      若没有类似选项，返回 2.3.2. 确认部署情况 检查是否正确部署 MinGW-W64；      在项目工作路径下会自动创建 CMakeLists.txt 文件，进行相应修改。      一个简单的 CMakeLists.txt 文件如下：cmake_minimum_required(VERSION 3.5.0)project(test VERSION 0.1.0 LANGUAGES C CXX)include(CTest)enable_testing()add_executable(main.cpp Normal_Bayes_Classifier.cpp)set(CPACK_PROJECT_NAME ${PROJECT_NAME})set(CPACK_PROJECT_VERSION ${PROJECT_VERSION})include(CPack)其中：  project(xxx)：填写项目名称，版本号，语言类型  add_executable(xxx)：填写编译所需的源代码文件  target_include_directories(path)：填写头文件路径  target_link_libraries(path)：填写可执行程序依赖的库文件名，如各类动态链接库2.3.5.3. 测试工具链CMake默认采用 out-of-source 构建方式，即会在 CMakeLists.txt 所在的目录下（一般也就是工程项目的根目录）新建一个 build 文件夹，用于存储 CMake 构建的中间文件和生成的目标文件。这种方法可以保证生成中间产物与源代码分离（即生成的所有目标文件都存储在 build 文件夹中，因此不会干扰源代码中的任何文件）。      手动构建    采用命令行的方式可操作如下      mkdir build  cd build  cmake ..            自动构建    若安装有 CMake Tools 插件并设置保存时自动构建，那么在使用快捷键 Ctrl + S 保存 CMakeLists.txt 时，会自动生成项目构建的中间文件。        构建结果    构建过程如下图所示。      构建完毕得到的中间文件如下图所示。            编译调试运行                  编译        按下 Ctrl + Shift + P 并运行 CMake：Build；或从底部状态栏中点击【build】按钮；下图是编译的示意图，编译后得到名为 exer 的可执行文件（文件位于 build 文件夹内）。                            调试/运行        调试：打开某个源代码文件，并设置一个断点。然后点击 VSCode 下方的 【虫子】 图标进行调试。  运行：点击下方的 【三角】 图标进行运行。            2.4. 部署 MSVC 编译器2.4.1. 下载和安装MSVC 编译器即 MicroSoft Visual C/C++ 编译器（核心文件为 cl.exe），如果下载安装了 Visual Studio 集成开发环境（如VS2022），则该编译器已经自动部署到了计算机中。采用 VSCode 作为编辑器时，可以只单独安装编译器而无需安装完整的 Visual Studio IDE。前往 Visual Studio 官网（https://visualstudio.microsoft.com/zh-hans/downloads/） ，往下拉，找到并展开 “Visual Studio 20xx 工具”，选择 “Visual Studio 20xx 生成工具”，下载并按照提示进行安装。仅安装 MSVC 编译器占用的空间远小于完整安装 VS IDE。2.4.2. 配置工具链VSCode进行编译连接等操作依赖一系列.json格式的配置文件，这些配置文件都位于工作路径下的.vscode文件夹内。2.4.2.1. VSCode 工具链配置      语言配置（c_cpp_properties.json）    打开VSCode，打开一个工作文件夹，写一个hello world的.cpp程序。在工作路径的根文件夹中，然后按下快捷键 Ctrl + Shift + P，搜索“c/c”，选择【C/C++: 编辑配置(JSON)】。VSCode 将自动创建 .vscode/c_cpp_properties.json 配置文件。或者，我们也可以手动创建该配置文件并填充内容。        根据个人安装MSVC编译器的位置不同，配置compilerPath路径（即 cl.exe 的路径）。以下图为例，除 compilerPath 外，其它配置项保持与图中一致。        注意，该路径也需要保存在系统的环境变量 Path 中。否则会导致 cl 命令不可用。        编译配置（task.json）    再次ctrl+shift+P，搜索 “task”，选择 “配置默认测试任务” → “使用模板创建…” → “Others 运行任意外部命令的示例”。VSCode将会自动创建.vscode/task.json配置文件，我们同样也可以手动创建该文件。然后，用以下代码替换文件的所有内容：      {      \"version\": \"2.0.0\",      \"tasks\": [          {              \"label\": \"msvc build\",              \"type\": \"shell\",              \"command\": \"cl.exe\",              \"args\": [                  \"/I'E:\\\\ProgramFiles\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.25.28610\\\\include'\",                  \"/I'C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.18362.0\\\\shared'\",                  \"/I'C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.18362.0\\\\ucrt'\",                  \"/I'C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.18362.0\\\\um'\",                  \"/I'C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.18362.0\\\\winrt'\",                  \"/I'${workspaceFolder}\\\\AAA\\\\AAAA\\\\'\",                  \"/I'${workspaceFolder}\\\\BBB\\\\'\",                  \"/I'${workspaceFolder}\\\\'\",                  \"/nologo\",                  \"${workspaceFolder}\\\\CCC\\\\CCCC\\\\*.c\",                  \"${workspaceFolder}\\\\DDD\\\\*.c\",                  \"${workspaceFolder}\\\\EEE\\\\*.cpp\",                  \"${workspaceFolder}\\\\*.cpp\",                  \"${workspaceFolder}\\\\*.c\",                  \"/Zi\",                  \"/EHsc\",                  \"/Fo:${workspaceFolder}\\\\build\\\\\",                  \"/Fe:winFFF.exe\",                  \"/link\",                  \"/libpath:'E:\\\\ProgramFiles\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.25.28610\\\\lib\\\\x64'\",                  \"/libpath:'C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.18362.0\\\\ucrt\\\\x64'\",                  \"/libpath:'C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.18362.0\\\\um\\\\x64'\"              ],              \"group\": {                  \"kind\": \"build\",                  \"isDefault\": true              },              \"presentation\": {                  \"reveal\": \"always\"              },              \"problemMatcher\": \"$msCompile\"          }      ]  }        下面对该文件中的 \"args\" 进行详细解读：          \"/I'includepath'\" 为程序依赖的头文件存放路径，/I 即include。第一条路径为MSVC编译器的头文件路径，后四条路径为Windows 10包含的头文件路径。具体路径根据个人的系统和编译器而异。这五条路径为必备的包含路径；      \"/I'${workspaceFolder}\\\\AAA\\\\AAAA\\\\'\" 等等为工程项目源代码所依赖的头文件的存放路径，其中${workspaceFolder} 为项目的工作路径根目录，AAA和AAAA为项目自定义的文件夹名，根据个人项目的具体情况设置。后面的BBB、CCC等类似；      \"/nologo\" 表示取消显示版权标志在编译器启动时和在编译期间显示信息性消息；      \"${workspaceFolder}\\\\CCC\\\\CCCC\\\\*.c\", 等等表示项目包含的需要编译的源代码文件（.c，.cpp）；      \"/Zi\" 选择为程序创建的调试信息的类型，此处将此信息保存在程序数据库(PDB)中；      \"/EHsc\" 选择异常处理模型，此处为同步异常处理模型；      \"/Fo:${workspaceFolder}\\\\build\\\\\", 设置创建的 .object 文件的存放路径，此处为工作路径下的build文件夹；      \"/Fe:winFFF.exe\" 设置生成的可执行文件.exe 的名称，此处为 winFFF.exe；      \"/link\" 传输指定的参数给link，此处表示将后面的路径传递给连接器用于连接；      \"/libpath:'winlibpath'\" 为 Window 10 的库文件存放路径，根据Windows环境而异。这三条路径为必备的库文件路径；        以一个最简单的一个hello world程序为例，源代码文件名为hello.cpp，相应的 task.json 文件中的 \"args\" 如下：      \"args\": [      \"/I'D:\\\\Programs\\\\Microsoft Visual Studio\\\\2019\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.24.28314\\\\include'\",      \"/I'C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.18362.0\\\\shared'\",      \"/I'C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.18362.0\\\\ucrt'\",      \"/I'C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.18362.0\\\\um'\",      \"${workspaceFolder}\\\\hello.cpp\",      \"/Zi\",      \"/EHsc\",      \"/Fo:${workspaceFolder}\\\\hello.obj\",      \"/Fe:${workspaceFolder}\\\\hello.exe\",      \"/link\",      \"/libpath:'D:\\\\Programs\\\\Microsoft Visual Studio\\\\2019\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.24.28314\\\\lib\\\\x64'\",      \"/libpath:'C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.18362.0\\\\ucrt\\\\x64'\",      \"/libpath:'C:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.18362.0\\\\um\\\\x64'\"  ],        其中，hello.cpp 也可以采用通配符的形式写为 *.cpp，方便后续扩展。        调试配置（launch.json）    点击 “调试” 图标菜单，选择 “添加配置” =&gt; “C++（Windows）” =&gt; “Default Configuration”，VSCode将自动创建 launch.json 文件，同样也可以手动创建该配置文件。        用以下内容替换该文件的全部默认内容。      {      \"version\": \"0.2.0\",      \"configurations\": [          {              \"name\": \"MSVC: 运行\",              \"type\": \"cppvsdbg\",              \"request\": \"launch\",              \"program\": \"${workspaceFolder}/winFFF.exe\",              \"args\": [],              \"stopAtEntry\": false,              \"cwd\": \"${workspaceFolder}\",              \"environment\": [],              \"externalConsole\": true          }      ]  }        注意，program 字段中的可执行文件名，必须与前面 tasks.json 中 args 字段的 \"/Fe:\" 参数完全一致（此处均为 winFFF.exe）。    至此，完成所有配置文件的生成。需要提醒的是，VSCode是基于工作路径进行编译调试的，若需要在其他文件夹（项目）中使用已有的配置时，只需要将当前的 .vscode 子文件夹复制到该项目的工作路径下，然后修改其中相应的参数项（如C/C++文件路径、可执行文件名称等）即可。        编译调试运行 与前面 MinGW 编译器类似。官方同样给出了详细的基于MSVC编译器的开发环境部署方法，见参考文献[1]。  2.4.2.2. CMake 工具链配置Working in Progress.3. VSCode 默认快捷键Ctrl + Shift + N 新建一个 VSCode 窗体Alt + left/right 回到上/下一个光标停留的位置Ctrl + Shift + P 调出执行命令的输入面板Ctrl + , 调出设置面板Ctrl + K, Ctrl + 0 折叠所有代码块Ctrl + K, Ctrl + J 展开所有代码块4. 参考文献[1] Micsosoft. Configure VS Code for Microsoft C++."
  },
  
  {
    "title": "欢迎使用Jekyll!",
    "url": "/posts/welcome-to-jekyll/",
    "categories": "Tutorial, Writing",
    "tags": "html",
    "date": "2015-03-08 22:21:49 +0800",
    





    
    "snippet": "本文介绍了基于 Chirpy Jekyll Theme 的个人博客环境的搭建方法，并介绍了部署到 github pages 的方法。  1. 前言  2. 图片  3. 公式  4. 关于页面1. 前言博客主题位于：https://github.com/cotes2020/jekyll-theme-chirpy  注意，本文内容可能随着时间的推移变得过时。2. 图片推荐在 assets/ 下...",
    "content": "本文介绍了基于 Chirpy Jekyll Theme 的个人博客环境的搭建方法，并介绍了部署到 github pages 的方法。  1. 前言  2. 图片  3. 公式  4. 关于页面1. 前言博客主题位于：https://github.com/cotes2020/jekyll-theme-chirpy  注意，本文内容可能随着时间的推移变得过时。2. 图片推荐在 assets/ 下面新建文件夹存放帖子图片，如 assets/postsimg/。在 md 文件中直接使用路径，如 ![img description](/assets/img/postsimg/20200505/1.jpg) 即可。帖子的图片无论是在本地（如VSCode打开xxx.github.io文件夹作为根目录）还是在线上（如 https://xxx.github.io）均能正常显示。3. 公式Jekyll支持Markdown的公式。在每个帖子开头增加 math: true 即可。他通过调用在线的 mathjax 来渲染。---title: xxxxdate: 20xx-xx-xx xx:xx:xx +0x00categories: [xxx, aaa]tags: [xxa]math: true # &lt;-- add this---4. 关于页面自行编辑 _tabs/about.md 文件。"
  }
  
]

