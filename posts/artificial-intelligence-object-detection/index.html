<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="zh-CN" 
  
>
  <!-- The Head -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="人工智能（目标检测）" />
<meta property="og:locale" content="zh_CN" />
<meta name="description" content="目标检测是计算机视觉领域的基础任务，旨在通过算法自动检测图像中包含的目标类别信息和位置信息。本文将详细介绍基于锚框（Anchor）的目标检测算法，并介绍其原理和实现方法。" />
<meta property="og:description" content="目标检测是计算机视觉领域的基础任务，旨在通过算法自动检测图像中包含的目标类别信息和位置信息。本文将详细介绍基于锚框（Anchor）的目标检测算法，并介绍其原理和实现方法。" />
<link rel="canonical" href="http://localhost:4000/posts/artificial-intelligence-object-detection/" />
<meta property="og:url" content="http://localhost:4000/posts/artificial-intelligence-object-detection/" />
<meta property="og:site_name" content="SIRLIS" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-12-08T21:06:49+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="人工智能（目标检测）" />
<meta name="twitter:site" content="@none" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-12-13T01:05:04+08:00","datePublished":"2025-12-08T21:06:49+08:00","description":"目标检测是计算机视觉领域的基础任务，旨在通过算法自动检测图像中包含的目标类别信息和位置信息。本文将详细介绍基于锚框（Anchor）的目标检测算法，并介绍其原理和实现方法。","headline":"人工智能（目标检测）","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/artificial-intelligence-object-detection/"},"url":"http://localhost:4000/posts/artificial-intelligence-object-detection/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>人工智能（目标检测） | SIRLIS
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="SIRLIS">
<meta name="application-name" content="SIRLIS">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.21.0/dist/tocbot.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  
    <!-- Switch the mode between dark and light. -->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() {
      return 'mode';
    }
    static get MODE_ATTR() {
      return 'data-mode';
    }
    static get DARK_MODE() {
      return 'dark';
    }
    static get LIGHT_MODE() {
      return 'light';
    }
    static get ID() {
      return 'mode-toggle';
    }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener('change', () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();
      });
    } /* constructor() */

    get sysDarkPrefers() {
      return window.matchMedia('(prefers-color-scheme: dark)');
    }

    get isSysDarkPrefer() {
      return this.sysDarkPrefers.matches;
    }

    get isDarkMode() {
      return this.mode === ModeToggle.DARK_MODE;
    }

    get isLightMode() {
      return this.mode === ModeToggle.LIGHT_MODE;
    }

    get hasMode() {
      return this.mode != null;
    }

    get mode() {
      return sessionStorage.getItem(ModeToggle.MODE_KEY);
    }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      document.documentElement.removeAttribute(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage(
        {
          direction: ModeToggle.ID,
          message: this.modeStatus
        },
        '*'
      );
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.notify();
    } /* flipMode() */
  } /* ModeToggle */

  const modeToggle = new ModeToggle();
</script>

  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle">
      
        
        <img src="/assets/img/head.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'">
      
    </a>

    <div class="site-title">
      <a href="/">SIRLIS</a>
    </div>
    <div class="site-subtitle fst-italic">分享科研和生活的日常</div>
  </div>
  <!-- .profile-wrapper -->

  <ul class="nav flex-column flex-grow-1 w-100 ps-0">
    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home"></i>
        <span>首页</span>
      </a>
    </li>
    <!-- the real tabs -->
    
      <li class="nav-item">
        <a href="/categories/" class="nav-link">
          <i class="fa-fw fas fa-stream"></i>
          

          <span>分类</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/tags/" class="nav-link">
          <i class="fa-fw fas fa-tags"></i>
          

          <span>标签</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/archives/" class="nav-link">
          <i class="fa-fw fas fa-archive"></i>
          

          <span>归档</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/about/" class="nav-link">
          <i class="fa-fw fas fa-info-circle"></i>
          

          <span>关于</span>
        </a>
      </li>
      <!-- .nav-item -->
    
  </ul>
  <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://github.com/sirlis"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="https://twitter.com/none"
          aria-label="twitter"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-twitter"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['lihongjue','buaa.edu.cn'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          

          

          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</div>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container px-xxl-5">
        <!-- The Top Bar -->

<div id="topbar-wrapper">
  <div
    id="topbar"
    class="container d-flex align-items-center justify-content-between h-100"
  >
    <span id="breadcrumb">
      

      
        
          
            <span>
              <a href="/">
                首页
              </a>
            </span>

          
        
          
        
          
            
              <span>人工智能（目标检测）</span>
            

          
        
      
    </span>
    <!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      文章
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="搜索..."
      >
    </span>
    <span id="search-cancel">取消</span>
  </div>
</div>

        











<div class="row">
  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pe-xl-4">
    

    <div class="post px-1 px-md-2">
      

      
        
      
        <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->



  
  

  <!-- CDN URL -->
  

  <!-- Add image path -->
  

  
    
      
      
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  

  



<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  




<!-- return -->




<h1 data-toc-skip>人工智能（目标检测）</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      发表于
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class=""
  data-ts="1765199209"
  data-df="YYYY/MM/DD"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  2025/12/08
</em>

    </span>

    <!-- lastmod date -->
    
    <span>
      更新于
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class=""
  data-ts="1765559104"
  data-df="YYYY/MM/DD"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  2025/12/13
</em>

    </span>
    

  

  <div class="d-flex justify-content-between">
    <!-- author(s) -->
    <span>
      

      作者

      <em>
      
        <a href="https://github.com/sirlis">sirlis</a>
      
      </em>
    </span>

    <div>
      <!-- read time -->
      <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="11139 字"
>
  <em>61 分钟</em>阅读</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <p>目标检测是计算机视觉领域的基础任务，旨在通过算法自动检测图像中包含的目标类别信息和位置信息。本文将详细介绍基于锚框（Anchor）的目标检测算法，并介绍其原理和实现方法。</p>

<!--more-->

<ul>
  <li><a href="#1-目标检测基础">1. 目标检测基础</a>
    <ul>
      <li><a href="#11-基于锚框的目标检测">1.1. 基于锚框的目标检测</a></li>
      <li><a href="#12-非锚框的目标检测">1.2. 非锚框的目标检测</a></li>
      <li><a href="#13-交并比iou">1.3. 交并比（IoU）</a></li>
    </ul>
  </li>
  <li><a href="#2-r-cnn-系列多阶段目标检测">2. R-CNN 系列多阶段目标检测</a>
    <ul>
      <li><a href="#21-r-cnn">2.1. R-CNN</a>
        <ul>
          <li><a href="#211-候选区域提取">2.1.1. 候选区域提取</a></li>
          <li><a href="#212-候选框分类">2.1.2. 候选框分类</a></li>
          <li><a href="#213-边界框回归">2.1.3. 边界框回归</a></li>
          <li><a href="#214-非极大值抑制nms">2.1.4. 非极大值抑制（NMS）</a></li>
          <li><a href="#215-总结">2.1.5. 总结</a></li>
        </ul>
      </li>
      <li><a href="#22-fast-r-cnn">2.2. Fast R-CNN</a>
        <ul>
          <li><a href="#221-roi-投影">2.2.1. RoI 投影</a></li>
          <li><a href="#222-roi-池化">2.2.2. RoI 池化</a></li>
          <li><a href="#223-损失函数">2.2.3. 损失函数</a></li>
          <li><a href="#224-总结">2.2.4. 总结</a></li>
        </ul>
      </li>
      <li><a href="#23-faster-r-cnn">2.3. Faster R-CNN</a>
        <ul>
          <li><a href="#231-rpn">2.3.1. RPN</a>
            <ul>
              <li><a href="#2311-锚框中心确定与逆向映射">2.3.1.1. 锚框中心确定与逆向映射</a></li>
              <li><a href="#2312-锚框尺寸设计">2.3.1.2. 锚框尺寸设计</a></li>
              <li><a href="#2313-rpn-训练">2.3.1.3. RPN 训练</a></li>
            </ul>
          </li>
          <li><a href="#232-网络结构">2.3.2. 网络结构</a></li>
          <li><a href="#233-检测头训练">2.3.3. 检测头训练</a></li>
          <li><a href="#234-最终输出">2.3.4. 最终输出</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#3-yolo-系列单阶段目标检测">3. YOLO 系列单阶段目标检测</a>
    <ul>
      <li><a href="#31-yolo-v1">3.1. YOLO v1</a>
        <ul>
          <li><a href="#311-网络结构">3.1.1. 网络结构</a></li>
          <li><a href="#312-损失函数">3.1.2. 损失函数</a></li>
          <li><a href="#313-讨论">3.1.3. 讨论</a></li>
        </ul>
      </li>
      <li><a href="#32-yolo-v2">3.2. YOLO v2</a></li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="1-目标检测基础"><span class="me-2">1. 目标检测基础</span><a href="#1-目标检测基础" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>不同于图像分类任务，目标检测任务需要识别图像中的多个目标对象，并给出每个目标的类别信息和 <strong>位置信息</strong>。</p>

<h3 id="11-基于锚框的目标检测"><span class="me-2">1.1. 基于锚框的目标检测</span><a href="#11-基于锚框的目标检测" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>如图所示，假设我们需要识别一张图片中的人脸，我们可以人为标记出图片中人脸的范围和位置（使用绿色方框），问题转化为，如何使用 CNN 来自动识别并定位图片中的人脸。</p>

<p><a href="/assets/img/postsimg/20251208/anchor-based-detection.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/anchor-based-detection.jpg" alt="基于锚框的目标检测" class="lazyload" data-proofer-ignore></a></p>

<p>一种思路是，在图片中人为设计许多锚框（Anchor Bo×es），然后使用 CNN 来识别锚框中的内容，同时想办法把锚框的位置和长宽信息预测的尽可能接近预先的标记框。可以看出，上述思想实际上是将目标检测问题转化为一个「<strong>图像分类</strong>」问题和一个「<strong>坐标回归</strong>」问题。</p>

<p>根据上述两个问题是「分阶段解决」还是「一步同时解决」，我们可以将目标检测方法分类为：</p>

<ul>
  <li>单阶段（single-stage）目标检测（YOLOv2等）</li>
  <li>多阶段（multi-stage）目标检测（R-CNN等）</li>
</ul>

<p><a href="/assets/img/postsimg/20251208/multi-stage-vs-single-stage.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/multi-stage-vs-single-stage.jpg" alt="多阶段目标检测和单阶段目标检测" class="lazyload" data-proofer-ignore></a></p>

<h3 id="12-非锚框的目标检测"><span class="me-2">1.2. 非锚框的目标检测</span><a href="#12-非锚框的目标检测" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>非锚框检测方法摒弃了预设锚框的设计，直接预测目标的位置和类别，主要分为两种思路：</p>

<ul>
  <li>基于关键点/中心点的检测
    <ul>
      <li>思想：不预测边界框，而是预测目标的中心点或关键点</li>
      <li>代表方法：CornerNet、CenterNet、ExtremeNet</li>
      <li>优势：避免了锚框的超参数调优，对形状变化更鲁棒</li>
    </ul>
  </li>
  <li>基于密集预测的检测
    <ul>
      <li>思想：在特征图的每个位置直接预测边界框参数</li>
      <li>代表方法：FCOS（Fully Convolutional One-Stage）、YOLOv1</li>
      <li>优势：更简单的流程，避免了锚框匹配的复杂性</li>
    </ul>
  </li>
</ul>

<h3 id="13-交并比iou"><span class="me-2">1.3. 交并比（IoU）</span><a href="#13-交并比iou" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>交并比（Intersection over Union，IoU）是两个框的相似度度量，用于度量两个框之间的相似度。其计算方式为：</p>

\[IoU = \frac{A_1 \cap A_2}{A_1 \cup A_2}\]

<p>图示如下：</p>

<p><a href="/assets/img/postsimg/20251208/iou.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/iou.jpg" alt="交并比" class="lazyload" data-proofer-ignore></a></p>

<h2 id="2-r-cnn-系列多阶段目标检测"><span class="me-2">2. R-CNN 系列多阶段目标检测</span><a href="#2-r-cnn-系列多阶段目标检测" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><a href="/assets/img/postsimg/20251208/rcnn.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/rcnn.jpg" alt="R-CNN系列目标检测" class="lazyload" data-proofer-ignore></a></p>

<h3 id="21-r-cnn"><span class="me-2">2.1. R-CNN</span><a href="#21-r-cnn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><a href="/assets/img/postsimg/20251208/rcnn-1.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/rcnn-1.jpg" alt="R-CNN" class="lazyload" data-proofer-ignore></a></p>

<p>其流程如下：</p>

<ol>
  <li>输入图像：输入一张带检测的图像；</li>
  <li>候选区域生成：使用 选择性搜索算法（Selective Search），在输入图像上生成 ~2K 个候选区域（region proposal）；</li>
  <li>候选区域处理：对每个候选区域进行预处理，并缩放到 $227\times 227$ 的尺寸（数字是否很熟悉？）；</li>
  <li>特征提取：将缩放后候选区域输入 Ale×Net，并最终提取得到 $4096$ 维度的特征；</li>
  <li>类别判断：把提取的特征送入 $20$ 个二分类 SVM 模型，得到 $20$ 个类别的概率，判断其属于哪一类；</li>
  <li>位置精修：使用回归器精细修正候选框的位置。</li>
</ol>

<h4 id="211-候选区域提取"><span class="me-2">2.1.1. 候选区域提取</span><a href="#211-候选区域提取" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>一张图像中可能存在多个物体需要分别定位和分类。显然，在训练分类器之前，需要使用一些方法将图像划分为小的区域，这些方法统称为 Region Proposal Algorithms。一张图像中包含的信息非常丰富，图像中的物体有不同的形状、尺寸、颜色、纹理，而且物体间还有层次（hierarchical）关系。下图给出了四个例子，来说明目标检测的难度。</p>

<p><a href="/assets/img/postsimg/20251208/region-proposal.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/region-proposal.jpg" alt="region proposal" class="lazyload" data-proofer-ignore></a></p>

<p>图（a）中的场景表明图像中不同物体之间是有一定的层次关系。图（b）中给出了两只猫，通过纹理很难找出这两只猫，但是通过颜色来可以很容易区分它们。图（c）中变色龙和周边颜色接近，但可以通过纹理来区分。图（d）中的车辆，我们需要把车身和车轮看做一个整体，但它们两者之间在纹理和颜色方面差别都非常大。</p>

<ul>
  <li><strong>E×haustive Search</strong></li>
</ul>

<p>刚开始人们想到的是穷举法（E×haustive Search），首先设计多个尺度的窗口，在每个尺度下按照一定步长进行滑动遍历（滑动窗口目标检测方法）。对于每一个窗口都分别计算 <a href="https://sirlis.cn/posts/Pattern-Recognition-Feature-Selection-and-E×traction/#122-%E6%96%B9%E5%90%91%E6%A2%AF%E5%BA%A6%E7%9B%B4%E6%96%B9%E5%9B%BEhog">HOG 特征</a>，然后送入提前训练好的 SVM 分类器进行判断，如果输出结果高于阈值则认为该框中含有目标。这个方式的局限性是搜索的范围很大，需要的计算量也很大，最后产生的提议区域也很多，即使改进的穷举法依然可以产生 $100000$ 多个提议区域，这对后面的区域特征提取和分类器训练带来不小的压力，所以不合适使用复杂的特征提取算法和分类器。</p>

<div class="language-plaintext highlighter-rouge"><div class="code-header">
        <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre># 假设图像尺寸：1000×1000像素
# 窗口大小：64×128（行人检测标准）
# 步长：8像素
# 尺度数：10个

# 单一尺度的窗口数
水平滑动次数 = (1000 - 64) / 8 ≈ 117
垂直滑动次数 = (1000 - 128) / 8 ≈ 109
单尺度窗口数 = 117 × 109 ≈ 12,753

# 多尺度（10个尺度）
总窗口数 = 12,753 × 10 ≈ 127,530
</pre></td></tr></tbody></table></code></div></div>

<p>此外，这个方法的窗口形状是固定的，比如对于行人设定的 $60\times 128$ 对与非行人类目标就不适用。</p>

<ul>
  <li><strong>Selective Search</strong></li>
</ul>

<p>选择性搜索是用于目标检测的区域提议算法，它计算速度快，具有很高的召回率。Selective Search 算法的核心是基于颜色，纹理，大小和形状兼容计算相似区域的分层分组，主要包含两个内容：</p>

<ul>
  <li>Hierarchical Grouping Algorithm</li>
  <li>Diversification Strategies</li>
</ul>

<p>这个方法主要有三个优势：捕捉不同尺度（Capture All Scales）、多样化（Diversification）、快速计算（Fast to Compute）。</p>

<p>在 Hierarchical Grouping Algorithm 中，首先将图像划分为多个区域，然后基于区域之间的相似性进行分组，两个最相似的区域被组合在一起形成一个新的区域，并将其添加到候选区域提议（Region Proposal）的列表中，重复上述过程直到整个图像变为一个区域。</p>

<p><a href="/assets/img/postsimg/20251208/Hierarchical-Grouping-Algorithm.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/Hierarchical-Grouping-Algorithm.jpg" alt="Hierarchical-Grouping-Algorithm" class="lazyload" data-proofer-ignore></a></p>

<p>在 Diversification Strategies 中，主要计算了不同的相似性度量方式，包括颜色相似度、纹理相似度、尺度相似度、形状重合度等。最终将他们加权得到总的相似性度量。</p>

<p>虽然 Selective Search 算法能够大幅降低（提取~2K候选区域），但计算量仍然过高（每一个候选区域都需要过一次 CNN，且相邻区域间存在大量重复计算）。</p>

<p>在送入 Ale×Net 之前，候选框需要扩展 16 个像素的上下文区域（避免裁剪丢失目标边缘特征），再强制缩放为 $227\times 227$ 尺寸，适配 Ale×Net 的输入要求。</p>

<h4 id="212-候选框分类"><span class="me-2">2.1.2. 候选框分类</span><a href="#212-候选框分类" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>对于每个候选框，输入预先训练好的 $20$ 个 SVM 分类器（只用于判断该输入候选框是该类样本还是背景），得到 $20$ 个类别的概率，然后选择概率最大的类别作为该候选框的类别，最终可以得到 $2000\times 1$ 的类别预测结果。</p>

<p>上述每个 SVM 分类器的训练流程严格依赖 CNN 提取的特征，且需要人工构造正负样本。</p>

<ul>
  <li>
    <p>CNN 特征预提取</p>

    <ul>
      <li>
        <p>CNN 预训练</p>

        <p>先在大规模分类数据集（如 ImageNet）上预训练一个 CNN（如 Ale×Net），目的是让 CNN 学会提取通用的图像特征。虽然将 CNN 当作分类器去训练，但是训练完毕后只使用其前面的 5 个卷积层 + 3 个池化层作为特征提取器。</p>
      </li>
      <li>
        <p>特征提取</p>

        <p>对训练集的每张图像，用 Selective Search 生成约 2000 个候选框，将每个候选框裁剪、缩放为 CNN 要求的固定尺寸（如 $227\times 227$），输入预训练 CNN，输出 $4096$ 维的特征向量—— 这是 SVM 的输入特征。</p>
      </li>
    </ul>
  </li>
  <li>
    <p>正负样本构建</p>

    <ul>
      <li>
        <p>样本标注</p>

        <p>正样本：对于当前类别 $C$，若候选框与该类的某个 GT 框的 IoU $≥ 0.5$，则标注为正样本（表示该候选框包含类别 $C$ 的目标）。注意：一个候选框只能属于一个类的正样本。</p>

        <p>负样本：若候选框与所有类的 GT 框的 IoU $&lt; 0.5$，则标注为负样本（表示该候选框是背景）。注意：负样本数量远大于正样本，训练时需负样本采样（避免样本不均衡），通常随机选取部分负样本，或采用难负样本挖掘（Hard Negative Mining） 提升训练效果。</p>
      </li>
    </ul>
  </li>
  <li>
    <p>SVM 训练</p>

    <ul>
      <li>构造样本集：$S_{C} = {(×_1, y_1), (×_2, y_2), …, (×_n, y_n)}$，其中 $×_i$ 为 $4096$ 维特征向量，$y_i$ 为类别标签（$+1$ 表示正样本，$-1$ 表示负样本背景）。</li>
      <li>使用线性 SVM 分类器，因为计算效率高，训练目标是找到一个最优超平面，将正样本（目标）和负样本（背景）分开，同时最大化分类间隔。</li>
      <li>损失函数：Hinge Loss，$L = \sum_{i}ma×(0, 1-y_i (w \cdot ×_i+b)) + \lambda/2 \sum_i w_i^2$</li>
    </ul>
  </li>
</ul>

<h4 id="213-边界框回归"><span class="me-2">2.1.3. 边界框回归</span><a href="#213-边界框回归" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>虽然已经完成了分类，但是每个候选框的坐标，也就是 Selective Search 生成的候选区域（region proposals）通常不够精确，主要体现在：</p>

<ul>
  <li>边界框可能只覆盖目标的一部分</li>
  <li>位置可能有偏移</li>
  <li>大小可能不完全匹配</li>
</ul>

<p>R-CNN 的作者表示，CNN 提取的深层特征（pool5 层）包含目标的精准位置线索，可通过<strong>线性模型</strong>学习这种 “候选框 - 真实锚框” 的映射关系，实现框的微调（Bounding Bo× Regression）。</p>

<blockquote>
  <p>Ale×Net 结构（R-CNN使用）</p>
  <div class="language-plaintext highlighter-rouge"><div class="code-header">
        <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre>conv1 → relu1 → pool1 → norm1 → 
conv2 → relu2 → pool2 → norm2 → 
conv3 → relu3 → 
conv4 → relu4 → 
conv5 → relu5 → pool5 → 
fc6 → fc7 → fc8
</pre></td></tr></tbody></table></code></div>  </div>
  <p>pool5 特征特点：</p>
  <ol>
    <li>空间维度：6×6×256=9216（对于 227×227 输入）</li>
    <li>其兼顾局部细节和全局语义，比浅层卷积特征更适合定位，比全连接层特征更具位置敏感性。</li>
  </ol>
</blockquote>

<p>线性模型的核心是学习候选框到真实锚框（Ground Truth）的 $4$ 个变换参数。线性模型的结构、目标函数和参数求解方式如下：</p>

<ol>
  <li><strong>目标参数定义</strong></li>
</ol>

<p>不直接预测边界框的绝对坐标，而是预测相对变换参数，以提升模型的尺度鲁棒性。设候选框$P=(P_×,P_y,P_w,P_h)$（$P_×,P_y$为中心坐标，$P_w,P_h$为宽高），真实锚框$G=(G_×,G_y,G_w,G_h)$，定义4个目标变换参数：</p>

\[\begin{cases}
t_×=\frac{G_× - P_×}{P_w}\\
t_y=\frac{G_y - P_y}{P_h}\\
t_w=\ln(\frac{G_w}{P_w})\\
t_h=\ln(\frac{G_h}{P_h})
\end{cases}\]

<p>其中$t_×,t_y$描述中心坐标的相对偏移，$t_w,t_h$描述宽高的相对缩放</p>

<details>
  <summary>
    <font color="blue">思考：为何宽高与中心坐标的相对变换参数形式不一样？</font>
  </summary>

  <font color="blue">
有如下几个考虑：

<br />


<b>为何宽高使用比值，而不是差值：</b>

 <br />
 
（1）尺度不变性。假设候选框宽度 $P_w=10$，真实锚框宽度 $G_w=20$，宽度差为 $10$。但如果 $P_w=100, G_w=110$，差值也是 $10$，但物理意义完全不同：第一个是宽度翻倍，第二个只是增加了 $10\%$。而使用比值可以反应不同尺度框的相对缩放关系。

<br />

（2）损失函数的公平性。在训练时，一张图像中可能同时存在大物体和小物体。如果对大物体的宽高预测误差为10像素，对小物体的误差也为10像素，数值上相同。但对小物体来说，10像素可能是巨大的相对误差（比如50%），而对大物体可能是微小误差（比如5%）。使用差值损失会导致模型偏向优化大物体的绝对误差，而忽视小物体的相对精度。使用比值（对数）后，所有尺寸的物体都在相对变化空间中进行优化，实现了尺度公平。

<br />

（3）梯度计算的稳定性。如果使用差值，对于不同尺度的物体，梯度数值范围差异很大。

<br />

（4）恢复预测时的数值合理性。如果网络预测宽度差值很不准确，比如为一个很大的负数 $t_w=-15$，在用这个差值对候选框进行纠正时会得到比如 $\hat{G_w}=10-15=-5$ 种非法数字。

<br />

<b>为何宽高使用对数，而不是直接使用比值：</b>

<br />

（1）放大一倍时比值为2，而缩小0.5倍时比值为0.5，二者在数值上不对称；如果使用对数，$ln(2)\appro× 0.693, ln(0.5)\appro× -0.693$，对数比值更适合表示缩放关系；

<br />

（2）直接比值的范围是 $(0,+\infty)$，这带来两个问题：（1）分布严重右偏，大多数比值在 $1$ 附近，但偶尔有极大值（如 $10$ 倍放大）；（2）梯度不稳定,大比值导致大梯度；

<br />

（3）取对数后，范围变为 $(-\infty, +\infty)$，大多数值集中在 $0$ 附近，分布更接近正态分布，适合神经网络优化。
</font>

</details>

<ol>
  <li><strong>线性模型结构</strong></li>
</ol>

<p>线性模型为 $4$ 个独立的 Ridge 回归（带 L2 正则的线性回归）模型，分别对应 $t_×,t_y,t_w,t_h$ 的预测。每个模型的表达式为 $\hat{t}=W^T f + b$，其中 $f$ 是 pool5 层的 9216 维特征向量，$W$ 是 9216 维的权重向量，$b$ 是偏置项，$\hat{t}$ 是预测的变换参数。使用独立模型可避免参数间的相互干扰，提升预测精度。</p>

<ol>
  <li><strong>损失函数与训练约束</strong></li>
</ol>

<p>训练的损失函数采用均方误差（MSE），即最小化</p>

\[\sum_{i=1}^N (\hat{t}_i - t_i)^2+\lambda||W||^2\]

<p>其中 $\lambda$ 是 L2 正则化系数，用于防止过拟合。补充材料特别强调，训练样本需满足候选框与真实锚框的 IoU（交并比）大于 $0.6$，因为只有候选框与目标足够接近时，候选框到真实锚框的映射才近似线性，这是线性回归模型有效的前提。</p>

<p>论文指出，无需多次迭代修正，一次线性回归的调整即可满足精度要求，多次调整反而会引入累积误差，降低检测性能。</p>

<h4 id="214-非极大值抑制nms"><span class="me-2">2.1.4. 非极大值抑制（NMS）</span><a href="#214-非极大值抑制nms" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>非极大值抑制（Non-Ma×imum Suppression，NMS）是候选框筛选阶段的核心操作，其作用是去除冗余的目标检测框，保留最精准的一个框来定位目标。</p>

<p>非极大值抑制作用于分类和回归之后，针对每个类别独立执行。其步骤如下：</p>

<ul>
  <li><strong>排序</strong>：对当前类别下所有候选框，按照 SVM 分类器输出的概率从高到低排序，得到一个候选框列表 $B$；</li>
  <li><strong>筛选</strong>：从排序后的列表 $B$ 中，取出第一个候选框放入最终列表 $D$，并计算其与其他候选框的 IoU（交并比），如果 IoU 大于阈值（如 $0.5$），则该候选框被标记为冗余，将其从 $B$ 中删除；</li>
  <li>重复上述筛选操作，直到整个候选框列表 $B$ 为空。最终列表 $D$ 中存放着该类别的所有最终检测框。</li>
</ul>

<h4 id="215-总结"><span class="me-2">2.1.5. 总结</span><a href="#215-总结" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>R-CNN 最大的问题在于：候选区域提取、目标特征分类、候选框回归，三个步骤相互独立，要分别训练，测试效率也较低。</p>

<h3 id="22-fast-r-cnn"><span class="me-2">2.2. Fast R-CNN</span><a href="#22-fast-r-cnn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>为了改善 R-CNN 的问题，作者提出了 Fast R-CNN。其核心改动是屏弃 SVM 分类器，改用 FC 层搭配两个不同的检测头同时完成分类和回归。那么作为 CNN 特征提取部分和 FC 层分类回归部分的连接，Fast R-CNN 的重要创新就在于提出的感兴趣区域投影（RoI Projection）和感兴趣区域池化（RoI Pooling）操作。</p>

<p><a href="/assets/img/postsimg/20251208/fast-rcnn.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/fast-rcnn.jpg" alt="fast-rcnn" class="lazyload" data-proofer-ignore></a></p>

<p>其主要流程如下：</p>

<ol>
  <li>输入图像：输入一张带检测的图像；</li>
  <li>候选区域生成：使用 选择性搜索算法（Selective Search），在输入图像上生成 ~2K 个候选区域（region proposal）；</li>
  <li>特征提取：将整张图片传入 CNN 提取特征；</li>
  <li>候选区域特征：利用 RoI Pooling 层将候选区域映射到固定大小，并提取特征（投影+池化）；</li>
  <li>分类和回归：把提取的特征仅分类和回归；</li>
</ol>

<h4 id="221-roi-投影"><span class="me-2">2.2.1. RoI 投影</span><a href="#221-roi-投影" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>感兴趣区域（Region of Interest, ROI）投影（Projection）指将原始图像坐标空间中的感兴趣区域投影到卷积特征图上的过程。</p>

<p>投影的核心在于坐标的线性缩放，这个缩放是由 CNN 网络的结构，或者更具体说，是由 CNN 结构中使用的 <strong>总步长</strong>（Total Stride） 决定的。总步长是网络从输入到输出特征图空间尺寸缩放的倍数。它由卷积层和池化层的 stride 乘积决定。</p>

<p>例如，一个经典的 VGG16 网络，在 conv5_3 之前，通常有 5 次步长为 2 的下采样（$2\times 2$ 池化，默认卷积使用 stride=2），这意味着特征图在宽和高上都变成了输入的 $1/(2^5) = 1/32$。则将原图像对应的四元数组转换到 feature maps 上就是每个值都除以 32 并 <strong>取整</strong> 到最接近的整数，得到投影的坐标，即为 ROI feture map。</p>

<p>注意，投影过程存在 <strong>第一次量化损失</strong>。损失的信息如下图蓝色区域所示。在图中的例子中，一个 ROI 的原始大小为 $200\times145$，左上角设置为 $(296\times 192)$ 。除以 $32$（比例因子）并取整，左上角变为 $(9,6)$，宽高变为 $6\times 4$，得到的 ROI feature maps 为 $[9,6,6,4]$。</p>

<p><a href="/assets/img/postsimg/20251208/roi-featurequant.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/roi-featurequant.jpg" alt="ROI量化损失" class="lazyload" data-proofer-ignore></a></p>

<h4 id="222-roi-池化"><span class="me-2">2.2.2. RoI 池化</span><a href="#222-roi-池化" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>RoI Pooling 利用特征采样，把不同空间大小的特征，变成空间大小一致的「<strong>固定大小特征</strong>」。这样做有两个好处：</p>

<ul>
  <li>RoI pooling 后接的是 FC 层，要求输入固定的维度；</li>
  <li>各个候选区域的特征大小一致，可以组成 batch 进行批处理。</li>
</ul>

<p><a href="/assets/img/postsimg/20251208/roi-pooling.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/roi-pooling.jpg" alt="RoI Pooling" class="lazyload" data-proofer-ignore></a></p>

<p>假设经过 ROI 池化后的固定大小为是一个超参数 $H\times W$ ，因为输入的 ROI feature map 大小不一样，假设为 $h\times w$，需要对这个特征图进行池化来减小尺寸，那么可以计算出池化窗口的尺寸为：$(h/H)\times (w/W)$。注意，池化窗口尺寸也需要进行 <strong>取整</strong>，如上图中，左上角的池化区域区域明显小于右上角的池化区域，这导致了 <strong>第二次量化损失</strong>（后续会有 RoI Align 方法消除该量化损失）。</p>

<p>最后，用这个计算出的窗口对 RoI feature map 做 ma× pooling，Pooling 对每一个特征图通道都是独立的。</p>

<h4 id="223-损失函数"><span class="me-2">2.2.3. 损失函数</span><a href="#223-损失函数" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>Fast R-CNN 的核心突破之一是实现分类与边界框回归的端到端联合训练，其损失函数设计兼顾了分类任务的类别判别和回归任务的框位置微调，整体为多任务损失（Multi-Task Loss），由分类损失和回归损失加权组合而成。</p>

\[L(p,u,t^u,v) = L_{cls}(p,u) + \lambda [u\geq 1]L_{reg}(t^u,v)\]

<p>其中：</p>

<ul>
  <li>$p$：预测的类别概率分布，维度为 $K+1$（$K$ 个目标类别 + 1 个背景类别）</li>
  <li>$u$：类别索引，$u=0$ 表示背景类别，$u=1,2,\cdots,K$ 表示目标类别</li>
  <li>$t^u$：预测的对应类别 $u$ 的边界框回归参数，维度为 $4$，即 $t_×,t_y,t_w,t_h$</li>
  <li>$v$：真实的边界框回归目标参数，维度为 $4$，即 $v_×,v_y,v_w,v_h$</li>
  <li>$\lambda$：回归损失的权重系数，平衡分类与回归任务的损失量级，一般取值为 $1$</li>
  <li>$[u\geq 1]$：指示函数，当$u\geq 1$ （非背景类）时值为 $1$，否则为 $0$</li>
</ul>

<p>分类损失采用交叉熵损失函数：</p>

\[L_{cls}(p,u) = -\log p_u\]

<details>
  <summary>
    <font color="blue">思考：如何从交叉熵损失函数的一般形式推导得到上述损失函数？</font>
  </summary>

  <font color="blue">对于标签 $u$，独热编码的真实标签为

$$y = [0,0,\cdots, \underbrace{1}_{第u位},\cdots, 0,0]$$

代入交叉熵公式

$$
\begin{aligned}
H(p,y) &amp;= - \sum_{i=0}^K y_i \log p_i = - \sum_{i=0}^K 1[i=u]\log p_i\\
&amp;=-(0\cdot \log p_0 +\cdots + 1\cdot \log p_u + \cdots + 0\cdot \log p_K)\\
&amp;= -\log p_u
\end{aligned}
$$
</font>
</details>

<p>回归损失采用平滑 $L_1$ 损失函数：</p>

\[L_{reg}(t,v) = \sum_{i\in\{×,y,w,h\}} \te×t{smooth}_{L1}(t_i^u-v_i)\]

<p>其中平滑 $L_1$ 损失函数定义为：</p>

\[L_{smoothL1}(×) = \begin{cases}
0.5×^2 &amp; \te×t{if } |×| &lt; 1\\
|×| - 0.5 &amp; \te×t{otherwise}
\end{cases}\]

<p>对损失函数分析如下：</p>

<ul>
  <li>当 $\vert ×\vert&lt;1$ 时，近似为 L2 损失，梯度随误差减小而降低，训练更稳定；</li>
  <li>当 $\vert ×\vert \geq 1$ 时，近似为 L1 损失，避免 L2 损失因离群点导致的<strong>梯度</strong>爆炸，提升鲁棒性。（<font color="blue">思考：为什么？</font>）</li>
</ul>

<h4 id="224-总结"><span class="me-2">2.2.4. 总结</span><a href="#224-总结" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<ul>
  <li>相比 R-CNN 速度提升 200 多倍，精度提高约 10 mAP；</li>
  <li>生成候选区域的算法（Selective Search）非常慢（耗时约 2s）。</li>
</ul>

<h3 id="23-faster-r-cnn"><span class="me-2">2.3. Faster R-CNN</span><a href="#23-faster-r-cnn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>相比 Fast R-CNN，Faster R-CNN 引入了区域提议网络（Region Proposal Network，RPN）来代替启发式搜索（Selective Search）来获得更好的锚框。</p>

<h4 id="231-rpn"><span class="me-2">2.3.1. RPN</span><a href="#231-rpn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p><a href="/assets/img/postsimg/20251208/faster-rcnn.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/faster-rcnn.jpg" alt="faster-rcnn" class="lazyload" data-proofer-ignore></a></p>

<p>观察上图可以发现，RPN 的输入是特征提取骨干网络部分的最后一层输出.在 RPN 输入的特征图上，从左上角开始，通过「<strong>滑动窗口</strong>」提取对应区域的特征区域信息，然后将其送入一个小网络中（如下图所示，实际上小网络和前面的特征提取网络共同组成 RPN ）。</p>

<p><a href="/assets/img/postsimg/20251208/RPN-0.5.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/RPN-0.5.jpg" alt="RPN0.5" class="lazyload" data-proofer-ignore></a></p>

<h5 id="2311-锚框中心确定与逆向映射"><span class="me-2">2.3.1.1. 锚框中心确定与逆向映射</span><a href="#2311-锚框中心确定与逆向映射" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5>

<p>特征图的每个像素点都会作为锚框的中心，这是锚框生成的基本规则。因此，锚框会从特征图的左上角开始，通过滑动窗口开始遍历。</p>

<p>接着，需要把锚框的中心坐标映射回原始的输入图像。通常为了简化计算，Faster R-CNN 的特征提取网络会保证 padding 是 “same” 或经过调整，使得特征图坐标到原图坐标的映射是整数倍关系。所以我们不需要考虑卷积层会缩小特征图尺寸，只需要考虑有多少池化层（下采样）即可。因此，RPN 输入特征图上的一个像素在原始图像上的位置只与「总步长」有关。比如 VGG16 的 conv5_3，从原图到该特征图的总步长是 16，即 <code class="language-plaintext highlighter-rouge">stride=16</code>。</p>

<blockquote>
  <p>注意区分「感受野大小」与「总步长」的区别：</p>
  <ul>
    <li>感受野大小：特征图上每个像素对应的原图理论最大视野范围；</li>
    <li>总步长：特征图上每个像素对应的原图的位置，或特征图上两个相邻像素在原图感受野的间隔距离。</li>
  </ul>
</blockquote>

<p>设特征图上的点坐标为 $[×_f, y_f]$（行和列），原图中锚框中心的坐标 $[×_o, y_o]$ 为：</p>

\[[×_o, y_o] = [(×_f+0.5)\times\te×t{stride},\; (y_f+0.5)\times\te×t{stride}]\]

<h5 id="2312-锚框尺寸设计"><span class="me-2">2.3.1.2. 锚框尺寸设计</span><a href="#2312-锚框尺寸设计" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5>

<p>光有锚框中心点依然无法产生锚框，因此人们「<strong>预先设计</strong>」了 $k$ 个形状不同的候选框，然后让网络预测候选框的相对偏移量（$k$ 个候选框会产生 $4k$ 个偏移量，即长宽和中心点的横纵坐标）。而每个候选框还需要额外预测两个分类概率值，用于判断该候选框是否属于背景或者目标（因此总共有 $2k$ 个分类得分）。</p>

<p><a href="/assets/img/postsimg/20251208/RPN-0.75.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/RPN-0.75.jpg" alt="RPN0.75" class="lazyload" data-proofer-ignore></a></p>

<p>Faster R-CNN 按照「<strong>特定的宽高比</strong>」设置 $9$ 个候选框，其由 $128^2, 256^2, 512^2$ 三个尺度和 $1:1, 2:1, 1:2$ 三个长宽比进行组合得到。</p>

<blockquote>
  <p>注意，候选框的尺寸和待检测的目标特性（数据集）有关系。比如，对于 COCO 数据集，因为其包含很多小目标，候选框的尺寸就额外设置有 $64^2$ 这种偏小的尺寸。</p>
</blockquote>

<p><a href="/assets/img/postsimg/20251208/RPN-1.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/RPN-1.jpg" alt="RPN1" class="lazyload" data-proofer-ignore></a></p>

<p>将网络输出的所有推荐的锚框进行可视化，如下图所示：</p>

<p><a href="/assets/img/postsimg/20251208/RPN-2.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/RPN-2.jpg" alt="RPN2" class="lazyload" data-proofer-ignore></a></p>

<h5 id="2313-rpn-训练"><span class="me-2">2.3.1.3. RPN 训练</span><a href="#2313-rpn-训练" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5>

<p>在训练（反向传播）时：我们需要为所有的锚框计算损失。为此，我们必须为每个锚框分配一个“标签”，告诉它：</p>

<ul>
  <li>
    <p>分类标签：这个锚框应该是背景（$0$）还是前景（$1$）？</p>
  </li>
  <li>
    <p>回归目标：如果它是前景，它应该向哪个真实锚框调整？（即那 $4$ 个偏移量的 “目标值” 是多少？）</p>
  </li>
</ul>

<p>因此，我们需要将 RPN 给出的候选锚框，与真实标签框进行匹配：</p>

<ul>
  <li>首先计算所有候选锚框与所有真实锚框的 IoU</li>
  <li>然后进行正样本分配
    <ul>
      <li>对每个真实锚框，找到与它 IoU 最大的那个候选锚框（即使 IoU 很小），强制标记为前景（保证每个真实锚框至少有一个锚框对应）。</li>
      <li>候选锚框与任意真实锚框的 IoU $\geq 0.7$（论文默认阈值），标记为前景。</li>
    </ul>
  </li>
  <li>接着进行负样本分配
    <ul>
      <li>与所有真实锚框 IoU $&lt; 0.3$ 的候选框，赋予负标签</li>
    </ul>
  </li>
  <li>最后舍弃中间锚框
    <ul>
      <li>IoU 在 $[0.3, 0.7]$ 之间的候选锚框，属于“模糊样本”。它们不分配标签，不参与训练。</li>
    </ul>
  </li>
</ul>

<p>基于上述分配，我们就可以算出每个样本的分类损失，和每个正样本的回归损失。则损失函数如下：</p>

\[L(\{p_i\}, \{t_i\}) = \frac{1}{N_{cls}}\sum_{i} L_{cls}(p_i, p_i^\star) + \lambda \frac{1}{N_{reg}}\sum_i p_i^\star L_{reg}(t_i, t_i^\star)\]

<p>其中：</p>

<ul>
  <li>$i$：mini-batch 中 anchor 的索引</li>
  <li>$p_i$：anchor $i$ 被预测包含有物体的概率</li>
  <li>$p_i^\star$：anchor $i$ 的真实标签（1 表示正样本，0 表示负样本）</li>
  <li>$t_i$：anchor $i$ 的预测锚框的回归参数向量</li>
  <li>$t_i^\star$：anchor $i$ 的真实锚框的回归参数向量</li>
  <li>$L_{cls}$：分类损失（二分类交叉熵损失函数）</li>
  <li>$L_{reg}$：回归损失（平滑 L1 损失函数）</li>
  <li>$N_{cls}$：分类损失归一化项（mini-batch 大小）</li>
  <li>$N_{reg}$：回归损失归一化项（论文设置为 2400，实际代码设置为 mini-batch 中正样本数量）</li>
  <li>$\lambda$：平衡权重（论文设置为 10, 实际代码中设置为 1）</li>
</ul>

<h4 id="232-网络结构"><span class="me-2">2.3.2. 网络结构</span><a href="#232-网络结构" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>下面给出 Faster R-CNN 的网络结构，并逐步拆解分析其前向传播过程。</p>

<p><a href="/assets/img/postsimg/20251208/faster-rcnn-structure.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/faster-rcnn-structure.jpg" alt="faster-rcnn-structure" class="lazyload" data-proofer-ignore></a></p>

<ul>
  <li><strong>（1）特征提取</strong>
    <ul>
      <li>将输入图像缩放至固定大小 <code class="language-plaintext highlighter-rouge">M×N</code>，然后送入主干网络（比如VGG16）的 13 个卷积层、13 个 ReLU 激活函数、4 个池化层，得到 <code class="language-plaintext highlighter-rouge">M/16×N/16×256</code> 的特征图。注意，这个特征图包含的锚框数量是 <code class="language-plaintext highlighter-rouge">M/16×N/16×9</code> 个，即特征图上每个像素点都对应着 9 个锚框。接着，特征图分别送入两个分支：RPN 和 ROI 池化。</li>
    </ul>
  </li>
  <li><strong>（2）RPN</strong>
    <ul>
      <li>预处理
        <ul>
          <li>首先经过 <code class="language-plaintext highlighter-rouge">3×3×256</code> 卷积和激活函数，相当于每个点又融合了周围 <code class="language-plaintext highlighter-rouge">3×3</code> 的空间信息（对于被遮挡的目标至关重要），同时通道数保持不变，特征图尺寸依然为 <code class="language-plaintext highlighter-rouge">M/16×N/16×256</code>。接着又分为两条线，分别做分类和回归：</li>
        </ul>
      </li>
      <li>分类（上一条线）：
        <ul>
          <li>注意到，特征图包含的锚框数量是 <code class="language-plaintext highlighter-rouge">M/16×N/16×9</code> 个，每个锚框又是一个（前景/背景）的二分类问题，因此分类分支中必须要将特征转变为 <code class="language-plaintext highlighter-rouge">M/16×N/16×9</code> 行 <code class="language-plaintext highlighter-rouge">2</code> 列的特征矩阵；</li>
          <li>首先经过 <code class="language-plaintext highlighter-rouge">1×1×18</code> 卷积，得到 <code class="language-plaintext highlighter-rouge">M/16×N/16×18</code> 的三维矩阵，然后经过 Reshape 得到 <code class="language-plaintext highlighter-rouge">[M/16×N/16×9, 2]</code> 二维特征矩阵，即可对每一行做 softma× 激活，得到每个锚框的两个原始分数（logits），第一个分数是属于背景的概率，第二个分数是属于前景（物体）的概率，二者和为 $1$。</li>
        </ul>
      </li>
      <li>回归（下一条线）
        <ul>
          <li>每个锚框需要预测 $4$ 个偏移量 $t_×, t_y, t_w, t_h$，因此一共需要 <code class="language-plaintext highlighter-rouge">M/16×N/16×9×4</code> 维度的特征。</li>
          <li>使用 <code class="language-plaintext highlighter-rouge">1×1×36</code> 卷积即可一步得到上述维度的特征；</li>
          <li>根据偏移量和预设锚框宽高尺寸，计算得到预测的锚框中心位置和宽高尺寸为：
            <div class="language-plaintext highlighter-rouge"><div class="code-header">
        <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>预测框中心× = 锚框中心× + t× × 锚框宽
预测框中心y = 锚框中心y + ty × 锚框高
预测框宽 = 锚框宽 × e×p(tw)
预测框高 = 锚框高 × e×p(th)
</pre></td></tr></tbody></table></code></div>            </div>
          </li>
          <li>应用上述计算完成的预测候选锚框的坐标和尺寸确定。</li>
        </ul>
      </li>
      <li>生成最终的候选区域
        <ul>
          <li>在完成分类和回归两个分支后，我们得到了所有候选框的位置、尺寸、二分类概率；</li>
          <li>如果不考虑背景分类，那么根据分类分支的前景概率，可先过滤掉概率低的框；</li>
          <li>对剩余的框进行非极大值抑制（NMS），去除高度重叠的框；</li>
          <li>最后选择选择前景概率最高的 $n$ 个框（训练时 $n=2000$，测试时 $n=300$）作为候选区域。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>（3）ROI Pooling</strong>
    <ul>
      <li>映射到特征图
        <ul>
          <li>将 RPN 得到的 $n$ 候选区域的坐标从原图空间映射到特征图空间</li>
          <li>长宽除以 $2^{stride}$，通道数保持不变（此处为 256）</li>
        </ul>
      </li>
      <li>区域裁剪
        <ul>
          <li>从共享特征图上裁剪出对应区域</li>
        </ul>
      </li>
      <li>最大池化
        <ul>
          <li>将每个区域池化为固定大小（如 <code class="language-plaintext highlighter-rouge">7×7</code>）</li>
        </ul>
      </li>
      <li>输出：<code class="language-plaintext highlighter-rouge">(n, 7, 7, 256)</code> 的张量
        <ul>
          <li><code class="language-plaintext highlighter-rouge">n</code> 为候选区域数量</li>
          <li><code class="language-plaintext highlighter-rouge">7×7</code> 为每个候选区域固定池化尺寸</li>
          <li><code class="language-plaintext highlighter-rouge">256</code> 为共享特征图的通道数</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>（4）检测头</strong>
    <ul>
      <li>检测头对每个候选区域进行最终的分类和边界框回归。它本质是一个小型全连接网络，接收固定尺寸的特征输入，输出最终的检测结果。</li>
      <li>特征展平
        <ul>
          <li>将 ROI 池化输出的 <code class="language-plaintext highlighter-rouge">(n, 7, 7, 256)</code> 张量展平为 <code class="language-plaintext highlighter-rouge">(n, 7×7×256)</code> 的二维矩阵，其中 <code class="language-plaintext highlighter-rouge">7×7×256=12544</code>，这是每个候选区域的固定长度特征向量。</li>
        </ul>
      </li>
      <li>全连接特征提取
        <ul>
          <li>经过第一个全连接层（fc6），将 <code class="language-plaintext highlighter-rouge">12544</code> 维特征降维到 <code class="language-plaintext highlighter-rouge">4096</code> 维，后接 ReLU 激活函数和 Dropout（通常 dropout 率为 <code class="language-plaintext highlighter-rouge">0.5</code>）以防止过拟合。</li>
          <li>再经过第二个全连接层（fc7），保持 <code class="language-plaintext highlighter-rouge">4096</code> 维，同样后接 ReLU 和 Dropout。</li>
          <li>这两个全连接层进一步融合全局信息，将局部区域特征转化为高度抽象的表征，为后续分类和回归提供判别性特征。</li>
        </ul>
      </li>
      <li>并行输出分支
        <ul>
          <li>分类分支
            <ul>
              <li>从 fc7 输出接一个全连接层，输出维度为 <code class="language-plaintext highlighter-rouge">K+1</code>，其中 <code class="language-plaintext highlighter-rouge">K</code> 是目标类别数（如 VOC 数据集的 20 类），加 1 表示背景类。输出尺寸为 <code class="language-plaintext highlighter-rouge">(n, K+1)</code></li>
              <li>对该 <code class="language-plaintext highlighter-rouge">K+1</code> 维向量应用 softmax 激活，得到每个候选区域属于每个类别的概率分布，概率最大的类别即为预测类别。</li>
            </ul>
          </li>
          <li>回归分支
            <ul>
              <li>从 fc7 输出接另一个全连接层，输出维度为 <code class="language-plaintext highlighter-rouge">4×(K+1)</code>。</li>
              <li>每个类别都对应 <code class="language-plaintext highlighter-rouge">4</code> 个边界框精修参数<code class="language-plaintext highlighter-rouge">（Δx, Δy, Δw, Δh）</code>，用于对候选区域的坐标进行微调。这些参数与 RPN 中的回归参数意义类似，但此处是针对具体类别的更精细调整。输出尺寸为 <code class="language-plaintext highlighter-rouge">(n, 4×(K+1))</code></li>
              <li>在实际预测时，仅使用预测类别对应的那 4 个偏移量对候选框进行调整，其余类别的偏移量被忽略。</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="233-检测头训练"><span class="me-2">2.3.3. 检测头训练</span><a href="#233-检测头训练" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>检测头的损失同样由两部分加权组成：分类损失（通常为交叉熵损失）和回归损失（通常为 Smooth L1 损失）。</p>

<p>回归损失仅对非背景类的候选区域计算，背景区域没有边界框真值，因此无需回归。</p>

<p>在端到端训练中，检测头的损失与 RPN 的损失相加，构成 Faster R-CNN 的总损失，通过反向传播同时优化 RPN 和检测头，共享的骨干网络参数也随之更新。</p>

<h4 id="234-最终输出"><span class="me-2">2.3.4. 最终输出</span><a href="#234-最终输出" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>对于每个候选区域，检测头输出：</p>

<ul>
  <li>
    <p>类别标签：K+1 个类别的概率分布，取最大概率对应的类别（若非背景）。</p>
  </li>
  <li>
    <p>精修后的边界框：在原始候选框基础上，应用预测类别的 4 个偏移量，得到更精确的物体位置。</p>
  </li>
</ul>

<p>最后，通常还会对所有预测结果进行跨类别的非极大值抑制（NMS），去除重复检测，生成图像最终的检测框及类别标签。</p>

<blockquote>
  <p>跨类别 NMS（Class-Agnostic NMS））是目标检测后处理中的一个重要步骤，它用于消除不同类别之间可能出现的重叠检测框，生成最终的干净检测结果。</p>

  <p>假设一张图像中：</p>

  <ul>
    <li>
      <p>一个检测器预测了一个”汽车”框和”卡车”框，但它们高度重叠</p>
    </li>
    <li>
      <p>实际上图像中只有一个车辆，但被两个不同类别的检测框覆盖</p>
    </li>
  </ul>

  <p>如果不进行跨类别抑制，会输出两个重叠的检测结果</p>
</blockquote>

<p>尽管有过度抑制的风险，但通过合理的阈值选择和算法改进，可以在精度和召回率之间取得良好平衡。在实际应用中，可根据具体场景和数据特性选择合适的NMS策略。</p>

<h2 id="3-yolo-系列单阶段目标检测"><span class="me-2">3. YOLO 系列单阶段目标检测</span><a href="#3-yolo-系列单阶段目标检测" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>回顾 RCNN 虽然会找到一些候选区域，但毕竟只是候选，等真正识别出其中的对象以后，还要对候选区进行微调，使之更接近真实的 bounding box。这个过程就是边框回归：将候选区bounding box 调整到更接近真实的 bounding box。</p>

<p>既然反正最后都是要调整的，干嘛还要先费劲去寻找候选区呢？大致有个区域范围就行了，按照这个思想就诞生了 YOLO 系列目标检测方法。</p>

<h3 id="31-yolo-v1"><span class="me-2">3.1. YOLO v1</span><a href="#31-yolo-v1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>YOLO（You Only Look Once）是一种开创性的实时目标检测算法，由 Joseph Redmon 等人于2015年提出。核心思想是将目标检测任务转化为单次前向传播的回归问题，通过单个神经网络同时预测目标边界框和类别概率，显著提升了检测速度，适用于对实时性要求高的场景。</p>

<h4 id="311-网络结构"><span class="me-2">3.1.1. 网络结构</span><a href="#311-网络结构" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>下面是 YOLO v1 的网络结构：</p>

<p><a href="/assets/img/postsimg/20251208/yolov1-structure.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/yolov1-structure.jpg" alt="yolo_v1-structure" class="lazyload" data-proofer-ignore></a></p>

<p>去掉候选区这个步骤以后，YOLO 的结构非常简单，就是单纯的卷积、池化最后加了两层全连接。单看网络结构的话，和普通的CNN对象分类网络几乎没有本质的区别，最大的差异是最后输出层用线性函数做激活函数，因为需要预测 bounding box 的位置（数值型），而不仅仅是对象的概率。所以粗略来说，YOLO 的整个结构就是输入图片经过神经网络的变换得到一个输出的张量，如下图所示。</p>

<p><a href="/assets/img/postsimg/20251208/yolov1-input-output.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/yolov1-input-output.jpg" alt="yolo_v1-input-output" class="lazyload" data-proofer-ignore></a></p>

<p>输入就是原始图像，唯一的要求是缩放到 $448\times 448$ 的大小。因为 YOLO v1 网络中的卷积层最后接了两个全连接层，全连接层是要求固定大小的向量作为输入，倒推回去也就要求原始图像有固定的尺寸。</p>

<p>具体来看每个网格对应的 $7\times 7 \times 30$ 维输出向量中包含了哪些信息：</p>

<p><a href="/assets/img/postsimg/20251208/yolov1-output.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20251208/yolov1-output.jpg" alt="yolo_v1-output" class="lazyload" data-proofer-ignore></a></p>

<ul>
  <li>类别预测：$20$ 个类别的概率向量（PASCAL VOC数据集有20类）；</li>
  <li>边界框预测：每个网格预测 <code class="language-plaintext highlighter-rouge">B=2</code> 个边界框，每个框包含 <code class="language-plaintext highlighter-rouge">5</code> 个值 <code class="language-plaintext highlighter-rouge">(x,y,w,h,confidence)</code>；
    <ul>
      <li>边界框中心坐标 (x, y)：
        <ul>
          <li>激活函数：<code class="language-plaintext highlighter-rouge">Sigmoid</code></li>
          <li>作用：将输出约束在 <code class="language-plaintext highlighter-rouge">(0, 1)</code> 之间，表示相对于该网格单元左上角的偏移比例。例如，(0.5, 0.5) 表示物体中心位于该网格的正中央。</li>
        </ul>
      </li>
      <li>边界框宽高 (w, h)：
        <ul>
          <li>激活函数：在v1原文描述中，这里使用的是线性输出（未用激活函数限制），但会通过图像宽高进行归一化。</li>
          <li>作用：预测边界框相对于整张图像的尺度。有些实现为了确保正值，会采用 exp() 函数处理，但原论文未明确提及，直接使用了线性输出。</li>
        </ul>
      </li>
      <li>置信度 (confidence)：
        <ul>
          <li>激活函数：<code class="language-plaintext highlighter-rouge">Sigmoid</code></li>
          <li>作用：表示该边界框包含一个物体的概率，与类别无关。值在 (0, 1) 之间。</li>
          <li>
            <font color="blue">思考：反向传播时，置信度标签如何给定？</font>
            <font color="lightgray">损失函数中设计两个指示函数</font>
          </li>
        </ul>
      </li>
      <li>类别条件概率 (class scores)：
        <ul>
          <li>激活函数：<code class="language-plaintext highlighter-rouge">Softmax</code></li>
          <li>作用：对每个网格单元，其 20 个类别输出通过 Softmax 激活，确保和为1。这表示 “如果这个网格里有物体，它属于各个类别的概率”。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<details>
  <summary>
    <font color="blue">思考：YOLO v1 一张图片最多能识别多少个对象？</font>
  </summary>

  <p>YOLO v1 默认最多可以识别 $S^2$ 个对象，其中 $S$ 是网格大小，默认为 $7$。每个网格可以预测 $B$ 个边界框，默认为 $2$。网格会从自己预测的 $B=2$ 个边界框中，挑选出与真实物体边界框交并比（IoU）更高的那一个，作为最终预测框。</p>

</details>

<h4 id="312-损失函数"><span class="me-2">3.1.2. 损失函数</span><a href="#312-损失函数" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>YOLO v1 的损失函数为：</p>

\[\begin{aligned}
    L_{\text{total}} = &amp;
    \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbf{1}_{ij}^{\text{obj}} \left[ (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 \right] \\
    &amp;+ \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbf{1}_{ij}^{\text{obj}} \left[ \left( \sqrt{w_i} - \sqrt{\hat{w}_i} \right)^2 + \left( \sqrt{h_i} - \sqrt{\hat{h}_i} \right)^2 \right] \\
    &amp;+ \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbf{1}_{ij}^{\text{obj}} (C_i - \hat{C}_i)^2 \\
    &amp;+ \lambda_{\text{noobj}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbf{1}_{ij}^{\text{noobj}} (C_i - \hat{C}_i)^2 \\
    &amp;+ \sum_{i=0}^{S^2} \mathbf{1}_{i}^{\text{obj}} \sum_{c \in \text{classes}} (p_i(c) - \hat{p}_i(c))^2
\end{aligned}\]

<p>其中：</p>

<ul>
  <li>$S \times S$： 图像被划分的网格数（通常 $S=7$，共$49$个网格）。</li>
  <li>$B$： 每个网格预测的边界框数量（YOLOv1中 $B=2$）。</li>
  <li>$\mathbf{1}_{i}^{\text{obj}}$： 指示函数，当第 $i$ 个网格<strong>包含</strong>某个真实物体的中心点时，其值为1；否则为0。控制「分类损失」是否生效。</li>
  <li>$\mathbf{1}_{ij}^{\text{obj}}$： 指示函数，当第 $i$ 个网格的第 $j$ 个预测框被分配<strong>负责</strong>预测某个真实物体时，其值为1；否则为0。控制「坐标损失」与「前景置信度损失」是否生效。选择与真实目标边界框的 IoU 更大的那个框置为 1；</li>
  <li>$\mathbf{1}_{ij}^{\text{noobj}}$： 指示函数，当第 $i$ 个网格的第 $j$ 个预测框<strong>不负责</strong>任何真实物体（即背景框）时，其值为 1；否则为 0。控制「背景置信度损失」是否生效。选择与真实目标边界框的 IoU 更小的那个框置为 1；</li>
  <li>$(x_i, y_i, w_i, h_i)$： 预测边界框的中心坐标（相对于网格左上角）和宽高（相对于整图）。</li>
  <li>$(\hat{x}_i, \hat{y}_i, \hat{w}_i, \hat{h}_i)$： 真实边界框（Ground Truth）的对应值。</li>
  <li>$C_i$： 预测框的置信度（Confidence Score）。</li>
  <li>$\hat{C}_i$： 真实置信度标签。对于“负责”框，$\hat{C}_i = 1$；对于背景框，$\hat{C}_i = 0$。</li>
  <li>$p_i(c)$： 预测的第 $i$ 个网格属于类别 $c$ 的条件概率。</li>
  <li>$\hat{p}_i(c)$： 真实的类别标签（one-hot向量形式）。</li>
  <li>$\lambda_{\text{coord}}$： 坐标损失的权重系数（论文中设为 $5$），用于提升定位精度的重要性。</li>
  <li>$\lambda_{\text{noobj}}$： 背景框置信度损失的权重系数（论文中设为 $0.5$），用于减轻大量简单负样本对训练的主导。</li>
</ul>

<details>
  <summary>
    <font color="blue">
思考：损失函数中，候选区域中心坐标损失、当第 $i$ 个网格的第 $j$ 个预测框不包含任何物体时，指示函数 $\mathbf{1}_{ij}^{\text{obj}}$ 和 $\mathbf{1}_{ij}^{\text{noobj}}$ 怎么设置？

</font>
  </summary>

  <p>均设为0。</p>

</details>

<p>下面对损失函数的每个部分分别展开详细阐述：</p>

<ul>
  <li><strong>候选区域中心坐标损失</strong></li>
</ul>

\[L_{\text{coord-cent}} = \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbf{1}_{ij}^{\text{obj}} \left[ (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 \right]\]

<p>迫使“负责”预测框的中心尽可能接近真实框中心。</p>

<ul>
  <li><strong>候选区域宽高损失</strong></li>
</ul>

\[L_{\text{coord-wh}} = \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbf{1}_{ij}^{\text{obj}} \left[ \left( \sqrt{w_i} - \sqrt{\hat{w}_i} \right)^2 + \left( \sqrt{h_i} - \sqrt{\hat{h}_i} \right)^2 \right]\]

<p>对宽高取平方根再计算误差，使网络对 小物体的尺寸误差更敏感，优化小物体检测。</p>

<ul>
  <li><strong>包含物体的置信度损失</strong></li>
</ul>

\[L_{\text{conf-obj}} = \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbf{1}_{ij}^{\text{obj}} (C_i - \hat{C}_i)^2\]

<p>迫使“负责”框的预测置信度 $C_i$ 接近 $1$。</p>

<ul>
  <li><strong>不包含物体的置信度损失</strong></li>
</ul>

\[L_{\text{conf-noobj}} = \lambda_{\text{noobj}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbf{1}_{ij}^{\text{noobj}} (C_i - \hat{C}_i)^2\]

<p>迫使背景框的预测置信度 $C_i$ 接近 $0$。$\lambda_{\text{noobj}} &lt; 1$ 防止简单负样本主导训练。</p>

<ul>
  <li><strong>分类损失</strong></li>
</ul>

\[L_{\text{class}} = \sum_{i=0}^{S^2} \mathbf{1}_{i}^{\text{obj}} \sum_{c \in \text{classes}} (p_i(c) - \hat{p}_i(c))^2\]

<p>迫使包含物体中心的网格预测出正确的类别概率分布。注意，</p>
<ul>
  <li><strong>分类是以网格为单位</strong>，与具体是哪个边界框无关。</li>
  <li>对于有对象的网格，分类的误差采用与标签的 one-hot 向量进行作差然后求平方，即<strong>把分类问题当作回归问题计算</strong> MSE 损失。</li>
</ul>

<h4 id="313-讨论"><span class="me-2">3.1.3. 讨论</span><a href="#313-讨论" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>YOLOv1 的设计哲学是：每个网格单元（grid cell）最多只负责预测一个物体。无论一个网格里实际有多少个物体，模型都只会为这个网格输出一组类别概率和一个最有可能的边界框（从该网格预测的 $2$ 个框中选一个）。</p>

<p>如果一个物体的中心点落在了某个网格内，那么这个网格就获得了预测该物体的“责任”。该网格会从自己预测的 $2$ 个边界框中，挑选出与真实物体边界框交并比（IoU）更高的那一个，作为最终预测框。该网格的类别预测则指向这个物体的类别。</p>

<p>因此产生根本限制：如果两个或多个物体的中心点非常接近，以至于落在了同一个网格内，那么YOLOv1就只能检测出其中一个（通常是IoU更高的，或损失函数训练后选定的那一个）。</p>

<p>这是YOLOv1召回率较低（即容易漏检物体）的主要原因，特别是在处理密集、小物体的场景时，这个问题会非常突出。</p>

<h3 id="32-yolo-v2"><span class="me-2">3.2. YOLO v2</span><a href="#32-yolo-v2" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
  <div class="post-meta mb-3">
    <i class="far fa-folder-open fa-fw me-1"></i>
    
      <a href='/categories/academic/'>Academic</a>,
      <a href='/categories/knowledge/'>Knowledge</a>
  </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw me-1"></i>
      
      <a href="/tags/artificial-intelligence/"
          class="post-tag no-text-decoration" >artificial intelligence</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        本文由作者按照 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         进行授权

      
    </div>

    <!-- Post sharing snippet -->

<div class="share-wrapper">
  <span class="share-label text-muted me-1">分享</span>
  <span class="share-icons">
    
    
    

    
      
      <a
        href="https://twitter.com/intent/tweet?text=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%88%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%89%20-%20SIRLIS&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fartificial-intelligence-object-detection%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Twitter"
        target="_blank"
        rel="noopener"
        aria-label="Twitter"
      >
        <i class="fa-fw fab fa-twitter"></i>
      </a>
    
      
      <a
        href="https://www.facebook.com/sharer/sharer.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%88%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%89%20-%20SIRLIS&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fartificial-intelligence-object-detection%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Facebook"
        target="_blank"
        rel="noopener"
        aria-label="Facebook"
      >
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    
      
      <a
        href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fartificial-intelligence-object-detection%2F&text=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%EF%BC%88%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%89%20-%20SIRLIS"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Telegram"
        target="_blank"
        rel="noopener"
        aria-label="Telegram"
      >
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <i
      id="copy-link"
      class="fa-fw fas fa-link small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="分享链接"
      data-title-succeed="链接已复制！"
    >
    </i>
  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
      
    </div>
  </div>
  <!-- #core-wrapper -->

  <!-- panel -->
  <div id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
    <div class="access">
      <!-- Get the last 5 posts from lastmod list. -->














  <div id="access-lastmod" class="post">
    <div class="panel-heading">最近更新</div>
    <ul class="post-content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/artificial-intelligence-object-detection/">人工智能（目标检测）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/artificial-intelligence-CNN-classification/">人工智能（图像分类）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Pattern-Recognition-Feature-Selection-and-Extraction/">模式识别（特征选择与特征提取）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Pattern-Recognition-CNN/">模式识别（卷积神经网络）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-Policy-Gradient/">强化学习（策略梯度法）</a>
        </li>
      
    </ul>
  </div>
  <!-- #access-lastmod -->


      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">热门标签</div>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/fuzzy/">fuzzy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/pattern-recognition/">pattern recognition</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/vscode/">vscode</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/artificial-intelligence/">artificial intelligence</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/other/">other</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/astronomy/">astronomy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c-c/">c/c++</a>
      
    </div>
  </div>


    </div>

    
      
      



  <div id="toc-wrapper" class="ps-0 pe-4 mb-5">
    <div class="panel-heading ps-3 pt-2 mb-2">文章内容</div>
    <nav id="toc"></nav>
  </div>


    
  </div>
</div>

<!-- tail -->

  <div class="row">
    <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-3 pe-xl-4 mt-5">
      
        
        <!--
  Recommend the other 3 posts according to the tags and categories of the current post,
  if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->








  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  






<!-- Fill with the other newlest posts -->





  <div id="related-posts" class="mb-2 mb-sm-4">
    <h3 class="pt-2 mb-4 ms-1" data-toc-skip>
      相关文章
    </h3>
    <div class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        
        
        <div class="col">
          <a href="/posts/artificial-intelligence-introduction/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1753959469"
  data-df="YYYY/MM/DD"
  
>
  2025/07/31
</em>

              <h4 class="pt-0 my-2" data-toc-skip>人工智能（绪论）</h4>
              <div class="text-muted small">
                <p>
                  





                  绪论。




  1. 什么是人工智能
    
      1.1. 人工智能
      1.2. 机器学习
      1.3. 深度学习
      1.4. 模式识别
      1.5. 关系图
    
  
  2. 人工智能的发展历史
    
      2.1. 萌芽与理论探索期
        
          2.1.1. 图灵测试
        
    ...
                </p>
              </div>
            </div>
          </a>
        </div>
      
        
        
        <div class="col">
          <a href="/posts/artificial-intelligence-knowledge-etc/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1756004629"
  data-df="YYYY/MM/DD"
  
>
  2025/08/24
</em>

              <h4 class="pt-0 my-2" data-toc-skip>人工智能（知识表示与推理）</h4>
              <div class="text-muted small">
                <p>
                  





                  在人工智能与知识管理领域，对知识的系统性认知与高效表示是实现智能推理和决策的基础。本文将从知识的本质出发，首先剖析知识的基本概念，明确其定义与分类，为后续探讨知识的表示与推理奠定理论基石；继而深入解析基于符号逻辑的多种知识表示方法，包括一阶谓词逻辑、产生式规则、框架式表示等经典范式，揭示逻辑推理的内在机制；同时，结合语义网技术，阐述以 RDF 为核心的知识表示体系及其在语义建模中的应用。通过...
                </p>
              </div>
            </div>
          </a>
        </div>
      
        
        
        <div class="col">
          <a href="/posts/reinforcement-learning-Value-Approximation/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1672654339"
  data-df="YYYY/MM/DD"
  
>
  2023/01/02
</em>

              <h4 class="pt-0 my-2" data-toc-skip>强化学习（值函数近似）</h4>
              <div class="text-muted small">
                <p>
                  





                  本文首先介绍了值函数近似（Value Approximation），然后分别结合 SARSA 和 Q-Learning 给出了两种 Q 函数近似的方法。通过分析线性函数作为估计函数的局限性，自然引入神经网络来进行非线性函数近似，引出了基于深度学习的 Q 函数估计网络：Deep Q-Network（DQN）。






  1. 引言
  2. 状态价值函数近似
    
      2.1...
                </p>
              </div>
            </div>
          </a>
        </div>
      
    </div>
    <!-- .card-deck -->
  </div>
  <!-- #related-posts -->


      
        
        <!-- Navigation buttons at the bottom of the post. -->

<div class="post-navigation d-flex justify-content-between">
  
    <a
      href="/posts/artificial-intelligence-CNN-classification/"
      class="btn btn-outline-primary"
      prompt="上一篇"
    >
      <p>人工智能（图像分类）</p>
    </a>
  

  
    <div
      class="btn btn-outline-primary disabled"
      prompt="下一篇"
    >
      <p>-</p>
    </div>
  
</div>

      
        
        <!--  The comments switcher -->

  
  <!-- https://utteranc.es/ -->
<script src="https://utteranc.es/client.js"
        repo="sirlis/sirlis.github.io"
        issue-term="pathname"
        crossorigin="anonymous"
        async>
</script>

<script type="text/javascript">
  $(function() {
    const origin = "https://utteranc.es";
    const iframe = "iframe.utterances-frame";
    const lightTheme = "github-light";
    const darkTheme = "github-dark";
    let initTheme = lightTheme;

    if ($("html[data-mode=dark]").length > 0
        || ($("html[data-mode]").length == 0
            && window.matchMedia("(prefers-color-scheme: dark)").matches)) {
      initTheme = darkTheme;
    }

    addEventListener("message", (event) => {
      let theme;

      /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */
      if (event.origin === origin) {
        /* page initial */
        theme = initTheme;

      } else if (event.source === window && event.data &&
            event.data.direction === ModeToggle.ID) {
        /* global theme mode changed */
        const mode = event.data.message;
        theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme);

      } else {
        return;
      }

      const message = {
        type: "set-theme",
        theme: theme
      };

      const utterances = document.querySelector(iframe).contentWindow;
      utterances.postMessage(message, origin);
    });

  });
</script>



      
    </div>
  </div>


        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-11 post-content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">热门标签</div>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/fuzzy/">fuzzy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/pattern-recognition/">pattern recognition</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/vscode/">vscode</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/artificial-intelligence/">artificial intelligence</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/other/">other</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/astronomy/">astronomy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c-c/">c/c++</a>
      
    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>
    </div>

    <!-- The Footer -->

<footer>
  <div class="container px-lg-4">
    <div class="d-flex justify-content-center align-items-center text-muted mx-md-3">
      <p>本站采用 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 主题 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>
      </p>

      <p>©
        2025
        <a href="https://github.com/sirlis">sirlis</a>.
        
          <span
            data-bs-toggle="tooltip"
            data-bs-placement="top"
            title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。"
          >保留部分权利。</span>
        
      </p>
    </div>
  </div>
</footer>


    <div id="mask"></div>

    <button id="back-to-top" aria-label="back-to-top" class="btn btn-lg btn-box-shadow">
      <i class="fas fa-angle-up"></i>
    </button>

    
      <div
        id="notification"
        class="toast"
        role="alert"
        aria-live="assertive"
        aria-atomic="true"
        data-bs-animation="true"
        data-bs-autohide="false"
      >
        <div class="toast-header">
          <button
            type="button"
            class="btn-close ms-auto"
            data-bs-dismiss="toast"
            aria-label="Close"
          ></button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="px-2 mb-3">发现新版本的内容。</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            更新
          </button>
        </div>
      </div>
    

    <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.0/dist/jquery.min.js,npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.7/dayjs.min.js,npm/dayjs@1.11.7/locale/zh.min.js,npm/dayjs@1.11.7/plugin/relativeTime.min.js,npm/dayjs@1.11.7/plugin/localizedFormat.min.js,npm/tocbot@4.21.0/dist/tocbot.min.js,npm/mermaid@9.4.3/dist/mermaid.min.js"></script>






<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
    /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
    MathJax = {
      tex: {
        /* start/end delimiter pairs for in-line math */
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ],
        /* start/end delimiter pairs for display math */
        displayMath: [
          ['$$', '$$'],
          ['\\[', '\\]']
        ]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>





    
      <!-- mermaid-js loader -->
<script type="text/javascript">
  (function () {
    function updateMermaid(event) {
      if (event.source === window && event.data && event.data.direction === ModeToggle.ID) {
        const mode = event.data.message;

        if (typeof mermaid === 'undefined') {
          return;
        }

        let expectedTheme = mode === ModeToggle.DARK_MODE ? 'dark' : 'default';
        let config = { theme: expectedTheme };

        /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */
        $('.mermaid').each(function () {
          let svgCode = $(this).prev().children().html();
          $(this).removeAttr('data-processed');
          $(this).html(svgCode);
        });

        mermaid.initialize(config);
        mermaid.init(undefined, '.mermaid');
      }
    }

    let initTheme = 'default';
    const html = document.documentElement;

    if (
      (html.hasAttribute('data-mode') && html.getAttribute('data-mode') === 'dark') ||
      (!html.hasAttribute('data-mode') && window.matchMedia('(prefers-color-scheme: dark)').matches)
    ) {
      initTheme = 'dark';
    }

    let mermaidConf = {
      theme: initTheme /* <default|dark|forest|neutral> */
    };

    /* Create mermaid tag */
    document.querySelectorAll('pre>code.language-mermaid').forEach((elem) => {
      const svgCode = elem.textContent;
      const backup = elem.parentElement;
      backup.classList.add('unloaded');
      /* create mermaid node */
      let mermaid = document.createElement('pre');
      mermaid.classList.add('mermaid');
      const text = document.createTextNode(svgCode);
      mermaid.appendChild(text);
      backup.after(mermaid);
    });

    mermaid.initialize(mermaidConf);

    window.addEventListener('message', updateMermaid);
  })();
</script>

    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  /* Note: dependent library will be loaded in `js-selector.html` */
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('search-results'),
    json: '/assets/js/data/search.json',
    searchResultTemplate: '<div class="px-1 px-sm-2 px-lg-4 px-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
    noResultsText: '<p class="mt-5"></p>',
    templateMiddleware: function(prop, value, template) {
      if (prop === 'categories') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
        }
      }

      if (prop === 'tags') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
        }
      }
    }
  });
</script>

  </body>
</html>

