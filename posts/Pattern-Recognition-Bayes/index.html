<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="zh-CN" 
  
>
  <!-- The Head -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="模式识别（贝叶斯决策）" />
<meta property="og:locale" content="zh_CN" />
<meta name="description" content="本文介绍了模式识别的贝叶斯决策，包括贝叶斯公式、最小错误贝叶斯决策、最小风险贝叶斯决策。" />
<meta property="og:description" content="本文介绍了模式识别的贝叶斯决策，包括贝叶斯公式、最小错误贝叶斯决策、最小风险贝叶斯决策。" />
<link rel="canonical" href="http://localhost:4000/posts/Pattern-Recognition-Bayes/" />
<meta property="og:url" content="http://localhost:4000/posts/Pattern-Recognition-Bayes/" />
<meta property="og:site_name" content="SIRLIS" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-03-12T21:22:19+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="模式识别（贝叶斯决策）" />
<meta name="twitter:site" content="@none" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-03-31T03:54:08+08:00","datePublished":"2024-03-12T21:22:19+08:00","description":"本文介绍了模式识别的贝叶斯决策，包括贝叶斯公式、最小错误贝叶斯决策、最小风险贝叶斯决策。","headline":"模式识别（贝叶斯决策）","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/Pattern-Recognition-Bayes/"},"url":"http://localhost:4000/posts/Pattern-Recognition-Bayes/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>模式识别（贝叶斯决策） | SIRLIS
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="SIRLIS">
<meta name="application-name" content="SIRLIS">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.21.0/dist/tocbot.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  
    <!-- Switch the mode between dark and light. -->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() {
      return 'mode';
    }
    static get MODE_ATTR() {
      return 'data-mode';
    }
    static get DARK_MODE() {
      return 'dark';
    }
    static get LIGHT_MODE() {
      return 'light';
    }
    static get ID() {
      return 'mode-toggle';
    }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener('change', () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();
      });
    } /* constructor() */

    get sysDarkPrefers() {
      return window.matchMedia('(prefers-color-scheme: dark)');
    }

    get isSysDarkPrefer() {
      return this.sysDarkPrefers.matches;
    }

    get isDarkMode() {
      return this.mode === ModeToggle.DARK_MODE;
    }

    get isLightMode() {
      return this.mode === ModeToggle.LIGHT_MODE;
    }

    get hasMode() {
      return this.mode != null;
    }

    get mode() {
      return sessionStorage.getItem(ModeToggle.MODE_KEY);
    }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      document.documentElement.removeAttribute(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage(
        {
          direction: ModeToggle.ID,
          message: this.modeStatus
        },
        '*'
      );
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.notify();
    } /* flipMode() */
  } /* ModeToggle */

  const modeToggle = new ModeToggle();
</script>

  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle">
      
        
        <img src="/assets/img/head.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'">
      
    </a>

    <div class="site-title">
      <a href="/">SIRLIS</a>
    </div>
    <div class="site-subtitle fst-italic">分享科研和生活的日常</div>
  </div>
  <!-- .profile-wrapper -->

  <ul class="nav flex-column flex-grow-1 w-100 ps-0">
    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home"></i>
        <span>首页</span>
      </a>
    </li>
    <!-- the real tabs -->
    
      <li class="nav-item">
        <a href="/categories/" class="nav-link">
          <i class="fa-fw fas fa-stream"></i>
          

          <span>分类</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/tags/" class="nav-link">
          <i class="fa-fw fas fa-tags"></i>
          

          <span>标签</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/archives/" class="nav-link">
          <i class="fa-fw fas fa-archive"></i>
          

          <span>归档</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/about/" class="nav-link">
          <i class="fa-fw fas fa-info-circle"></i>
          

          <span>关于</span>
        </a>
      </li>
      <!-- .nav-item -->
    
  </ul>
  <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://github.com/sirlis"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="https://twitter.com/none"
          aria-label="twitter"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-twitter"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['lihongjue','buaa.edu.cn'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          

          

          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</div>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container px-xxl-5">
        <!-- The Top Bar -->

<div id="topbar-wrapper">
  <div
    id="topbar"
    class="container d-flex align-items-center justify-content-between h-100"
  >
    <span id="breadcrumb">
      

      
        
          
            <span>
              <a href="/">
                首页
              </a>
            </span>

          
        
          
        
          
            
              <span>模式识别（贝叶斯决策）</span>
            

          
        
      
    </span>
    <!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      文章
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="搜索..."
      >
    </span>
    <span id="search-cancel">取消</span>
  </div>
</div>

        











<div class="row">
  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pe-xl-4">
    

    <div class="post px-1 px-md-2">
      

      
        
      
        <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->



  
  

  <!-- CDN URL -->
  

  <!-- Add image path -->
  

  
    
      
      
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  

  



<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  

  
  

  




<!-- return -->




<h1 data-toc-skip>模式识别（贝叶斯决策）</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      发表于
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class=""
  data-ts="1710249739"
  data-df="YYYY/MM/DD"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  2024/03/12
</em>

    </span>

    <!-- lastmod date -->
    
    <span>
      更新于
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class=""
  data-ts="1743364448"
  data-df="YYYY/MM/DD"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  2025/03/31
</em>

    </span>
    

  

  <div class="d-flex justify-content-between">
    <!-- author(s) -->
    <span>
      

      作者

      <em>
      
        <a href="https://github.com/sirlis">sirlis</a>
      
      </em>
    </span>

    <div>
      <!-- read time -->
      <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="8401 字"
>
  <em>46 分钟</em>阅读</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <p>本文介绍了模式识别的贝叶斯决策，包括贝叶斯公式、最小错误贝叶斯决策、最小风险贝叶斯决策。</p>

<!--more-->

<hr />

<ul>
  <li><a href="#1-决策理论与方法">1. 决策理论与方法</a>
    <ul>
      <li><a href="#11-基于先验概率的决策">1.1. 基于先验概率的决策</a></li>
      <li><a href="#12-基于贝叶斯公式后验概率的决策">1.2. 基于贝叶斯公式（后验概率）的决策</a></li>
    </ul>
  </li>
  <li><a href="#2-最小错误贝叶斯决策">2. 最小错误贝叶斯决策</a>
    <ul>
      <li><a href="#21-直观举例">2.1. 直观举例</a></li>
      <li><a href="#22-类概率密度">2.2. 类概率密度</a></li>
      <li><a href="#23-错误率分析">2.3. 错误率分析</a></li>
      <li><a href="#24-决策规则">2.4. 决策规则</a></li>
    </ul>
  </li>
  <li><a href="#3-正态分布样本的最小错误贝叶斯决策">3. 正态分布样本的最小错误贝叶斯决策</a>
    <ul>
      <li><a href="#31-多元正态分布">3.1. 多元正态分布</a></li>
      <li><a href="#32-各类协方差矩阵相等且为特殊对角阵">3.2. 各类协方差矩阵相等且为特殊对角阵</a></li>
      <li><a href="#33-各类协方差矩阵相等">3.3. 各类协方差矩阵相等</a></li>
      <li><a href="#34-各类协方差不等一般情况">3.4. 各类协方差不等（一般情况）</a></li>
    </ul>
  </li>
  <li><a href="#4-最小风险贝叶斯决策">4. 最小风险贝叶斯决策</a>
    <ul>
      <li><a href="#41-举例说明">4.1. 举例说明</a></li>
      <li><a href="#42-风险因子损失函数">4.2. 风险因子（损失函数）</a></li>
      <li><a href="#43-条件期望风险条件平均损失">4.3. 条件期望风险（条件平均损失）</a></li>
      <li><a href="#44-判决准则">4.4. 判决准则</a></li>
    </ul>
  </li>
  <li><a href="#5-最小最大贝叶斯决策">5. 最小最大贝叶斯决策</a>
    <ul>
      <li><a href="#51-期望风险">5.1. 期望风险</a></li>
      <li><a href="#52-期望风险与先验概率的关系">5.2. 期望风险与先验概率的关系</a></li>
      <li><a href="#53-最小化最大期望风险">5.3. 最小化最大期望风险</a></li>
    </ul>
  </li>
  <li><a href="#6-参考文献">6. 参考文献</a></li>
</ul>

<h2 id="1-决策理论与方法"><span class="me-2">1. 决策理论与方法</span><a href="#1-决策理论与方法" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>如果每一类在空间中互不相交，有清晰的决策边界，这种叫做<strong>确定统计分类</strong>。如果这些类相互之间有重合，新的样本的特征落到一个重合区域，那么就要判断该样本属于某一类的概率。从而通过比较某些概率的大小来进行分类，这种叫做<strong>不确定统计分类</strong>。</p>

<p>确定统计分类也可以通过设计线性分类器来完成分类，而对于不确定统计分类，一方面可以继续采用线性分类的思想设计分类器，另一方面也可以采用本文将要介绍的贝叶斯决策。后面我们会看到，线性分类的最优分类器是<strong>最小错误贝叶斯决策</strong>。</p>

<h3 id="11-基于先验概率的决策"><span class="me-2">1.1. 基于先验概率的决策</span><a href="#11-基于先验概率的决策" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>记 $x$ 为观察到的样本特征，分类空间为 $A={a_1, a_2, \cdots, a_n}$，其中 $a_i$ 为第 $i$ 类，$p(A)$ 为该空间的发生概率（先验概率分布）。</p>

<ul>
  <li>$x=[x_1, x_2, \cdots, x_d]^\top$ 为由 $d$ 维空间组成的特征向量。</li>
  <li>当 $p(a_j)&gt;p(a_{others})$ 时，记<strong>决策规则</strong> $x\in a_j$。</li>
  <li>当作出决策之后，<strong>单分类错误率</strong> $p(error_j) = 1-p(a_j)$，即 $x\notin a_j$ 的概率。</li>
</ul>

<blockquote>
  <p>现假设你面前有10张卷子，老师告诉你有 5 份是说没有复习实际也没有复习的学渣的，有 5 份是说没有复习却复习的很好的学霸的，你从里面任意抽了一份出来，<strong>不看分数不看名字</strong>，问你卷子是学渣还是学霸的。此时由于你只知道学渣学霸的试卷各占一半，因此你只能随便猜一个答案，那么你的单分类错误率是 $0.5$。此时就是基于先验概率的决策。</p>
</blockquote>

<p>可以看到，一般决策过程仅依靠先验概率 $p(a_j)$，使得对 $x$ 的观察（特征，也就是试卷分数）并没有对决策过程产生影响，总体错误率仍有降低的空间。</p>

<h3 id="12-基于贝叶斯公式后验概率的决策"><span class="me-2">1.2. 基于贝叶斯公式（后验概率）的决策</span><a href="#12-基于贝叶斯公式后验概率的决策" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>贝叶斯决策（Bayes Decision） 是十大经典机器学习算法之一，是统计机器学习的典型。通过观察到样本的特征 $x$ 后，通过贝叶斯公式，可以有效降低错误率。贝叶斯决策也被称作<strong>统计决策理论</strong>。</p>

<blockquote>
  <p>现假设你面前有10张卷子，老师告诉你有 5 份是说没有复习实际也没有复习的学渣的，有 5 份是说没有复习却复习的很好的学霸的，你从里面任意抽了一份出来，得分90+，不看名字，你多半会说这是学霸的卷子，或许你没有发现，在你做判断的一瞬间已经无意中使用了贝叶斯决策。</p>
</blockquote>

<p>贝叶斯公式旨在通过一个已知的结果，并结合一些经验性或统计性的信息来倒推出最可能产生该结果的原因，即所谓执果索因。对于一个 $c$ 分类任务，贝叶斯公式如下</p>

\[p(\omega_{i}\mid x)=\frac{p(x\mid\omega_{i})p(\omega_{i})}{p(x)}=\frac{p(x\mid\omega_{i})p(\omega_{i})}{\sum_{j=1}^{c}p(x\mid\omega_{j})p(\omega_{j})},i=1,2, \cdots c \tag{1}\]

<p>其中，举例说明（$c=2$）如下：</p>

<ul>
  <li>$\omega_1,\omega_2$：表示两个类别，此处分别为学渣、学霸；</li>
  <li>$p(\omega_{i})$：表示类别 $i$ 的<strong>先验概率</strong>，即每一类样本整体出现的概率，此处 $p(\omega_{1})=0.5=p(\omega_{2})$，表示两类试卷各占一半；</li>
  <li>$x$：表示观测/抽样数据，假设 $x=1$ 为拿到90+分的试卷，$x=0$ 则表示拿到了不超过90分的试卷；</li>
  <li>$p(x=1\vert\omega_i)$：表示类别 $i$ 的条件概率，即第$i$类中的某样本特征出现的概率，反映了在 $w_i$类中观察到特征值 $\boldsymbol{x}$ 的可能性（likelihood），也称为<strong>似然度</strong>，一般是已知的；</li>
  <li>$p(x=1)$：表示两类学生考 90+ 分的概率，是一个<strong>全概率</strong>；</li>
  <li>$p(\omega_i\vert x=1)$：<strong>后验概率</strong>，同样也是一个条件概率，表示已知考试成绩为 90+ 分，那么该试卷属于第 $\omega_i$ 类的概率；后验概率也是我们需要求得的概率，通过它可以实现分类，比如选取后验概率最大者对应的类别作为分类结果。</li>
</ul>

<p>可以看出，后验概率即为我们需要求取的概率。后验概率其实是在衡量各组分对结果的贡献，概率大，表示所有此结果中该组分（类）占比大。在引例中不知道那张试卷分数时，卷子可能属于10个人中的任意一人，即两个组分（类别）在概率上都贡献了5个人，各占0.5。而在知道卷面成绩90+后，贡献就悄然发生了变化。</p>

<blockquote>
  <p>已知学渣和学霸各占总样本的一半人数也就是5人，则先验概率为</p>

\[p(w_1)=0.5, p(w_2)=0.5\]

  <p>假设通过以往所有的考试信息，得出w1组得分90+的概率为0.2，w2组得分90+的概率为0.8，即条件概率（似然度）为</p>

\[p(x=1|w_1)=0.2, p(x=1|w_2)=0.8\]

  <p>代入贝叶斯公式即可求得后验概率</p>

\[\begin{aligned}
p(w_1|x=1)&amp;=\frac{0.2*0.5}{0.2*0.5+0.8*0.5}=0.2, \\
p(w_2|x=1)&amp;=\frac{0.8*0.5}{0.2*0.5+0.8*0.5}=0.8
\end{aligned}\]

  <p>可以看出，成绩90+的试卷属于$w_1$ 组的概率为0.2，属于 $w_2$ 组的概率为0.8，因此这张卷子更有可能是学霸的。</p>
</blockquote>

<p>贝叶斯公式特点：</p>

<ul>
  <li>条件概率（似然度）是计算后验概率的基础，是通过大量统计来得到的，这就是大数定理。</li>
  <li>许多事件的发生不具有可重复性，所以条件概率只能根据对置信度的主观判断，然后再以新获得的信息对条件概率进行修正。</li>
  <li>贝叶斯决策是基于概率的，所以分类决策一定存在错误率，即使错误率很低。</li>
</ul>

<p>贝叶斯决策就是在贝叶斯公式计算出后验概率的基础上，进一步做归属的决定——分类，如上述引例中，决策就是决定90+或者不超过90分的卷子归于 $w_1$ 组（类）或者归于 $w_2$ 组（类）。</p>

<p>不同的贝叶斯分类器有不同的贝叶斯决策，其主要包括两种决策方式，即最小错误贝叶斯决策，和最小风险贝叶斯决策。</p>

<h2 id="2-最小错误贝叶斯决策"><span class="me-2">2. 最小错误贝叶斯决策</span><a href="#2-最小错误贝叶斯决策" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<h3 id="21-直观举例"><span class="me-2">2.1. 直观举例</span><a href="#21-直观举例" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>最小错误贝叶斯决策就是<strong>选择后验概率最大的类作为判断</strong>的决策。</p>

<blockquote>
  <p>上述例中，在 $x=1$ 时，由于</p>

\[p(w_1|x=1)=0.2 &lt; p(w_2|x=1)=0.8\]

  <p>所以将90+的卷子归属到 $w_2$，犯错的概率会最小。犯错的概率就是90+的卷子可能属于 $w_1$ 的概率，即
\(p(w_1|x=1)=0.2 = 1 - p(w_2|x=1)\)</p>

  <p>同理，在 $x=0$ 时，将90或者90-的卷子归属到 $w_1$，犯错的概率会最小。犯错的概率是</p>

\[p(w_2|x=0)=0.2=1 - p(w_1|x=0)\]

  <p>上述例子是符合直觉的，在数学上需要更为严谨的推导。</p>
</blockquote>

<h3 id="22-类概率密度"><span class="me-2">2.2. 类概率密度</span><a href="#22-类概率密度" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>对于前述例子，会觉得它更像是一个简单的数学问题，而不是一个模式识别问题。因为在实际模式识别中，首先，待分类数据 $x$ 往往不会只有 $[0,1]$ （此处为 90+分和不足90分）两种取值，而会是一系列取值，如得分为 $[0,1,\cdots,99,100]$；对应的类的条件概率往往不是几个孤立的冲激，而是一个连续的概率密度函数（PDF），如下图所示：</p>

<p><a href="/assets/img/postsimg/20240312/01.pdf.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20240312/01.pdf.jpg" alt="pdf" class="lazyload" data-proofer-ignore></a></p>

<p>类条件概率反映出样本在特征空间的分布（学渣的卷面分数分布和学霸的卷面分数分布），这个分布一般而言是需要根据样本数据统计计算得到的。正因为不同类别的类条件概率分布在特征空间会重叠，导致了判决错误的发生。</p>

<h3 id="23-错误率分析"><span class="me-2">2.3. 错误率分析</span><a href="#23-错误率分析" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>为什么最小错误率贝叶斯决策的错误率是最小的？从定义出发：<strong>选择后验概率最大的类作为判断</strong>的决策。以一维二分类问题进行说明。对于两类问题，统计判决的基本方法是根据前述类的概率和概率密度将模式的特征空间划分为两个子区域 $\mathcal{R}_1, \mathcal{R}_2$，当 $x\in\mathcal{R}_1$ 时判断为 $x\in w_1$ 类，当 $x\in\mathcal{R}_2$ 时判断为 $x\in w_2$ 类。则错误率取决于两个子空间的划分情况，或者说两个子空间分界面 $t$ 的选择。</p>

<p><a href="/assets/img/postsimg/20240312/02.pe.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20240312/02.pe.jpg" alt="pe" class="lazyload" data-proofer-ignore></a></p>

<p>显然，此时会发生两种错误：</p>

<ol>
  <li>把实际是 $w_1$ 类的样本错误判断为 $w_2$ 类。这种情况发生的原因是属于 $w_1$ 类的特征分布在 $w_2$ 的特征空间区域 $\mathcal{R}_2$ 中。这时，误判概率为（图中方格区域的面积）</li>
</ol>

\[p(e_1) = \int_{\mathcal{R}_2} p(x \vert w_1)\text{d}x\]

<ol>
  <li>另一种错误是把实际是 $w_2$ 类的样本错误判断为 $w_1$ 类。这种情况发生的原因是属于 $w_2$ 类的特征分布在 $w_1$ 的特征空间区域 $\mathcal{R}_1$ 中。这时，误判概率为（图中斜纹区域的面积）</li>
</ol>

\[p(e_2) = \int_{\mathcal{R}_1} p(x \vert w_2)\text{d}x\]

<p>考虑到两个类别发生的概率分别为 $p(w_1), p(w_2)$ ，则总的误判概率为</p>

\[p(e) = p(w_1) \cdot p(e_1)+ p(w_2) \cdot p(e_2) = p(w_1)\int_{\mathcal{R}_2} p(x \vert w_1)\text{d}x + p(w_2)\int_{\mathcal{R}_1} p(x \vert w_2)\text{d}x\]

<p>其中 $p(w_1), p(w_2)$ 对于积分来说是与 $x$ 无关的常数，因此可以在积分符号内或者外出现。</p>

<p>我们希望总错误率最小，等价于希望总的正确判断的概率最大，总正确率为</p>

\[p(c) = p(w_1)\int_{\mathcal{R}_1} p(x \vert w_1)\text{d}x + p(w_2)\int_{\mathcal{R}_2} p(x \vert w_2)\text{d}x \tag{2}\]

<p>注意到（$w_2$ 类别在全空间要么判断正确要么判断错误）</p>

\[\begin{aligned}
1 &amp;= \int_{\mathcal{R}_1} p(x \vert w_2)\text{d}x + \int_{\mathcal{R}_2} p(x \vert w_2)\text{d}x \\
\Rightarrow \quad p(w_2) &amp;= p(w_2)\int_{\mathcal{R}_1} p(x \vert w_2)\text{d}x + p(w_2)\int_{\mathcal{R}_2} p(x \vert w_2)\text{d}x\\
\Rightarrow \textcolor{blue}{\quad p(w_2)\int_{\mathcal{R}_2} p(x \vert w_2)\text{d}x} &amp;= p(w_2) - p(w_2)\int_{\mathcal{R}_1} p(x \vert w_2)\text{d}x \\
\end{aligned} \tag{3}\]

<p>上述等式左边代入式 $(2)$，有</p>

\[\begin{aligned}
p(c) &amp;= p(w_1)\int_{\mathcal{R}_1} p(x \vert w_1)\text{d}x + p(w_2) - p(w_2)\int_{\mathcal{R}_1} p(x \vert w_2)\text{d}x\\
&amp;= p(w_2) + \int_{\mathcal{R}_1} [\;p(w_1)p(x \vert w_1)-p(w_2) p(x \vert w_2)\;]\text{d}x\\
\end{aligned}\]

<p>式中 $\mathcal{R}_1$ 是未知的，直接求解很困难。但考查上式可以发现，为了使其最大，$w_1$ 的决策域 $\mathcal{R}_1$ 应该是 $R$ 中所有满足条件</p>

\[p(w_1)p(x \vert w_1) &gt; p(w_2)p(x \vert w_2)\]

<p>的样本点组成的集合。</p>

<p>同理（对式$(2)$左右同时乘以$p(w_1)$然后代入式$(1)$ 得到另一个$p(c)$ 的表达式进行分析），决策域 $\mathcal{R}_2$ 应该是 $R$ 中所有满足条件</p>

\[p(w_1)p(x \vert w_1) &lt; p(w_2)p(x \vert w_2)\]

<p>的样本组成的集合。</p>

<p>易知，<strong>任何其他划分对应的正确率都要小于按照上述划分的正确率</strong>。所以，最小错误率贝叶斯决策（选择后验概率最大的类作为判断）的错误率是最小的。即<strong>最小错误贝叶斯决策 = 最大后验贝叶斯决策</strong>。此时决策面 $t$ 正好为两类的类条件概率密度函数的交点。由于概率非负，如果每一次决策错误率都最小，那么总的错误率也是最小的。</p>

<p>根据前述决策规则，只需要比较类的概率密度函数乘以一个常数（先验概率，不随采样而变，是一个常数值）的结果。显然，图中 $t$ 为决策点，在 $x&lt;t$ 时，对产生数据 $x$ 的贡献 $w_1$ 大于 $w_2$，故最小错误贝叶斯决策将 $x$ 归属为 $w_1$，在 $x&gt;t$ 时，对产生数据 $x$ 的贡献 $w_2$ 大于 $w_1$，故最小错误贝叶斯决策将 $x$ 归属为 $w_2$。</p>

<blockquote>
  <p>若为 $c$ 分类问题，贝叶斯错误率为</p>

\[p(e) = \int[1- \max_i p(w_i \vert x)]p(x)\text{d}x\]
</blockquote>

<h3 id="24-决策规则"><span class="me-2">2.4. 决策规则</span><a href="#24-决策规则" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>根据前述错误率分析，我们需要选择后验概率最大的类作为分类决策规则。对于 $c$ 分类任务，后验概率为</p>

\[p(w_i \vert \boldsymbol{x}) = \frac{p(\boldsymbol{x} \vert w_i)p(w_i)}{ p(\boldsymbol{x})} = \frac{p(\boldsymbol{x} \vert w_i)p(w_i)}{\sum_{j=1}^c p(\boldsymbol{x} \vert w_j)p(w_j)},i=1,2, \cdots c\]

<p>与二分类的分类规则类似，有</p>

<p><strong>【决策规则1】</strong></p>

\[p(w_i \vert \boldsymbol{x}) = \max\; p(w_j \vert \boldsymbol{x}), j\in[1,c] \quad \Rightarrow \boldsymbol{x}\in w_i\]

<p>后验概率用贝叶斯公式展开后，由于分母的 $p(\boldsymbol{x})$ 相同，因此可以忽略分母直接比较分子，得到等效分类规则如下</p>

<p><strong>【决策规则2】</strong></p>

\[p(\boldsymbol{x} \vert w_i)p(w_i) = \max\; [p(\boldsymbol{x} \vert w_j)p(w_j)], j\in[1,c] \quad \Rightarrow \boldsymbol{x}\in w_i\]

<p>由于先验概率 $p(w_i)$ 是事先确定的，与当前样本  $\boldsymbol{x}$ 无关，因此人们经常把二分类问题的决策规则整理成下面的形式</p>

<p><strong>【决策规则3】</strong></p>

\[l(\boldsymbol{x})=\frac{p(\boldsymbol{x}\vert w_1)}{p(\boldsymbol{x}\vert w_2)} \gtrless \frac{p(w_2)}{p(w_1)}=\lambda \quad \Rightarrow \boldsymbol{x} \in \left\{
  \begin{matrix}
  w_1\\
  w_2
\end{matrix}
\right.\]

<p>上式中，概率密度值 $p(\boldsymbol{x}\vert w_i)$ 即为前面贝叶斯公式介绍时提到的似然度，两类似然度的比值 $l(\boldsymbol{x})$ 被称为<strong>似然比（likelihood ratio）</strong>。这样可以事先计算出阈值 $\lambda$，对每一个样本计算似然比 $l(\boldsymbol{x})$ 并与 $\lambda$ 比较，大于阈值则决策为第一类，反之决策为第二类。</p>

<p>更进一步，许多情况下，用对数形式计算可能更加方便，因此人们定义了负对数似然比</p>

\[h(\boldsymbol{x}) = -\ln[l(\boldsymbol{x})] = -\ln[p(\boldsymbol{x}\vert w_1)] + \ln[p(\boldsymbol{x}\vert w_2)]\]

<p>相应的决策规则为</p>

<p><strong>【决策规则4】</strong></p>

\[h(\boldsymbol{x})\lessgtr\ln\frac{p(w_1)}{p(w_2)} \quad \Rightarrow \boldsymbol{x} \in \left\{
  \begin{matrix}
  w_1\\
  w_2
\end{matrix}
\right.\]

<p>负对数似然比 $h(\boldsymbol{x})$ 是 $\boldsymbol{x}$ 的函数，由于 $\boldsymbol{x}$ 是一个随机向量，则 $h(\boldsymbol{x})$ 也是随机变量，其概率分布密度函数可定义为 $p(h\vert w_i)$。由于该函数是一维概率密度函数，易于积分，所以用它计算错误率较为方便，则二分类的错误率可表述为</p>

\[\begin{aligned}
p(e_1) &amp;= \int_{\mathcal{R}_2} p(x \vert w_1)\text{d}x = \int_{t}^{+\infty} p(h \vert w_1)\text{d}h\\
p(e_2) &amp;= \int_{\mathcal{R}_1} p(x \vert w_2)\text{d}x = \int_{-\infty}^{t} p(h \vert w_2)\text{d}h
\end{aligned}\tag{4}\]

<p>其中 $t = \ln\frac{p(w_1)}{p(w_2)}$。</p>

<p>只要 $h(\boldsymbol{x})$ 的概率密度的解析形式已知，就可以计算出错误率。需要注意的是，当 $\boldsymbol{x}$ 是高维特征时，总错误率涉及到多重积分，计算比较困难，因此只能在一些特定简化条件下进行错误率的理论计算。比如在下一章节中，假设样本特征服从正态分布，可以对最小错误贝叶斯决策展开分析，导出分类器的解析表达式和错误率的解析形式。</p>

<h2 id="3-正态分布样本的最小错误贝叶斯决策"><span class="me-2">3. 正态分布样本的最小错误贝叶斯决策</span><a href="#3-正态分布样本的最小错误贝叶斯决策" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>正态分布假设是工程应用中最普遍的假设，因为：</p>

<ul>
  <li>正态分布在数学上比较简单，便于进行分析</li>
  <li>正态分布在物理上经常是总体分布的合理近似</li>
</ul>

<p>本节着重讨论样本分布属于正态分布时，最小错误率贝叶斯决策的情况。</p>

<h3 id="31-多元正态分布"><span class="me-2">3.1. 多元正态分布</span><a href="#31-多元正态分布" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>对于样本特征 $\boldsymbol{x}=[x_1,x_2,\cdots,x_d]^\top$ 的多元正态分布的概率密度函数定义为</p>

\[p(\boldsymbol{x}) = \frac{1}{\sqrt{(2\pi)^d\vert\boldsymbol{\Sigma}\vert}
}e^{-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})}\]

<p>其中均值向量和协方差矩阵分别为</p>

\[\begin{aligned}
\boldsymbol{\mu} &amp;= \mathbb{E}[\boldsymbol{x}] = (\mu_1,\mu_2,\cdots,\mu_d)^\top\in\mathbb{R}^{d}\\
\boldsymbol{\Sigma} &amp;= \mathbb{E}[(\boldsymbol{x}-\boldsymbol{\mu})(\boldsymbol{x}-\boldsymbol{\mu})^\top] = [\sigma^2_{ij}]\in\mathbb{R}^{d\times d}\\
\end{aligned}\]

<p>正态分布有几个优良性质（后面会用到）</p>

<ul>
  <li>正态分布的边缘分布仍然是正态分布</li>
  <li>正态分布的条件分布仍然是正态分布</li>
  <li>正态分布各分量的线性组合仍然是正态分布</li>
</ul>

<p>已知最小错误率贝叶斯决策的判别函数为</p>

\[g_i(\boldsymbol{x}) = p(\boldsymbol{x}\vert w_i)p(w_i),\;i=1,2,\cdots,c\]

<p>假设特征的先验概率符合多元正态分布，代入上式取自然对数，得到判别函数为</p>

\[\begin{aligned}
  \ln g_i(\boldsymbol{x}) &amp;= \ln p(\boldsymbol{x}\vert w_i) + \ln p(w_i)\\
  &amp;= \ln \frac{1}{\sqrt{(2\pi)^d\vert\boldsymbol{\Sigma}\vert}}
  -\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu}) + \ln p(w_i)\\
  &amp;= -\frac{d}{2}\ln(2\pi) - \frac{1}{2}\ln\vert\boldsymbol{\Sigma}\vert - \frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu}) + \ln p(w_i)\\
  \end{aligned}\]

<p>对于贝叶斯决策，决策面方程为</p>

\[g_i(\boldsymbol{x}) = g_j(\boldsymbol{x})\]

<p>即</p>

\[-\frac{1}{2}[(\boldsymbol{x}-\boldsymbol{\mu})^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu}) - (\boldsymbol{x}_j-\boldsymbol{\mu})^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol{x}_j-\boldsymbol{\mu})]-\frac{1}{2}\ln\frac{\vert\boldsymbol{\Sigma_i}\vert}{\vert \boldsymbol{\Sigma_j}\vert} + \ln \frac{p(w_i)}{p(w_j)} = 0\]

<h3 id="32-各类协方差矩阵相等且为特殊对角阵"><span class="me-2">3.2. 各类协方差矩阵相等且为特殊对角阵</span><a href="#32-各类协方差矩阵相等且为特殊对角阵" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>假设样本的特征向量的各个分量独立且具有相同的方差 $\sigma^2$，即 $\boldsymbol{\Sigma}_1 = \boldsymbol{\Sigma}_2 = \boldsymbol{\Sigma} = \sigma^2\boldsymbol{I}$，此时有</p>

\[\boldsymbol{\Sigma}_i = \sigma^2\boldsymbol{I},\quad\vert\boldsymbol{\Sigma}_i\vert = \sigma^{2d},\quad\boldsymbol{\Sigma}_i^{-1} = \frac{1}{\sigma^2}\boldsymbol{I},\quad i=1,2,\cdots,c\\\]

<p>判别函数简化为</p>

\[g_i(\boldsymbol{x}) = -\frac{1}{2\sigma^2}(\boldsymbol{x}-\boldsymbol{\mu})^\top(\boldsymbol{x}-\boldsymbol{\mu})- \frac{d}{2}\ln {2\pi} - \frac{1}{2}p(w_i)\]

<p>假设 $c$ 个类别的先验概率均相同（ $p(w_i)=p(w_j),\forall i,j=1,2,\cdots,c$），并且注意到贝叶斯决策要求对不同类别的判别函数进行比较，那么可以忽略所有与类别无关的常数。则判别函数进一步简化为</p>

\[\begin{aligned}
g_i(\boldsymbol{x}) &amp;= -\frac{1}{2\sigma^2}(\boldsymbol{x}-\boldsymbol{\mu})^\top(\boldsymbol{x}-\boldsymbol{\mu}) = -\frac{1}{2\sigma^2}\Vert \boldsymbol{x}-\boldsymbol{\mu} \Vert^2
\end{aligned}\]

<p>可以看出，若要对位置样本进行分类，只需要计算该样本特征特征向量到各类均值的欧式距离，然后把样本归类到距离最近的类别即可，说明<strong>此时的最小错误率贝叶斯分类器等价于最小距离分类器或垂直平分分类器</strong>。</p>

<p>继续对判别函数进行线性化，有</p>

\[\begin{aligned}
g_i(\boldsymbol{x}) &amp;=-\frac{1}{2\sigma^2}(\boldsymbol{x}-\boldsymbol{\mu})^\top(\boldsymbol{x}-\boldsymbol{\mu}) \quad \textcolor{blue}{\text{Euclidean Distance}}\\
&amp;= -\frac{1}{2\sigma^2}(-2\boldsymbol{\mu}_i^\top \boldsymbol{x}+\boldsymbol{\mu}_i^\top \boldsymbol{\mu}_i)\\
&amp;= \frac{1}{\sigma^2}\boldsymbol{\mu}_i^\top\boldsymbol{x} - \frac{1}{2\sigma^2}\boldsymbol{\mu}^\top \boldsymbol{\mu}\\
&amp;= \boldsymbol{w}_i^\top\boldsymbol{x} + w_{i0}\quad \textcolor{blue}{\text{linear}}
\end{aligned}\]

<p>可以看出决策面确实是一个超平面。如果先验概率 $p(w_i)\neq p(w_j)$，则决策面向先验概率小的那一类平移。</p>

<h3 id="33-各类协方差矩阵相等"><span class="me-2">3.3. 各类协方差矩阵相等</span><a href="#33-各类协方差矩阵相等" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>假设各类协方差矩阵相等（即$\boldsymbol{\Sigma}_1 = \boldsymbol{\Sigma}_2 = \boldsymbol{\Sigma}$，但不再满足 $\boldsymbol{\Sigma} = \sigma^2\boldsymbol{I}$），再假设各类先验概率相等，判别函数简化为</p>

\[\begin{aligned}
g_i(\boldsymbol{x}) &amp;= -\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu}_i)^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_i)\quad \textcolor{blue}{\text{Mahalanobis Distance}}\\
&amp;= -\frac{1}{2}(\textcolor{red}{\boldsymbol{x}^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{x}}-2\boldsymbol{\mu}_i^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{x} + \boldsymbol{\mu}_i^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_i)\\
&amp;= -\boldsymbol{\mu}_i^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{x} + \frac{1}{2}\boldsymbol{\mu}^\top\boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}\quad \textcolor{blue}{\text{ignore constant}}\\
&amp;=\boldsymbol{w}_i^\top\boldsymbol{x} + w_{i0}\quad \textcolor{blue}{\text{linear}}\\
\end{aligned}\]

<p>注意因为协方差矩阵相等，因此对于不同类别来说展开后第一项（标红）都是常数，因此可以忽略。</p>

<p>此时决策规则为按最小马氏距离的平方进行判别。按马氏距离判别仍然是线性的。</p>

<blockquote>
  <p>马氏距离：$D_M(\boldsymbol{x},\boldsymbol{\mu}) = \sqrt{(\boldsymbol{x}-\boldsymbol{\mu})^\top \boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})} $</p>
</blockquote>

<p>类似地，如果先验概率相等，则决策面过均值向量连线的终点（但不再垂直）。如果先验概率 $p(w_i)\neq p(w_j)$，则决策面向先验概率小的那一类平移。</p>

<p>继续分析该情况下的错误率，将复对数似然比展开得到</p>

\[\begin{aligned}
  h(\boldsymbol{x}) &amp;= -\ln[p(\boldsymbol{x}\vert w_1)] + \ln[p(\boldsymbol{x}\vert w_2)] \\
  &amp;=\frac{1}{2}[(\boldsymbol{x}-\boldsymbol{\mu}_1)^\top\boldsymbol{\Sigma}_1^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_1) - (\boldsymbol{x}-\boldsymbol{\mu}_2)^\top\boldsymbol{\Sigma}_2^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_2)] + \frac{1}{2}\ln\frac{\vert\boldsymbol{\Sigma}_1\vert}{\vert \boldsymbol{\Sigma}_2\vert}\\
  &amp;= (\boldsymbol{\mu}_2 - \boldsymbol{\mu}_1)^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{x} + \frac{1}{2}(\boldsymbol{\mu}_1^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_1-\boldsymbol{\mu}_2^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_2)\\
  &amp;= \boldsymbol{a}^\top\boldsymbol{x} + \boldsymbol{b}\quad \textcolor{blue}{\text{linear}}
\end{aligned}\]

<p>可以看出，负对数似然比是关于 $\boldsymbol{x}$ 的线性函数，又已知 $\boldsymbol{x}$ 服从正态分布，则负对数似然比也是一维正态分布。对于负对数似然比的两个类条件概率密度函数 $p(h\vert w_1),p(h\vert w_2)$ 也服从正态分布，分别计算其一维正态分布的均值和方差。</p>

<p>均值为</p>

\[\begin{aligned}
  \eta_1 &amp;= \mathbb{E}[h(\boldsymbol{x})\vert w_1] = h(\boldsymbol{\mu}_1)\\
  &amp;= (\boldsymbol{\mu}_2 - \boldsymbol{\mu}_1)^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_1 + \frac{1}{2}(\boldsymbol{\mu}_1^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_1-\boldsymbol{\mu}_2^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_2)\\
  &amp;= \textcolor{red}{\boldsymbol{\mu}_2^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_1} - \frac{1}{2}\boldsymbol{\mu}_1^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_1 -\frac{1}{2}\boldsymbol{\mu}_2^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_2\\
  &amp;= - \frac{1}{2}\boldsymbol{\mu}_1^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_1 + \textcolor{red}{\frac{1}{2}\boldsymbol{\mu}_1^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_2+\frac{1}{2}\boldsymbol{\mu}_2^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_1} - \frac{1}{2}\boldsymbol{\mu}_2^\top\boldsymbol{\Sigma}^{-1}\boldsymbol{\mu}_2\quad (\Sigma\;\text{is symmetric})\\
  &amp;= -\frac{1}{2}(\boldsymbol{\mu}_2 - \boldsymbol{\mu}_1)^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu}_2 - \boldsymbol{\mu}_1)\\
  &amp;= -\frac{1}{2}D_M(\boldsymbol{\mu_2},\boldsymbol{\mu_1})^2 = -\eta
\end{aligned}\]

<p>考虑对多元正态分布的线性变换，其方差定义为：</p>

\[\begin{aligned}
Var(h(\boldsymbol{x})\vert w_1) &amp;= \boldsymbol{a}^\top\boldsymbol{\Sigma}\boldsymbol{a}\\
&amp;= (\boldsymbol{\mu}_2 - \boldsymbol{\mu}_1)^\top \boldsymbol{\Sigma}^{-1}\boldsymbol{\Sigma}\boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu}_2 - \boldsymbol{\mu}_1)\\
&amp;= (\boldsymbol{\mu}_2 - \boldsymbol{\mu}_1)^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu}_2 - \boldsymbol{\mu}_1)\\
&amp;= D_M(\boldsymbol{\mu_2},\boldsymbol{\mu_1})^2 = 2\eta
\end{aligned}\]

<p>所以</p>

\[p(h(\boldsymbol{x})\vert w_1)\sim N(-\eta, 2\eta)\]

<p>同理可得</p>

\[\begin{aligned}
p(h(\boldsymbol{x})\vert w_2)\sim N(\eta, 2\eta)
\end{aligned}\]

<p>至此，我们就得到了负对数似然比（服从一维正态分布）在两个类条件概率密度函数 $p(h\vert w_1),p(h\vert w_2)$ 的均值和方差。代入式 $(4)$ 可以计算两种情况下的错误率</p>

\[\begin{aligned}
p(e_1) &amp;= \int_t^{+\infty} p(h\vert w_1)dh \\
&amp;= \int_t^{+\infty} \frac{1}{(2\pi)^{0.5}\sigma} \text{exp}\left\{\frac{1}{2}(\frac{h+\eta}{\sigma})^2\right\} dh\\
&amp;= \int_t^{+\infty} \frac{1}{(2\pi)^{0.5}} \text{exp}\left\{\frac{1}{2}(\frac{h+\eta}{\sigma})^2\right\} d(\frac{h+\eta}{\sigma})\\
&amp;= \int_{\frac{t+\eta}{\sigma}}^{+\infty} \frac{1}{(2\pi)^{0.5}} \text{exp}\left\{\frac{1}{2}\varepsilon^2\right\} d\varepsilon \sim N(0,1)
\end{aligned}\]

\[\begin{aligned}
p(e_2) &amp;= \int_{-\infty}^t p(h\vert w_2)dh \\
&amp;= \int_{-\infty}^t \frac{1}{(2\pi)^{0.5}\sigma} \text{exp}\left\{\frac{1}{2}(\frac{h-\eta}{\sigma})^2\right\} dh\\
&amp;= \int_{-\infty}^t \frac{1}{(2\pi)^{0.5}} \text{exp}\left\{\frac{1}{2}(\frac{h-\eta}{\sigma})^2\right\} d(\frac{h+\eta}{\sigma})\\
&amp;= \int_{-\infty}^{\frac{t-\eta}{\sigma}} \frac{1}{(2\pi)^{0.5}} \text{exp}\left\{\frac{1}{2}\varepsilon^2\right\} d\varepsilon \sim N(0,1)
\end{aligned}\]

<p>已知 $t,\boldsymbol{\mu}_1, \boldsymbol{\mu}_2, \boldsymbol{\Sigma}_1, \boldsymbol{\Sigma}_2$ 时，查标准正态分布表就能得到两个错误率。</p>

<p>实际上，贝叶斯错误率可以写为标准正态分布的累积分布函数的形式：</p>

\[p(e) = \Phi(-\frac{1}{2}D_M(\boldsymbol{\mu_2},\boldsymbol{\mu_1}))\]

<p>标准正态分布的累积分布函数（CDF）表示标准正态分布（均值为 0，方差为 1）在 $z$ 左侧的概率</p>

\[\Phi(z) = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{z}e^{-\frac{x^2}{2}}dx\]

<p>由于标准正态分布是对称的，$\Phi(z) = 1-\Phi(-z)$，因此</p>

\[p(e) = 1-\Phi(\frac{1}{2}D_M(\boldsymbol{\mu_2},\boldsymbol{\mu_1}))\]

<p>可分析如下：</p>

<ul>
  <li>当马氏距离为 0 时，CDF 值为 0.5，此时错误率是 0.5（原始样本特征的概率密度函数重合，相当于随机猜测）</li>
  <li>当马氏距离增大时，CDF 值不断减小，此时错误率单调递减；</li>
  <li>当马氏距离为正无穷时，此时错误率趋近于 0（原始样本特征的概率密度函数几乎完全分离）</li>
</ul>

<p>但是还是要注意，以上分析的前提是类条件概率密度可以被精确估计。实际上，样本量有限，无法准确估计概率密度。另外，特征增加当然可能使错误率反而增加，除了因为估计不准确之外，还可能是高斯密度这个前提本身就是不准的。而且，样本量小而特征很多，无疑会带来很多麻烦，比如过拟合等。</p>

<h3 id="34-各类协方差不等一般情况"><span class="me-2">3.4. 各类协方差不等（一般情况）</span><a href="#34-各类协方差不等一般情况" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>判别函数（忽略常数项后）形式如下：</p>

\[\begin{aligned}
g_i(\boldsymbol{x}) &amp;= - \frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^\top\boldsymbol{\Sigma}_i^{-1}(\boldsymbol{x}-\boldsymbol{\mu}) - \frac{1}{2}\ln\vert\boldsymbol{\Sigma}_i\vert + \ln p(w_i)\\
&amp;= -\frac{1}{2}\boldsymbol{\Sigma}_i^{-1}\boldsymbol{x} + \boldsymbol{\Sigma}_i^{-1}\boldsymbol{\mu}_i\boldsymbol{x} -\frac{1}{2}\boldsymbol{\mu}_i^\top\boldsymbol{\Sigma}_i^{-1}\boldsymbol{\mu}_i -\frac{1}{2}\ln\vert\boldsymbol{\Sigma}_i\vert + \ln p(w_i)\\
&amp;=\boldsymbol{x}^\top\boldsymbol{W}^{-1}\boldsymbol{x} + \boldsymbol{w}_i^\top\boldsymbol{x} + w_{i0}\\
\end{aligned}\]

<p>这类判别函数为 $\boldsymbol{x}$ 的<strong>二次型</strong>，决策面为二次超曲面，当 $\boldsymbol{\Sigma}_i,\boldsymbol{\mu},p(w_i)$的的取值不同时，形成的曲面形状也不一样，有超球面、超椭球面、超抛物面、超双曲面等。</p>

<h2 id="4-最小风险贝叶斯决策"><span class="me-2">4. 最小风险贝叶斯决策</span><a href="#4-最小风险贝叶斯决策" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>最小错误率决策足以胜任一般的决策场景。但是如果考虑不同的决策错误会带来不同的风险，则需要赋予不同的权重。比如，如果一个人处于癌症早期，而模型判定他是正常的，那此类决策可能带来生命的代价，因此需要给此类决策高权重。而如果一个人是正常的，模型判定他为癌症早期，代价是给病人和家属带来巨大的精神负担，但相对于生命而言可能相对可以接受，因此需要给此类决策低权重。显然，判定正确没有代价，权重为0。</p>

<h3 id="41-举例说明"><span class="me-2">4.1. 举例说明</span><a href="#41-举例说明" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>还是用上述引例深入分析，假设把一张学渣的（$w_1$）卷子错判成学霸的（$w_2$），会对学渣造成 <strong>10点</strong> 暴击伤害（因为导致学渣以为自己进步神速最后还是会被无情打碎幻想），反之如果把一张学霸的卷子判成学渣只有 <strong>1点</strong> 普通伤害（学霸很自信不会轻易动摇）。如果判定正确，大家则相安无事。那么我们就为学渣（$w_1$）的卷子判定成学霸（$w_2$）的决策加 10 点权值，然后为学霸（$w_2$）的卷子判定成学渣（$w_1$）的决策加 1 点权值，判断正确的权值为零，那我们可以得到如下<strong>决策表</strong>。</p>

<div class="table-wrapper"><table>
  <thead>
    <tr>
      <th style="text-align: center">决策</th>
      <th style="text-align: center"> </th>
      <th style="text-align: center">真实类别（学渣）</th>
      <th style="text-align: center">真实类别（学霸）</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">\</td>
      <td style="text-align: center">$w_1$</td>
      <td style="text-align: center">$w_2$</td>
    </tr>
    <tr>
      <td style="text-align: center">分类结果（学渣）</td>
      <td style="text-align: center">$w_1$</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
    </tr>
    <tr>
      <td style="text-align: center">分类结果（学霸）</td>
      <td style="text-align: center">$w_2$</td>
      <td style="text-align: center">10</td>
      <td style="text-align: center">0</td>
    </tr>
  </tbody>
</table></div>

<p>假设同样是抽到了一张90+的卷子，即 $x=1$。对于最小错误贝叶斯决策，$p(\omega_1\vert x=1) = 0.2$，$p(\omega_2\vert x=1) = 0.8$，将该卷子判定为学霸的（$w_2$）是最佳决策。</p>

<p>现在如果依旧判定为 $w_2$，那么其风险为 $R = 10 \times 0.2 + 0 \times 0.8 = 2$，而判定为 $w_1$，风险则为 $R_1 = 0* 0.2 + 0.8*1 = 0.8$。对于最小风险贝叶斯决策，判定为 $w_1$ 是最佳决策。剧情出现了 180 度大转弯，说明考虑风险后发现将学渣的卷子误判的代价更高，因此更倾向于误判学霸的卷子。</p>

<h3 id="42-风险因子损失函数"><span class="me-2">4.2. 风险因子（损失函数）</span><a href="#42-风险因子损失函数" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>从决策论的角度，可将最小风险贝叶斯决策重新表述如下：</p>

<ul>
  <li>样本 $\boldsymbol{x}$ 看作 d 维随机向量 $\boldsymbol{x} = [x_1,x_2,\cdots,x_d]^\top$</li>
  <li>状态空间 $\Omega$ 由 $c$ 个可能的状态组成（$c$ 类）：$\Omega={w_1,w_2,\cdots, w_c}$</li>
  <li>
    <p>对随机向量 $\boldsymbol{x}$ 可能采取的（分类）决策组成了决策空间，它由 $k$ 个决策组成：$A={a_1,a_2,\cdots, a_k}$</p>

    <p>注意，这里并没有假定 $k=c$，因为可能采取的（分类）决策除了判别为某一类外，还可能做出拒绝分类的决策，即不能判别样本属于任何一类，有时也可以在决策时把几类合并为同一个大类，等等。</p>
  </li>
</ul>

<p>定义对于实际状态为 $w_j$ 的向量 $\boldsymbol{x}$ 采取决策 $a_i$ 所带来的<strong>风险因子</strong>（损失函数）为</p>

\[\lambda(a_i, w_j)=\lambda_{ij},\quad i= 1,\cdots, k,\; j=1,\cdots, c\]

<p><strong>通常可以用表格的形式给出风险因子，被称为决策表</strong>。决策表是人在实际应用中根据问题的背景和知识事先给定的。在实际应用中，需要认真分析研究问题的内在特点和分类目的，与应用领域的专家共同设计出适当的决策表，才能保证模式识别发挥有效的作用。</p>

<p>需要注意的是，通常正确分类决策的损失函数 $\lambda(a_i, w_i)=0$，即分类正确的情况下是没有损失的。</p>

<h3 id="43-条件期望风险条件平均损失"><span class="me-2">4.3. 条件期望风险（条件平均损失）</span><a href="#43-条件期望风险条件平均损失" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>条件期望风险是指在给定观测数据 $\boldsymbol{x}$ 的条件下，采取某个决策 $a_i$（将其划分为类别 $i$）所产生的期望风险，又称为条件平均损失。</p>

<p>对于样本 $\boldsymbol{x}$ 的各状态后验概率为 $p(w_j \vert \boldsymbol{x}),\;j=1,\cdots,c$，对它采取决策 $a_i,\;i=1,\cdots,k$ 的<strong>条件期望风险</strong>是</p>

\[R(a_i|\boldsymbol{x})=E[\lambda(a_i,w_j)|\boldsymbol{x}] = \sum_{j=1}^c \lambda(a_i,w_j)p(w_j|\boldsymbol{x}) \tag{5}\]

<p>对于特定的决策，其风险是所有后验的概率与风险因子的乘积之和，即不再仅仅考虑后验概率了，还要额外考虑风险因子。</p>

<h3 id="44-判决准则"><span class="me-2">4.4. 判决准则</span><a href="#44-判决准则" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>最小风险贝叶斯决策就是对所有决策 $a_i$ 都分别求出条件期望风险，然后选择<strong>条件期望风险最小的决策</strong>。具体步骤如下：</p>

<ul>
  <li>首先，将先验概率和似然度（经过统计或经验得到）代入贝叶斯公式计算出后验概率（式 $(1)$）。</li>
  <li>然后，利用后验概率和事先定义的决策表（表格的形式的风险因子），计算条件期望损失（式 $(5)$）。</li>
  <li>最后，选取其中条件期望损失最小的决策，得到最小风险贝叶斯决策：</li>
</ul>

\[a = \arg \min_{i} R(a_i|\boldsymbol{x}),\; i=1,2,\cdots,c\]

<p>显然，对于二分类任务，当 $\lambda(1,1)=\lambda(2,2)=0,\lambda(1,2)=\lambda(2,1)=1$ 时，最小风险贝叶斯决策退化为最小错误贝叶斯决策。</p>

<h2 id="5-最小最大贝叶斯决策"><span class="me-2">5. 最小最大贝叶斯决策</span><a href="#5-最小最大贝叶斯决策" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>在最小风险贝叶斯决策中，先验概率 $p(w_i)$ 被认为是确定的。然而在实际应用中，各类的先验概率有时不能精确确定（如从黑箱中拿彩色小球，采样次数不够可能导致对小球颜色估计的先验概率有偏差），或在分析过程中各类的先验概率是变动的。此时，若再用固定先验概率条件下的某个最小风险贝叶斯分类器来进行决策，其结果实际上不是最小风险的。随着先验概率的变化，这个按照之前经验确定的某个具体先验概率取值后得到的最小风险贝叶斯决策，其实际风险可能会变大。</p>

<p>最小最大决策就是在各类的先验概率变化的情况下，取最大风险为最小的某个最小风险贝叶斯分类器作为实际使用的分类器。</p>

<h3 id="51-期望风险"><span class="me-2">5.1. 期望风险</span><a href="#51-期望风险" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>设特征空间 $R$ 中判决域为 $\mathcal{R}_i(i=1,2,\cdots,c)$，于是求得条件期望风险关于 $\boldsymbol{x}$ 的数学期望为</p>

\[R = \sum_{i=1}^c\int_{\mathcal{R}_i} R(\alpha_i \vert \boldsymbol{x})p(\boldsymbol{x}) \text{d}x\]

<p>期望风险 $R$ 反映在整个特征空间不同的 $x$ 取值 采取决策 $\alpha(x)$ （决策可看成是随机向量 $x$ 的函数）所带来的平均风险。与之相比，条件期望风险只反映对某 $x$ 取值的决策行动 $\alpha_i$ 所带来的风险。</p>

<h3 id="52-期望风险与先验概率的关系"><span class="me-2">5.2. 期望风险与先验概率的关系</span><a href="#52-期望风险与先验概率的关系" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>对于二分类问题，设某个最小风险贝叶斯分类器将特征空间 $R$ 划分为两个子区域，记 $\lambda_{ij}$ 为将实属 $w_j$ 类的样本判为 $w_i$ 的风险因子，则误判的期望风险为</p>

\[\begin{aligned}
  R &amp;= \int_R R(\alpha \vert \boldsymbol{x})p(\boldsymbol{x}) \text{d}x\\
  &amp;= \int_{\mathcal{R}_1} R(\alpha_1 \vert \boldsymbol{x})p(\boldsymbol{x}) \text{d}x + \int_{\mathcal{R}_2} R(\alpha_2 \vert \boldsymbol{x})p(\boldsymbol{x}) \text{d}x\\
  &amp;= \int_{\mathcal{R}_1} \sum_{j=1}^2\lambda_{1j} p(\boldsymbol{x}\vert w_j)p(w_j) \text{d}x + \int_{\mathcal{R}_2} \sum_{j=1}^2\lambda_{2j} p(\boldsymbol{x}\vert w_j)p(w_j) \text{d}\quad\textcolor{blue}{\text{using Bayes and definition of}\; R(\alpha\vert x)}\\
  &amp;= \lambda_{11}p(w_1)\int_{\mathcal{R}_1} p(\boldsymbol{x}\vert w_1)\text{d}x + \lambda_{12}p(w_2)\int_{\mathcal{R}_1} p(\boldsymbol{x}\vert w_2)\text{d}x + \lambda_{21}p(w_1)\int_{\mathcal{R}_2} p(\boldsymbol{x}\vert w_1)\text{d}x + \lambda_{22}p(w_2)\int_{\mathcal{R}_2} p(\boldsymbol{x}\vert w_2)\text{d}x\\
\end{aligned}\]

<p>引入类别 $w_j$ 下样本落在 $\mathcal{R}_i$ 的概率</p>

\[p(\mathcal{R}_i\vert w_j) = \int_{\mathcal{R}_i} p(\boldsymbol{x}\vert w_j)\text{d}x\]

<p>将期望风险表示为</p>

\[R = \lambda_{11}p(w_1)p(\mathcal{R}_1\vert w_1) + \lambda_{12}p(w_2)p(\mathcal{R}_1\vert w_2) + \lambda_{21}p(w_1)p(\mathcal{R}_2\vert w_1) + \lambda_{22}p(w_2)p(\mathcal{R}_2\vert w_2)\tag{6}\]

<p>又已知（样本要么属于 $w_1$ 类要么属于 $w_2$ 类，要么落在 $\mathcal{R}_1$ 区域要么落在 $\mathcal{R}_2$ 区域）</p>

\[\begin{aligned}
p(w_1) + p(w_2) &amp;= 1\\
p(\mathcal{R}_1\vert w_j) + p(\mathcal{R}_2\vert w_j) &amp;= 1\\
\end{aligned}\]

<p>代入式 $(6)$ 有</p>

\[\begin{aligned}
  R &amp;= \lambda_{11}p(w_1)\left[\textcolor{blue}{1 - p(\mathcal{R}_2\vert w_1)}\right] + \lambda_{12}[\textcolor{blue}{1-p(w_1)}]p(\mathcal{R}_1\vert w_2) + \lambda_{21}p(w_1)p(\mathcal{R}_2\vert w_1) + \lambda_{22}[\textcolor{blue}{1-p(w_1)}]\left[\textcolor{blue}{1-p(\mathcal{R}_1\vert w_2)}\right]\\
  &amp;= \textcolor{green}{\lambda_{22} + (\lambda_{12}-\lambda_{22})p(\mathcal{R}_1\vert w_2)} + \textcolor{red}{p(w_1)}\textcolor{blue}{[ \lambda_{11}-\lambda_{22} + (\lambda_{21}-\lambda_{11})p(\mathcal{R}_2\vert w_1)+ (\lambda_{22} -\lambda_{12})p(\mathcal{R}_1\vert w_2)  ]}\\
  &amp;= \textcolor{green}{A} + \textcolor{red}{p(w_1)}\textcolor{blue}{B}
\end{aligned} \tag{7}\]

<p>在已知类概率密度函数 $p(x\vert w_j)$ 的前提下，一旦 $\mathcal{R}_1,\mathcal{R}_2$ 确定，误判的期望风险是先验概率 $p(w_1)$ 的线性函数，此时不难计算出期望风险的上下界（一定在直线与边界的两个交点分别取得）。</p>

<h3 id="53-最小化最大期望风险"><span class="me-2">5.3. 最小化最大期望风险</span><a href="#53-最小化最大期望风险" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>根据我们前述目标，需要最小化前面确定的期望风险的最大值，下面结合图例进行分析</p>

<p><a href="/assets/img/postsimg/20240312/minimun%20average%20risk.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20240312/minimun%20average%20risk.jpg" alt="minimum average risk" class="lazyload" data-proofer-ignore></a></p>

<ul>
  <li><strong>外层循环</strong></li>
  <li>
    <p>考虑到先验概率不确定性，遍历其取值区间 $[0,1]$，对于第 $i$ 个具体的取值，可以按照最小风险贝叶斯决策的原理设计出最佳的决策域 $\mathcal{R}_1,\mathcal{R}_2$，同时计算出此时的期望风险为 $R^{\star}$</p>

    <ul>
      <li><strong>内层计算</strong>：</li>
      <li>对 $p(w_1)$ 的第 $i$ 个具体的取值和对应的 $\mathcal{R}_1,\mathcal{R}_2$，考虑 $p(w_1)$ 偏离这个具体取值时的情况。极端情况下，先验概率可能在 $[0,1]$ 区间随意偏离。</li>
      <li>前面式 $(8)$ 已知期望风险和先验概率 $p(w_1)$ 呈线性关系，那么根据其取值区间 $[0,1]$，代入式 $(8)$ 容易找到其上界（某个端点），记为 $R^{\star}_{i\max}$</li>
      <li>比较 $R^{\star}_{i\max}$ 和 $R^{\star}$ 的关系
        <ul>
          <li>如果 $R^{\star}_{i\max}&gt;R^{\star}$ 则表示没有找到最大误判平均风险的极小值（图中蓝线），continue。</li>
          <li>若满足，则找到最大误判平均风险的极小值（图中红线），break。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>$i = i+1$ 确定下一个先验概率的具体取值，回到第一步。</li>
</ul>

<p>可以发现，最大的误判期望风险，其极小值情况是最小风险贝叶斯决策域 $\mathcal{R}_1,\mathcal{R}_2$ 使得式 $(8)$ 中的系数 $B=0$，此时无论先验概率 $p(w_1)$ 如何变化，期望风险 $R$ 与先验概率无关（因为系数 $B=0$），从而使的期望风险 $R$ 恒等于常数，最大的期望风险值是所有最小风险贝叶斯决策中最小的，对应的最小风险贝叶斯决策称为<strong>最小最大贝叶斯决策</strong>。</p>

<h2 id="6-参考文献"><span class="me-2">6. 参考文献</span><a href="#6-参考文献" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>[1] 漆比特. <a href="https://bln.csdn.net/sinat_35907936/article/details/108894542">CSDN 机器学习十大经典算法：深入浅出聊贝叶斯决策（贝叶斯公式，最小风险贝叶斯，最小错误贝叶斯）</a></p>

</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
  <div class="post-meta mb-3">
    <i class="far fa-folder-open fa-fw me-1"></i>
    
      <a href='/categories/academic/'>Academic</a>,
      <a href='/categories/knowledge/'>Knowledge</a>
  </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw me-1"></i>
      
      <a href="/tags/pattern-recognition/"
          class="post-tag no-text-decoration" >pattern recognition</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        本文由作者按照 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         进行授权

      
    </div>

    <!-- Post sharing snippet -->

<div class="share-wrapper">
  <span class="share-label text-muted me-1">分享</span>
  <span class="share-icons">
    
    
    

    
      
      <a
        href="https://twitter.com/intent/tweet?text=%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%EF%BC%88%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%EF%BC%89%20-%20SIRLIS&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FPattern-Recognition-Bayes%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Twitter"
        target="_blank"
        rel="noopener"
        aria-label="Twitter"
      >
        <i class="fa-fw fab fa-twitter"></i>
      </a>
    
      
      <a
        href="https://www.facebook.com/sharer/sharer.php?title=%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%EF%BC%88%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%EF%BC%89%20-%20SIRLIS&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FPattern-Recognition-Bayes%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Facebook"
        target="_blank"
        rel="noopener"
        aria-label="Facebook"
      >
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    
      
      <a
        href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FPattern-Recognition-Bayes%2F&text=%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%EF%BC%88%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%EF%BC%89%20-%20SIRLIS"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Telegram"
        target="_blank"
        rel="noopener"
        aria-label="Telegram"
      >
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <i
      id="copy-link"
      class="fa-fw fas fa-link small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="分享链接"
      data-title-succeed="链接已复制！"
    >
    </i>
  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
      
    </div>
  </div>
  <!-- #core-wrapper -->

  <!-- panel -->
  <div id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
    <div class="access">
      <!-- Get the last 5 posts from lastmod list. -->














  <div id="access-lastmod" class="post">
    <div class="panel-heading">最近更新</div>
    <ul class="post-content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Pattern-Recognition-Nonlinear-Classifier/">模式识别（非线性分类器）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Pattern-Recognition-Bayes/">模式识别（贝叶斯决策）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-Temporal-Differences/">强化学习（时序差分法）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-markov-process/">强化学习（马尔可夫决策过程）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-Monte-Carlo/">强化学习（蒙特卡洛法）</a>
        </li>
      
    </ul>
  </div>
  <!-- #access-lastmod -->


      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">热门标签</div>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/fuzzy/">fuzzy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/vscode/">vscode</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/other/">other</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/astronomy/">astronomy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c-c/">c/c++</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/computer-vision/">computer vision</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/meta-learning/">meta learning</a>
      
    </div>
  </div>


    </div>

    
      
      



  <div id="toc-wrapper" class="ps-0 pe-4 mb-5">
    <div class="panel-heading ps-3 pt-2 mb-2">文章内容</div>
    <nav id="toc"></nav>
  </div>


    
  </div>
</div>

<!-- tail -->

  <div class="row">
    <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-3 pe-xl-4 mt-5">
      
        
        <!--
  Recommend the other 3 posts according to the tags and categories of the current post,
  if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->








  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  






<!-- Fill with the other newlest posts -->





  <div id="related-posts" class="mb-2 mb-sm-4">
    <h3 class="pt-2 mb-4 ms-1" data-toc-skip>
      相关文章
    </h3>
    <div class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        
        
        <div class="col">
          <a href="/posts/Pattern-Recognition-Linear-Classifier/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1709447119"
  data-df="YYYY/MM/DD"
  
>
  2024/03/03
</em>

              <h4 class="pt-0 my-2" data-toc-skip>模式识别（线性分类器）</h4>
              <div class="text-muted small">
                <p>
                  





                  本文介绍了模式识别的线性分类器，包括线性分类器的基础概念、垂直平分准则以及垂直平分分类器、Fisher 投影准则、感知准则、最小错分样本准则、最小平方误差准则、最小二乘估计。






  1. 引言
  2. 线性分类器基础
    
      2.1. 线性判别函数
      2.2. 广义线性判别函数
      2.3. 二分类与多分类
      2.4. 线性分类器设计的基...
                </p>
              </div>
            </div>
          </a>
        </div>
      
        
        
        <div class="col">
          <a href="/posts/Pattern-Recognition-LDA&PCA/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1714615399"
  data-df="YYYY/MM/DD"
  
>
  2024/05/02
</em>

              <h4 class="pt-0 my-2" data-toc-skip>模式识别（LDA和PCA）</h4>
              <div class="text-muted small">
                <p>
                  





                  本文介绍了模式识别种常用的两种特征选择与特征降维方法，即线性判别分析（Linear Discriminant Analysis，LDA）和主成分分析（Principal Component Analysis，PCA）。






  1. 特征降维
  2. 线性判别分析（LDA）
    
      2.1. Fisher 投影准则
      2.2. 瑞利商与广义瑞利商
     ...
                </p>
              </div>
            </div>
          </a>
        </div>
      
        
        
        <div class="col">
          <a href="/posts/Pattern-Recognition-Nonlinear-Classifier/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1743341659"
  data-df="YYYY/MM/DD"
  
>
  2025/03/30
</em>

              <h4 class="pt-0 my-2" data-toc-skip>模式识别（非线性分类器）</h4>
              <div class="text-muted small">
                <p>
                  





                  本文介绍了模式识别的非线性分类器，主要包括近邻法分类器、支持向量机（SVM）、决策树，最后介绍分类器的集成。






  1. 引言
  2. 近邻法分类器
    
      2.1. 最近邻法
      2.2. K 近邻法
      2.3. KD 树
      2.4. 构造 KD 树
    
  
  3. 支持向量机（SVM）
    
      3.1. 线性支...
                </p>
              </div>
            </div>
          </a>
        </div>
      
    </div>
    <!-- .card-deck -->
  </div>
  <!-- #related-posts -->


      
        
        <!-- Navigation buttons at the bottom of the post. -->

<div class="post-navigation d-flex justify-content-between">
  
    <a
      href="/posts/Pattern-Recognition-Linear-Classifier/"
      class="btn btn-outline-primary"
      prompt="上一篇"
    >
      <p>模式识别（线性分类器）</p>
    </a>
  

  
    <a
      href="/posts/Pattern-Recognition-LDA&PCA/"
      class="btn btn-outline-primary"
      prompt="下一篇"
    >
      <p>模式识别（LDA和PCA）</p>
    </a>
  
</div>

      
        
        <!--  The comments switcher -->

  
  <!-- https://utteranc.es/ -->
<script src="https://utteranc.es/client.js"
        repo="sirlis/sirlis.github.io"
        issue-term="pathname"
        crossorigin="anonymous"
        async>
</script>

<script type="text/javascript">
  $(function() {
    const origin = "https://utteranc.es";
    const iframe = "iframe.utterances-frame";
    const lightTheme = "github-light";
    const darkTheme = "github-dark";
    let initTheme = lightTheme;

    if ($("html[data-mode=dark]").length > 0
        || ($("html[data-mode]").length == 0
            && window.matchMedia("(prefers-color-scheme: dark)").matches)) {
      initTheme = darkTheme;
    }

    addEventListener("message", (event) => {
      let theme;

      /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */
      if (event.origin === origin) {
        /* page initial */
        theme = initTheme;

      } else if (event.source === window && event.data &&
            event.data.direction === ModeToggle.ID) {
        /* global theme mode changed */
        const mode = event.data.message;
        theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme);

      } else {
        return;
      }

      const message = {
        type: "set-theme",
        theme: theme
      };

      const utterances = document.querySelector(iframe).contentWindow;
      utterances.postMessage(message, origin);
    });

  });
</script>



      
    </div>
  </div>


        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-11 post-content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">热门标签</div>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/fuzzy/">fuzzy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/vscode/">vscode</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/other/">other</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/astronomy/">astronomy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c-c/">c/c++</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/computer-vision/">computer vision</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/meta-learning/">meta learning</a>
      
    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>
    </div>

    <!-- The Footer -->

<footer>
  <div class="container px-lg-4">
    <div class="d-flex justify-content-center align-items-center text-muted mx-md-3">
      <p>本站采用 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 主题 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>
      </p>

      <p>©
        2025
        <a href="https://github.com/sirlis">sirlis</a>.
        
          <span
            data-bs-toggle="tooltip"
            data-bs-placement="top"
            title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。"
          >保留部分权利。</span>
        
      </p>
    </div>
  </div>
</footer>


    <div id="mask"></div>

    <button id="back-to-top" aria-label="back-to-top" class="btn btn-lg btn-box-shadow">
      <i class="fas fa-angle-up"></i>
    </button>

    
      <div
        id="notification"
        class="toast"
        role="alert"
        aria-live="assertive"
        aria-atomic="true"
        data-bs-animation="true"
        data-bs-autohide="false"
      >
        <div class="toast-header">
          <button
            type="button"
            class="btn-close ms-auto"
            data-bs-dismiss="toast"
            aria-label="Close"
          ></button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="px-2 mb-3">发现新版本的内容。</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            更新
          </button>
        </div>
      </div>
    

    <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.0/dist/jquery.min.js,npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.7/dayjs.min.js,npm/dayjs@1.11.7/locale/zh.min.js,npm/dayjs@1.11.7/plugin/relativeTime.min.js,npm/dayjs@1.11.7/plugin/localizedFormat.min.js,npm/tocbot@4.21.0/dist/tocbot.min.js"></script>






<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
    /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
    MathJax = {
      tex: {
        /* start/end delimiter pairs for in-line math */
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ],
        /* start/end delimiter pairs for display math */
        displayMath: [
          ['$$', '$$'],
          ['\\[', '\\]']
        ]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>





    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  /* Note: dependent library will be loaded in `js-selector.html` */
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('search-results'),
    json: '/assets/js/data/search.json',
    searchResultTemplate: '<div class="px-1 px-sm-2 px-lg-4 px-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
    noResultsText: '<p class="mt-5"></p>',
    templateMiddleware: function(prop, value, template) {
      if (prop === 'categories') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
        }
      }

      if (prop === 'tags') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
        }
      }
    }
  });
</script>

  </body>
</html>

