<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="zh-CN" 
  
>
  <!-- The Head -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="深度学习基础（LSTM）" />
<meta property="og:locale" content="zh_CN" />
<meta name="description" content="本文介绍了 LSTM （长短时记忆网络）的基本概念，以及正/反向传播的推导过程，然后分析了 LSTM 如何克服 RNN 的梯度消失问题，最后介绍了 PyTorch 的 LSTM 模块的实现。" />
<meta property="og:description" content="本文介绍了 LSTM （长短时记忆网络）的基本概念，以及正/反向传播的推导过程，然后分析了 LSTM 如何克服 RNN 的梯度消失问题，最后介绍了 PyTorch 的 LSTM 模块的实现。" />
<link rel="canonical" href="http://localhost:4000/posts/deep-learning-LSTM/" />
<meta property="og:url" content="http://localhost:4000/posts/deep-learning-LSTM/" />
<meta property="og:site_name" content="SIRLIS" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-04T10:39:19+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="深度学习基础（LSTM）" />
<meta name="twitter:site" content="@none" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-09-23T00:26:26+08:00","datePublished":"2020-10-04T10:39:19+08:00","description":"本文介绍了 LSTM （长短时记忆网络）的基本概念，以及正/反向传播的推导过程，然后分析了 LSTM 如何克服 RNN 的梯度消失问题，最后介绍了 PyTorch 的 LSTM 模块的实现。","headline":"深度学习基础（LSTM）","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/deep-learning-LSTM/"},"url":"http://localhost:4000/posts/deep-learning-LSTM/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>深度学习基础（LSTM） | SIRLIS
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="SIRLIS">
<meta name="application-name" content="SIRLIS">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.21.0/dist/tocbot.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  
    <!-- Switch the mode between dark and light. -->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() {
      return 'mode';
    }
    static get MODE_ATTR() {
      return 'data-mode';
    }
    static get DARK_MODE() {
      return 'dark';
    }
    static get LIGHT_MODE() {
      return 'light';
    }
    static get ID() {
      return 'mode-toggle';
    }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener('change', () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();
      });
    } /* constructor() */

    get sysDarkPrefers() {
      return window.matchMedia('(prefers-color-scheme: dark)');
    }

    get isSysDarkPrefer() {
      return this.sysDarkPrefers.matches;
    }

    get isDarkMode() {
      return this.mode === ModeToggle.DARK_MODE;
    }

    get isLightMode() {
      return this.mode === ModeToggle.LIGHT_MODE;
    }

    get hasMode() {
      return this.mode != null;
    }

    get mode() {
      return sessionStorage.getItem(ModeToggle.MODE_KEY);
    }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      document.documentElement.removeAttribute(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage(
        {
          direction: ModeToggle.ID,
          message: this.modeStatus
        },
        '*'
      );
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.notify();
    } /* flipMode() */
  } /* ModeToggle */

  const modeToggle = new ModeToggle();
</script>

  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle">
      
        
        <img src="/assets/img/head.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'">
      
    </a>

    <div class="site-title">
      <a href="/">SIRLIS</a>
    </div>
    <div class="site-subtitle fst-italic">分享科研和生活的日常</div>
  </div>
  <!-- .profile-wrapper -->

  <ul class="nav flex-column flex-grow-1 w-100 ps-0">
    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home"></i>
        <span>首页</span>
      </a>
    </li>
    <!-- the real tabs -->
    
      <li class="nav-item">
        <a href="/categories/" class="nav-link">
          <i class="fa-fw fas fa-stream"></i>
          

          <span>分类</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/tags/" class="nav-link">
          <i class="fa-fw fas fa-tags"></i>
          

          <span>标签</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/archives/" class="nav-link">
          <i class="fa-fw fas fa-archive"></i>
          

          <span>归档</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/about/" class="nav-link">
          <i class="fa-fw fas fa-info-circle"></i>
          

          <span>关于</span>
        </a>
      </li>
      <!-- .nav-item -->
    
  </ul>
  <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://github.com/sirlis"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="https://twitter.com/none"
          aria-label="twitter"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-twitter"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['lihongjue','buaa.edu.cn'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          

          

          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</div>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container px-xxl-5">
        <!-- The Top Bar -->

<div id="topbar-wrapper">
  <div
    id="topbar"
    class="container d-flex align-items-center justify-content-between h-100"
  >
    <span id="breadcrumb">
      

      
        
          
            <span>
              <a href="/">
                首页
              </a>
            </span>

          
        
          
        
          
            
              <span>深度学习基础（LSTM）</span>
            

          
        
      
    </span>
    <!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      文章
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="搜索..."
      >
    </span>
    <span id="search-cancel">取消</span>
  </div>
</div>

        











<div class="row">
  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pe-xl-4">
    

    <div class="post px-1 px-md-2">
      

      
        
      
        <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->



  
  

  <!-- CDN URL -->
  

  <!-- Add image path -->
  

  
    
      
      
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  

  



<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  

  
  

  

  
  

  




<!-- return -->




<h1 data-toc-skip>深度学习基础（LSTM）</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      发表于
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class=""
  data-ts="1601779159"
  data-df="YYYY/MM/DD"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  2020/10/04
</em>

    </span>

    <!-- lastmod date -->
    
    <span>
      更新于
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class=""
  data-ts="1695399986"
  data-df="YYYY/MM/DD"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  2023/09/23
</em>

    </span>
    

  

  <div class="d-flex justify-content-between">
    <!-- author(s) -->
    <span>
      

      作者

      <em>
      
        <a href="https://github.com/sirlis">sirlis</a>
      
      </em>
    </span>

    <div>
      <!-- read time -->
      <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="4423 字"
>
  <em>24 分钟</em>阅读</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <p>本文介绍了 LSTM （长短时记忆网络）的基本概念，以及正/反向传播的推导过程，然后分析了 LSTM 如何克服 RNN 的梯度消失问题，最后介绍了 PyTorch 的 LSTM 模块的实现。</p>

<!--more-->

<hr />

<ul>
  <li><a href="#1-lstm">1. LSTM</a>
    <ul>
      <li><a href="#11-概念">1.1. 概念</a></li>
      <li><a href="#12-模型">1.2. 模型</a></li>
      <li><a href="#13-前向传播">1.3. 前向传播</a></li>
      <li><a href="#14-如何解决梯度消失">1.4. 如何解决梯度消失</a></li>
      <li><a href="#15-如何解决梯度爆炸">1.5. 如何解决梯度爆炸</a></li>
    </ul>
  </li>
  <li><a href="#2-实际案例">2. 实际案例</a>
    <ul>
      <li><a href="#21-lstm-的-pytorch-类">2.1. LSTM 的 PyTorch 类</a></li>
      <li><a href="#22-lstm-实现-mnist-识别">2.2. LSTM 实现 MNIST 识别</a></li>
    </ul>
  </li>
  <li><a href="#3-常见错误">3. 常见错误</a>
    <ul>
      <li><a href="#31-cudnn_status_bad_param">3.1. CUDNN_STATUS_BAD_PARAM</a></li>
    </ul>
  </li>
  <li><a href="#4-参考文献">4. 参考文献</a></li>
</ul>

<h1 id="1-lstm">1. LSTM</h1>

<h2 id="11-概念"><span class="me-2">1.1. 概念</span><a href="#11-概念" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>长短期记忆（Long short-term memory, LSTM）是一种特殊的RNN（Gers et al.,2000; Hochreiter et al., 1997），主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现。</p>

<p>LSTM 与 RNN 的主要输入输出区别如下图所示</p>

<p><a href="/assets/img/postsimg/20201004/1.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20201004/1.jpg" alt="rnn-lstm" class="lazyload" data-proofer-ignore></a></p>

<h2 id="12-模型"><span class="me-2">1.2. 模型</span><a href="#12-模型" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>LSTM 网络的循环单元结构如下图所示</p>

<p><a href="/assets/img/postsimg/20201004/2.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20201004/2.jpg" alt="lstm" class="lazyload" data-proofer-ignore></a></p>

<p>其中，LSTM 引入三个门来控制信息的传递，分别为遗忘门 $\boldsymbol{f}_t$、输入门 $\boldsymbol{i}_t$、输出门 $\boldsymbol{o}_t$。三个门的作用是：</p>

<ul>
  <li>遗忘门 $\boldsymbol{f}<em>t$ 控制上一个时刻的内部状态 $\boldsymbol{c}</em>{t-1}$ 需要遗忘多少信息；</li>
  <li>输入门 $\boldsymbol{i}_t$ 控制当前时刻的候选状态 $\boldsymbol{c}_t$ 有多少信息需要保存；</li>
  <li>输出门 $\boldsymbol{o}_t$ 控制当前时刻的内部状态 $\boldsymbol{c}_t$ 有多少信息需要输出给外部状态 $\boldsymbol{h}_t$。</li>
</ul>

<h2 id="13-前向传播"><span class="me-2">1.3. 前向传播</span><a href="#13-前向传播" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>三个门的计算方式为：</p>

\[\begin{aligned}
\boldsymbol{f}_t &amp;= \sigma(\boldsymbol W_f \boldsymbol{h}_{t-1} + \boldsymbol{U}_f \boldsymbol{x}_t + \boldsymbol{b}_f)=\sigma([\boldsymbol W_f, \boldsymbol{U}_f]\cdot[\boldsymbol{h}_{t-1}, \boldsymbol{x}_t]^T + \boldsymbol{b}_f)\\
\boldsymbol{i}_t &amp;= \sigma(\boldsymbol W_i \boldsymbol{h}_{t-1} + \boldsymbol{U}_i \boldsymbol{x}_t + \boldsymbol{b}_i)=\sigma([\boldsymbol W_i, \boldsymbol{U}_i]\cdot[\boldsymbol{h}_{t-1}, \boldsymbol{x}_t]^T + \boldsymbol{b}_f)\\
\boldsymbol{o}_t &amp;= \sigma(\boldsymbol W_o \boldsymbol{h}_{t-1} + \boldsymbol{U}_o \boldsymbol{x}_t + \boldsymbol{b}_o)=\sigma([\boldsymbol W_o, \boldsymbol{U}_o]\cdot[\boldsymbol{h}_{t-1}, \boldsymbol{x}_t]^T + \boldsymbol{b}_f)\\
\end{aligned}\]

<p>其中，$\sigma$ 为 $sigmoid$ 激活函数，输出区间为 $[0,1]$。也就是说，LSTM 网络中的“门”是一种“软”门，取值在 $[0,1]$ 之间，表示以一定的比例允许信息通过。注意到，等式右边包含一个对 $\boldsymbol{h}_{t-1}$ 和 $\boldsymbol{x}_t$ <strong>向量拼接</strong>的操作，相应的参数也因此进行了拼接。</p>

<p>相比 RNN，LSTM 引入了一个新的状态，称为细胞状态（cell state），表示为 $\boldsymbol{c}_t$，专门进行现行的循环信息传递，同时输出（非线性地）输出信息给隐层状态 $\boldsymbol{h}_t\in \mathbb{R}^D$。计算公式如下</p>

\[\begin{aligned}
\boldsymbol{c}_t &amp;= \tanh(\boldsymbol W_c \boldsymbol{h}_{t-1} + \boldsymbol{U}_c \boldsymbol{x}_t + \boldsymbol{b}_c)=\tanh([\boldsymbol W_c, \boldsymbol{U}_c]\cdot[\boldsymbol{h}_{t-1}, \boldsymbol{x}_t]^T + \boldsymbol{b}_f)\\
\boldsymbol{c}_t &amp;= \boldsymbol{f}_t \odot \boldsymbol{c}_{t-1} + \boldsymbol{i}_t \odot \boldsymbol{c}_t\\
\boldsymbol{h}_t &amp;= \boldsymbol{o}_t \odot \tanh(\boldsymbol{c}_t)
\end{aligned}\]

<p>其中，</p>
<ul>
  <li>$\boldsymbol{c}_t\in\mathbb{R}^D$ 是通过非线性函数（$\tanh$）得到的候选状态，</li>
  <li>$\boldsymbol{c}_{t-1}$ 是上一时刻的记忆单元，</li>
  <li>$\odot$ 是向量的元素乘积。</li>
</ul>

<p>在每个时刻，LSTM 网络的细胞状态 $\boldsymbol{c}_t$ 记录了截至当前时刻的历史信息。</p>

<p>根据不同的门状态取值，可以实现不同的功能。当 $\boldsymbol{f}_t = 0,\boldsymbol{i}_t = 1$ 时，记忆单元将历史信息清空，并将候选状态向量 $\boldsymbol{c}_t$ 写入，但此时记忆单元 $\boldsymbol{c}_t$ 依然和上一时刻的历史信息相关。当$\boldsymbol{f}_t = 1,\boldsymbol{i}_t = 0$ 时，记忆单元将复制上一时刻的内容，不写入新的信息。</p>

<p>需要注意的是，<strong>LSTM 中的 $\boldsymbol{c}_t$ 对应于传统 RNN 中的 $\boldsymbol{h}_t$</strong>，通常是上一个传过来的历史状态乘以遗忘门后加上一些新信息得到，因此更新比较缓慢。而 LSTM 中的 $\boldsymbol{h}_t$ 则变化剧烈的多，在不同的时刻下的取值往往区别很大。</p>

<p>再次进行维度分析，$\boldsymbol{h}_t,\boldsymbol{c}_t,\boldsymbol{i}_t,\boldsymbol{f}_t,\boldsymbol{o}_t \in \mathbb R^D$ 且 $\boldsymbol{b}_f,\boldsymbol{b}_i,\boldsymbol{b}_o,\boldsymbol{b}_c \in \mathbb R^D$，$\boldsymbol{x}_t\in \mathbb R^M$，那么 $\boldsymbol W_f,\boldsymbol W_i,\boldsymbol W_o,\boldsymbol W_c \in \mathbb R^{D\times M}$， $\boldsymbol{U}_f,\boldsymbol{U}_i,\boldsymbol{U}_o,\boldsymbol{U}_c \in \mathbb R^{D\times D}$。则上面所有式子可简洁描述为</p>

\[\begin{aligned}
\begin{bmatrix}
 \boldsymbol{c}_t\\ 
 \boldsymbol{o}_t\\
 \boldsymbol{i}_t\\
 \boldsymbol{f}_t 
\end{bmatrix}=
\begin{bmatrix}
 \tanh\\ 
 \sigma\\
 \sigma\\
 \sigma 
\end{bmatrix}\left( \boldsymbol W
\begin{bmatrix}
 \boldsymbol{h}_{t-1}\\ 
 \boldsymbol{x}_t
\end{bmatrix}+\boldsymbol b
 \right)
\end{aligned}\]

<p>其中</p>

\[\begin{aligned}
\boldsymbol W &amp;=\begin{bmatrix}
 \boldsymbol W_c &amp; \boldsymbol{U}_c\\ 
 \boldsymbol W_o &amp; \boldsymbol{U}_o\\
 \boldsymbol W_i &amp; \boldsymbol{U}_i\\ 
 \boldsymbol W_f &amp; \boldsymbol{U}_f
\end{bmatrix} \in \mathbb R^{4D\times (D+M)}\\
\boldsymbol b &amp;= \begin{bmatrix}
 \boldsymbol{b}_c\\ 
 \boldsymbol{b}_o\\
 \boldsymbol{b}_i\\
 \boldsymbol{b}_f 
\end{bmatrix}\in \mathbb R^{4D}
\end{aligned}\]

<p>循环神经网络中的隐状态 $\boldsymbol h$ 存储了历史信息，可以看作一种记忆（Memory）。在简单循环网络中，隐状态每个时刻都会被重写，因此可以看作一种短期记忆（Short-Term Memory）。在神经网络中，长期记忆（Long-Term Memory）可以看作网络参数，隐含了从训练数据中学到的经验，其更新周期要远远慢于短期记忆。</p>

<p>而在 LSTM 网络中，记忆单元 $\boldsymbol c$ 可以在某个时刻捕捉到某个关键信息，并有能力将此关键信息保存一定的时间间隔。记忆单元 $\boldsymbol c$ 中保存信息的生命周期要长于短期记忆 $\boldsymbol h$，但又远远短于长期记忆，<strong>长短期记忆是指长的“短期记忆”。因此称为长短期记忆（Long Short-Term Memory）</strong>。</p>

<h2 id="14-如何解决梯度消失"><span class="me-2">1.4. 如何解决梯度消失</span><a href="#14-如何解决梯度消失" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><a href="https://www.zhihu.com/question/34878706">LSTM如何来避免梯度弥散和梯度爆炸？</a></p>

<p>LSTM 通过引入门机制，把矩阵乘法变成了 element-wise 的 <a href="https://baike.baidu.com/item/%E5%93%88%E8%BE%BE%E7%8E%9B%E7%A7%AF">Hadamard product</a>（哈达玛积，逐元素相乘）。这样做后，细胞状态 $\boldsymbol{c}_t$ （对应于 RNN 中的隐状态 $\boldsymbol{h}_t$）的更新公式变为</p>

\[\boldsymbol{c}_t = \boldsymbol{f}_t \odot \boldsymbol{c}_{t-1} + \boldsymbol{i}_t \odot \tanh(\boldsymbol W_c \boldsymbol{h}_{t-1} + \boldsymbol{U}_c \boldsymbol{x}_t + \boldsymbol{b}_c)\]

<p>进一步推导</p>

\[\begin{aligned}
\frac{\partial \boldsymbol L}{\partial \boldsymbol{c}_{t-1}} &amp;= \frac{\partial L}{\partial c_t}\frac{\partial c_t}{\partial c_{t-1}} = \frac{\partial L}{\partial c_t} \odot diag(f_t+\cdots)
\end{aligned}\]

<p>公式里其余的项不重要，这里就用省略号代替了。可以看出当 $f_t=1$ 时，就算其余项很小，梯度仍然可以很好地传导到上一个时刻，此时即使层数较深也不会发生 Gradient Vanish 的问题；当 $f_t=0$ 时，即上一时刻的信号不影响到当前时刻，则此项也会为0。$f_t$ 在这里控制着梯度传导到上一时刻的衰减程度，与它 Forget Gate 的功能一致。</p>

<p>这样的方式本质上类似 Highway Network 或者 ResNet（残差连接），使得梯度的信息可以“贯穿”时间线，缓解梯度消散。</p>

<p><a href="/assets/img/postsimg/20201004/3.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20201004/3.jpg" alt="highway" class="lazyload" data-proofer-ignore></a></p>

<p>这里需要强调的是：LSTM不是让所有远距离的梯度值都不会消散，而是只让具有时序关键信息位置的梯度可以一直传递。另一方面，仅在 $c_t$ 通路上缓解了梯度消失问题，而在 $h_t$ 通路上梯度消失依然存在。</p>

<h2 id="15-如何解决梯度爆炸"><span class="me-2">1.5. 如何解决梯度爆炸</span><a href="#15-如何解决梯度爆炸" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>关于梯度爆炸问题： $f_t$ 已经在 $[0,1]$ 范围之内了。而且梯度爆炸爆炸也是相对容易解决的问题，可以用梯度裁剪(gradient clipping)来解决：只要设定阈值，当提出梯度超过此阈值，就进行截取即可。</p>

<p>另一种解读参见 [<a href="#ref1">1</a>] 。</p>

<h1 id="2-实际案例">2. 实际案例</h1>

<h2 id="21-lstm-的-pytorch-类"><span class="me-2">2.1. LSTM 的 PyTorch 类</span><a href="#21-lstm-的-pytorch-类" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>官方文档链接<a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html">在此</a>（https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html ）</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">CLASStorch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>参数列表如下</p>

<ul>
  <li>
    <p><strong>input_size</strong> – The number of expected features in the input <em>x</em></p>
  </li>
  <li>
    <p><strong>hidden_size</strong> – The number of features in the hidden state <em>h</em></p>
  </li>
  <li>
    <p><strong>num_layers</strong> – Number of recurrent layers. E.g., setting <code class="language-plaintext highlighter-rouge">num_layers=2</code> would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1</p>
  </li>
  <li>
    <p><strong>bias</strong> – If False, then the layer does not use bias weights <em>b_ih</em> and <em>b_hh</em>. Default: <code class="language-plaintext highlighter-rouge">True</code></p>
  </li>
  <li>
    <p><strong>batch_first</strong> – If <code class="language-plaintext highlighter-rouge">True</code>, then the input and output tensors are provided as (batch, seq, feature). Default: <code class="language-plaintext highlighter-rouge">False</code></p>
  </li>
  <li>
    <p><strong>dropout</strong> – If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to <code class="language-plaintext highlighter-rouge">dropout</code>. Default: 0</p>
  </li>
  <li>
    <p>bidirectional – If <code class="language-plaintext highlighter-rouge">True</code>, becomes a bidirectional LSTM. Default: <code class="language-plaintext highlighter-rouge">False</code></p>
  </li>
</ul>

<p>我们再次将 LSTM 的前向传播列写如下便于比对</p>

\[\begin{aligned}
\boldsymbol{f}_t &amp;= \sigma(\boldsymbol W_f \boldsymbol{h}_{t-1} + \boldsymbol{U}_f \boldsymbol{x}_t + \boldsymbol{b}_f)\\
\boldsymbol{i}_t &amp;= \sigma(\boldsymbol W_i \boldsymbol{h}_{t-1} + \boldsymbol{U}_i \boldsymbol{x}_t + \boldsymbol{b}_i)\\
\boldsymbol{o}_t &amp;= \sigma(\boldsymbol W_o \boldsymbol{h}_{t-1} + \boldsymbol{U}_o \boldsymbol{x}_t + \boldsymbol{b}_o)\\
\boldsymbol{c}_t &amp;= \tanh(\boldsymbol W_c \boldsymbol{h}_{t-1} + \boldsymbol{U}_c \boldsymbol{x}_t + \boldsymbol{b}_c)\\
\boldsymbol{c}_t &amp;= \boldsymbol{f}_t \odot \boldsymbol{c}_{t-1} + \boldsymbol{i}_t \odot \boldsymbol{c}_t\\
\boldsymbol{h}_t &amp;= \boldsymbol{o}_t \odot \tanh(\boldsymbol{c}_t)
\end{aligned}\]

<p>前面我们已经假设，$\boldsymbol{h}_t,\boldsymbol{c}_t,\boldsymbol{i}_t,\boldsymbol{f}_t,\boldsymbol{o}_t \in \mathbb R^D$ 且 $\boldsymbol{b}_f,\boldsymbol{b}_i,\boldsymbol{b}_o,\boldsymbol{b}_c \in \mathbb R^D$，$\boldsymbol{x}_t\in \mathbb R^M$，那么 $\boldsymbol W_f,\boldsymbol W_i,\boldsymbol W_o,\boldsymbol W_c \in \mathbb R^{D\times M}$， $\boldsymbol{U}_f,\boldsymbol{U}_i,\boldsymbol{U}_o,\boldsymbol{U}_c \in \mathbb R^{D\times D}$。</p>

<p><code class="language-plaintext highlighter-rouge">input_size</code> 就是输入层维度 $M$，比如某个词或者某张图的 embedding dim （特征维度）。</p>

<p><code class="language-plaintext highlighter-rouge">hidden_size</code> 就是隐层 $h_t$ 的维度 $D$。</p>

<p><code class="language-plaintext highlighter-rouge">num_layers</code> 是 LSTM 堆叠的层数。LSTM 可以按照下图的形式进行堆叠。</p>

<p><a href="/assets/img/postsimg/20201004/4.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20201004/4.jpg" alt="num_layers lstm" class="lazyload" data-proofer-ignore></a></p>

<p><code class="language-plaintext highlighter-rouge">batch_first</code> 是一个可选参数，指定是否将 <code class="language-plaintext highlighter-rouge">batch_size</code> 作为输入输出张量的第一个维度，如果是，则输入和输入的维度顺序为（<code class="language-plaintext highlighter-rouge">batch_size， seq_length，input_size</code>），否则，输入和输出的默认维度顺序是（<code class="language-plaintext highlighter-rouge">seq_length, batch_size, input_size</code>）。</p>

<h2 id="22-lstm-实现-mnist-识别"><span class="me-2">2.2. LSTM 实现 MNIST 识别</span><a href="#22-lstm-实现-mnist-识别" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>注意，后文中的所有代码均为片段，全部凑在一起时无法直接运行的！旨在辅助进行理解。</p>

<p>考虑到网络每一时刻输入的是一个 vector，我们可以假设这个 vector 对应的是 <strong>图像的一行</strong>，有多少行就对应多少时刻，那最后一个时刻输入的是最后一行。最后输出的 $h_t$ 实际上就是该图像对应的类别。</p>

<p>MNIST 手写数字图片大小为 28*28，那么可以将每张图片看作长为28的序列，序列中的每个元素的特征维度是28，这样就将图片变成了一个序列。</p>

<p>那么有</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">input_size</span> <span class="o">=</span> <span class="mi">28</span> <span class="c1"># image width
</span><span class="n">sequence_size</span> <span class="o">=</span> <span class="mi">28</span> <span class="c1"># image height (time step)
</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># user defined
</span><span class="n">output_size</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># 10 classes of number from 0 to 9
</span><span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># user defined
</span></pre></td></tr></tbody></table></code></div></div>

<p>其中 <code class="language-plaintext highlighter-rouge">hidden_size</code> 和 <code class="language-plaintext highlighter-rouge">num_layers</code> 均由用户自定义。</p>

<p>然后我们开始构建 LSTM 网络的类。</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">MNIST_LSTM</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">MNIST_LSTM</span><span class="p">,</span><span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="c1"># fully connect
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x -     [batch_size, sequence_dim, input_dim]
</span>        <span class="c1"># r_out - [batch_size, sequence_dim, hidden_size]
</span>        <span class="c1"># h_n -   [layer_dim, batch_size, hidden_size]
</span>        <span class="c1"># h_c -   [layer_dim, batch_size, hidden_size]
</span>        <span class="n">r_out</span><span class="p">,</span> <span class="p">(</span><span class="n">h_n</span><span class="p">,</span> <span class="n">h_c</span><span class="p">)</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
        <span class="c1"># out -   [batch_size, output_size]
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">r_out</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:])</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></td></tr></tbody></table></code></div></div>

<p>在网络初始化时，我们引入了定义的 4 个形参 <code class="language-plaintext highlighter-rouge">input_size, hidden_size, num_layers, output_size</code>，确定网络的结构中的输入维度，隐层神经元个数，隐层层数，输出维度。</p>

<p>然后，按照上面定义的结构定义一个 torch 官方提供的 <code class="language-plaintext highlighter-rouge">torch.nn.LSTM</code> 单元，并且设定其 <code class="language-plaintext highlighter-rouge">batch_first=True</code>，即将数据的批数放到输入输出向量的第一个维度。</p>

<p>最后，定义一个全连接层，将隐层信息映射到输出维度。</p>

<p>在定义网络前向传播时，首先给 LSTM 传入输入向量 <code class="language-plaintext highlighter-rouge">x</code> 和 初始隐层向量 <code class="language-plaintext highlighter-rouge">(h_n,h_c)</code>。此处 <code class="language-plaintext highlighter-rouge">x</code> 维度为 <code class="language-plaintext highlighter-rouge">[batch_size, sequence_size, input_size]</code>，初始隐层向量为 <code class="language-plaintext highlighter-rouge">None</code>，即表示初始时刻隐层向量均为 0 。</p>

<p>经过前向传播，LSTM 单元的输出为 <code class="language-plaintext highlighter-rouge">r_out, (h_n, h_c)</code>。其中</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">r_out</code> 也就是上面图中的 <strong>output</strong> 保存了<strong>最后一层，每个 time step 的输出</strong> <code class="language-plaintext highlighter-rouge">h</code>，如果是双向 LSTM，每个 time step 的输出 <code class="language-plaintext highlighter-rouge">h = [h正向, h逆向]</code> (同一个 time step 的正向和逆向的h连接起来)。
    <ul>
      <li>所以 <code class="language-plaintext highlighter-rouge">r_out</code> 无需层维度信息，而包含时间序列信息，其维度为 <code class="language-plaintext highlighter-rouge">[batch_size, sequence_size, output_size]</code>；</li>
      <li>如果 <code class="language-plaintext highlighter-rouge">num_layers=1</code>，lstm 只有一层，则 <code class="language-plaintext highlighter-rouge">r_out</code> 为<strong>每个 time step 的输出</strong>。</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">h_n</code> 保存了<strong>每一层，最后一个time step 的输出</strong> <code class="language-plaintext highlighter-rouge">h</code>，如果是双向LSTM，单独保存前向和后向的最后一个 time step 的输出 h。
    <ul>
      <li>所以 <code class="language-plaintext highlighter-rouge">h_n</code> 包含层维度信息，无需时间序列信息，其维度为 <code class="language-plaintext highlighter-rouge">[layer_size, batch_size, hidden_size]</code>；注意到 <code class="language-plaintext highlighter-rouge">batch_first=True</code> 不会影响到 <code class="language-plaintext highlighter-rouge">h_n</code>，因此第一个维度是层个数；</li>
      <li>如果 <code class="language-plaintext highlighter-rouge">num_layers=1</code>，lstm 只有一层，则 <code class="language-plaintext highlighter-rouge">h_n</code> 为<strong>最后一个 time step 的输出</strong>。</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">c_n</code> 与 <code class="language-plaintext highlighter-rouge">h_n</code> 一致，只是它保存的是 <code class="language-plaintext highlighter-rouge">c</code> 的值。</li>
</ul>

<p>继续经过全连接层，输入 <code class="language-plaintext highlighter-rouge">r_out</code> 输出 <code class="language-plaintext highlighter-rouge">out</code> ：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">r_out[:,-1,:]</code> 表示读取 <code class="language-plaintext highlighter-rouge">r_out</code> 第二维的倒数第一个元素对应的其余维度数据。由于 <code class="language-plaintext highlighter-rouge">r_out</code> 的第二维是 <code class="language-plaintext highlighter-rouge">sequence_size</code> 也就是 time step，倒数第一个元素对应的其余维度数据也就是最后一个时刻的数据 <code class="language-plaintext highlighter-rouge">[batch_size, hidden_size]</code>；</li>
  <li>当 <code class="language-plaintext highlighter-rouge">layer_size = 1</code> 时，<code class="language-plaintext highlighter-rouge">r_out[:,-1,:] = h_n[-1,:,:]</code>；</li>
  <li>经过全连接层，得到 batch 中每张图片的最终分类结果 <code class="language-plaintext highlighter-rouge">[batch_size, output_size]</code>。</li>
</ul>

<p>最后设计训练和测试环节。</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>

    <span class="n">root</span> <span class="o">=</span> <span class="sh">"</span><span class="s">./mnist/MNIST/raw/</span><span class="sh">"</span>

    <span class="n">train_mean</span> <span class="o">=</span> <span class="mf">0.1307</span>
    <span class="n">train_std</span> <span class="o">=</span> <span class="mf">0.3081</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">test_batch_size</span> <span class="o">=</span> <span class="mi">50</span>

    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">num_workers</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">pin_memory</span><span class="sh">'</span><span class="p">:</span> <span class="bp">True</span><span class="p">}</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">((</span><span class="n">train_mean</span><span class="p">,),</span> <span class="p">(</span><span class="n">train_std</span><span class="p">,))</span>
        <span class="p">])</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span>
        <span class="nc">DATA</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span>
        <span class="nc">DATA</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">test_batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="nc">MNIST_LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">layer_num</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
        <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">lossfcn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>

    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">accuracy_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">iteration_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">EPOCHS</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">EPOCH: {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="mf">999.0</span>
        <span class="k">for</span> <span class="n">batchidx</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
            <span class="c1"># 一个batch 转换为RNN的输入维度
</span>            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">sequence_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">()</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">.</span><span class="nf">long</span><span class="p">()</span> <span class="c1"># cross entropy requires a long scalar
</span>            <span class="c1"># 移入GPU
</span>            <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
                <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># 梯度清零
</span>            <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="c1"># 前向传播
</span>            <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="c1"># 计算损失
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="nf">lossfcn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="c1"># 反向传播
</span>            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="c1"># 更新参数
</span>            <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
            <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># 打印训练信息
</span>            <span class="k">if</span> <span class="n">batchidx</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">batch index: {}, images: {}/{}+[{}], loss: {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span>
                    <span class="n">batchidx</span><span class="p">,</span>
                    <span class="n">batchidx</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">train_loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">loss</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()))</span>

        <span class="c1"># 模型验证
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="c1"># 迭代测试集，获取数据，预测
</span>        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">sequence_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="c1"># 模型预测
</span>                <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
                <span class="c1"># 获取预测概率最大值的下标
</span>                <span class="n">_</span><span class="p">,</span> <span class="n">predict</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="c1"># 统计测试集的大小
</span>                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="c1"># 统计预测正确的数量
</span>                <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
                    <span class="n">predict</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">predict</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predict</span> <span class="o">==</span> <span class="n">labels</span><span class="p">).</span><span class="nf">sum</span><span class="p">()</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="c1"># 保存accuracy，loss，iteration
</span>            <span class="n">loss_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
            <span class="n">accuracy_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
            <span class="n">iteration_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nb">iter</span><span class="p">)</span>
            <span class="c1"># 打印信息
</span>            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">iter: {}, Loss: {}, Accu: {}%</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nb">iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">))</span>
            <span class="nf">print</span><span class="p">()</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="nf">main</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p>注意，上述代码并没有采用一般教程中的使用 Pytorch 代码直接下载并使用 MNIST 数据集，而是将数据集下载好后，提取出其中所有图片，保存在 raw 文件夹中，然后构造一个 <code class="language-plaintext highlighter-rouge">DataLoader</code> 类型的 <code class="language-plaintext highlighter-rouge">DATA</code> 来实现数据加载，这样可以便于我们之后将网络迁移至自己的数据集上训练。</p>

<p>为了便于比较，这里给出一段借助 <code class="language-plaintext highlighter-rouge">torchvision.datasets</code> 直接下载和加载 MNIST 数据集的代码</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre><span class="c1"># MNIST Dataset
</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="nc">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">./data/</span><span class="sh">'</span><span class="p">,</span>
                                           <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
                                           <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="nc">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">./data/</span><span class="sh">'</span><span class="p">,</span>
                                          <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                                          <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">())</span>

<span class="c1"># Data Loader (Input Pipeline)
</span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                           <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span>
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                          <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>最终也得到了用于训练和测试的 <code class="language-plaintext highlighter-rouge">train_loader, test_loader</code>。其中</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">root='./data/'</code> 表明将下载的数据集存放于代码同级路径下的 data 文件夹；</li>
  <li><code class="language-plaintext highlighter-rouge">train=true</code> 表明下载的数据集是用于训练的数据集；</li>
  <li><code class="language-plaintext highlighter-rouge">transform=transforms.ToTensor()</code> 表明对下载的数据集进行一个数据处理操作：
<code class="language-plaintext highlighter-rouge">ToTensor(object)</code> Convert a <code class="language-plaintext highlighter-rouge">numpy.ndarray</code> (H x W x C) in the range [0, 255] to a <code class="language-plaintext highlighter-rouge">torch.FloatTensor</code> of shape (C x H x W) in the range [0.0, 1.0].</li>
  <li><code class="language-plaintext highlighter-rouge">download=True</code> 表明如果检测到 <code class="language-plaintext highlighter-rouge">root</code> 下没有数据集时自动下载数据所有数据，包括训练数据和测试数据，因此在 <code class="language-plaintext highlighter-rouge">train=True</code> 时设置一次即可。</li>
</ul>

<p>PyTorch 官方给出的基于 CNN 的 MNIST 手写数字识别代码<a href="https://github.com/pytorch/examples/blob/master/mnist/main.py">在此</a>（https://github.com/pytorch/examples/blob/master/mnist/main.py ），以供参考。</p>

<p>注意到上述链接的代码中，除了 <code class="language-plaintext highlighter-rouge">ToTensor()</code> 之外还用到了另一个转换，<code class="language-plaintext highlighter-rouge">Normalize()</code> 如下：</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
                           <span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
                           <span class="n">transforms</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                       <span class="p">])</span>
</pre></td></tr></tbody></table></code></div></div>

<p>总结而言，<code class="language-plaintext highlighter-rouge">ToTensor()</code> 能够把灰度范围从 0-255 变换到 0-1 之间，而后面的 <code class="language-plaintext highlighter-rouge">transform.Normalize()</code> 则把 0-1 数据执行以下操作：</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">image</span><span class="o">=</span><span class="p">(</span><span class="n">image</span><span class="o">-</span><span class="n">mean</span><span class="p">)</span><span class="o">/</span><span class="n">std</span>
</pre></td></tr></tbody></table></code></div></div>

<p>如果取 <code class="language-plaintext highlighter-rouge">mean=0.5, std=0.5</code> 那么 <code class="language-plaintext highlighter-rouge">Normalize</code> 把 0-1 数据变换到 (-1,1)，号称可以加快模型收敛速度 [<a href="#ref2">2</a>]。当然此处MNIST应用时 <code class="language-plaintext highlighter-rouge">mean=0.1307, std=0.3081</code> 。</p>

<p>当 <code class="language-plaintext highlighter-rouge">seed=0</code> 时，即</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="n">use_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda:0</span><span class="sh">'</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>20 次迭代后的训练结果如下</p>

<div class="language-plaintext highlighter-rouge"><div class="code-header">
        <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre></td><td class="rouge-code"><pre>......
EPOCH: 20
batch index: 0, images: 0/60000+[64], loss: 0.14547616243362427
batch index: 50, images: 3200/60000+[64], loss: 0.04679613187909126
batch index: 100, images: 6400/60000+[64], loss: 0.05385994166135788
batch index: 150, images: 9600/60000+[64], loss: 0.044658079743385315
batch index: 200, images: 12800/60000+[64], loss: 0.08235453814268112
batch index: 250, images: 16000/60000+[64], loss: 0.12099026888608932
batch index: 300, images: 19200/60000+[64], loss: 0.04762731492519379
batch index: 350, images: 22400/60000+[64], loss: 0.07588448375463486
batch index: 400, images: 25600/60000+[64], loss: 0.03385855257511139
batch index: 450, images: 28800/60000+[64], loss: 0.056658919900655746
batch index: 500, images: 32000/60000+[64], loss: 0.10723046958446503
batch index: 550, images: 35200/60000+[64], loss: 0.029729364439845085
batch index: 600, images: 38400/60000+[64], loss: 0.21459335088729858
batch index: 650, images: 41600/60000+[64], loss: 0.023649774491786957
batch index: 700, images: 44800/60000+[64], loss: 0.2532099485397339
batch index: 750, images: 48000/60000+[64], loss: 0.044361311942338943
batch index: 800, images: 51200/60000+[64], loss: 0.08944762498140335
batch index: 850, images: 54400/60000+[64], loss: 0.22417518496513367
batch index: 900, images: 57600/60000+[64], loss: 0.1285378485918045
iter: 18760, Loss: 0.034618619829416275, Accu: 97.50999450683594%
</pre></td></tr></tbody></table></code></div></div>

<p>注意，如果不改变 <code class="language-plaintext highlighter-rouge">seed</code> 那么重复多次训练的结果不会变。随机数种子影响神经网络初始参数的随机初始化取值。</p>

<h1 id="3-常见错误">3. 常见错误</h1>

<h2 id="31-cudnn_status_bad_param"><span class="me-2">3.1. CUDNN_STATUS_BAD_PARAM</span><a href="#31-cudnn_status_bad_param" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>在 LSTM 的 <code class="language-plaintext highlighter-rouge">forward</code> 过程中，下述语句</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">r_out</span><span class="p">,</span> <span class="p">(</span><span class="n">h_n</span><span class="p">,</span> <span class="n">h_c</span><span class="p">)</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>提示 RuntimeError</p>

<div class="language-plaintext highlighter-rouge"><div class="code-header">
        <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>发生异常: RuntimeError
cuDNN error: CUDNN_STATUS_BAD_PARAM
  File "xxx.py", line xx, in forward
    r_out, (h_n, h_c) = self.lstm(x, None)
</pre></td></tr></tbody></table></code></div></div>

<p>参考<a href="https://blog.csdn.net/daixiangzi/article/details/107671246">此处</a>（https://blog.csdn.net/daixiangzi/article/details/107671246 ）</p>

<p>核心问题在于，LSTM 的 <code class="language-plaintext highlighter-rouge">forward</code> 要求输入数据的类型为 <code class="language-plaintext highlighter-rouge">float32</code>，而在实际代码中我们将其输入为了<code class="language-plaintext highlighter-rouge">float64</code>或者其它类型的数据。因此需要在输入模型训练之前进行数据转换即可解决问题</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span> <span class="o">=</span> <span class="n">trainX</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">trainY</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h1 id="4-参考文献">4. 参考文献</h1>

<p><span id="ref1">[1]</span> 谓之小一. <a href="https://zhuanlan.zhihu.com/p/136223550">LSTM如何解决RNN带来的梯度消失问题</a>.</p>

<p><span id="ref2">[2]</span> 小研一枚. <a href="https://blog.csdn.net/qq_35027690/article/details/103742697">pytorch的transform中ToTensor接着Normalize</a>.</p>

</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
  <div class="post-meta mb-3">
    <i class="far fa-folder-open fa-fw me-1"></i>
    
      <a href='/categories/academic/'>Academic</a>,
      <a href='/categories/knowledge/'>Knowledge</a>
  </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw me-1"></i>
      
      <a href="/tags/deep-learning/"
          class="post-tag no-text-decoration" >deep learning</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        本文由作者按照 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         进行授权

      
    </div>

    <!-- Post sharing snippet -->

<div class="share-wrapper">
  <span class="share-label text-muted me-1">分享</span>
  <span class="share-icons">
    
    
    

    
      
      <a
        href="https://twitter.com/intent/tweet?text=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%EF%BC%88LSTM%EF%BC%89%20-%20SIRLIS&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fdeep-learning-LSTM%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Twitter"
        target="_blank"
        rel="noopener"
        aria-label="Twitter"
      >
        <i class="fa-fw fab fa-twitter"></i>
      </a>
    
      
      <a
        href="https://www.facebook.com/sharer/sharer.php?title=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%EF%BC%88LSTM%EF%BC%89%20-%20SIRLIS&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fdeep-learning-LSTM%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Facebook"
        target="_blank"
        rel="noopener"
        aria-label="Facebook"
      >
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    
      
      <a
        href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fdeep-learning-LSTM%2F&text=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%EF%BC%88LSTM%EF%BC%89%20-%20SIRLIS"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Telegram"
        target="_blank"
        rel="noopener"
        aria-label="Telegram"
      >
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <i
      id="copy-link"
      class="fa-fw fas fa-link small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="分享链接"
      data-title-succeed="链接已复制！"
    >
    </i>
  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
      
    </div>
  </div>
  <!-- #core-wrapper -->

  <!-- panel -->
  <div id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
    <div class="access">
      <!-- Get the last 5 posts from lastmod list. -->














  <div id="access-lastmod" class="post">
    <div class="panel-heading">最近更新</div>
    <ul class="post-content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Pattern-Recognition-Nonlinear-Classifier/">模式识别（非线性分类器）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Pattern-Recognition-Bayes/">模式识别（贝叶斯决策）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-Temporal-Differences/">强化学习（时序差分法）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-markov-process/">强化学习（马尔可夫决策过程）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-Monte-Carlo/">强化学习（蒙特卡洛法）</a>
        </li>
      
    </ul>
  </div>
  <!-- #access-lastmod -->


      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">热门标签</div>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/fuzzy/">fuzzy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/vscode/">vscode</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/other/">other</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/astronomy/">astronomy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c-c/">c/c++</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/computer-vision/">computer vision</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/meta-learning/">meta learning</a>
      
    </div>
  </div>


    </div>

    
      
      



  <div id="toc-wrapper" class="ps-0 pe-4 mb-5">
    <div class="panel-heading ps-3 pt-2 mb-2">文章内容</div>
    <nav id="toc"></nav>
  </div>


    
  </div>
</div>

<!-- tail -->

  <div class="row">
    <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-3 pe-xl-4 mt-5">
      
        
        <!--
  Recommend the other 3 posts according to the tags and categories of the current post,
  if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->








  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  






<!-- Fill with the other newlest posts -->





  <div id="related-posts" class="mb-2 mb-sm-4">
    <h3 class="pt-2 mb-4 ms-1" data-toc-skip>
      相关文章
    </h3>
    <div class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        
        
        <div class="col">
          <a href="/posts/deep-learning-basic-hp-and-opt/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1592036659"
  data-df="YYYY/MM/DD"
  
>
  2020/06/13
</em>

              <h4 class="pt-0 my-2" data-toc-skip>深度学习基础（基本超参数和优化器）</h4>
              <div class="text-muted small">
                <p>
                  





                  本文介绍了深度学习中的基本概念，包括 batch、epoch、iteration、optimizer等，其中优化器包括 BGD、SGD、Adam等，为后深度学习提供基础。






  1. 基本超参数
    
      1.1. epoch
      1.2. batch \&amp;amp; batch_size
      1.3. iteration
    
  
  2. 优化器...
                </p>
              </div>
            </div>
          </a>
        </div>
      
        
        
        <div class="col">
          <a href="/posts/deep-learning-basic-conv2d/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1592123059"
  data-df="YYYY/MM/DD"
  
>
  2020/06/14
</em>

              <h4 class="pt-0 my-2" data-toc-skip>深度学习基础（PyTorch的CNN组成）</h4>
              <div class="text-muted small">
                <p>
                  





                  本文介绍了深度学习中，卷积网络的基本知识，包括2d卷积层、池化层、线性层、softmax 激活函数、交叉熵损失函数等，并结合它们在 Pytorch 中的定义和实现进行说明。






  1. 层
    
      1.1. Conv2d
        
          1.1.1. dilation
          1.1.2. padding
        
     ...
                </p>
              </div>
            </div>
          </a>
        </div>
      
        
        
        <div class="col">
          <a href="/posts/deep-learning-basic-dataloader/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1592295859"
  data-df="YYYY/MM/DD"
  
>
  2020/06/16
</em>

              <h4 class="pt-0 my-2" data-toc-skip>深度学习基础（PyTorch的数据集）</h4>
              <div class="text-muted small">
                <p>
                  





                  本文介绍了 Pytorch 中针对计算机视觉方面的基本数据库类Dataset，基本的手写数字数据库MNIST，以及数据库加载函数 DataLoader。






  1. torchvision
  2. Dataset
    
      2.1. 默认类
      2.2. 自定义类
    
  
  3. DataLoader
  4. MNIST
  5. 参考文献


1...
                </p>
              </div>
            </div>
          </a>
        </div>
      
    </div>
    <!-- .card-deck -->
  </div>
  <!-- #related-posts -->


      
        
        <!-- Navigation buttons at the bottom of the post. -->

<div class="post-navigation d-flex justify-content-between">
  
    <a
      href="/posts/deep-learning-RNN/"
      class="btn btn-outline-primary"
      prompt="上一篇"
    >
      <p>深度学习基础（RNN）</p>
    </a>
  

  
    <a
      href="/posts/astronomy-basic-JPL-ephemeris/"
      class="btn btn-outline-primary"
      prompt="下一篇"
    >
      <p>天文学基础（JPL星历）</p>
    </a>
  
</div>

      
        
        <!--  The comments switcher -->

  
  <!-- https://utteranc.es/ -->
<script src="https://utteranc.es/client.js"
        repo="sirlis/sirlis.github.io"
        issue-term="pathname"
        crossorigin="anonymous"
        async>
</script>

<script type="text/javascript">
  $(function() {
    const origin = "https://utteranc.es";
    const iframe = "iframe.utterances-frame";
    const lightTheme = "github-light";
    const darkTheme = "github-dark";
    let initTheme = lightTheme;

    if ($("html[data-mode=dark]").length > 0
        || ($("html[data-mode]").length == 0
            && window.matchMedia("(prefers-color-scheme: dark)").matches)) {
      initTheme = darkTheme;
    }

    addEventListener("message", (event) => {
      let theme;

      /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */
      if (event.origin === origin) {
        /* page initial */
        theme = initTheme;

      } else if (event.source === window && event.data &&
            event.data.direction === ModeToggle.ID) {
        /* global theme mode changed */
        const mode = event.data.message;
        theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme);

      } else {
        return;
      }

      const message = {
        type: "set-theme",
        theme: theme
      };

      const utterances = document.querySelector(iframe).contentWindow;
      utterances.postMessage(message, origin);
    });

  });
</script>



      
    </div>
  </div>


        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-11 post-content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">热门标签</div>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/fuzzy/">fuzzy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/vscode/">vscode</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/other/">other</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/astronomy/">astronomy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c-c/">c/c++</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/computer-vision/">computer vision</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/meta-learning/">meta learning</a>
      
    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>
    </div>

    <!-- The Footer -->

<footer>
  <div class="container px-lg-4">
    <div class="d-flex justify-content-center align-items-center text-muted mx-md-3">
      <p>本站采用 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 主题 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>
      </p>

      <p>©
        2025
        <a href="https://github.com/sirlis">sirlis</a>.
        
          <span
            data-bs-toggle="tooltip"
            data-bs-placement="top"
            title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。"
          >保留部分权利。</span>
        
      </p>
    </div>
  </div>
</footer>


    <div id="mask"></div>

    <button id="back-to-top" aria-label="back-to-top" class="btn btn-lg btn-box-shadow">
      <i class="fas fa-angle-up"></i>
    </button>

    
      <div
        id="notification"
        class="toast"
        role="alert"
        aria-live="assertive"
        aria-atomic="true"
        data-bs-animation="true"
        data-bs-autohide="false"
      >
        <div class="toast-header">
          <button
            type="button"
            class="btn-close ms-auto"
            data-bs-dismiss="toast"
            aria-label="Close"
          ></button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="px-2 mb-3">发现新版本的内容。</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            更新
          </button>
        </div>
      </div>
    

    <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.0/dist/jquery.min.js,npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.7/dayjs.min.js,npm/dayjs@1.11.7/locale/zh.min.js,npm/dayjs@1.11.7/plugin/relativeTime.min.js,npm/dayjs@1.11.7/plugin/localizedFormat.min.js,npm/tocbot@4.21.0/dist/tocbot.min.js"></script>






<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
    /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
    MathJax = {
      tex: {
        /* start/end delimiter pairs for in-line math */
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ],
        /* start/end delimiter pairs for display math */
        displayMath: [
          ['$$', '$$'],
          ['\\[', '\\]']
        ]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>





    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  /* Note: dependent library will be loaded in `js-selector.html` */
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('search-results'),
    json: '/assets/js/data/search.json',
    searchResultTemplate: '<div class="px-1 px-sm-2 px-lg-4 px-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
    noResultsText: '<p class="mt-5"></p>',
    templateMiddleware: function(prop, value, template) {
      if (prop === 'categories') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
        }
      }

      if (prop === 'tags') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
        }
      }
    }
  });
</script>

  </body>
</html>

