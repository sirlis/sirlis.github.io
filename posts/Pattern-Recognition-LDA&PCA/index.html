<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="zh-CN" 
  
>
  <!-- The Head -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="模式识别（LDA和PCA）" />
<meta property="og:locale" content="zh_CN" />
<meta name="description" content="本文介绍了模式识别种常用的两种特征选择与特征降维方法，即线性判别分析（Linear Discriminant Analysis，LDA）和主成分分析（Principal Component Analysis，PCA）。" />
<meta property="og:description" content="本文介绍了模式识别种常用的两种特征选择与特征降维方法，即线性判别分析（Linear Discriminant Analysis，LDA）和主成分分析（Principal Component Analysis，PCA）。" />
<link rel="canonical" href="http://localhost:4000/posts/Pattern-Recognition-LDA&PCA/" />
<meta property="og:url" content="http://localhost:4000/posts/Pattern-Recognition-LDA&PCA/" />
<meta property="og:site_name" content="SIRLIS" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-05-02T10:03:19+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="模式识别（LDA和PCA）" />
<meta name="twitter:site" content="@none" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-02-27T16:09:44+08:00","datePublished":"2024-05-02T10:03:19+08:00","description":"本文介绍了模式识别种常用的两种特征选择与特征降维方法，即线性判别分析（Linear Discriminant Analysis，LDA）和主成分分析（Principal Component Analysis，PCA）。","headline":"模式识别（LDA和PCA）","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/Pattern-Recognition-LDA&PCA/"},"url":"http://localhost:4000/posts/Pattern-Recognition-LDA&PCA/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>模式识别（LDA和PCA） | SIRLIS
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="SIRLIS">
<meta name="application-name" content="SIRLIS">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.21.0/dist/tocbot.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  
    <!-- Switch the mode between dark and light. -->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() {
      return 'mode';
    }
    static get MODE_ATTR() {
      return 'data-mode';
    }
    static get DARK_MODE() {
      return 'dark';
    }
    static get LIGHT_MODE() {
      return 'light';
    }
    static get ID() {
      return 'mode-toggle';
    }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener('change', () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();
      });
    } /* constructor() */

    get sysDarkPrefers() {
      return window.matchMedia('(prefers-color-scheme: dark)');
    }

    get isSysDarkPrefer() {
      return this.sysDarkPrefers.matches;
    }

    get isDarkMode() {
      return this.mode === ModeToggle.DARK_MODE;
    }

    get isLightMode() {
      return this.mode === ModeToggle.LIGHT_MODE;
    }

    get hasMode() {
      return this.mode != null;
    }

    get mode() {
      return sessionStorage.getItem(ModeToggle.MODE_KEY);
    }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      document.documentElement.removeAttribute(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage(
        {
          direction: ModeToggle.ID,
          message: this.modeStatus
        },
        '*'
      );
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.notify();
    } /* flipMode() */
  } /* ModeToggle */

  const modeToggle = new ModeToggle();
</script>

  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle">
      
        
        <img src="/assets/img/head.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'">
      
    </a>

    <div class="site-title">
      <a href="/">SIRLIS</a>
    </div>
    <div class="site-subtitle fst-italic">分享科研和生活的日常</div>
  </div>
  <!-- .profile-wrapper -->

  <ul class="nav flex-column flex-grow-1 w-100 ps-0">
    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home"></i>
        <span>首页</span>
      </a>
    </li>
    <!-- the real tabs -->
    
      <li class="nav-item">
        <a href="/categories/" class="nav-link">
          <i class="fa-fw fas fa-stream"></i>
          

          <span>分类</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/tags/" class="nav-link">
          <i class="fa-fw fas fa-tags"></i>
          

          <span>标签</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/archives/" class="nav-link">
          <i class="fa-fw fas fa-archive"></i>
          

          <span>归档</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/about/" class="nav-link">
          <i class="fa-fw fas fa-info-circle"></i>
          

          <span>关于</span>
        </a>
      </li>
      <!-- .nav-item -->
    
  </ul>
  <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://github.com/sirlis"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="https://twitter.com/none"
          aria-label="twitter"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-twitter"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['lihongjue','buaa.edu.cn'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          

          

          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</div>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container px-xxl-5">
        <!-- The Top Bar -->

<div id="topbar-wrapper">
  <div
    id="topbar"
    class="container d-flex align-items-center justify-content-between h-100"
  >
    <span id="breadcrumb">
      

      
        
          
            <span>
              <a href="/">
                首页
              </a>
            </span>

          
        
          
        
          
            
              <span>模式识别（LDA和PCA）</span>
            

          
        
      
    </span>
    <!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      文章
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="搜索..."
      >
    </span>
    <span id="search-cancel">取消</span>
  </div>
</div>

        











<div class="row">
  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pe-xl-4">
    

    <div class="post px-1 px-md-2">
      

      
        
      
        <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->



  
  

  <!-- CDN URL -->
  

  <!-- Add image path -->
  

  
    
      
      
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  

  



<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  




<!-- return -->




<h1 data-toc-skip>模式识别（LDA和PCA）</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      发表于
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class=""
  data-ts="1714615399"
  data-df="YYYY/MM/DD"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  2024/05/02
</em>

    </span>

    <!-- lastmod date -->
    
    <span>
      更新于
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class=""
  data-ts="1740643784"
  data-df="YYYY/MM/DD"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  2025/02/27
</em>

    </span>
    

  

  <div class="d-flex justify-content-between">
    <!-- author(s) -->
    <span>
      

      作者

      <em>
      
        <a href="https://github.com/sirlis">sirlis</a>
      
      </em>
    </span>

    <div>
      <!-- read time -->
      <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="3814 字"
>
  <em>21 分钟</em>阅读</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <p>本文介绍了模式识别种常用的两种特征选择与特征降维方法，即线性判别分析（Linear Discriminant Analysis，LDA）和主成分分析（Principal Component Analysis，PCA）。</p>

<!--more-->

<hr />

<ul>
  <li><a href="#1-特征降维">1. 特征降维</a></li>
  <li><a href="#2-线性判别分析lda">2. 线性判别分析（LDA）</a>
    <ul>
      <li><a href="#21-fisher-投影准则">2.1. Fisher 投影准则</a></li>
      <li><a href="#22-瑞利商与广义瑞利商">2.2. 瑞利商与广义瑞利商</a></li>
      <li><a href="#23-二分类-lda">2.3. 二分类 LDA</a></li>
      <li><a href="#24-多分类-lda">2.4. 多分类 LDA</a></li>
      <li><a href="#25-lda-的特点">2.5. LDA 的特点</a></li>
    </ul>
  </li>
  <li><a href="#3-主成分分析pca">3. 主成分分析（PCA）</a>
    <ul>
      <li><a href="#31-数学推导">3.1. 数学推导</a>
        <ul>
          <li><a href="#311-最近重构性k-l变换">3.1.1. 最近重构性（K-L变换）</a></li>
          <li><a href="#312-最大可分性">3.1.2. 最大可分性</a></li>
        </ul>
      </li>
      <li><a href="#32-算法流程">3.2. 算法流程</a></li>
      <li><a href="#33-pca-的特点">3.3. PCA 的特点</a></li>
    </ul>
  </li>
  <li><a href="#4-参考文献">4. 参考文献</a></li>
</ul>

<h2 id="1-特征降维"><span class="me-2">1. 特征降维</span><a href="#1-特征降维" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>机器学习的很多算法复杂度和数据的维数有着密切关系，甚至与维数呈指数级关联。当数据的特征维度达到成千上万甚至几十万的规模时，机器学习的资源消耗是不可接受的，且有很多特征可能与要解决的分类问题关系不大，因此就会对数据采取降维的操作。</p>

<p>降维就意味着信息的丢失，因为原本每个特征理论上都可以反映出原始数据的某些特质。但鉴于实际数据的特征之间本身常常存在相关性，所以在降维时可以采取一些办法降低信息的损失。</p>

<p>特征降维有两种方法：</p>
<ul>
  <li><strong>特征选择</strong>：从已有特征向量中选择出若干维度的特征组成新的特征向量，新特征向量的维度一般远小于原始特征向量；</li>
  <li><strong>特征提取</strong>：将原始特征向量经过某种数学变换得到新的特征向量，新特征向量的维度一般远小于原始特征向量；</li>
</ul>

<h2 id="2-线性判别分析lda"><span class="me-2">2. 线性判别分析（LDA）</span><a href="#2-线性判别分析lda" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>线性判别分析（Linear Discriminant Analysis，LDA）是一种监督学习的降维技术，主要用于数据预处理中的降维、分类任务。LDA的目标是最大化类间区分度的坐标轴成分，将特征空间投影到一个维度更小的 $k$ 维子空间中，同时保持区分类别的信息。简而言之，LDA投影后的数据类内方差最小，类间方差最大。</p>

<h3 id="21-fisher-投影准则"><span class="me-2">2.1. Fisher 投影准则</span><a href="#21-fisher-投影准则" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>参考前述线性分类器中的 <a href="../Pattern-Recognition-Linear-Classifier/#4-fisher-投影准则">Fisher投影准则</a>) 介绍。</p>

<h3 id="22-瑞利商与广义瑞利商"><span class="me-2">2.2. 瑞利商与广义瑞利商</span><a href="#22-瑞利商与广义瑞利商" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>定义<strong>瑞利商</strong>为</p>

\[R(A,x)=\frac{x^HAx}{x^Hx}\]

<p>其中 $x$ 是非零向量，$A\in R^{n\times n}$ 是 Hermitan 矩阵（自共轭矩阵，矩阵中每一个第$i$行第$j$列元素都与第$j$行第$i$列元素共轭相等）。</p>

<p>性质：瑞利商的最大值等于矩阵 $A$ 最大的特征值，最小值等于矩阵 $A$ 的最小特征值。即</p>

\[\lambda_{min} &lt; R(A,x) &lt; \lambda_{max}\]

<p>定义<strong>广义瑞利商</strong>为</p>

\[R(A,x)=\frac{x^HAx}{x^HBx}\]

<p>其中 $B$ 为正定矩阵，其他定义同瑞利商。</p>

<p>性质：广义瑞利商的最大值为矩阵 $B^{-\frac{1}{2}}AB^{-\frac{1}{2}}$ 或者说 是矩阵 $B^{-1}A$的最大特征值，最小值是其最小特征值。</p>

<h3 id="23-二分类-lda"><span class="me-2">2.3. 二分类 LDA</span><a href="#23-二分类-lda" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>参考前述线性分类器中的 Fisher 投影准则介绍，类间离散度矩阵为</p>

\[\boldsymbol{S}_b = (\boldsymbol{\mu}_1-\boldsymbol{\mu}_2)(\boldsymbol{\mu}_1-\boldsymbol{\mu}_2)^T\]

<p>为两向量的外积，其秩为1。</p>

<blockquote>
  <ul>
    <li>一个向量可以看做一个$n\times 1$ 矩阵或者 $1\times n$ 的矩阵，而一个矩阵 $A$ 的秩 $R(A)\leq \min(n,m)$，其中 $n$ 和 $m$ 是这个矩阵的行数和列数，所以单个向量的秩是1；</li>
    <li>两向量外积也就是一个 $n\times 1$ 矩阵和一个 $1\times n$ 矩阵的积，又两矩阵的积的秩小于等于两者中秩最小的矩阵的秩，也就是 $R(AB)\leq \min(R(A),R(B))$，这里 $R(A)=R(B)=1$,所以 $R(AB)\leq 1$，即两向量外积的秩至多是1。</li>
  </ul>
</blockquote>

<p>类内离散度矩阵为</p>

\[\boldsymbol{S}_w = \sum_{i=1}^2 \boldsymbol{S}_{wi}=\sum_{i=1}^2 \sum_{x\in w_i}(x-\mu_i)(x-\mu_i)^T\]

<p>二分类LDA的优化目标函数可以写成</p>

\[\arg\max_{\boldsymbol{w}} J(\boldsymbol{w}) = \frac{\boldsymbol{w}^T\boldsymbol{S}_b\boldsymbol{w}}{\boldsymbol{w}^T\boldsymbol{S}_w\boldsymbol{w}}\]

<p>目标是求使得 $J(\boldsymbol{w})$ 最大的投影方向 $\boldsymbol{w}$。</p>

<p>根据前述 Fisher 投影准则的推导，上述优化问题最终可转化为求矩阵 $\boldsymbol{S}_w^{-1}\boldsymbol{S}_b$ 的特征值 $\lambda$ 和特征向量 $\boldsymbol{w}^{\star}$。</p>

<p>这里给出另外一种推导思路，上述目标函数正好是广义瑞利商的形式，因此其最大值为 $\boldsymbol{S}_w^{-1}\boldsymbol{S}_b$ 的最大特征值，那么投影方向 $\boldsymbol{w}$ 即为 $\boldsymbol{S}_w^{-1}\boldsymbol{S}_b$ 对应特征值 $\lambda$ 的特征向量。</p>

<p>若 $\boldsymbol{S}_w$ 不可逆，可进行如下操作进行松弛</p>

\[\boldsymbol{S}_w = \boldsymbol{S}_w + \beta \boldsymbol{I}\]

<p>其中 $\beta$ 是一个很小的数。</p>

<p>实际使用时为得到数值解的稳定性，通常对 $\boldsymbol{S}_w$ 进行奇异值分解得到 $\boldsymbol{S}_w^{-1}$</p>

\[\boldsymbol{S}_w=\boldsymbol{U}\Sigma \boldsymbol{V}^T \Rightarrow \boldsymbol{S}_w^{-1} = \boldsymbol{V}\Sigma \boldsymbol{U}^T\]

<h3 id="24-多分类-lda"><span class="me-2">2.4. 多分类 LDA</span><a href="#24-多分类-lda" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>假设为 $C$ 分类，类内离散度矩阵定义保持不变，有</p>

\[\boldsymbol{S}_w = \sum_{i=1}^C \boldsymbol{S}_{wi}=\sum_{i=1}^C \sum_{x\in w_i}(x-\mu_i)(x-\mu_i)^T\]

<p>对于类间离散度矩阵，无法像之前二分类那样定义（即 $\boldsymbol{S}_b=(\boldsymbol{\mu}_1-\boldsymbol{\mu}_2)(\boldsymbol{\mu}_1-\boldsymbol{\mu}_2)^T$），即原来度量的是两个均值点的散列情况，现在度量的是每类均值点相对于样本中心的散列情况。类似于将 $\boldsymbol{\mu}_i$ 看作样本点，$\boldsymbol{\mu}$ 是均值的协方差矩阵。如果某类里面的样本点较多，那么其权重稍大，权重用 $N_i/N$ 表示，但由于 $J(\boldsymbol{w})$对倍数不敏感，因此使用 $N_i$ 即可</p>

\[\boldsymbol{S}_b= \sum_{i=1}^C N_i(\boldsymbol{\mu}_i-\boldsymbol{\mu})(\boldsymbol{\mu}_i-\boldsymbol{\mu})^T\]

<p>注意到，$\boldsymbol{S}_b$ 仍然是 $C$ 个秩为 1 的向量外积得到的矩阵求和，因此 $\boldsymbol{S}_b$ 的秩不会超过 $C$。</p>

<blockquote>
  <p>矩阵的秩小于等于各个相加矩阵的秩的和，即 $R(A+B)\leq R(A)+R(B)$</p>
</blockquote>

<p>又因为，各个类别的均值与总样本均值之间线性相关，即</p>

\[\boldsymbol{\mu} = \frac{1}{N} \sum_{\forall \boldsymbol{x}}\boldsymbol{x} = \frac{1}{N}\sum_{\boldsymbol{x}\in w_i} N_i\boldsymbol{\mu}_i\]

<p>知道了前 $C-1$ 个 $(\boldsymbol{\mu}_i-\boldsymbol{\mu})$ 后，最后一个 $(\boldsymbol{\mu}_C-\boldsymbol{\mu})$ 可以有前面的 $\boldsymbol{\mu}_i$ 来线性表示，因此$\boldsymbol{S}_b$ 的秩为 $C-1$。</p>

<p>所以在计算特征向量矩阵（类内散度矩阵 $\boldsymbol{S}_w$ 的逆 $\times$ 类间散度矩阵 $\boldsymbol{S}_b$）时，可以发现只有 $C-1$ 个特征值不为零的特征向量。因此，<strong>LDA 最多将特征维度降低到 $C-1$ 维</strong>。</p>

<h3 id="25-lda-的特点"><span class="me-2">2.5. LDA 的特点</span><a href="#25-lda-的特点" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>LDA 是一个有监督的方法，具有如下特点：</p>

<ul>
  <li>根据原始数据样本的均值进行分类</li>
  <li>不同类数据拥有相近的协方差矩阵</li>
</ul>

<p>当然，在实际情况中，不可能满足以上两个假设。但是当数据主要是由均值来区分的时候，LDA一般都可以取得很好的效果。见下面两个对比图。</p>

<p><a href="/assets/img/postsimg/20240502/LDAvsPCA_1.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20240502/LDAvsPCA_1.jpg" alt="" class="lazyload" data-proofer-ignore></a></p>

<p>上图中，两类数据的均值差异较大，但协方差矩阵十分接近，因此 LDA 分类效果好于 PCA。</p>

<p><a href="/assets/img/postsimg/20240502/LDAvsPCA_2.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20240502/LDAvsPCA_2.jpg" alt="" class="lazyload" data-proofer-ignore></a></p>

<p>上图中，两类数据的均值差异很小，但协方差矩阵相差十分明显，因此 LDA 分类效果差于 PCA。</p>

<p>LDA 的优点:</p>

<ul>
  <li>计算速度快</li>
  <li>充分利用了先验知识</li>
</ul>

<p>LDA 的缺点:</p>

<ul>
  <li>不适合对非高斯分布的样本降维</li>
  <li>降维之后的维数最多为类别数-1，所以当数据维度很高，但是类别数少的时候，算法并不适用</li>
  <li>可能会过度拟合数据</li>
</ul>

<h2 id="3-主成分分析pca"><span class="me-2">3. 主成分分析（PCA）</span><a href="#3-主成分分析pca" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>主成分分析（Principal Component Analysis，PCA）是常用的特征提取数据分析方法。PCA是通过<strong>线性变换</strong>，将原始数据变换为一组各维度线性无关的数据表示方法，可用于提取数据的主要特征分量，常用于高维数据的降维。</p>

<p>为了最大限度保留对原始数据的解释，一般会用最大方差理论或最小损失理论，使得第一主成分有着最大的方差或变异数 (就是说其能尽量多的解释原始数据的差异)；随后的每一个主成分都与前面的主成分正交，且有着仅次于前一主成分的最大方差 (正交简单的理解就是两个主成分空间夹角为90°，两者之间无线性关联，从而完成去冗余操作)。</p>

<p>PCA 降维的原理在于，大部分方差集中在前 $k$ 个坐标轴，后续坐标轴方差接近 0，因此可忽略后者，仅保留前 $k$ 个坐标轴。这相当于保留主要特征维度，忽略方差接近 0 的特征，实现数据降维。</p>

<h3 id="31-数学推导"><span class="me-2">3.1. 数学推导</span><a href="#31-数学推导" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>PCA 的推导思路在于，对于正交属性空间中的样本点，如何用一个超平面对所有样本进行恰当的表达？核心在于以下两点：</p>

<ul>
  <li>最近重构性：样本点到这个超平面的距离都足够近，也即投影<strong>前后</strong>所有样本点的总距离最小。</li>
  <li>最大可分性：样本点在这个超平面上的投影尽可能分开，也即投影<strong>后</strong>的样本点方差最大。</li>
</ul>

<p>基于最近重构性和最大可分性，能分别得到PCA的两种<strong>等价推导</strong>，下面分别展开说明。</p>

<h4 id="311-最近重构性k-l变换"><span class="me-2">3.1.1. 最近重构性（K-L变换）</span><a href="#311-最近重构性k-l变换" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>首先对 $n$ 个 $m$ 维样本进行中心化，即将所有样本变换为均值为 0，也即</p>

\[\sum_{i=1}^n \boldsymbol{x}_i=0\]

<p>假设将样本投影到一组完备归一化正交向量系 $\boldsymbol{w}=[w_1, w_2, \cdots]$，那么对于第 $i$ 个样本有</p>

\[\boldsymbol{x}_i = \sum_{j=1}^{+\infty} z_j \boldsymbol{w}_j,\quad z_j \in \mathbb{R}\]

<p>其中 $z_j$ 为投影后样本的第 $j$ 个维度分量，有</p>

\[z_j = \boldsymbol{w}_j^T \boldsymbol{x}_i\]

<p>则投影后的第 $i$ 个样本为</p>

\[\boldsymbol{z}_i=\boldsymbol{W}^T\boldsymbol{x}_i\]

<p>且有</p>

\[\boldsymbol{w}^T_i\boldsymbol{w}_j=\begin{cases}
1,i=j \\
0,i\neq j &amp; 
\end{cases}\]

<p>我们采用 PCA 的目的是对样本（也即特征）进行降维，则我们希望用有限的 $d$ 项（$d&lt;m$）来逼近（恢复出）原始样本，则对于第 $i$ 个样本有</p>

\[\hat{\boldsymbol{x}}_i = \sum_{j=1}^{d} z_j \boldsymbol{w}_j = \boldsymbol{W}\boldsymbol{z}_i\]

<p>对所有 $n$ 个样本均进行投影后，带来的均方误差为</p>

\[\begin{aligned}
  \sum_{i=1}^n \Vert \hat{\boldsymbol{x}}_i - \boldsymbol{x}_i \Vert^2 &amp;= \sum_{i=1}^n \Vert \boldsymbol{W}\boldsymbol{z}_i- \boldsymbol{x}_i \Vert^2\\
  &amp;=\sum_{i=1}^n(\boldsymbol{W}\boldsymbol{z}_i)^T(\boldsymbol{W}\boldsymbol{z}_i) - 2\sum_{i=1}^n(\boldsymbol{W}\boldsymbol{z}_i)^T\boldsymbol{x}_i + \sum_{i=1}^n\boldsymbol{x}_i^T\boldsymbol{x}_i\\
  &amp;=\sum_{i=1}^n\boldsymbol{z}_i^T\boldsymbol{W}^T\boldsymbol{W}\boldsymbol{z}_i - 2\sum_{i=1}^n\boldsymbol{z}_i^T\boldsymbol{W}^T\boldsymbol{x}_i + \sum_{i=1}^n\boldsymbol{x}_i^T\boldsymbol{x}_i\\
  &amp;=-\sum_{i=1}^n\boldsymbol{z}_i^T\boldsymbol{z}_i + \sum_{i=1}^n\boldsymbol{x}_i^T\boldsymbol{x}_i\\
  &amp;= -\sum_{i=1}^n \text{tr}(\boldsymbol{z}_i\boldsymbol{z}_i^T) + \sum_{i=1}^n\boldsymbol{x}_i^T\boldsymbol{x}_i\\
  &amp;= -\text{tr}\left(\boldsymbol{W}^T\left(\sum_{i=1}^n\boldsymbol{x}_i\boldsymbol{x}_i^T\right)\boldsymbol{W}\right) + \sum_{i=1}^n\boldsymbol{x}_i^T\boldsymbol{x}_i\\
  &amp;= -\text{tr}(\boldsymbol{W}^T\boldsymbol{X}\boldsymbol{X}^T\boldsymbol{W}) + \sum_{i=1}^n\boldsymbol{x}_i^T\boldsymbol{x}_i
\end{aligned}\]

<blockquote>
  <p>矩阵二次型可以用迹表示为 $\boldsymbol{x}^T\boldsymbol{A}\boldsymbol{x}=\text{tr}(\boldsymbol{A}\boldsymbol{x}\boldsymbol{x}^T)$</p>
</blockquote>

<p>注意到，$\boldsymbol{X}\boldsymbol{X}^T$ 是样本的协方差矩阵，$\boldsymbol{W}$ 的每个列向量是标准正交基，最后一个求和式是常量。因此最小化均方误差等价于</p>

\[\begin{aligned}
\arg\min_{\boldsymbol{W}} &amp;\quad -\text{tr}(\boldsymbol{W}^T\boldsymbol{X}\boldsymbol{X}^T\boldsymbol{W}) \\
s.t. &amp;\quad \boldsymbol{W}^T\boldsymbol{W}=\boldsymbol{I}
\end{aligned}\]

<p>采用拉格朗日乘子法</p>

\[J(\boldsymbol{W}) = -\text{tr}(\boldsymbol{W}^T\boldsymbol{X}\boldsymbol{X}^T\boldsymbol{W})+\lambda(\boldsymbol{W}^T\boldsymbol{W}-\boldsymbol{I})\]

<p>对上式求导，令导数等于零，整理有</p>

\[\boldsymbol{X}\boldsymbol{X}^T\boldsymbol{W} = \lambda \boldsymbol{W}\]

<p>则 $\boldsymbol{W}$ 的取值应为协方差矩阵 $\boldsymbol{X}\boldsymbol{X}^T$ 最大的 $d$ 个特征值对应的特征向量组成。根据 $\boldsymbol{z}_i=\boldsymbol{W}^T\boldsymbol{x}_i$ 即可将特征降维。</p>

<p>在信号处理领域，上述过程被称为 <strong>K-L变换</strong>，用于离散信号的去相关的线性变换。从数学上看，KL变换和PCA的核心步骤是相同的：都是对协方差矩阵进行特征值分解，然后选择最大的特征值对应的特征向量作为投影方向。KL变换更偏向于信号处理领域，强调信号的能量集中特性，适用于随机信号的降维和压缩。PCA更偏向于统计学和机器学习领域，强调数据的方差解释能力，适用于数据的降维和可视化。两者在数学上是等价的，但在应用背景和解释方式上有所不同。</p>

<h4 id="312-最大可分性"><span class="me-2">3.1.2. 最大可分性</span><a href="#312-最大可分性" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p>要让投影后所有样本点能尽可能分开，则投影后样本点方差最大。已知样本点的投影为 $\boldsymbol{z}_i=\boldsymbol{W}^T\boldsymbol{x}_i$ ，则投影后样本点的方差为</p>

\[\begin{aligned}
\sum_{i}(\boldsymbol{W}^{\mathrm{T}}\boldsymbol{x}_{i}-0)^{2} &amp;= \sum_{i}\text{tr}(\boldsymbol{W}^{\mathrm{T}}\boldsymbol{x}_{i}(\boldsymbol{W}^{\mathrm{T}}\boldsymbol{x}_{i})^{\mathrm{T}})\\
&amp;=\sum_{i}\mathrm{tr}(\boldsymbol{W}^{\mathrm{T}}\boldsymbol{x}_{i}\boldsymbol{x}_{i}^{T}\boldsymbol{W})\\
&amp;=\text{tr}(\boldsymbol{W}^{\mathrm{T}}\boldsymbol{X}\boldsymbol{X}^{\mathrm{T}}\boldsymbol{W})
\end{aligned}\]

<p>最大化上述方差等价于求解如下优化问题</p>

\[\begin{aligned}
\arg\max_{\boldsymbol{W}} &amp;\quad \text{tr}(\boldsymbol{W}^T\boldsymbol{X}\boldsymbol{X}^T\boldsymbol{W}) \\
s.t. &amp;\quad \boldsymbol{W}^T\boldsymbol{W}=\boldsymbol{I}
\end{aligned}\]

<p>可以发现和最近重构性等价。</p>

<h3 id="32-算法流程"><span class="me-2">3.2. 算法流程</span><a href="#32-算法流程" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>假设有 $m$ 个 $n$ 维向量，想将其变换为由 $d$ 个 $n$ 维向量表示的新空间中，那么首先将 $d$ 个基按行组成矩阵 $W$，然后将向量按列组成矩阵 $X$，那么两矩阵的乘积 $WX$ 就是变换结果，其中 $WX$ 的第 $m$ 列为 $X$ 中第 $m$ 列变换后的结果。</p>

<p>首先将 $m$ 个 $n$ 维数据排列成  $n$ 行 $m$ 列矩阵的形式，即每一列是一个样本数据</p>

\[\boldsymbol{X} = [\boldsymbol{X}_1, \boldsymbol{X}_2,\cdots, \boldsymbol{X}_m] \in \mathbb{R}^{n\times m}\]

<p>然后对数据进行中心化，即计算所有数据的均值后，将所有数据减去均值</p>

\[\begin{aligned}
\bar{\boldsymbol{X}}&amp;=[\boldsymbol{X}_1-\boldsymbol{\mu}, \boldsymbol{X}_2-\boldsymbol{\mu},\cdots, \boldsymbol{X}_m-\boldsymbol{\mu}]\\
&amp;=[\bar{\boldsymbol{X}}_1, \bar{\boldsymbol{X}}_2,\cdots, \bar{\boldsymbol{X}}_m]\\
&amp;=\begin{bmatrix}
\bar x^1_1 &amp; \bar x^2_1 &amp; \cdots &amp; \bar x^m_1\\
\bar x^1_2 &amp; \bar x^2_2 &amp; \cdots &amp; \bar x^m_2\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\bar x^1_n &amp; \bar x^2_n &amp; \cdots &amp; \bar x^m_n\\
\end{bmatrix}
\end{aligned}\]

<p>此时满足</p>

\[\sum_{i=0}^m \bar{\boldsymbol{X}}_i = 0\]

<p>然后计算这个矩阵的协方差矩阵，即</p>

\[\begin{aligned}
\boldsymbol{\Sigma} &amp;= \frac{1}{m-1}\bar{\boldsymbol{X}}\bar{\boldsymbol{X}}^T \in \mathbb{R}^{n \times n}\\
&amp;=\frac{1}{m-1} \begin{bmatrix}
\sum_{i=1}^m (\bar x^i_1)^2 &amp; \sum_{i=1}^m \bar x^i_1\cdot \bar x^i_2 &amp; \cdots &amp; \sum_{i=1}^m \bar x^i_1\cdot \bar x^i_n\\
\sum_{i=1}^m \bar x^i_2\cdot \bar x^i_1 &amp; \sum_{i=1}^m (\bar x^i_2)^2 &amp; \cdots &amp; \sum_{i=1}^m \bar x^i_2\cdot \bar x^i_n\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\sum_{i=1}^m \bar x^i_n\cdot \bar x^i_1 &amp; \sum_{i=1}^m \bar x^i_n\cdot \bar x^i_2 &amp; \cdots &amp; \sum_{i=1}^m (\bar x^i_n)^2\\
\end{bmatrix}
\end{aligned}\]

<p>其中，对角线上的元素为各个随机变量（特征）的方差，非对角线上的元素为两两随机变量之间的协方差。</p>

<p>求出协方差矩阵的特征值 $\lambda_i$ 和对应的正交化单位特征向量 $\boldsymbol{w}_i$。</p>

<p>将特征向量按照对应特征值从大到小，自上而下按行排列成矩阵，取前 $d$ 行组成矩阵 $\boldsymbol{W}$。</p>

<p>$\boldsymbol{Y} = \boldsymbol{W}\boldsymbol{X}$ 即为降维到 $d$ 维后的数据。（如果按列排列特征向量，则 $\boldsymbol{W}$ 取转置）</p>

<h3 id="33-pca-的特点"><span class="me-2">3.3. PCA 的特点</span><a href="#33-pca-的特点" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>根据上面对PCA的数学原理的解释，可以了解到一些PCA的能力和限制。PCA本质上是将方差最大的方向作为主要特征，并且在各个正交方向上将数据“离相关”，也就是让它们在不同正交方向上没有相关性。</p>

<p>因此，PCA也存在一些限制，例如它可以很好的解除线性相关，但是对于高阶相关性就没有办法了，对于存在高阶相关性的数据，可以考虑Kernel PCA，通过Kernel函数将非线性相关转为线性相关。另外，PCA假设数据各主特征是分布在正交方向上，如果在非正交方向上存在几个方差较大的方向，PCA的效果就大打折扣了。</p>

<p>最后需要说明的是，PCA是一种无参数技术，也就是说面对同样的数据，如果不考虑清洗，谁来做结果都一样，没有主观参数的介入，所以PCA便于通用实现，但是本身无法个性化的优化。</p>

<h2 id="4-参考文献"><span class="me-2">4. 参考文献</span><a href="#4-参考文献" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>[1] <a href="https://www.cnblogs.com/sowhat1412/p/12734337.html">CSDN【机器学习】LDA 浅谈 Linear Discriminant Analysis</a></p>

<p>[2] <a href="https://blog.csdn.net/YMilton/article/details/89263997">CSDN PCA(主成分分析方法)</a></p>

</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
  <div class="post-meta mb-3">
    <i class="far fa-folder-open fa-fw me-1"></i>
    
      <a href='/categories/academic/'>Academic</a>,
      <a href='/categories/knowledge/'>Knowledge</a>
  </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw me-1"></i>
      
      <a href="/tags/pattern-recognition/"
          class="post-tag no-text-decoration" >pattern recognition</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        本文由作者按照 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         进行授权

      
    </div>

    <!-- Post sharing snippet -->

<div class="share-wrapper">
  <span class="share-label text-muted me-1">分享</span>
  <span class="share-icons">
    
    
    

    
      
      <a
        href="https://twitter.com/intent/tweet?text=%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%EF%BC%88LDA%E5%92%8CPCA%EF%BC%89%20-%20SIRLIS&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FPattern-Recognition-LDA%26PCA%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Twitter"
        target="_blank"
        rel="noopener"
        aria-label="Twitter"
      >
        <i class="fa-fw fab fa-twitter"></i>
      </a>
    
      
      <a
        href="https://www.facebook.com/sharer/sharer.php?title=%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%EF%BC%88LDA%E5%92%8CPCA%EF%BC%89%20-%20SIRLIS&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FPattern-Recognition-LDA%26PCA%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Facebook"
        target="_blank"
        rel="noopener"
        aria-label="Facebook"
      >
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    
      
      <a
        href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FPattern-Recognition-LDA%26PCA%2F&text=%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%EF%BC%88LDA%E5%92%8CPCA%EF%BC%89%20-%20SIRLIS"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Telegram"
        target="_blank"
        rel="noopener"
        aria-label="Telegram"
      >
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <i
      id="copy-link"
      class="fa-fw fas fa-link small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="分享链接"
      data-title-succeed="链接已复制！"
    >
    </i>
  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
      
    </div>
  </div>
  <!-- #core-wrapper -->

  <!-- panel -->
  <div id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
    <div class="access">
      <!-- Get the last 5 posts from lastmod list. -->














  <div id="access-lastmod" class="post">
    <div class="panel-heading">最近更新</div>
    <ul class="post-content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-Temporal-Differences/">强化学习（时序差分法）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-Value-Approximation/">强化学习（值函数近似）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Pattern-Recognition-Nonlinear-Classifier/">模式识别（非线性分类器）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Pattern-Recognition-Bayes/">模式识别（贝叶斯决策）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-markov-process/">强化学习（马尔可夫决策过程）</a>
        </li>
      
    </ul>
  </div>
  <!-- #access-lastmod -->


      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">热门标签</div>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/fuzzy/">fuzzy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/vscode/">vscode</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/other/">other</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/astronomy/">astronomy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c-c/">c/c++</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/computer-vision/">computer vision</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/meta-learning/">meta learning</a>
      
    </div>
  </div>


    </div>

    
      
      



  <div id="toc-wrapper" class="ps-0 pe-4 mb-5">
    <div class="panel-heading ps-3 pt-2 mb-2">文章内容</div>
    <nav id="toc"></nav>
  </div>


    
  </div>
</div>

<!-- tail -->

  <div class="row">
    <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-3 pe-xl-4 mt-5">
      
        
        <!--
  Recommend the other 3 posts according to the tags and categories of the current post,
  if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->








  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  






<!-- Fill with the other newlest posts -->





  <div id="related-posts" class="mb-2 mb-sm-4">
    <h3 class="pt-2 mb-4 ms-1" data-toc-skip>
      相关文章
    </h3>
    <div class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        
        
        <div class="col">
          <a href="/posts/Pattern-Recognition-Linear-Classifier/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1709447119"
  data-df="YYYY/MM/DD"
  
>
  2024/03/03
</em>

              <h4 class="pt-0 my-2" data-toc-skip>模式识别（线性分类器）</h4>
              <div class="text-muted small">
                <p>
                  





                  本文介绍了模式识别的线性分类器，包括线性分类器的基础概念、垂直平分准则以及垂直平分分类器、Fisher 投影准则、感知准则、最小错分样本准则、最小平方误差准则、最小二乘估计。






  1. 引言
  2. 线性分类器基础
    
      2.1. 线性判别函数
      2.2. 广义线性判别函数
      2.3. 二分类与多分类
      2.4. 线性分类器设计的基...
                </p>
              </div>
            </div>
          </a>
        </div>
      
        
        
        <div class="col">
          <a href="/posts/Pattern-Recognition-Bayes/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1710249739"
  data-df="YYYY/MM/DD"
  
>
  2024/03/12
</em>

              <h4 class="pt-0 my-2" data-toc-skip>模式识别（贝叶斯决策）</h4>
              <div class="text-muted small">
                <p>
                  





                  本文介绍了模式识别的贝叶斯决策，包括贝叶斯公式、最小错误贝叶斯决策、最小风险贝叶斯决策。






  1. 决策理论与方法
    
      1.1. 基于先验概率的决策
      1.2. 基于贝叶斯公式（后验概率）的决策
    
  
  2. 最小错误贝叶斯决策
    
      2.1. 直观举例
      2.2. 类概率密度
      2.3. 错误率分析
 ...
                </p>
              </div>
            </div>
          </a>
        </div>
      
        
        
        <div class="col">
          <a href="/posts/Pattern-Recognition-Nonlinear-Classifier/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1743341659"
  data-df="YYYY/MM/DD"
  
>
  2025/03/30
</em>

              <h4 class="pt-0 my-2" data-toc-skip>模式识别（非线性分类器）</h4>
              <div class="text-muted small">
                <p>
                  





                  很多情况下，类别之间的分类边界并不是线性的，一种更好的选择是使用更复杂的非线性函数来描述分类。本文介绍了模式识别常用的非线性分类器，主要包括近邻法分类器（NN、KNN）、支持向量机（SVM）、决策树（DT），最后介绍分类器的集成。本章内容预计花费 4 个课时学习。






  1. 引言
  2. 近邻法分类器（NN / KNN）
    
      2.1. 最近邻法
      2...
                </p>
              </div>
            </div>
          </a>
        </div>
      
    </div>
    <!-- .card-deck -->
  </div>
  <!-- #related-posts -->


      
        
        <!-- Navigation buttons at the bottom of the post. -->

<div class="post-navigation d-flex justify-content-between">
  
    <a
      href="/posts/Pattern-Recognition-Bayes/"
      class="btn btn-outline-primary"
      prompt="上一篇"
    >
      <p>模式识别（贝叶斯决策）</p>
    </a>
  

  
    <a
      href="/posts/deep-learning-basic-math/"
      class="btn btn-outline-primary"
      prompt="下一篇"
    >
      <p>深度学习（基础数学知识）</p>
    </a>
  
</div>

      
        
        <!--  The comments switcher -->

  
  <!-- https://utteranc.es/ -->
<script src="https://utteranc.es/client.js"
        repo="sirlis/sirlis.github.io"
        issue-term="pathname"
        crossorigin="anonymous"
        async>
</script>

<script type="text/javascript">
  $(function() {
    const origin = "https://utteranc.es";
    const iframe = "iframe.utterances-frame";
    const lightTheme = "github-light";
    const darkTheme = "github-dark";
    let initTheme = lightTheme;

    if ($("html[data-mode=dark]").length > 0
        || ($("html[data-mode]").length == 0
            && window.matchMedia("(prefers-color-scheme: dark)").matches)) {
      initTheme = darkTheme;
    }

    addEventListener("message", (event) => {
      let theme;

      /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */
      if (event.origin === origin) {
        /* page initial */
        theme = initTheme;

      } else if (event.source === window && event.data &&
            event.data.direction === ModeToggle.ID) {
        /* global theme mode changed */
        const mode = event.data.message;
        theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme);

      } else {
        return;
      }

      const message = {
        type: "set-theme",
        theme: theme
      };

      const utterances = document.querySelector(iframe).contentWindow;
      utterances.postMessage(message, origin);
    });

  });
</script>



      
    </div>
  </div>


        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-11 post-content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">热门标签</div>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/fuzzy/">fuzzy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/vscode/">vscode</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/other/">other</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/astronomy/">astronomy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c-c/">c/c++</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/computer-vision/">computer vision</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/meta-learning/">meta learning</a>
      
    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>
    </div>

    <!-- The Footer -->

<footer>
  <div class="container px-lg-4">
    <div class="d-flex justify-content-center align-items-center text-muted mx-md-3">
      <p>本站采用 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 主题 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>
      </p>

      <p>©
        2025
        <a href="https://github.com/sirlis">sirlis</a>.
        
          <span
            data-bs-toggle="tooltip"
            data-bs-placement="top"
            title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。"
          >保留部分权利。</span>
        
      </p>
    </div>
  </div>
</footer>


    <div id="mask"></div>

    <button id="back-to-top" aria-label="back-to-top" class="btn btn-lg btn-box-shadow">
      <i class="fas fa-angle-up"></i>
    </button>

    
      <div
        id="notification"
        class="toast"
        role="alert"
        aria-live="assertive"
        aria-atomic="true"
        data-bs-animation="true"
        data-bs-autohide="false"
      >
        <div class="toast-header">
          <button
            type="button"
            class="btn-close ms-auto"
            data-bs-dismiss="toast"
            aria-label="Close"
          ></button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="px-2 mb-3">发现新版本的内容。</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            更新
          </button>
        </div>
      </div>
    

    <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.0/dist/jquery.min.js,npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.7/dayjs.min.js,npm/dayjs@1.11.7/locale/zh.min.js,npm/dayjs@1.11.7/plugin/relativeTime.min.js,npm/dayjs@1.11.7/plugin/localizedFormat.min.js,npm/tocbot@4.21.0/dist/tocbot.min.js"></script>






<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
    /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
    MathJax = {
      tex: {
        /* start/end delimiter pairs for in-line math */
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ],
        /* start/end delimiter pairs for display math */
        displayMath: [
          ['$$', '$$'],
          ['\\[', '\\]']
        ]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>





    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  /* Note: dependent library will be loaded in `js-selector.html` */
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('search-results'),
    json: '/assets/js/data/search.json',
    searchResultTemplate: '<div class="px-1 px-sm-2 px-lg-4 px-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
    noResultsText: '<p class="mt-5"></p>',
    templateMiddleware: function(prop, value, template) {
      if (prop === 'categories') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
        }
      }

      if (prop === 'tags') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
        }
      }
    }
  });
</script>

  </body>
</html>

