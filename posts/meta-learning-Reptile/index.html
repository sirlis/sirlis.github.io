<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="zh-CN" 
  
>
  <!-- The Head -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="元学习文章阅读（Reptile）" />
<meta property="og:locale" content="zh_CN" />
<meta name="description" content="Reptile 于2018年由 OpenAI 提出，是一种非常简单而有效的基于优化的（Optimized-based）小样本学习方法，通过多步梯度下降来学习一个较优的模型初始参数。" />
<meta property="og:description" content="Reptile 于2018年由 OpenAI 提出，是一种非常简单而有效的基于优化的（Optimized-based）小样本学习方法，通过多步梯度下降来学习一个较优的模型初始参数。" />
<link rel="canonical" href="http://localhost:4000/posts/meta-learning-Reptile/" />
<meta property="og:url" content="http://localhost:4000/posts/meta-learning-Reptile/" />
<meta property="og:site_name" content="SIRLIS" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-14T14:35:19+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="元学习文章阅读（Reptile）" />
<meta name="twitter:site" content="@none" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-10-10T15:02:18+08:00","datePublished":"2020-07-14T14:35:19+08:00","description":"Reptile 于2018年由 OpenAI 提出，是一种非常简单而有效的基于优化的（Optimized-based）小样本学习方法，通过多步梯度下降来学习一个较优的模型初始参数。","headline":"元学习文章阅读（Reptile）","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/meta-learning-Reptile/"},"url":"http://localhost:4000/posts/meta-learning-Reptile/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>元学习文章阅读（Reptile） | SIRLIS
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="SIRLIS">
<meta name="application-name" content="SIRLIS">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.21.0/dist/tocbot.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  
    <!-- Switch the mode between dark and light. -->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() {
      return 'mode';
    }
    static get MODE_ATTR() {
      return 'data-mode';
    }
    static get DARK_MODE() {
      return 'dark';
    }
    static get LIGHT_MODE() {
      return 'light';
    }
    static get ID() {
      return 'mode-toggle';
    }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener('change', () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();
      });
    } /* constructor() */

    get sysDarkPrefers() {
      return window.matchMedia('(prefers-color-scheme: dark)');
    }

    get isSysDarkPrefer() {
      return this.sysDarkPrefers.matches;
    }

    get isDarkMode() {
      return this.mode === ModeToggle.DARK_MODE;
    }

    get isLightMode() {
      return this.mode === ModeToggle.LIGHT_MODE;
    }

    get hasMode() {
      return this.mode != null;
    }

    get mode() {
      return sessionStorage.getItem(ModeToggle.MODE_KEY);
    }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      document.documentElement.removeAttribute(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage(
        {
          direction: ModeToggle.ID,
          message: this.modeStatus
        },
        '*'
      );
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.notify();
    } /* flipMode() */
  } /* ModeToggle */

  const modeToggle = new ModeToggle();
</script>

  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle">
      
        
        <img src="/assets/img/head.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'">
      
    </a>

    <div class="site-title">
      <a href="/">SIRLIS</a>
    </div>
    <div class="site-subtitle fst-italic">分享科研和生活的日常</div>
  </div>
  <!-- .profile-wrapper -->

  <ul class="nav flex-column flex-grow-1 w-100 ps-0">
    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home"></i>
        <span>首页</span>
      </a>
    </li>
    <!-- the real tabs -->
    
      <li class="nav-item">
        <a href="/categories/" class="nav-link">
          <i class="fa-fw fas fa-stream"></i>
          

          <span>分类</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/tags/" class="nav-link">
          <i class="fa-fw fas fa-tags"></i>
          

          <span>标签</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/archives/" class="nav-link">
          <i class="fa-fw fas fa-archive"></i>
          

          <span>归档</span>
        </a>
      </li>
      <!-- .nav-item -->
    
      <li class="nav-item">
        <a href="/about/" class="nav-link">
          <i class="fa-fw fas fa-info-circle"></i>
          

          <span>关于</span>
        </a>
      </li>
      <!-- .nav-item -->
    
  </ul>
  <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://github.com/sirlis"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="https://twitter.com/none"
          aria-label="twitter"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-twitter"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['lihongjue','buaa.edu.cn'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          

          

          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</div>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container px-xxl-5">
        <!-- The Top Bar -->

<div id="topbar-wrapper">
  <div
    id="topbar"
    class="container d-flex align-items-center justify-content-between h-100"
  >
    <span id="breadcrumb">
      

      
        
          
            <span>
              <a href="/">
                首页
              </a>
            </span>

          
        
          
        
          
            
              <span>元学习文章阅读（Reptile）</span>
            

          
        
      
    </span>
    <!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      文章
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="搜索..."
      >
    </span>
    <span id="search-cancel">取消</span>
  </div>
</div>

        











<div class="row">
  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pe-xl-4">
    

    <div class="post px-1 px-md-2">
      

      
        
      
        <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->



  
  

  <!-- CDN URL -->
  

  <!-- Add image path -->
  

  
    
      
      
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  
    

    
    

    

    
    

    
    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    

    

    <!-- lazy-load images <https://github.com/aFarkas/lazysizes#readme> -->
    
    

    <!-- add image placeholder -->
    
      
    

    <!-- Bypass the HTML-proofer test -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        
      
    

    <!-- combine -->
    

  

  



<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  

  
  

  

  
  

  




<!-- return -->




<h1 data-toc-skip>元学习文章阅读（Reptile）</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      发表于
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class=""
  data-ts="1594708519"
  data-df="YYYY/MM/DD"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  2020/07/14
</em>

    </span>

    <!-- lastmod date -->
    
    <span>
      更新于
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class=""
  data-ts="1696921338"
  data-df="YYYY/MM/DD"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  2023/10/10
</em>

    </span>
    

  

  <div class="d-flex justify-content-between">
    <!-- author(s) -->
    <span>
      

      作者

      <em>
      
        <a href="https://github.com/sirlis">sirlis</a>
      
      </em>
    </span>

    <div>
      <!-- read time -->
      <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="4908 字"
>
  <em>27 分钟</em>阅读</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <p>Reptile 于2018年由 OpenAI 提出，是一种非常简单而有效的基于优化的（Optimized-based）小样本学习方法，通过多步梯度下降来学习一个较优的模型初始参数。</p>

<!--more-->

<hr />

<ul>
  <li><a href="#1-reptile">1. Reptile</a>
    <ul>
      <li><a href="#11-算法">1.1. 算法</a></li>
      <li><a href="#12-数学分析">1.2. 数学分析</a></li>
      <li><a href="#13-梯度的泰勒展开的领头阶">1.3. 梯度的泰勒展开的领头阶</a></li>
      <li><a href="#14-另一种推导方式">1.4. 另一种推导方式</a></li>
      <li><a href="#15-梯度的泰勒展开的领头阶继续">1.5. 梯度的泰勒展开的领头阶（继续）</a></li>
      <li><a href="#16-另一种不严谨的分析">1.6. 另一种不严谨的分析</a></li>
      <li><a href="#17-实验">1.7. 实验</a></li>
    </ul>
  </li>
  <li><a href="#2-比较">2. 比较</a></li>
  <li><a href="#3-算法实现">3. 算法实现</a></li>
  <li><a href="#4-reptile回归sin函数">4. reptile回归sin函数</a></li>
  <li><a href="#5-参考文献">5. 参考文献</a></li>
</ul>

<h1 id="1-reptile">1. Reptile</h1>

<p>2018.《On First-Order Meta-Learning Algorithms》和《Reptile: a Scalable Metalearning Algorithm》</p>

<p>Reptile是OpenAI提出的一种非常简单的meta learning 算法。与MAML类似，也是学习网络参数的初始值。</p>

<h2 id="11-算法"><span class="me-2">1.1. 算法</span><a href="#11-算法" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>算法伪代码如下</p>

<p><a href="/assets/img/postsimg/20200713/7.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20200713/7.jpg" alt="image-20200717113006074" class="lazyload" data-proofer-ignore></a></p>

<p>其中，$\phi$ 是模型的初始参数，$\tau$ 是某个 task，$U_\tau^k(\phi)$ 表示从 $\phi$ 开始对损失函数进行 $k$ 次随机梯度下降，返回更新后的参数 $\widetilde{\phi}$。</p>

<p>在最后一步中，通过 $\widetilde{\phi}-\phi$ 这种残差形式来更新一次初始参数。</p>

<p>如果 $k=1$，该算法等价于「联合训练」（joint training，通过训练来最小化在一系列训练任务上期望损失）。</p>

<p>Reptile 要求 $k&gt;1$，更新依赖于损失函数的高阶导数，此时 Reptile 的行为与 $k=1$（联合训练）时截然不同。</p>

<p>Reptile 与 MAML 和 FOMAML 紧密相关，但是也存在不同</p>

<ul>
  <li>
    <p>Reptile <strong>无需对每一个任务进行训练-测试（training-testing）划分</strong>。</p>
  </li>
  <li>
    <p>相比 MAML 需要进行二重梯度计算，Reptile 只需要进行一重梯度计算，计算速度更快。</p>
  </li>
</ul>

<p>Reptile 的图例如下。</p>

<p><a href="/assets/img/postsimg/20200713/9.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20200713/9.jpg" alt="alt text" class="lazyload" data-proofer-ignore></a></p>

<h2 id="12-数学分析"><span class="me-2">1.2. 数学分析</span><a href="#12-数学分析" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><strong>基于优化的元学习问题</strong>（Optimization-based Meta-Learning）的目标：找寻一组<strong>模型初始参数</strong> $\boldsymbol \phi$，使得模型在面对随机选取的新任务 $\tau \sim \mathcal T$ 时，经过 $k$ 次梯度更新，在 $\tau$ 上的损失函数就能达到很小。</p>

<p>用数学语言描述，即</p>

\[\mathop{minimize}_{\phi} \; \mathbb E_{\tau}[L_{\tau}(^{k}_\tau\boldsymbol \phi)]
= \mathop{minimize}_{\phi} \; \mathbb E_{\tau}[L_{\tau}(U^k_\tau(\boldsymbol \phi))]\]

<p>其中</p>

\[\widetilde{\boldsymbol\phi} = {}^{k}_\tau \boldsymbol \phi=U^k_\tau(\boldsymbol \phi)\]

<p>是在任务 $\tau$ 上经过 $k$ 次更新后的模型参数。</p>

<p>Reptile 算法中<strong>将</strong> $(\boldsymbol \phi - \widetilde{\boldsymbol\phi}) / \alpha$ <strong>看作梯度</strong>，其中 $\alpha$ 为 SGD 中的学习率，即</p>

\[g_{Reptile} = (\boldsymbol \phi - \widetilde{\boldsymbol\phi}) / \alpha\]

<p>注意到，SGD 随机梯度下降的核心是，<strong>梯度是期望，期望可使用小规模的样本近似估计。</strong></p>

<p>对于采用 SGD 的传统监督学习，模型参数更新方式为</p>

\[\phi = \widetilde \phi = \phi - \beta \cdot \mathbb E[\nabla^kL_\tau] =? \phi - \beta \cdot \nabla^k\mathbb E[L_\tau]\]

<p>问题1：梯度和期望能否交换顺序？</p>

<p>传统监督学习的参数更新可简写为 $SGD(\mathbb E[L_\tau],\theta,k)$。</p>

<p>采用 SGD 的 Reptile 的模型参数更新方式为：</p>

\[\phi = \phi + \beta\cdot \mathbb E[\widetilde\phi-\phi]/\alpha\]

<p>又因为 $\widetilde \phi = SGD(L_\tau,\theta,k)$，那么相应的参数更新可简写为 $\mathbb E[ SGD(L_\tau,\theta,k)]$。</p>

<p>问题2：$SGD(\mathbb E[L_\tau],\theta,k)$ 与 $\mathbb E[ SGD(L_\tau,\theta,k)]$ 有什么关系？</p>

<p>下面需要按照 $k$ 的取值分情况讨论。</p>

<ul>
  <li><strong>如果 $k=1$</strong>，那么有</li>
</ul>

\[\begin{aligned}
g_{Reptile,k=1} &amp;= \mathbb E_\tau [(\boldsymbol \phi - \widetilde{\boldsymbol\phi}) / \alpha]\\
&amp;= \mathbb E_\tau [(\boldsymbol \phi - U_\tau(\boldsymbol \phi)) / \alpha]\\
&amp;= \mathbb E_\tau [\boldsymbol \phi - U_\tau(\boldsymbol \phi)] / \alpha\\
&amp;= \boldsymbol \phi / \alpha - \mathbb E_\tau [U_\tau(\boldsymbol \phi)] / \alpha \quad where \; \alpha,\phi=const \\
\end{aligned}\]

<p>又知道，$U_\tau(\boldsymbol\phi)$ 是计算 $k=1$ 次的梯度算子（省略 $k$）</p>

\[U_\tau(\boldsymbol\phi) = \boldsymbol \phi - \alpha \nabla_{\boldsymbol\phi} L_\tau(\boldsymbol\phi)\]

<p>则</p>

\[\begin{aligned}
\mathbb E_\tau [U_\tau(\boldsymbol \phi)] &amp;= \mathbb E_\tau[\boldsymbol \phi - \alpha \nabla_{\boldsymbol\phi} L_\tau(\boldsymbol\phi)]\\
&amp;= \boldsymbol\phi - \alpha \cdot \mathbb E_\tau [\nabla_{\boldsymbol\phi} L_\tau(\boldsymbol \phi)]
\end{aligned}\]

<p>带入上式计算 $g_{Reptile,k=1}$，有</p>

\[g_{Reptile,k=1} = \mathbb E_\tau[\nabla_{\boldsymbol\phi} L_\tau(\boldsymbol\phi)]\]

<p>因此有</p>

\[g_{Reptile,k=1} = \mathbb E_\tau [(\boldsymbol \phi - \widetilde{\boldsymbol\phi}) / \alpha] = \mathbb E_\tau[\nabla_{\boldsymbol\phi} L_\tau(\boldsymbol\phi)]\]

<p>另外，根据<a href="https://math.stackexchange.com/questions/1962991/expectation-of-gradient-in-stochastic-gradient-descent-algorithm">此处</a>的讨论，以及后续两处讨论，当损失函数足够光滑和有界时，期望和梯度可以交换顺序</p>

<blockquote>
  <p>The first step is probably the nastiest (although not in the discrete case I guess), but we can interchange the gradient and expectation assuming L is sufficiently smooth and bounded (which it probably is). See here(1) and here(2).</p>
</blockquote>

<p>(1) <a href="https://math.stackexchange.com/questions/217702/when-can-we-interchange-the-derivative-with-an-expectation">When can we interchange the derivative with an expectation?</a></p>

<p>(2) <a href="https://stats.stackexchange.com/questions/227065/expectation-of-gradients">Expectation of gradients</a></p>

\[\mathbb E_{\tau\sim \mathcal T}[\nabla L_n(\phi)]=\nabla \mathbb E_{\tau\sim \mathcal T}[L_n(\phi)]\]

<p>那么</p>

\[g_{Reptile,k=1} = \mathbb E_\tau [(\boldsymbol \phi - \widetilde{\boldsymbol\phi}) / \alpha] = \mathbb E_\tau[\nabla_{\boldsymbol\phi} L_\tau(\boldsymbol\phi)]= \nabla_{\boldsymbol\phi} \mathbb E_\tau[L_\tau(\boldsymbol\phi)]\]

<p>即 $k=1$ 时，Reptile 和 在期望损失 $\mathbb E_\tau [L_\tau]$ 上的联合训练 等价。</p>

<ul>
  <li><strong>如果 $k&gt;1$</strong>，那么</li>
</ul>

\[g_{Reptile,k&gt;1} = \boldsymbol\phi / \alpha - \mathbb E_\tau [U_{\phi}^k(\boldsymbol\phi)]/\alpha\]

<p>而</p>

\[U_{\phi}^k(\boldsymbol\phi) = \boldsymbol \phi- \alpha \boldsymbol g_1- \alpha \boldsymbol g_2-...- \alpha \boldsymbol g_k\]

<p>其中</p>

\[\begin{aligned}
\boldsymbol g_1 &amp; = \nabla_{\boldsymbol \theta} L_\tau(\boldsymbol \theta), \quad {}^1\boldsymbol \theta = \boldsymbol \theta - \alpha \boldsymbol g_1\\
\boldsymbol g_2 &amp; = \nabla_{ {}^1\boldsymbol \theta} L_\tau({}^1\boldsymbol \theta)\\
&amp;= \nabla_{ {}^1\boldsymbol \theta} L_\tau(\boldsymbol \theta - \alpha \boldsymbol g_1)\\
&amp;= \nabla_{ {}^1\boldsymbol \theta} L_\tau(\boldsymbol \theta - \alpha (\nabla_{\boldsymbol \theta} L_\tau(\boldsymbol \theta)))\\
...&amp;...
\end{aligned}\]

<p>$\mathbb E_\tau [U_{\phi}^k(\boldsymbol\phi)]$ 中包含了高阶项信息，从而与 $\nabla \mathbb E[L_\tau]$ 不再相关。此时 Reptile 收敛到的参数解与传统监督学习完全不同。</p>

<h2 id="13-梯度的泰勒展开的领头阶"><span class="me-2">1.3. 梯度的泰勒展开的领头阶</span><a href="#13-梯度的泰勒展开的领头阶" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>那么，为什么Reptile就这么简单的多更新几步梯度（ k&gt;1 ）就能很好的进行元学习呢？作者通过泰勒展开的领头阶来分析。</p>

<p>首先定义四个<strong>辅助变量</strong>，假设模型初始参数为 $\phi_1$，$i\in [1, k]$ 指代第 $i$ 次梯度下降的训练过程：</p>

\[\begin{aligned}
g_i &amp;= L_i'(\phi_i)
\;\;(gradient \; obtained\; during\;SGD)\\
\phi_{i+1} &amp;= \phi_i-\alpha g_i
\;\;(sequence\;of\;parameters)\\
\overline{g}_i &amp;= L_i'(\phi_1)
\;\;(gradient\;at\;initial\;point)\\
\overline{H}_i &amp;= L_i''(\phi_1)
\;\;(Hessian\;at\;initial\;point)\\
\end{aligned}\]

<p>然后将 $g_i$ 在原始参数 $\phi_1$ 上泰勒展开至 “二阶导+高次项” 的形式</p>

\[\begin{aligned}
g_i = L_i'(\phi_i) &amp;= L_i'(\phi_1) + L_i''(\phi_1)(\phi_i - \phi_1) + O(||\phi_i - \phi_1||^2)\\
&amp;= \overline{g}_i + \overline{H}_i(\phi_i - \phi_1) + O(\alpha^2)\\
&amp;= \overline{g}_i - \alpha\overline{H}_i\sum_{j=1}^{i-1}g_j + O(\alpha^2)\\
&amp;= \overline{g}_i - \alpha\overline{H}_i\sum_{j=1}^{i-1}\overline{g}_j + O(\alpha^2)\\
\end{aligned}\]

<p>下面分析上式的推导过程。根据第二个辅助变量的定义，进行链式展开，高阶项的推导过程如下</p>

\[\begin{aligned}
&amp;\phi_i = \phi_1 - \alpha g_1 - \alpha g_2 - ... - \alpha g_{i-1}\\
\Rightarrow \quad &amp;O(||\phi_i - \phi_1||^2) = O(|| - \alpha \sum_{j=1}^{i-1} g_j||^2) = O(\alpha^2)
\end{aligned}\]

<p>同理，第二个等号右边，Hessian 矩阵右乘的括号和可化为 $g_i$ 的和形式。</p>

<p>最后一个等号右边，可以直接将 $g_i$ 替换为 $\overline g_i$ 是因为</p>

\[\begin{aligned}
\alpha\overline{H}_i\sum_0^{i-1}g_i &amp;= \alpha\overline{H}_i\sum_0^{i-1}L_i'(\phi_i) \\
&amp;= \alpha\overline{H}_i\sum_0^{i-1}[L_i'(\phi_1) + L_i''(\phi_1)(\phi_i - \phi_1)+O(\alpha^2)]\\
&amp;=\alpha\overline{H}_i\sum_0^{i-1}[\overline g_i- \alpha\overline{H}_i\sum_{j=1}^{i-1}g_j + O(\alpha^2)]\\
&amp;= \alpha\overline{H}_i\sum_0^{i-1}\overline g_i + O(\alpha^2)
\end{aligned}\]

<p>至此，我们可以得到$g_i$ 在原始参数 $\phi_1$ 上的泰勒展开如下</p>

\[g_i = \overline{g}_i - \alpha\overline{H}_i\sum_{j=1}^{i-1}\overline{g}_j + O(\alpha^2)\]

<p>然后，我们对 $g_{MAML}$ 进行分析</p>

\[\begin{aligned}
g_{MAML} &amp;= \frac{\partial}{\partial\phi_1}L_k(\phi_k)\\
&amp;= L'_k(\phi_k)\frac{\partial\phi_k}{\partial\phi_1}\\
&amp;= L'_k(\phi_k)\frac{\partial}{\partial\phi_1}[U_{k-1}(U_{k-2}(...(U_1(\phi_1))))]\\
&amp;= L'_k(\phi_k)U'_1(\phi_1)U'_2(\phi_2)\cdots U'_{k-1}(\phi_{k-1})\\
&amp;= L'_k(\phi_k)(I-\alpha L''_1(\phi_1))\cdots(I-\alpha L''_{k-1}(\phi_{k-1}))\\
&amp;=L'_k(\phi_k)\left(\prod_{i=1}^{k-1}(I-\alpha L''_i(\phi_i))\right)\\
&amp;=g_k\left(\prod_{i=1}^{k-1}(I-\alpha L''_i(\phi_i))\right)
\end{aligned}\]

<p>此处，令 $\alpha=0^+$，我们可以给出 $g_{FOMAML}$ 的表达式</p>

\[g_{FOMAML} = g_k\]

<p>根据前面已经推得的 $g_i$ 在原始参数上的泰勒展开式，带入得</p>

\[g_{FOMAML} = \overline{g}_k - \alpha\overline{H}_k\sum_{j=1}^{k-1}\overline{g}_j + O(\alpha^2)\]

<p>继续推导 $g_{MAML}$，借助第四个辅助变量定义，我们对 $\alpha L’‘_i(\phi_i)$ 在原始参数上进行泰勒展开</p>

\[\begin{aligned}
\alpha L''_i(\phi_i) &amp;= \alpha L''_i(\phi_1) + \alpha H'_i(\phi_1 - \phi_1) + O(\alpha^2) \\
&amp;= \alpha \overline H_i + \alpha H'_i\sum \alpha g_{i-1} + O(\alpha^2)\\
&amp;= \alpha \overline H_i + O(\alpha^2)
\end{aligned}\]

<p>带入 $g_{MAML}$，有</p>

\[g_{MAML} = g_k\left(\prod_{i=1}^{k-1}(I-\alpha \overline H_i)\right) + O(\alpha^2)\]

<p>又根据前面已经推得的 $g_i$ 在原始参数上的泰勒展开式，带入得</p>

\[\begin{aligned}
g_{MAML} &amp;= \left(\overline{g}_k - \alpha\overline{H}_k\sum_{j=1}^{k-1}\overline{g}_j\right) \left( \prod_{i=1}^{k-1}(I-\alpha \overline H_i)\right) + O(\alpha^2)\\
&amp;= \left(\overline{g}_k - \alpha\overline{H}_k\sum_{j=1}^{k-1}\overline{g}_j\right) [ (I-\alpha \overline H_1)\cdots(I-\alpha \overline H_{k-1}) ] + O(\alpha^2)\\
&amp;= \left(\overline{g}_k - \alpha\overline{H}_k\sum_{j=1}^{k-1}\overline{g}_j\right) [I-\alpha \overline H_1 - \cdots - \alpha \overline H_{k-1} + O(\alpha^2)] + O(\alpha^2)\\
&amp;= \left(\overline{g}_k - \alpha\overline{H}_k\sum_{j=1}^{k-1}\overline{g}_j\right) \left(I-\alpha \sum_{j=1}^{k-1}\overline H_j\right) + O(\alpha^2)\\
&amp;= \overline{g}_k - \alpha\overline{g}_k\sum_{j=1}^{k-1}\overline H_j - \alpha\overline{H}_k\sum_{j=1}^{k-1}\overline{g}_j + O(\alpha^2)
\end{aligned}\]

<p>而对于 Reptile 的梯度，根据定义</p>

\[\begin{aligned}
g_{Reptile} &amp;= (\phi - \widetilde \phi)/\alpha\\
&amp;= [\phi - (\phi - \alpha g_1 - \alpha g_2 - \cdots - \alpha g_k)]/\alpha\\
&amp;= g_1 + g_2 + \cdots + g_k
\end{aligned}\]

<p>将 MAML、FOMAML 和 Reptile 三者的梯度同时列写如下</p>

\[\begin{aligned}
  g_{MAML} &amp;=\overline{g}_k - \alpha\overline{g}_k\sum_{j=1}^{k-1}\overline H_j - \alpha\overline{H}_k\sum_{j=1}^{k-1}\overline{g}_j + O(\alpha^2)\\
  g_{FOMAML} &amp;= \overline{g}_k - \alpha\overline{H}_k\sum_{j=1}^{k-1}\overline{g}_j + O(\alpha^2)\\
  g_{Reptile} &amp;= g_1 + g_2 + \cdots + g_k
\end{aligned}\]

<p>为了简化分析，令 $k=2$，有</p>

\[\begin{aligned}
  g_{MAML} &amp; &amp;=\overline{g}_2 - \alpha\overline{g}_2\overline H_1 - \alpha\overline{H}_2\overline{g}_1 + O(\alpha^2)\\
  g_{FOMAML} &amp;= g_2 &amp;=  \overline{g}_2 - \alpha\overline{H}_2\overline{g}_1 + O(\alpha^2)\\
  g_{Reptile} &amp;= g_1 + g_2 &amp;=\overline{g}_1 + \overline{g}_2 - \alpha\overline{H}_2 g_1 + O(\alpha^2)
\end{aligned}\]

<h2 id="14-另一种推导方式"><span class="me-2">1.4. 另一种推导方式</span><a href="#14-另一种推导方式" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>直接假设 $k=2$，以两步 SGD 为例分析参数更新过程。</p>

<p>简化起见，我们将损失函数对模型参数的梯度记为 $L’$，那么两步 SGD 更新后的模型参数为 $\phi_3$，有</p>

\[\begin{aligned}
\phi_1 &amp;= \phi\\
\phi_2 &amp;= \phi_1 - \alpha L_1'(\phi_1)\\
\phi_3 &amp;= \phi_2 - \alpha L_1'(\phi_1) - \alpha L_2'(\phi_2)
\end{aligned}\]

<p>下面定义几个<strong>辅助变量</strong>，其中 $i\in [1, k]$ 指代第 $i$ 个 minibatch，也即第 $i$ 次梯度下降的训练过程（？）</p>

\[\begin{aligned}
g_i &amp;= L_i'(\phi_i)
\;\;(gradient \; obtained\; during\;SGD)\\
\phi_{i+1} &amp;= \phi_i-\alpha g_i
\;\;(sequence\;of\;parameters)\\
\overline{g}_i &amp;= L_i'(\phi_1)
\;\;(gradient\;at\;initial\;point)\\
\overline{H}_i &amp;= L_i''(\phi_1)
\;\;(Hessian\;at\;initial\;point)\\
\end{aligned}\]

<p>首先，采用<strong>泰勒展开</strong>将 $g_i$ 展开至 “二阶导+高次项” 的形式</p>

\[\begin{aligned}
g_i &amp;= L_i'(\phi_i) = L_i'(\phi_1) + L_i''(\phi_1)(\phi_i - \phi_1) + O(||\phi_i - \phi_1||^2)\\
&amp;= \overline{g}_i + \overline{H}_i(\phi_i - \phi_1) + O(\alpha^2)\\
&amp;= \overline{g}_i - \alpha\overline{H}_i\sum_0^{i-1}g_i + O(\alpha^2)\\
&amp;= \overline{g}_i - \alpha\overline{H}_i\sum_0^{i-1}\overline{g}_i + O(\alpha^2)\\
\end{aligned}\]

<p>最后一步的依据是，$g_i = \overline{g}_i + O(\alpha)$ 带入倒数第二行时，后面的 $O(\alpha)$ 与求和符号前的 $\alpha$ 相乘，即变为 $O(\alpha^2)$ 从而合并为一项。</p>

<p>下面取  $k=2$ ，即两步SGD，分别推导 MAML、FOMAML、Reptile 的梯度。<a href="https://www.cnblogs.com/veagau/p/11816163.html#42-reptile实现">这个参考</a> [<a href="#ref3">3</a>] 考虑了 $k$ 为任意情况下的通解，在  $k=2$ 时的结果与本文相同。</p>

<p>对于二阶的MAML，初始参数 $\phi_1$ 首先在support set上梯度更新一次得到 $\phi_2$ ，然后将 $\phi_2$ 在 query set 上计算损失函数，再计算梯度更新模型的初始参数。即 query set 的 loss 要对 $\phi_2$ 求导，链式法则 loss 对  $\phi_2$ 求导乘以  $\phi_2$ 对 $\phi_1$ 求导</p>

\[\begin{aligned}
g_{MAML} &amp;= \frac{\partial}{\partial\phi_1}L_2(\phi_2) = \frac{\partial \phi_2}{\partial \phi_1} L_2'(\phi_2) \\
 &amp;= (I-\alpha L_1''(\phi_1))L_2'(\phi_2)\\
 &amp;= (I-\alpha L_1''(\phi_1))(L_2'(\phi_1) + L_2''(\phi_1)(\phi_2 - \phi_1) + O(\alpha^2))\\
 &amp;= (I-\alpha L_1''(\phi_1))(L_2'(\phi_1) + L_2''(\phi_1)(\phi_2 - \phi_1)) + O(\alpha^2)\\
 &amp;= (I-\alpha L_1''(\phi_1))(L_2'(\phi_1) - \alpha L_2''(\phi_1)L_1'(\phi_1)) + O(\alpha^2)\\
 &amp;= L_2'(\phi_1)-\alpha L_2''(\phi_1)L_1'(\phi_1) - \alpha L_1''(\phi_1)L_2'(\phi_1) + O(\alpha^2)\\
 \end{aligned}\]

<p>对于FOMAML，其一阶简化是简化了参数 $\phi_2$ 对初始参数 $\phi_1$ 求导部分，即 $\frac{\partial \phi_2}{\partial \phi_1} = const$，则只剩下 loss 对参数 $\phi_2$ 的求导。</p>

\[\begin{aligned}
g_{FOMAML} &amp;= L_2'(\phi_2) = L_2'(\phi_1) + L_2''(\phi_1)(\phi_2 - \phi_1) + O(\alpha^2)\\
&amp;= L_2'(\phi_1) -\alpha L_2''(\phi_1)L_1'(\phi_1) + O(\alpha^2)
\end{aligned}\]

<p>对于Reptile，根据梯度定义和SGD过程有</p>

\[\begin{aligned}
g_{Reptile} &amp;= (\phi_1 - \phi_3)/\alpha = L_1'(\phi_1)+L_2'(\phi_2)\\
&amp;= L_1'(\phi_1)+L_2'(\phi_1)+ L_2''(\phi_1)(\phi_2-\phi_1) + O(\alpha^2)\\
&amp;= L_1'(\phi_1)+L_2'(\phi_1)-\alpha L_2''(\phi_1)L_1'(\phi_1) + O(\alpha^2)
\end{aligned}\]

<p>接下来对上面的三个梯度进行变量替换，全部用之前定义的辅助变量来表示</p>

\[\begin{aligned}
g_{MAML} &amp; &amp;= \overline{g}_2 - \alpha \overline{H_2}\overline{g}_1-\alpha\overline{H_1}\overline{g}_2+O(\alpha^2)\\
g_{FOMAML} &amp;= g_2 &amp;= \overline{g}_2-\alpha\overline{H}_2\overline{g}_1+O(\alpha^2)\\
g_{Reptile} &amp;= g_1+g_2 &amp;= \overline{g}_1+\overline{g}_2-\alpha \overline{H}_2\overline{g}_1 + O(\alpha^2)\\
\end{aligned}\]

<p>可以得到与上一节一致的结果。</p>

<h2 id="15-梯度的泰勒展开的领头阶继续"><span class="me-2">1.5. 梯度的泰勒展开的领头阶（继续）</span><a href="#15-梯度的泰勒展开的领头阶继续" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>再次定义两个期望参数如下。</p>

<p><strong>第一个</strong>：AvgGrad 定义为loss对初始参数的梯度的平均期望</p>

\[AvgGrad = \mathbb E_{\tau,1}[\overline{g}_1] =\mathbb E_{\tau,2}[\overline{g}_2]\]

<p>（-AvgGrad）是参数 $\phi$ 在最小化 joint training 问题中的下降方向。就是想在所有batch上减小loss，也就是减小整体的任务损失。</p>

<blockquote>
  <p>为什么此处 $\overline{g}_1$ 和 $\overline{g}_2$ 的期望相等呢，因为它们都是表示的是loss对原始参数的梯度，只不过对应于不同的batch。在minibatch中，一个batch用于进行一次梯度下降，因为batch是随机的，所以loss对原始参数的梯度与batch是无关的。</p>
</blockquote>

<p><strong>第二个</strong>：AvgGradInner</p>

\[\begin{aligned}
AvgGradInner &amp;= \mathbb E_{\tau,1,2}[\overline{H}_1\overline{g}_2]\\
&amp;= \mathbb E_{\tau,1,2}[\overline{H}_2\overline{g}_1]\\
&amp;= \frac{1}{2}\mathbb E_{\tau,1,2}[\overline{H}_1\overline{g}_2+\overline{H}_2\overline{g}_1]\\
&amp;= \frac{1}{2}\mathbb E_{\tau,1,2}[\frac{\partial}{\partial \phi_1}(\overline{g}_1\cdot \overline{g}_2)]
\end{aligned}\]

<p>(-AvgGradInner) 的方向可以增大不同minibatch间梯度的内积，从而提高泛化能力。换句话说，AvgGradInner是 $\overline{g}_0\overline{g}_1$ 的对原始参数的导数，因为梯度在参数更新时是加负号的，<strong>所以是在最大化同一任务中不同minibatch之间梯度的内积</strong>。对其中一个batch进行梯度更新会显著改善另一个batch的的表现，这样就增加了模型的泛化性和快速学习的能力。</p>

<p>下面就可以对上述三个梯度进行进一步替换，$k=2$ 时</p>

\[\begin{aligned}
\mathbb{E}[g_{MAML}] &amp;= (1)AvgGrad - (2\alpha)AvgGradInner + O(\alpha^2)\\
\mathbb{E}[g_{FOMAML}] &amp;= (1)AvgGrad - (\alpha)AvgGradInner + O(\alpha^2)\\
\mathbb{E}[g_{Reptile}] &amp;= (2)AvgGrad - (\alpha)AvgGradInner + O(\alpha^2)\\
\end{aligned}\]

<p>扩展到 $k&gt;2$ 的情况有 [<a href="#ref3">3</a>]</p>

\[\begin{aligned}
\mathbb{E}[g_{MAML}] &amp;= (1)AvgGrad - (2(k-1)\alpha)AvgGradInner + O(\alpha^2)\\
\mathbb{E}[g_{FOMAML}] &amp;= (1)AvgGrad - ((k-1)\alpha)AvgGradInner + O(\alpha^2)\\
\mathbb{E}[g_{Reptile}] &amp;= (2)AvgGrad - (\frac{1}{2}k(k-1)\alpha)AvgGradInner + O(\alpha^2)\\
\end{aligned}\]

<p>可以看到三者AvgGradInner与AvgGrad之间的系数比的关系是：<strong>MAML &gt; FOMAML &gt; Retile</strong>。这个比例与步长 $\alpha$，迭代次数 $k$ 正相关。</p>

<p><strong>综上所述， MAML 和 Reptile 的优化目标相同，都是更好的任务表现（由 AvgGrad 主导）和更好的泛化能力（由 AvgGradInner 主导）。</strong></p>

<h2 id="16-另一种不严谨的分析"><span class="me-2">1.6. 另一种不严谨的分析</span><a href="#16-另一种不严谨的分析" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><del>另一种分析有效的方法借助了流形，Reptile 收敛于一个解，这个解在欧式空间上与每个任务的最优解的流形接近。没看懂不管了。作者自己也号称不如泰勒展开严谨。</del></p>

<blockquote>
  <p>This is a informal argument and should be taken much less seriously than the preceding Taylor series analysis</p>
</blockquote>

<h2 id="17-实验"><span class="me-2">1.7. 实验</span><a href="#17-实验" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><strong>少样本分类</strong></p>

<p><a href="/assets/img/postsimg/20200713/11.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20200713/11.jpg" alt="img" class="lazyload" data-proofer-ignore></a></p>

<p><a href="/assets/img/postsimg/20200713/12.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20200713/12.jpg" alt="img" class="lazyload" data-proofer-ignore></a></p>

<p>从两个表格中的数据可以看出，MAML与Reptile在加入了转导（Transduction）后，在Mini-ImageNet上进行实验，Reptile的表现要更好一些，而Omniglot数据集上正好相反。</p>

<p><strong>不同的内循环梯度组合比较</strong></p>

<p>通过在内循环中使用四个不重合的Mini-Batch，产生梯度数据 g1,g2,g3,g4 ，然后将它们以不同的方式进行线性组合（等价于执行多次梯度更新）用于外部循环的更新，进而比较它们之间的性能表现，实验结果如下图：</p>

<p><a href="/assets/img/postsimg/20200713/13.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20200713/13.jpg" alt="img" class="lazyload" data-proofer-ignore></a></p>

<p>从曲线可以看出：</p>

<ul>
  <li>仅使用一个批次的数据产生的梯度的效果并不显著，因为相当于让模型用见到过的少量的数据去优化所有任务。</li>
  <li>进行了两步更新的Reptile（绿线）的效果要明显不如进行了两步更新的FOMAML（红线），因为Reptile在AvgGradInner上的<strong>权重</strong>（AvgGradInner与AvgGrad的系数的比例）要小于FOMAML。</li>
  <li>随着mini-batch数量的增多，所有算法的性能也在提升。通过同时利用多步的梯度更新，Reptile的表现要比仅使用最后一步梯度更新的FOMAML的表现好。</li>
</ul>

<p><strong>内循环中Mini-Batch 重合比较</strong></p>

<p>Reptile和FOMAML在内循环过程中都是使用的SGD进行的优化，在这个优化过程中任何微小的变化都将导致最终模型性能的巨大变化，因此这部分的实验主要是探究两者对于内循环中的超数的敏感性，同时也验证了FOMAML在minibatch以错误的方式选取时会出现显著的性能下降情况。</p>

<p>mini-batch的选择有两种方式：</p>

<ul>
  <li><strong>shared-tail（共尾）</strong>：最后一个内循环的数据来自以前内循环批次的数据</li>
  <li><strong>separate-tail（分尾）</strong>：最后一个内循环的数据与以前内循环批次的数据不同</li>
</ul>

<p><a href="/assets/img/postsimg/20200713/14.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20200713/14.jpg" alt="img" class="lazyload" data-proofer-ignore></a></p>

<p>采用不同的mini-batch选取方式在FOMAML上进行实验，发现随着内循环迭代次数的增多，采用分尾方式的FOMAML模型的测试准确率要高一些，因为在这种情况下，测试的数据选取方式与训练过程中的数据选取方式更为接近。</p>

<p>当采用不同的批次大小时，采用共尾方式选取数据的FOMAML的准确性会随着批次大小的增加而显著减小。当采用<strong>full-batch</strong>时，共尾FOMAML的表现会随着外循环步长的加大而变差。</p>

<p><strong>共尾FOMAML的表现如此敏感的原因可能是最初的几次SGD更新让模型达到了局部最优，以后的梯度更新就会使参数在这个局部最优附近波动。</strong></p>

<h1 id="2-比较">2. 比较</h1>

<p>再次比较Model Pre-training、MAML 和 Reptile方法。</p>

<p><a href="/assets/img/postsimg/20200713/4.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20200713/4.jpg" alt="alt text" class="lazyload" data-proofer-ignore></a></p>

<p>（左：MAML。右：Model Pre-training）</p>

<p><a href="/assets/img/postsimg/20200713/9.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20200713/9.jpg" alt="alt text" class="lazyload" data-proofer-ignore></a></p>

<p>（Reptile）</p>

<p>Pre-training采用task的loss对参数的梯度更新模型的原始参数。</p>

<p>MAML采用task的第二次梯度计算更新模型的原始参数。</p>

<p>Reptile采用多次梯度计算更新模型的原始参数。</p>

<p><a href="/assets/img/postsimg/20200713/10.jpg" class="popup img-link "><img data-src="/assets/img/postsimg/20200713/10.jpg" alt="10" class="lazyload" data-proofer-ignore></a></p>

<p>上面这个图不具体，但是很直观的展示了这些算法的区别。$g_i$ 表示第 $i$ 次负梯度计算。这里的MAML是一阶的，沿着 $g_2$ 方向更新，Reptile 沿着 $g_1+g_2$  的方向更新，而我们常规的预训练模型就是沿着 $g_1$ 方向更新。</p>

<h1 id="3-算法实现">3. 算法实现</h1>

<p><a href="https://github.com/dragen1860/Reptile-Pytorch">First-order近似实现Reptile</a>：https://github.com/dragen1860/Reptile-Pytorch</p>

<h1 id="4-reptile回归sin函数">4. reptile回归sin函数</h1>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">autograd</span> <span class="k">as</span> <span class="n">ag</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">plot</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">innerstepsize</span> <span class="o">=</span> <span class="mf">0.02</span> <span class="c1"># stepsize in inner SGD
</span><span class="n">innerepochs</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># number of epochs of each inner SGD
</span><span class="n">outerstepsize0</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="c1"># stepsize of outer optimization, i.e., meta-optimization
</span><span class="n">niterations</span> <span class="o">=</span> <span class="mi">30000</span> <span class="c1"># number of outer updates; each iteration we sample one task and update on it
</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nc">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># Define task distribution
</span><span class="n">x_all</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">)[:,</span><span class="bp">None</span><span class="p">]</span> <span class="c1"># generate 50 x points within [-5,5]
</span><span class="n">ntrain</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># Size of training minibatches
</span><span class="k">def</span> <span class="nf">gen_task</span><span class="p">():</span>
    <span class="sh">"</span><span class="s">Generate regression problem</span><span class="sh">"</span>
    <span class="n">phase</span> <span class="o">=</span> <span class="n">rng</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span>
    <span class="n">ampl</span> <span class="o">=</span> <span class="n">rng</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">f_randomsine</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">phase</span><span class="p">)</span> <span class="o">*</span> <span class="n">ampl</span>
    <span class="k">return</span> <span class="n">f_randomsine</span>

<span class="c1"># Define model. Reptile paper uses ReLU, but Tanh gives slightly better results
</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">totorch</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ag</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nf">totorch</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="nf">totorch</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">ypred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">ypred</span> <span class="o">-</span> <span class="n">y</span><span class="p">).</span><span class="nf">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="p">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">innerstepsize</span> <span class="o">*</span> <span class="n">param</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">data</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nf">totorch</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="n">data</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()</span>

<span class="c1"># Choose a fixed task and minibatch for visualization
</span><span class="n">f_plot</span> <span class="o">=</span> <span class="nf">gen_task</span><span class="p">()</span>
<span class="n">xtrain_plot</span> <span class="o">=</span> <span class="n">x_all</span><span class="p">[</span><span class="n">rng</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x_all</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">ntrain</span><span class="p">)]</span>

<span class="c1"># Reptile training loop
</span><span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">niterations</span><span class="p">):</span> <span class="c1"># iterate 30000 times
</span>    <span class="n">weights_before</span> <span class="o">=</span> <span class="nf">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">())</span>
    <span class="c1"># Generate task
</span>    <span class="n">f</span> <span class="o">=</span> <span class="nf">gen_task</span><span class="p">()</span>
    <span class="n">y_all</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">x_all</span><span class="p">)</span>
    <span class="c1"># Do SGD on this task
</span>    <span class="n">inds</span> <span class="o">=</span> <span class="n">rng</span><span class="p">.</span><span class="nf">permutation</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x_all</span><span class="p">))</span> <span class="c1"># get random index of 0-50
</span>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">innerepochs</span><span class="p">):</span> <span class="c1"># SGD 1 times
</span>        <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">x_all</span><span class="p">),</span> <span class="n">ntrain</span><span class="p">):</span> <span class="c1"># from 0-50, select a num every 'ntrain' interval
</span>            <span class="n">mbinds</span> <span class="o">=</span> <span class="n">inds</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">start</span><span class="o">+</span><span class="n">ntrain</span><span class="p">]</span> <span class="c1"># get randomly index from 'start' to 'ntrain'
</span>            <span class="nf">train_on_batch</span><span class="p">(</span><span class="n">x_all</span><span class="p">[</span><span class="n">mbinds</span><span class="p">],</span> <span class="n">y_all</span><span class="p">[</span><span class="n">mbinds</span><span class="p">])</span>
    <span class="c1"># Interpolate between current weights and trained weights from this task
</span>    <span class="c1"># I.e. (weights_before - weights_after) is the meta-gradient
</span>    <span class="n">weights_after</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">()</span>
    <span class="n">outerstepsize</span> <span class="o">=</span> <span class="n">outerstepsize0</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">iteration</span> <span class="o">/</span> <span class="n">niterations</span><span class="p">)</span> <span class="c1"># linear schedule
</span>    <span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">({</span><span class="n">name</span> <span class="p">:</span>
        <span class="n">weights_before</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">weights_after</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">-</span> <span class="n">weights_before</span><span class="p">[</span><span class="n">name</span><span class="p">])</span> <span class="o">*</span> <span class="n">outerstepsize</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">weights_before</span><span class="p">})</span>

    <span class="c1"># Periodically plot the results on a particular task and minibatch
</span>    <span class="k">if</span> <span class="n">plot</span> <span class="ow">and</span> <span class="n">iteration</span><span class="o">==</span><span class="mi">0</span> <span class="ow">or</span> <span class="p">(</span><span class="n">iteration</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">cla</span><span class="p">()</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">f_plot</span>
        <span class="n">weights_before</span> <span class="o">=</span> <span class="nf">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">())</span> <span class="c1"># save snapshot before evaluation
</span>        <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_all</span><span class="p">,</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x_all</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">pred after 0</span><span class="sh">"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">inneriter</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">32</span><span class="p">):</span>
            <span class="nf">train_on_batch</span><span class="p">(</span><span class="n">xtrain_plot</span><span class="p">,</span> <span class="nf">f</span><span class="p">(</span><span class="n">xtrain_plot</span><span class="p">))</span>
            <span class="nf">if </span><span class="p">(</span><span class="n">inneriter</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">8</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">frac</span> <span class="o">=</span> <span class="p">(</span><span class="n">inneriter</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">32</span>
                <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_all</span><span class="p">,</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x_all</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">pred after %i</span><span class="sh">"</span><span class="o">%</span><span class="p">(</span><span class="n">inneriter</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="n">frac</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">frac</span><span class="p">))</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_all</span><span class="p">,</span> <span class="nf">f</span><span class="p">(</span><span class="n">x_all</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">true</span><span class="sh">"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">lossval</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="nf">predict</span><span class="p">(</span><span class="n">x_all</span><span class="p">)</span> <span class="o">-</span> <span class="nf">f</span><span class="p">(</span><span class="n">x_all</span><span class="p">)).</span><span class="nf">mean</span><span class="p">()</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">xtrain_plot</span><span class="p">,</span> <span class="nf">f</span><span class="p">(</span><span class="n">xtrain_plot</span><span class="p">),</span> <span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">k</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="sh">"</span><span class="s">lower right</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">pause</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
        <span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">weights_before</span><span class="p">)</span> <span class="c1"># restore from snapshot
</span>        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">-----------------------------</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">iteration               </span><span class="si">{</span><span class="n">iteration</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">loss on plotted curve   </span><span class="si">{</span><span class="n">lossval</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># optimized in one example for brevity
</span></pre></td></tr></tbody></table></code></div></div>

<ul>
  <li>用 $sin$ 函数来测试Reptile算法。
    <ul>
      <li>在 $[-5,5]$ 区间内随机取50个$x$点</li>
      <li>在 $[0,2\pi]$ 区间内随机取相位$P$</li>
      <li>在 $[0.1,5]$ 区间内随机取幅值$A$</li>
    </ul>
  </li>
  <li>
    <p>那么就可以随机生成任意相位幅值的50个点的sin函数：$Asin(x+P)$</p>
  </li>
  <li>设置minibatch的个数为ntrain=10，也就是一次训练10个点</li>
  <li>
    <p>先随机产生一个 $sin$ 函数，并在其上随机取10个点，作为测试集</p>
  </li>
  <li>进行外环迭代 niterations=30000次
    <ul>
      <li>随机产生一个 $sin$ 函数</li>
      <li>进行内环迭代innerepochs=1次
        <ul>
          <li>随机取50个点（$x$）中的10个点（ntrain）</li>
          <li>训练一次（SGD）</li>
          <li>取5次直到取完所有50个点</li>
          <li>[完成内环迭代]</li>
        </ul>
      </li>
      <li>更新外层学习率 outerstepsize = outerstepsize0 * (1 - iteration / niterations)</li>
      <li>更新模型参数 weights_before+ (weights_after - weights_before) * outerstepsize</li>
    </ul>
  </li>
  <li>若外环迭代达到1000次的整数倍，那么将训练的模型在测试集上测试</li>
  <li>测试迭代inneriter=32次
    <ul>
      <li>在测试集上训练一次（10个离散点）</li>
      <li>每过8次画一次图上的曲线（50个离散点）</li>
    </ul>
  </li>
  <li>MSE衡量测试结果</li>
  <li>[完成外环迭代]</li>
</ul>

<h1 id="5-参考文献">5. 参考文献</h1>

<p><span id="ref1">[1]</span>  <a href="https://www.zhihu.com/people/rustinnnnn">Rust-in</a>. <a href="https://zhuanlan.zhihu.com/p/66926599">MAML 论文及代码阅读笔记</a>.</p>

<p><span id="ref2">[2]</span> 人工智障. <a href="https://www.zhihu.com/question/266497742/answer/550695031">MAML算法，model-agnostic metalearnings?</a></p>

<p><span id="ref3">[3]</span> <a href="https://www.cnblogs.com/veagau/">Veagau</a>. <a href="https://www.cnblogs.com/veagau/p/11816163.html">【笔记】Reptile-一阶元学习算法</a></p>

<p>[4] <a href="https://blog.csdn.net/qq_41694504">pure water</a>. <a href="https://blog.csdn.net/qq_41694504/article/details/106750606">Reptile原理以及代码详解</a></p>

</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
  <div class="post-meta mb-3">
    <i class="far fa-folder-open fa-fw me-1"></i>
    
      <a href='/categories/academic/'>Academic</a>,
      <a href='/categories/paper/'>Paper</a>
  </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw me-1"></i>
      
      <a href="/tags/deep-learning/"
          class="post-tag no-text-decoration" >deep learning</a>
      
      <a href="/tags/meta-learning/"
          class="post-tag no-text-decoration" >meta learning</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        本文由作者按照 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         进行授权

      
    </div>

    <!-- Post sharing snippet -->

<div class="share-wrapper">
  <span class="share-label text-muted me-1">分享</span>
  <span class="share-icons">
    
    
    

    
      
      <a
        href="https://twitter.com/intent/tweet?text=%E5%85%83%E5%AD%A6%E4%B9%A0%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88Reptile%EF%BC%89%20-%20SIRLIS&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fmeta-learning-Reptile%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Twitter"
        target="_blank"
        rel="noopener"
        aria-label="Twitter"
      >
        <i class="fa-fw fab fa-twitter"></i>
      </a>
    
      
      <a
        href="https://www.facebook.com/sharer/sharer.php?title=%E5%85%83%E5%AD%A6%E4%B9%A0%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88Reptile%EF%BC%89%20-%20SIRLIS&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fmeta-learning-Reptile%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Facebook"
        target="_blank"
        rel="noopener"
        aria-label="Facebook"
      >
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    
      
      <a
        href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fmeta-learning-Reptile%2F&text=%E5%85%83%E5%AD%A6%E4%B9%A0%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88Reptile%EF%BC%89%20-%20SIRLIS"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Telegram"
        target="_blank"
        rel="noopener"
        aria-label="Telegram"
      >
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <i
      id="copy-link"
      class="fa-fw fas fa-link small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="分享链接"
      data-title-succeed="链接已复制！"
    >
    </i>
  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
      
    </div>
  </div>
  <!-- #core-wrapper -->

  <!-- panel -->
  <div id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
    <div class="access">
      <!-- Get the last 5 posts from lastmod list. -->














  <div id="access-lastmod" class="post">
    <div class="panel-heading">最近更新</div>
    <ul class="post-content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Pattern-Recognition-Bayes/">模式识别（贝叶斯决策）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Pattern-Recognition-LInear-Classifier/">模式识别（线性分类器）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-Policy-Gradient/">强化学习（策略梯度法）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-markov-process/">强化学习（马尔可夫决策过程）</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/reinforcement-learning-Dynamic-Programming/">强化学习（动态规划）</a>
        </li>
      
    </ul>
  </div>
  <!-- #access-lastmod -->


      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">热门标签</div>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/fuzzy/">fuzzy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/vscode/">vscode</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/other/">other</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/astronomy/">astronomy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c-c/">c/c++</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/computer-vision/">computer vision</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/meta-learning/">meta learning</a>
      
    </div>
  </div>


    </div>

    
      
      



  <div id="toc-wrapper" class="ps-0 pe-4 mb-5">
    <div class="panel-heading ps-3 pt-2 mb-2">文章内容</div>
    <nav id="toc"></nav>
  </div>


    
  </div>
</div>

<!-- tail -->

  <div class="row">
    <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-3 pe-xl-4 mt-5">
      
        
        <!--
  Recommend the other 3 posts according to the tags and categories of the current post,
  if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->








  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  






<!-- Fill with the other newlest posts -->





  <div id="related-posts" class="mb-2 mb-sm-4">
    <h3 class="pt-2 mb-4 ms-1" data-toc-skip>
      相关文章
    </h3>
    <div class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        
        
        <div class="col">
          <a href="/posts/meta-learning-MAML/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1594622119"
  data-df="YYYY/MM/DD"
  
>
  2020/07/13
</em>

              <h4 class="pt-0 my-2" data-toc-skip>元学习文章阅读（MAML）</h4>
              <div class="text-muted small">
                <p>
                  





                  MAML 是2017年 Chelsea Finn 大佬提出的一种基于优化（Optimized-based）的小样本学习方法，核心在两个不同的数据集中分别计算梯度和更新参数。






  1. MAML
    
      1.1. 算法
      1.2. 梯度下降数学分析
      1.3. 基于优化的元学习目标
      1.4. MAML数学分析
      1.5. FO...
                </p>
              </div>
            </div>
          </a>
        </div>
      
        
        
        <div class="col">
          <a href="/posts/MetaLearning-ProtoNet/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1595399719"
  data-df="YYYY/MM/DD"
  
>
  2020/07/22
</em>

              <h4 class="pt-0 my-2" data-toc-skip>元学习文章阅读（Prototypical Network）</h4>
              <div class="text-muted small">
                <p>
                  





                  Prototypical Network 又称为原型网络，是2017年 NIPS 会议论文提出的一种神经网络训练方法，是一种基于度量（Metrix-based）的小样本学习方法，通过计算 support set 中的嵌入中心，然后通过衡量新样本与这些中心的距离来完成分类。






  1. Prototypical Network
    
      1.1. 模型
      1.2...
                </p>
              </div>
            </div>
          </a>
        </div>
      
        
        
        <div class="col">
          <a href="/posts/meta-learning-basic/" class="card post-preview h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em
  class="small"
  data-ts="1594535719"
  data-df="YYYY/MM/DD"
  
>
  2020/07/12
</em>

              <h4 class="pt-0 my-2" data-toc-skip>元学习基础</h4>
              <div class="text-muted small">
                <p>
                  





                  小样本学习（Few-Shot Learning）问题是一个新兴的机器学习问题，旨在研究当样本个数严重不足时，如何训练一个模型，能够快速的完成学习（分类、回归、强化学习等）任务。进一步引入元学习的思想来解决小样本学习问题。






  1. 小样本学习问题
  2. 元学习方法
  3. 训练过程
    
      3.1. 深度学习的训练过程
      3.2. 元学习的训练过程
...
                </p>
              </div>
            </div>
          </a>
        </div>
      
    </div>
    <!-- .card-deck -->
  </div>
  <!-- #related-posts -->


      
        
        <!-- Navigation buttons at the bottom of the post. -->

<div class="post-navigation d-flex justify-content-between">
  
    <a
      href="/posts/Latex-TexStudio/"
      class="btn btn-outline-primary"
      prompt="上一篇"
    >
      <p>LaTeX+TexStudio环境配置</p>
    </a>
  

  
    <a
      href="/posts/MetaLearning-ProtoNet/"
      class="btn btn-outline-primary"
      prompt="下一篇"
    >
      <p>元学习文章阅读（Prototypical Network）</p>
    </a>
  
</div>

      
        
        <!--  The comments switcher -->

  
  <!-- https://utteranc.es/ -->
<script src="https://utteranc.es/client.js"
        repo="sirlis/sirlis.github.io"
        issue-term="pathname"
        crossorigin="anonymous"
        async>
</script>

<script type="text/javascript">
  $(function() {
    const origin = "https://utteranc.es";
    const iframe = "iframe.utterances-frame";
    const lightTheme = "github-light";
    const darkTheme = "github-dark";
    let initTheme = lightTheme;

    if ($("html[data-mode=dark]").length > 0
        || ($("html[data-mode]").length == 0
            && window.matchMedia("(prefers-color-scheme: dark)").matches)) {
      initTheme = darkTheme;
    }

    addEventListener("message", (event) => {
      let theme;

      /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */
      if (event.origin === origin) {
        /* page initial */
        theme = initTheme;

      } else if (event.source === window && event.data &&
            event.data.direction === ModeToggle.ID) {
        /* global theme mode changed */
        const mode = event.data.message;
        theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme);

      } else {
        return;
      }

      const message = {
        type: "set-theme",
        theme: theme
      };

      const utterances = document.querySelector(iframe).contentWindow;
      utterances.postMessage(message, origin);
    });

  });
</script>



      
    </div>
  </div>


        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-11 post-content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">热门标签</div>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/fuzzy/">fuzzy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/vscode/">vscode</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/other/">other</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/reinforcement-learning/">reinforcement learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/astronomy/">astronomy</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/c-c/">c/c++</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/computer-vision/">computer vision</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/meta-learning/">meta learning</a>
      
    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>
    </div>

    <!-- The Footer -->

<footer>
  <div class="container px-lg-4">
    <div class="d-flex justify-content-center align-items-center text-muted mx-md-3">
      <p>本站采用 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 主题 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>
      </p>

      <p>©
        2024
        <a href="https://github.com/sirlis">sirlis</a>.
        
          <span
            data-bs-toggle="tooltip"
            data-bs-placement="top"
            title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。"
          >保留部分权利。</span>
        
      </p>
    </div>
  </div>
</footer>


    <div id="mask"></div>

    <button id="back-to-top" aria-label="back-to-top" class="btn btn-lg btn-box-shadow">
      <i class="fas fa-angle-up"></i>
    </button>

    
      <div
        id="notification"
        class="toast"
        role="alert"
        aria-live="assertive"
        aria-atomic="true"
        data-bs-animation="true"
        data-bs-autohide="false"
      >
        <div class="toast-header">
          <button
            type="button"
            class="btn-close ms-auto"
            data-bs-dismiss="toast"
            aria-label="Close"
          ></button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="px-2 mb-3">发现新版本的内容。</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            更新
          </button>
        </div>
      </div>
    

    <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.0/dist/jquery.min.js,npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.7/dayjs.min.js,npm/dayjs@1.11.7/locale/zh.min.js,npm/dayjs@1.11.7/plugin/relativeTime.min.js,npm/dayjs@1.11.7/plugin/localizedFormat.min.js,npm/tocbot@4.21.0/dist/tocbot.min.js"></script>






<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
    /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
    MathJax = {
      tex: {
        /* start/end delimiter pairs for in-line math */
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ],
        /* start/end delimiter pairs for display math */
        displayMath: [
          ['$$', '$$'],
          ['\\[', '\\]']
        ]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>





    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  /* Note: dependent library will be loaded in `js-selector.html` */
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('search-results'),
    json: '/assets/js/data/search.json',
    searchResultTemplate: '<div class="px-1 px-sm-2 px-lg-4 px-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
    noResultsText: '<p class="mt-5"></p>',
    templateMiddleware: function(prop, value, template) {
      if (prop === 'categories') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
        }
      }

      if (prop === 'tags') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
        }
      }
    }
  });
</script>

  </body>
</html>

